,Unnamed: 0,smpnum,reqnum,errors,status,model,num_users,requests,latency_ms,records,n_gpus,gpu_type,start_timestamp,end_timestamp,experiment_duration_s,n_input_tokens,n_output_tokens,latency_ms_per_token,timestamps_per_token
0,0,69,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049234,120,,,"[56, 703, 54]","[1697552047652, 1697552048355, 1697552048409]"
1,1,262,0,[],200,llama-13b,64,1,1441.0,1.0,1,A100,1697552047599,1697552049040,120,39.0,1.0,"[158, 1282]","[1697552047757, 1697552049039]"
2,2,879,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049235,120,,,"[77, 1366]","[1697552047673, 1697552049039]"
3,3,778,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047639,1697552049235,120,,,[205],[1697552047844]
4,4,536,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047594,1697552049234,120,,,"[154, 1291]","[1697552047748, 1697552049039]"
5,5,427,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049235,120,,,"[76, 1367]","[1697552047672, 1697552049039]"
6,6,836,0,[],200,llama-13b,64,1,1443.0,1.0,1,A100,1697552047596,1697552049039,120,11.0,1.0,"[72, 1371]","[1697552047668, 1697552049039]"
7,7,613,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049233,120,,,"[86, 1356]","[1697552047682, 1697552049038]"
8,8,11,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047599,1697552049234,120,,,"[163, 1277]","[1697552047762, 1697552049039]"
9,9,202,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047639,1697552050145,120,,,[215],[1697552047854]
10,10,444,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049235,120,,,"[71, 1371]","[1697552047667, 1697552049038]"
11,11,858,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047639,1697552050147,120,,,[142],[1697552047781]
12,12,673,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049234,120,,,"[66, 747]","[1697552047662, 1697552048409]"
13,13,641,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047600,1697552049235,120,,,[167],[1697552047767]
14,14,591,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047639,1697552050145,120,,,[200],[1697552047839]
15,15,202,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047639,1697552050147,120,,,[137],[1697552047776]
16,16,507,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047594,1697552049233,120,,,"[89, 1356]","[1697552047683, 1697552049039]"
17,17,533,0,[],200,llama-13b,64,1,813.0,1.0,1,A100,1697552047596,1697552048409,120,216.0,2.0,"[22, 791]","[1697552047618, 1697552048409]"
18,18,907,1,[],200,llama-13b,64,1,1736.0,1.0,1,A100,1697552050150,1697552051886,120,10.0,1.0,"[36, 1699]","[1697552050186, 1697552051885]"
19,19,13,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047594,1697552049233,120,,,"[19, 51, 745]","[1697552047613, 1697552047664, 1697552048409]"
20,20,561,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051887,1697552053354,120,,,"[7, 1397]","[1697552051894, 1697552053291]"
21,21,161,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049238,1697552051366,120,,,[26],[1697552049264]
22,22,332,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053361,1697552055781,120,,,[126],[1697552053487]
23,23,837,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051370,1697552052660,120,,,[36],[1697552051406]
24,24,80,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055788,1697552057503,120,,,[157],[1697552055945]
25,25,493,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552052664,1697552054788,120,,,"[51, 1271]","[1697552052715, 1697552053986]"
26,26,165,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552048413,1697552050146,120,,,[12],[1697552048425]
27,27,698,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049233,120,,,"[31, 727, 55]","[1697552047627, 1697552048354, 1697552048409]"
28,28,626,1,[],200,llama-13b,64,1,1735.0,1.0,1,A100,1697552050151,1697552051886,120,10.0,1.0,"[94, 1641]","[1697552050245, 1697552051886]"
29,29,718,0,[],200,llama-13b,64,1,1441.0,1.0,1,A100,1697552047599,1697552049040,120,13.0,1.0,"[163, 1278]","[1697552047762, 1697552049040]"
30,30,208,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049233,120,,,"[32, 726, 54]","[1697552047628, 1697552048354, 1697552048408]"
31,31,410,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049239,1697552051366,120,,,[114],[1697552049353]
32,32,231,0,[],200,llama-13b,64,1,1401.0,1.0,1,A100,1697552047639,1697552049040,120,13.0,1.0,"[147, 1254]","[1697552047786, 1697552049040]"
33,33,286,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051889,1697552053352,120,,,[19],[1697552051908]
34,34,788,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049239,1697552051368,120,,,[50],[1697552049289]
35,35,424,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047639,1697552050145,120,,,[210],[1697552047849]
36,36,752,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049234,120,,,"[61, 698, 54]","[1697552047657, 1697552048355, 1697552048409]"
37,37,590,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049235,120,,,"[67, 692, 54]","[1697552047663, 1697552048355, 1697552048409]"
38,38,39,0,[],200,llama-13b,64,1,1445.0,1.0,1,A100,1697552047594,1697552049039,120,8.0,1.0,"[159, 1286]","[1697552047753, 1697552049039]"
39,39,466,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049043,1697552050146,120,,,[37],[1697552049080]
40,40,99,0,[],200,llama-13b,64,1,1445.0,1.0,1,A100,1697552047594,1697552049039,120,10.0,1.0,"[98, 1347]","[1697552047692, 1697552049039]"
41,41,822,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049043,1697552050146,120,,,[32],[1697552049075]
42,42,233,2,[],200,llama-13b,64,1,1736.0,1.0,1,A100,1697552050150,1697552051886,120,6.0,1.0,"[86, 1650]","[1697552050236, 1697552051886]"
43,43,823,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051888,1697552053352,120,,,"[21, 1382]","[1697552051909, 1697552053291]"
44,44,744,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049042,1697552050146,120,,,[23],[1697552049065]
45,45,593,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053357,1697552054789,120,,,"[23, 1231]","[1697552053380, 1697552054611]"
46,46,679,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049044,1697552050146,120,,,[41],[1697552049085]
47,47,371,0,[],200,llama-13b,64,1,1401.0,1.0,1,A100,1697552047639,1697552049040,120,13.0,1.0,"[215, 1185]","[1697552047854, 1697552049039]"
48,48,921,0,[],200,llama-13b,64,1,1438.0,1.0,1,A100,1697552047602,1697552049040,120,31.0,1.0,"[165, 1273]","[1697552047767, 1697552049040]"
49,49,248,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054796,1697552056509,120,,,[49],[1697552054845]
50,50,693,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049233,120,,,"[97, 1346]","[1697552047693, 1697552049039]"
51,51,575,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049042,1697552050146,120,,,[19],[1697552049061]
52,52,841,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049043,1697552050146,120,,,[28],[1697552049071]
53,53,343,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047602,1697552049234,120,,,"[169, 1269]","[1697552047771, 1697552049040]"
54,54,533,0,[],200,llama-13b,64,1,813.0,1.0,1,A100,1697552047596,1697552048409,120,216.0,2.0,"[47, 766]","[1697552047643, 1697552048409]"
55,55,396,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552050149,1697552053353,120,,,"[30, 1707, 809]","[1697552050179, 1697552051886, 1697552052695]"
56,56,618,2,[],200,llama-13b,64,1,1733.0,1.0,1,A100,1697552050153,1697552051886,120,9.0,1.0,"[97, 1636]","[1697552050250, 1697552051886]"
57,57,144,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053358,1697552054789,120,,,"[20, 1233]","[1697552053378, 1697552054611]"
58,58,462,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049238,1697552051365,120,,,[16],[1697552049254]
59,59,672,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049235,120,,,[82],[1697552047678]
60,60,550,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049239,1697552051367,120,,,[40],[1697552049279]
61,61,928,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049238,1697552051367,120,,,[37],[1697552049275]
62,62,25,6,[],200,llama-13b,64,1,1672.0,1.0,1,A100,1697552056514,1697552058186,120,12.0,1.0,"[46, 1626]","[1697552056560, 1697552058186]"
63,63,325,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049239,1697552051366,120,,,[100],[1697552049339]
64,64,273,3,[],200,llama-13b,64,1,1403.0,1.0,1,A100,1697552051888,1697552053291,120,19.0,1.0,"[11, 1392]","[1697552051899, 1697552053291]"
65,65,697,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051373,1697552052660,120,,,[43],[1697552051416]
66,66,778,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049233,120,,,"[42, 771]","[1697552047638, 1697552048409]"
67,67,611,7,[],200,llama-13b,64,1,1709.0,1.0,1,A100,1697552058189,1697552059898,120,14.0,1.0,"[30, 1679]","[1697552058219, 1697552059898]"
68,68,329,3,[],200,llama-13b,64,1,1323.0,1.0,1,A100,1697552052663,1697552053986,120,15.0,1.0,"[37, 1286]","[1697552052700, 1697552053986]"
69,69,563,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049233,120,,,"[51, 708, 54]","[1697552047647, 1697552048355, 1697552048409]"
70,70,427,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049233,120,,,"[37, 721, 55]","[1697552047633, 1697552048354, 1697552048409]"
71,71,99,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053992,1697552055781,120,,,[39],[1697552054031]
72,72,553,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047599,1697552049234,120,,,"[158, 1282]","[1697552047757, 1697552049039]"
73,73,490,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049042,1697552050146,120,,,[18],[1697552049060]
74,74,81,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049238,1697552051366,120,,,[7],[1697552049245]
75,75,430,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049238,1697552051366,120,,,[31],[1697552049269]
76,76,781,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051374,1697552052661,120,,,[93],[1697552051467]
77,77,386,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059901,1697552062307,120,,,"[21, 1785]","[1697552059922, 1697552061707]"
78,78,435,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552052666,1697552054789,120,,,"[89, 1231]","[1697552052755, 1697552053986]"
79,79,207,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051370,1697552052660,120,,,[26],[1697552051396]
80,80,394,0,[],200,llama-13b,64,1,1400.0,1.0,1,A100,1697552047639,1697552049039,120,11.0,1.0,"[205, 1195]","[1697552047844, 1697552049039]"
81,81,55,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049043,1697552050146,120,,,[42],[1697552049085]
82,82,39,9,[],200,llama-13b,64,1,1344.0,1.0,1,A100,1697552062311,1697552063655,120,8.0,1.0,"[21, 1323]","[1697552062332, 1697552063655]"
83,83,717,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063657,1697552064541,120,,,[11],[1697552063668]
84,84,267,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552050152,1697552053353,120,,,"[98, 1636, 809]","[1697552050250, 1697552051886, 1697552052695]"
85,85,757,2,[],200,llama-13b,64,1,1737.0,1.0,1,A100,1697552050149,1697552051886,120,20.0,1.0,"[32, 1705]","[1697552050181, 1697552051886]"
86,86,372,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064544,1697552066163,120,,,"[29, 979]","[1697552064573, 1697552065552]"
87,87,39,0,[],200,llama-13b,64,1,759.0,1.0,1,A100,1697552047596,1697552048355,120,8.0,1.0,"[21, 738]","[1697552047617, 1697552048355]"
88,88,738,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552048359,1697552050146,120,,,[9],[1697552048368]
89,89,908,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552050149,1697552053353,120,,,"[15, 1721, 810]","[1697552050164, 1697552051885, 1697552052695]"
90,90,400,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552050150,1697552053352,120,,,"[34, 1702, 809]","[1697552050184, 1697552051886, 1697552052695]"
91,91,141,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066166,1697552067382,120,,,"[96, 1100]","[1697552066262, 1697552067362]"
92,92,851,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053360,1697552055780,120,,,[112],[1697552053472]
93,93,861,0,[],200,llama-13b,64,1,1401.0,1.0,1,A100,1697552047639,1697552049040,120,10.0,1.0,"[200, 1201]","[1697552047839, 1697552049040]"
94,94,562,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053358,1697552054789,120,,,"[85, 1168]","[1697552053443, 1697552054611]"
95,95,805,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047598,1697552049234,120,,,"[149, 1292]","[1697552047747, 1697552049039]"
96,96,371,0,[],200,llama-13b,64,1,1438.0,1.0,1,A100,1697552047602,1697552049040,120,13.0,1.0,"[170, 1268]","[1697552047772, 1697552049040]"
97,97,731,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067387,1697552068961,120,,,"[150, 1083, 151, 141]","[1697552067537, 1697552068620, 1697552068771, 1697552068912]"
98,98,609,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049043,1697552050145,120,,,[32],[1697552049075]
99,99,417,3,[],200,llama-13b,64,1,1402.0,1.0,1,A100,1697552051889,1697552053291,120,17.0,1.0,"[30, 1372]","[1697552051919, 1697552053291]"
100,100,186,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053294,1697552054789,120,,,"[9, 683]","[1697552053303, 1697552053986]"
101,101,621,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055785,1697552057501,120,,,[26],[1697552055811]
102,102,309,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054794,1697552056509,120,,,[17],[1697552054811]
103,103,775,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054793,1697552056509,120,,,[13],[1697552054806]
104,104,753,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049234,120,,,"[57, 702, 54]","[1697552047653, 1697552048355, 1697552048409]"
105,105,575,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049243,1697552051366,120,,,[115],[1697552049358]
106,106,547,6,[],200,llama-13b,64,1,1669.0,1.0,1,A100,1697552056516,1697552058185,120,12.0,1.0,"[64, 1605]","[1697552056580, 1697552058185]"
107,107,234,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051374,1697552053354,120,,,"[174, 1742]","[1697552051548, 1697552053290]"
108,108,281,5,[],200,llama-13b,64,1,1498.0,1.0,1,A100,1697552057512,1697552059010,120,23.0,1.0,"[134, 1364]","[1697552057646, 1697552059010]"
109,109,49,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059013,1697552060883,120,,,"[18, 867]","[1697552059031, 1697552059898]"
110,110,711,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049238,1697552051366,120,,,[17],[1697552049255]
111,111,262,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054793,1697552056509,120,,,[16],[1697552054809]
112,112,372,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051370,1697552052660,120,,,[31],[1697552051401]
113,113,199,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049243,1697552051368,120,,,[135],[1697552049378]
114,114,413,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049243,1697552051367,120,,,[135],[1697552049378]
115,115,852,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552056512,1697552059167,120,,,"[18, 1655]","[1697552056530, 1697552058185]"
116,116,85,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552050148,1697552053353,120,,,"[15, 1722, 810]","[1697552050163, 1697552051885, 1697552052695]"
117,117,592,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552050153,1697552053353,120,,,"[102, 1631, 810]","[1697552050255, 1697552051886, 1697552052696]"
118,118,536,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051374,1697552053353,120,,,"[169, 1748]","[1697552051543, 1697552053291]"
119,119,252,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053359,1697552055780,120,,,[98],[1697552053457]
120,120,304,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049239,1697552051366,120,,,[109],[1697552049348]
121,121,609,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047594,1697552049234,120,,,"[144, 1301]","[1697552047738, 1697552049039]"
122,122,284,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049233,120,,,[91],[1697552047687]
123,123,781,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053358,1697552054789,120,,,"[40, 1213]","[1697552053398, 1697552054611]"
124,124,52,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049238,1697552051366,120,,,[27],[1697552049265]
125,125,625,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059173,1697552060882,120,,,"[38, 1414]","[1697552059211, 1697552060625]"
126,126,141,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049043,1697552050147,120,,,[27],[1697552049070]
127,127,777,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051376,1697552052660,120,,,[172],[1697552051548]
128,128,284,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060889,1697552063764,120,,,"[53, 2109]","[1697552060942, 1697552063051]"
129,129,203,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051374,1697552052660,120,,,[86],[1697552051460]
130,130,553,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049234,120,,,"[52, 707, 54]","[1697552047648, 1697552048355, 1697552048409]"
131,131,96,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047639,1697552050145,120,,,[210],[1697552047849]
132,132,448,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049233,120,,,"[27, 732, 54]","[1697552047623, 1697552048355, 1697552048409]"
133,133,791,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552050149,1697552053353,120,,,"[20, 2526]","[1697552050169, 1697552052695]"
134,134,609,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049234,120,,,"[62, 697, 54]","[1697552047658, 1697552048355, 1697552048409]"
135,135,793,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552052665,1697552054789,120,,,[95],[1697552052760]
136,136,211,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054803,1697552056509,120,,,[70],[1697552054873]
137,137,565,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054794,1697552056509,120,,,[37],[1697552054831]
138,138,216,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049239,1697552051367,120,,,[45],[1697552049284]
139,139,920,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051374,1697552052660,120,,,[88],[1697552051462]
140,140,312,5,[],200,llama-13b,64,1,1671.0,1.0,1,A100,1697552056515,1697552058186,120,23.0,1.0,"[55, 1615]","[1697552056570, 1697552058185]"
141,141,582,3,[],200,llama-13b,64,1,1320.0,1.0,1,A100,1697552052666,1697552053986,120,19.0,1.0,"[90, 1230]","[1697552052756, 1697552053986]"
142,142,895,6,[],200,llama-13b,64,1,1709.0,1.0,1,A100,1697552058190,1697552059899,120,15.0,1.0,"[35, 1673]","[1697552058225, 1697552059898]"
143,143,13,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047597,1697552049233,120,,,"[140, 1302]","[1697552047737, 1697552049039]"
144,144,671,7,[],200,llama-13b,64,1,1804.0,1.0,1,A100,1697552059904,1697552061708,120,12.0,1.0,"[33, 1771]","[1697552059937, 1697552061708]"
145,145,600,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049243,1697552051367,120,,,[120],[1697552049363]
146,146,324,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552061711,1697552063764,120,,,"[29, 1265, 46]","[1697552061740, 1697552063005, 1697552063051]"
147,147,796,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552056512,1697552059167,120,,,"[16, 1657]","[1697552056528, 1697552058185]"
148,148,351,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053990,1697552055780,120,,,[16],[1697552054006]
149,149,369,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051374,1697552052661,120,,,[74],[1697552051448]
150,150,595,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049239,1697552051367,120,,,[41],[1697552049280]
151,151,565,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059172,1697552060882,120,,,"[15, 1434]","[1697552059187, 1697552060621]"
152,152,372,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051373,1697552052660,120,,,[79],[1697552051452]
153,153,328,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049239,1697552051367,120,,,[46],[1697552049285]
154,154,313,7,[],200,llama-13b,64,1,2116.0,1.0,1,A100,1697552060890,1697552063006,120,20.0,1.0,"[77, 2039]","[1697552060967, 1697552063006]"
155,155,262,2,[],200,llama-13b,64,1,1733.0,1.0,1,A100,1697552050153,1697552051886,120,39.0,1.0,"[107, 1626]","[1697552050260, 1697552051886]"
156,156,98,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051370,1697552052660,120,,,[21],[1697552051391]
157,157,38,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051889,1697552053353,120,,,"[14, 1388]","[1697552051903, 1697552053291]"
158,158,1,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552052664,1697552054788,120,,,"[41, 1281]","[1697552052705, 1697552053986]"
159,159,659,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057513,1697552060882,120,,,"[131, 2253]","[1697552057644, 1697552059897]"
160,160,444,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049238,1697552051366,120,,,[12],[1697552049250]
161,161,306,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053359,1697552054789,120,,,[98],[1697552053457]
162,162,704,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054797,1697552056509,120,,,[71],[1697552054868]
163,163,248,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049243,1697552051366,120,,,[116],[1697552049359]
164,164,143,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552052663,1697552053353,120,,,"[27, 601]","[1697552052690, 1697552053291]"
165,165,14,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051373,1697552053354,120,,,"[112, 1805]","[1697552051485, 1697552053290]"
166,166,358,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552056512,1697552059167,120,,,"[23, 1650]","[1697552056535, 1697552058185]"
167,167,865,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051375,1697552052660,120,,,[168],[1697552051543]
168,168,434,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060886,1697552062306,120,,,"[7, 1292]","[1697552060893, 1697552062185]"
169,169,135,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059172,1697552060882,120,,,"[20, 1429]","[1697552059192, 1697552060621]"
170,170,98,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051373,1697552052661,120,,,[65],[1697552051438]
171,171,634,3,[],200,llama-13b,64,1,1322.0,1.0,1,A100,1697552052664,1697552053986,120,13.0,1.0,"[86, 1236]","[1697552052750, 1697552053986]"
172,172,604,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053359,1697552055780,120,,,[123],[1697552053482]
173,173,289,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053989,1697552055781,120,,,[12],[1697552054001]
174,174,449,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552050149,1697552053353,120,,,"[27, 1710, 809]","[1697552050176, 1697552051886, 1697552052695]"
175,175,803,3,[],200,llama-13b,64,1,1321.0,1.0,1,A100,1697552052665,1697552053986,120,20.0,1.0,"[86, 1235]","[1697552052751, 1697552053986]"
176,176,339,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047639,1697552050147,120,,,[143],[1697552047782]
177,177,630,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049243,1697552051367,120,,,[131],[1697552049374]
178,178,891,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054794,1697552056509,120,,,[40],[1697552054834]
179,179,928,1,[],200,llama-13b,64,1,1733.0,1.0,1,A100,1697552050154,1697552051887,120,20.0,1.0,"[111, 1621]","[1697552050265, 1697552051886]"
180,180,459,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053989,1697552055781,120,,,[12],[1697552054001]
181,181,697,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051889,1697552053353,120,,,"[25, 1377]","[1697552051914, 1697552053291]"
182,182,715,7,[],200,llama-13b,64,1,1297.0,1.0,1,A100,1697552060889,1697552062186,120,20.0,1.0,"[48, 1249]","[1697552060937, 1697552062186]"
183,183,663,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552056512,1697552059168,120,,,"[33, 1641]","[1697552056545, 1697552058186]"
184,184,110,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053357,1697552054788,120,,,"[18, 1236]","[1697552053375, 1697552054611]"
185,185,316,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059176,1697552060882,120,,,"[163, 1285]","[1697552059339, 1697552060624]"
186,186,445,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053358,1697552054789,120,,,"[45, 1208]","[1697552053403, 1697552054611]"
187,187,493,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062189,1697552063765,120,,,"[15, 802, 45]","[1697552062204, 1697552063006, 1697552063051]"
188,188,158,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047602,1697552049235,120,,,"[175, 1263]","[1697552047777, 1697552049040]"
189,189,100,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054794,1697552056509,120,,,[27],[1697552054821]
190,190,146,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063775,1697552064878,120,,,[97],[1697552063872]
191,191,228,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055786,1697552057502,120,,,[35],[1697552055821]
192,192,802,5,[],200,llama-13b,64,1,1673.0,1.0,1,A100,1697552056512,1697552058185,120,9.0,1.0,"[28, 1645]","[1697552056540, 1697552058185]"
193,193,463,6,[],200,llama-13b,64,1,1709.0,1.0,1,A100,1697552058189,1697552059898,120,39.0,1.0,"[30, 1679]","[1697552058219, 1697552059898]"
194,194,231,7,[],200,llama-13b,64,1,1805.0,1.0,1,A100,1697552059903,1697552061708,120,13.0,1.0,"[29, 1776]","[1697552059932, 1697552061708]"
195,195,847,10,[],200,llama-13b,64,1,1262.0,1.0,1,A100,1697552064883,1697552066145,120,10.0,1.0,"[55, 1206]","[1697552064938, 1697552066144]"
196,196,503,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066147,1697552067382,120,,,"[24, 1191]","[1697552066171, 1697552067362]"
197,197,118,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051369,1697552052660,120,,,[21],[1697552051390]
198,198,738,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049243,1697552051367,120,,,[125],[1697552049368]
199,199,823,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552052664,1697552054789,120,,,"[31, 1291]","[1697552052695, 1697552053986]"
200,200,821,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552061711,1697552063764,120,,,"[24, 1270, 46]","[1697552061735, 1697552063005, 1697552063051]"
201,201,722,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054796,1697552056509,120,,,[57],[1697552054853]
202,202,92,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060889,1697552062307,120,,,"[33, 1263]","[1697552060922, 1697552062185]"
203,203,494,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552056513,1697552059167,120,,,"[30, 1642]","[1697552056543, 1697552058185]"
204,204,477,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054797,1697552056509,120,,,[71],[1697552054868]
205,205,273,12,[],200,llama-13b,64,1,1226.0,1.0,1,A100,1697552067395,1697552068621,120,19.0,1.0,"[169, 1057]","[1697552067564, 1697552068621]"
206,206,674,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062310,1697552063764,120,,,"[7, 1338]","[1697552062317, 1697552063655]"
207,207,252,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552056514,1697552059168,120,,,"[41, 1631]","[1697552056555, 1697552058186]"
208,208,451,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063770,1697552064878,120,,,[27],[1697552063797]
209,209,19,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068625,1697552069276,120,,,[37],[1697552068662]
210,210,724,2,[],200,llama-13b,64,1,1734.0,1.0,1,A100,1697552050152,1697552051886,120,11.0,1.0,"[93, 1641]","[1697552050245, 1697552051886]"
211,211,107,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064883,1697552066164,120,,,[31],[1697552064914]
212,212,806,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066166,1697552067381,120,,,"[78, 1118]","[1697552066244, 1697552067362]"
213,213,473,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051888,1697552053354,120,,,"[16, 1387]","[1697552051904, 1697552053291]"
214,214,601,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069283,1697552071282,120,,,[75],[1697552069358]
215,215,378,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071288,1697552072656,120,,,[77],[1697552071365]
216,216,33,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072659,1697552073396,120,,,"[8, 708]","[1697552072667, 1697552073375]"
217,217,837,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049233,120,,,"[36, 722, 55]","[1697552047632, 1697552048354, 1697552048409]"
218,218,440,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067384,1697552068961,120,,,"[163, 1073, 151, 140]","[1697552067547, 1697552068620, 1697552068771, 1697552068911]"
219,219,43,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053294,1697552054789,120,,,"[11, 681]","[1697552053305, 1697552053986]"
220,220,126,4,[],200,llama-13b,64,1,1251.0,1.0,1,A100,1697552053360,1697552054611,120,19.0,1.0,"[107, 1144]","[1697552053467, 1697552054611]"
221,221,912,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552052663,1697552054788,120,,,"[42, 1281]","[1697552052705, 1697552053986]"
222,222,301,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049243,1697552051367,120,,,[130],[1697552049373]
223,223,564,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054795,1697552056509,120,,,[53],[1697552054848]
224,224,71,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051374,1697552053353,120,,,"[98, 1819]","[1697552051472, 1697552053291]"
225,225,632,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054794,1697552056509,120,,,[30],[1697552054824]
226,226,258,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047596,1697552049233,120,,,"[46, 713, 54]","[1697552047642, 1697552048355, 1697552048409]"
227,227,312,5,[],200,llama-13b,64,1,1672.0,1.0,1,A100,1697552056514,1697552058186,120,23.0,1.0,"[44, 1628]","[1697552056558, 1697552058186]"
228,228,210,13,[],200,llama-13b,64,1,1663.0,1.0,1,A100,1697552068964,1697552070627,120,140.0,2.0,"[26, 1041, 595]","[1697552068990, 1697552070031, 1697552070626]"
229,229,894,6,[],200,llama-13b,64,1,1709.0,1.0,1,A100,1697552058189,1697552059898,120,14.0,1.0,"[25, 1684]","[1697552058214, 1697552059898]"
230,230,72,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051374,1697552053353,120,,,"[164, 1753]","[1697552051538, 1697552053291]"
231,231,666,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059902,1697552062307,120,,,"[10, 1796]","[1697552059912, 1697552061708]"
232,232,654,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053358,1697552054789,120,,,"[30, 1223]","[1697552053388, 1697552054611]"
233,233,654,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053358,1697552054789,120,,,"[35, 1218]","[1697552053393, 1697552054611]"
234,234,400,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552056515,1697552059169,120,,,"[53, 1618]","[1697552056568, 1697552058186]"
235,235,432,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054796,1697552056508,120,,,[67],[1697552054863]
236,236,148,7,[],200,llama-13b,64,1,1452.0,1.0,1,A100,1697552059176,1697552060628,120,16.0,1.0,"[95, 1355]","[1697552059271, 1697552060626]"
237,237,169,3,[],200,llama-13b,64,1,1253.0,1.0,1,A100,1697552053358,1697552054611,120,10.0,1.0,"[27, 1226]","[1697552053385, 1697552054611]"
238,238,734,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060637,1697552062307,120,,,"[39, 1033]","[1697552060676, 1697552061709]"
239,239,506,9,[],200,llama-13b,64,1,1343.0,1.0,1,A100,1697552062312,1697552063655,120,16.0,1.0,"[49, 1294]","[1697552062361, 1697552063655]"
240,240,327,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062311,1697552063765,120,,,"[15, 1328]","[1697552062326, 1697552063654]"
241,241,166,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063659,1697552064541,120,,,[15],[1697552063674]
242,242,840,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054614,1697552055782,120,,,[30],[1697552054644]
243,243,85,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552056510,1697552059167,120,,,"[15, 1660]","[1697552056525, 1697552058185]"
244,244,798,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070628,1697552071972,120,,,[9],[1697552070637]
245,245,494,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055787,1697552057503,120,,,[76],[1697552055863]
246,246,431,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054794,1697552056509,120,,,[22],[1697552054816]
247,247,792,6,[],200,llama-13b,64,1,1449.0,1.0,1,A100,1697552059175,1697552060624,120,11.0,1.0,"[62, 1387]","[1697552059237, 1697552060624]"
248,248,86,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552056513,1697552059167,120,,,"[25, 1647]","[1697552056538, 1697552058185]"
249,249,788,6,[],200,llama-13b,64,1,1450.0,1.0,1,A100,1697552059176,1697552060626,120,31.0,1.0,"[168, 1281]","[1697552059344, 1697552060625]"
250,250,449,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060636,1697552062307,120,,,"[31, 1041]","[1697552060667, 1697552061708]"
251,251,446,7,[],200,llama-13b,64,1,1072.0,1.0,1,A100,1697552060636,1697552061708,120,26.0,1.0,"[21, 1051]","[1697552060657, 1697552061708]"
252,252,219,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062312,1697552063764,120,,,"[54, 1289]","[1697552062366, 1697552063655]"
253,253,223,8,[],200,llama-13b,64,1,1296.0,1.0,1,A100,1697552061710,1697552063006,120,16.0,1.0,"[11, 1284]","[1697552061721, 1697552063005]"
254,254,271,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057509,1697552059167,120,,,"[42, 1458]","[1697552057551, 1697552059009]"
255,255,175,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047594,1697552049233,120,,,[148],[1697552047742]
256,256,855,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059173,1697552060882,120,,,"[39, 1410]","[1697552059212, 1697552060622]"
257,257,244,1,[],200,llama-13b,64,1,1734.0,1.0,1,A100,1697552050152,1697552051886,120,9.0,1.0,"[88, 1646]","[1697552050240, 1697552051886]"
258,258,890,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552056512,1697552059168,120,,,[53],[1697552056565]
259,259,807,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063008,1697552064541,120,,,[21],[1697552063029]
260,260,495,14,[],200,llama-13b,64,1,1066.0,1.0,1,A100,1697552068966,1697552070032,120,13.0,1.0,"[39, 1027]","[1697552069005, 1697552070032]"
261,261,200,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552058188,1697552060883,120,,,"[21, 1688]","[1697552058209, 1697552059897]"
262,262,413,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049239,1697552051368,120,,,[99],[1697552049338]
263,263,577,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064543,1697552066163,120,,,[19],[1697552064562]
264,264,663,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059172,1697552060882,120,,,"[30, 1419]","[1697552059202, 1697552060621]"
265,265,209,11,[],200,llama-13b,64,1,1196.0,1.0,1,A100,1697552066166,1697552067362,120,20.0,1.0,"[101, 1095]","[1697552066267, 1697552067362]"
266,266,183,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051373,1697552052661,120,,,[69],[1697552051442]
267,267,878,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060889,1697552063764,120,,,"[58, 2059, 45]","[1697552060947, 1697552063006, 1697552063051]"
268,268,905,12,[],200,llama-13b,64,1,175.0,1.0,1,A100,1697552067364,1697552067539,120,11.0,1.0,"[13, 162]","[1697552067377, 1697552067539]"
269,269,317,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060889,1697552063764,120,,,"[68, 2049, 45]","[1697552060957, 1697552063006, 1697552063051]"
270,270,527,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063771,1697552064878,120,,,[106],[1697552063877]
271,271,302,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064883,1697552066164,120,,,"[41, 1220]","[1697552064924, 1697552066144]"
272,272,389,0,[],200,llama-13b,64,1,759.0,1.0,1,A100,1697552047596,1697552048355,120,8.0,1.0,"[41, 718]","[1697552047637, 1697552048355]"
273,273,4,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053360,1697552055780,120,,,[102],[1697552053462]
274,274,156,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070033,1697552071281,120,,,[16],[1697552070049]
275,275,161,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552048357,1697552050146,120,,,[19],[1697552048376]
276,276,88,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063775,1697552064879,120,,,[165],[1697552063940]
277,277,678,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064884,1697552067381,120,,,"[86, 1690]","[1697552064970, 1697552066660]"
278,278,562,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067541,1697552068961,120,,,"[41, 1038, 151, 140]","[1697552067582, 1697552068620, 1697552068771, 1697552068911]"
279,279,447,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067387,1697552067820,120,,,[91],[1697552067478]
280,280,677,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055787,1697552057503,120,,,[81],[1697552055868]
281,281,106,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067823,1697552069276,120,,,[59],[1697552067882]
282,282,332,14,[],200,llama-13b,64,1,1065.0,1.0,1,A100,1697552068966,1697552070031,120,39.0,1.0,"[73, 992]","[1697552069039, 1697552070031]"
283,283,231,0,[],200,llama-13b,64,1,760.0,1.0,1,A100,1697552047594,1697552048354,120,13.0,1.0,"[19, 741]","[1697552047613, 1697552048354]"
284,284,818,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552048356,1697552050146,120,,,[7],[1697552048363]
285,285,916,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070035,1697552071277,120,,,[24],[1697552070059]
286,286,884,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066167,1697552067381,120,,,"[72, 1123]","[1697552066239, 1697552067362]"
287,287,596,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552050149,1697552053353,120,,,"[21, 1715, 810]","[1697552050170, 1697552051885, 1697552052695]"
288,288,729,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053358,1697552055780,120,,,[84],[1697552053442]
289,289,25,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055786,1697552057503,120,,,[67],[1697552055853]
290,290,346,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552050150,1697552053353,120,,,"[24, 1712, 809]","[1697552050174, 1697552051886, 1697552052695]"
291,291,606,5,[],200,llama-13b,64,1,1498.0,1.0,1,A100,1697552057512,1697552059010,120,9.0,1.0,"[124, 1373]","[1697552057636, 1697552059009]"
292,292,383,6,[],200,llama-13b,64,1,885.0,1.0,1,A100,1697552059013,1697552059898,120,15.0,1.0,"[30, 855]","[1697552059043, 1697552059898]"
293,293,806,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054793,1697552056509,120,,,[36],[1697552054829]
294,294,661,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067383,1697552067819,120,,,[68],[1697552067451]
295,295,467,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552056515,1697552059169,120,,,[60],[1697552056575]
296,296,237,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059175,1697552060883,120,,,"[78, 1371]","[1697552059253, 1697552060624]"
297,297,821,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060889,1697552063764,120,,,"[63, 2054, 45]","[1697552060952, 1697552063006, 1697552063051]"
298,298,572,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063770,1697552064878,120,,,[28],[1697552063798]
299,299,554,3,[],200,llama-13b,64,1,1322.0,1.0,1,A100,1697552052664,1697552053986,120,26.0,1.0,"[36, 1286]","[1697552052700, 1697552053986]"
300,300,249,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053358,1697552054789,120,,,"[42, 1211]","[1697552053400, 1697552054611]"
301,301,7,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053356,1697552054789,120,,,"[12, 1243]","[1697552053368, 1697552054611]"
302,302,342,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064883,1697552066164,120,,,"[38, 1223]","[1697552064921, 1697552066144]"
303,303,805,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069283,1697552071280,120,,,[96],[1697552069379]
304,304,155,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059172,1697552060882,120,,,"[29, 1421]","[1697552059201, 1697552060622]"
305,305,1,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066167,1697552067382,120,,,"[115, 1080]","[1697552066282, 1697552067362]"
306,306,206,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053991,1697552055781,120,,,[20],[1697552054011]
307,307,699,11,[],200,llama-13b,64,1,1226.0,1.0,1,A100,1697552067395,1697552068621,120,39.0,1.0,"[167, 1059]","[1697552067562, 1697552068621]"
308,308,361,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068623,1697552069274,120,,,[15],[1697552068638]
309,309,317,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067824,1697552069276,120,,,[58],[1697552067882]
310,310,702,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054794,1697552056509,120,,,[20],[1697552054814]
311,311,332,5,[],200,llama-13b,64,1,1673.0,1.0,1,A100,1697552056512,1697552058185,120,39.0,1.0,"[21, 1652]","[1697552056533, 1697552058185]"
312,312,86,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069280,1697552071281,120,,,[57],[1697552069337]
313,313,912,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055785,1697552057501,120,,,[31],[1697552055816]
314,314,676,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071287,1697552072657,120,,,[58],[1697552071345]
315,315,565,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057506,1697552059169,120,,,"[20, 1482]","[1697552057526, 1697552059008]"
316,316,447,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072661,1697552074776,120,,,[95],[1697552072756]
317,317,336,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059175,1697552060883,120,,,"[98, 1352]","[1697552059273, 1697552060625]"
318,318,132,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 6.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069277,1697552070586,120,,,[8],[1697552069285]
319,319,102,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552058188,1697552060882,120,,,"[16, 1693]","[1697552058204, 1697552059897]"
320,320,93,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047598,1697552049234,120,,,"[145, 1296]","[1697552047743, 1697552049039]"
321,321,691,7,[],200,llama-13b,64,1,1297.0,1.0,1,A100,1697552060889,1697552062186,120,47.0,1.0,"[67, 1230]","[1697552060956, 1697552062186]"
322,322,556,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071284,1697552071972,120,,,[22],[1697552071306]
323,323,714,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070588,1697552071277,120,,,[10],[1697552070598]
324,324,828,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054614,1697552055781,120,,,[35],[1697552054649]
325,325,487,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071289,1697552072656,120,,,[81],[1697552071370]
326,326,463,8,[],200,llama-13b,64,1,816.0,1.0,1,A100,1697552062190,1697552063006,120,39.0,1.0,"[19, 797]","[1697552062209, 1697552063006]"
327,327,141,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072659,1697552074777,120,,,"[51, 1345]","[1697552072710, 1697552074055]"
328,328,795,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049239,1697552051366,120,,,[104],[1697552049343]
329,329,116,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063009,1697552064541,120,,,[15],[1697552063024]
330,330,449,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051370,1697552052660,120,,,[25],[1697552051395]
331,331,816,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074781,1697552075453,120,,,[25],[1697552074806]
332,332,220,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552052663,1697552053353,120,,,"[32, 596]","[1697552052695, 1697552053291]"
333,333,822,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064544,1697552066163,120,,,"[33, 975]","[1697552064577, 1697552065552]"
334,334,809,4,[],200,llama-13b,64,1,1253.0,1.0,1,A100,1697552053358,1697552054611,120,16.0,1.0,"[46, 1207]","[1697552053404, 1697552054611]"
335,335,580,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054614,1697552055781,120,,,[8],[1697552054622]
336,336,240,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055786,1697552057501,120,,,[35],[1697552055821]
337,337,469,18,[],200,llama-13b,64,1,764.0,1.0,1,A100,1697552075458,1697552076222,120,17.0,1.0,"[25, 739]","[1697552075483, 1697552076222]"
338,338,8,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057509,1697552059167,120,,,"[32, 1468]","[1697552057541, 1697552059009]"
339,339,217,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049238,1697552051366,120,,,[21],[1697552049259]
340,340,96,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063771,1697552064879,120,,,[67],[1697552063838]
341,341,246,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076224,1697552079383,120,,,"[17, 1036, 873, 483]","[1697552076241, 1697552077277, 1697552078150, 1697552078633]"
342,342,865,11,[],200,llama-13b,64,1,1007.0,1.0,1,A100,1697552064546,1697552065553,120,9.0,1.0,"[96, 911]","[1697552064642, 1697552065553]"
343,343,830,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079391,1697552080744,120,,,"[46, 1188]","[1697552079437, 1697552080625]"
344,344,600,21,[],200,llama-13b,64,1,1254.0,1.0,1,A100,1697552080748,1697552082002,120,23.0,1.0,"[25, 1228]","[1697552080773, 1697552082001]"
345,345,221,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049243,1697552051367,120,,,[121],[1697552049364]
346,346,264,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082005,1697552083468,120,,,"[26, 807]","[1697552082031, 1697552082838]"
347,347,33,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083472,1697552083903,120,,,[36],[1697552083508]
348,348,622,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083908,1697552084997,120,,,[57],[1697552083965]
349,349,810,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051374,1697552053353,120,,,"[103, 1813]","[1697552051477, 1697552053290]"
350,350,854,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047594,1697552049235,120,,,"[83, 1361]","[1697552047677, 1697552049038]"
351,351,10,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055783,1697552057501,120,,,[18],[1697552055801]
352,352,708,6,[],200,llama-13b,64,1,1502.0,1.0,1,A100,1697552057507,1697552059009,120,140.0,1.0,"[24, 1478]","[1697552057531, 1697552059009]"
353,353,578,3,[],200,llama-13b,64,1,1252.0,1.0,1,A100,1697552053359,1697552054611,120,31.0,1.0,"[93, 1159]","[1697552053452, 1697552054611]"
354,354,238,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054613,1697552055781,120,,,[6],[1697552054619]
355,355,477,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066168,1697552067382,120,,,"[168, 1026]","[1697552066336, 1697552067362]"
356,356,627,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049243,1697552051367,120,,,[126],[1697552049369]
357,357,340,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059011,1697552060883,120,,,"[15, 872]","[1697552059026, 1697552059898]"
358,358,287,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051376,1697552052660,120,,,[182],[1697552051558]
359,359,112,8,[],200,llama-13b,64,1,2163.0,1.0,1,A100,1697552060889,1697552063052,120,16.0,2.0,"[73, 2044, 45]","[1697552060962, 1697552063006, 1697552063051]"
360,360,57,3,[],200,llama-13b,64,1,1320.0,1.0,1,A100,1697552052666,1697552053986,120,13.0,1.0,"[99, 1221]","[1697552052765, 1697552053986]"
361,361,695,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063054,1697552064541,120,,,[15],[1697552063069]
362,362,687,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552052662,1697552053353,120,,,"[23, 606]","[1697552052685, 1697552053291]"
363,363,635,7,[],200,llama-13b,64,1,1299.0,1.0,1,A100,1697552060887,1697552062186,120,23.0,1.0,"[33, 1266]","[1697552060920, 1697552062186]"
364,364,71,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051370,1697552052660,120,,,[30],[1697552051400]
365,365,57,3,[],200,llama-13b,64,1,1252.0,1.0,1,A100,1697552053359,1697552054611,120,13.0,1.0,"[113, 1139]","[1697552053472, 1697552054611]"
366,366,767,3,[],200,llama-13b,64,1,1321.0,1.0,1,A100,1697552052665,1697552053986,120,11.0,1.0,"[80, 1241]","[1697552052745, 1697552053986]"
367,367,21,2,[],200,llama-13b,64,1,1401.0,1.0,1,A100,1697552051890,1697552053291,120,15.0,1.0,"[28, 1373]","[1697552051918, 1697552053291]"
368,368,600,3,[],200,llama-13b,64,1,691.0,1.0,1,A100,1697552053295,1697552053986,120,23.0,1.0,"[24, 667]","[1697552053319, 1697552053986]"
369,369,767,3,[],200,llama-13b,64,1,1323.0,1.0,1,A100,1697552052664,1697552053987,120,11.0,1.0,"[73, 1250]","[1697552052737, 1697552053987]"
370,370,861,2,[],200,llama-13b,64,1,1736.0,1.0,1,A100,1697552050150,1697552051886,120,10.0,1.0,"[39, 1697]","[1697552050189, 1697552051886]"
371,371,522,3,[],200,llama-13b,64,1,1401.0,1.0,1,A100,1697552051890,1697552053291,120,20.0,1.0,"[34, 1367]","[1697552051924, 1697552053291]"
372,372,292,4,[],200,llama-13b,64,1,692.0,1.0,1,A100,1697552053294,1697552053986,120,286.0,1.0,"[6, 686]","[1697552053300, 1697552053986]"
373,373,640,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054615,1697552055781,120,,,[19],[1697552054634]
374,374,877,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053989,1697552055780,120,,,[17],[1697552054006]
375,375,418,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055786,1697552057503,120,,,[60],[1697552055846]
376,376,375,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053990,1697552055780,120,,,[6],[1697552053996]
377,377,185,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051374,1697552052660,120,,,[91],[1697552051465]
378,378,29,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055784,1697552057501,120,,,[17],[1697552055801]
379,379,646,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053992,1697552055780,120,,,[29],[1697552054021]
380,380,649,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055786,1697552057503,120,,,[72],[1697552055858]
381,381,763,3,[],200,llama-13b,64,1,1322.0,1.0,1,A100,1697552052664,1697552053986,120,20.0,1.0,"[46, 1276]","[1697552052710, 1697552053986]"
382,382,705,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057508,1697552059169,120,,,"[28, 1473]","[1697552057536, 1697552059009]"
383,383,415,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055784,1697552057502,120,,,[22],[1697552055806]
384,384,71,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057510,1697552059168,120,,,"[51, 1448]","[1697552057561, 1697552059009]"
385,385,540,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053989,1697552055780,120,,,[7],[1697552053996]
386,386,467,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064543,1697552066163,120,,,[20],[1697552064563]
387,387,477,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059172,1697552060883,120,,,"[7, 1442]","[1697552059179, 1697552060621]"
388,388,693,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071287,1697552072657,120,,,[63],[1697552071350]
389,389,303,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057509,1697552059169,120,,,"[62, 1439]","[1697552057571, 1697552059010]"
390,390,346,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072660,1697552074776,120,,,"[79, 1316]","[1697552072739, 1697552074055]"
391,391,130,8,[],200,llama-13b,64,1,2114.0,1.0,1,A100,1697552060892,1697552063006,120,14.0,1.0,"[90, 2024]","[1697552060982, 1697552063006]"
392,392,80,8,[],200,llama-13b,64,1,1447.0,1.0,1,A100,1697552059179,1697552060626,120,13.0,1.0,"[165, 1281]","[1697552059344, 1697552060625]"
393,393,660,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060636,1697552062308,120,,,"[11, 1061]","[1697552060647, 1697552061708]"
394,394,120,11,[],200,llama-13b,64,1,1196.0,1.0,1,A100,1697552066166,1697552067362,120,17.0,1.0,"[76, 1120]","[1697552066242, 1697552067362]"
395,395,124,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074781,1697552075453,120,,,[55],[1697552074836]
396,396,704,19,[],200,llama-13b,64,1,1808.0,1.0,1,A100,1697552075469,1697552077277,120,14.0,1.0,"[106, 1702]","[1697552075575, 1697552077277]"
397,397,836,9,[],200,llama-13b,64,1,647.0,1.0,1,A100,1697552063008,1697552063655,120,11.0,1.0,"[15, 632]","[1697552063023, 1697552063655]"
398,398,37,7,[],200,llama-13b,64,1,1803.0,1.0,1,A100,1697552059905,1697552061708,120,20.0,1.0,"[22, 1781]","[1697552059927, 1697552061708]"
399,399,825,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067365,1697552067819,120,,,[31],[1697552067396]
400,400,478,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067825,1697552069274,120,,,[113],[1697552067938]
401,401,818,6,[],200,llama-13b,64,1,1498.0,1.0,1,A100,1697552057511,1697552059009,120,13.0,1.0,"[70, 1428]","[1697552057581, 1697552059009]"
402,402,491,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063658,1697552064541,120,,,[16],[1697552063674]
403,403,582,7,[],200,llama-13b,64,1,885.0,1.0,1,A100,1697552059013,1697552059898,120,19.0,1.0,"[25, 860]","[1697552059038, 1697552059898]"
404,404,268,11,[],200,llama-13b,64,1,1008.0,1.0,1,A100,1697552064545,1697552065553,120,19.0,1.0,"[97, 911]","[1697552064642, 1697552065553]"
405,405,854,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060886,1697552062307,120,,,"[19, 1280]","[1697552060905, 1697552062185]"
406,406,851,12,[],200,llama-13b,64,1,1103.0,1.0,1,A100,1697552065558,1697552066661,120,23.0,1.0,"[28, 1074]","[1697552065586, 1697552066660]"
407,407,622,13,[],200,llama-13b,64,1,875.0,1.0,1,A100,1697552066664,1697552067539,120,20.0,1.0,"[15, 860]","[1697552066679, 1697552067539]"
408,408,512,8,[],200,llama-13b,64,1,1344.0,1.0,1,A100,1697552062311,1697552063655,120,11.0,1.0,"[35, 1309]","[1697552062346, 1697552063655]"
409,409,255,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069283,1697552071278,120,,,[91],[1697552069374]
410,410,835,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059176,1697552060884,120,,,"[102, 1346]","[1697552059278, 1697552060624]"
411,411,839,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071286,1697552072657,120,,,[55],[1697552071341]
412,412,242,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059901,1697552062307,120,,,"[6, 1801]","[1697552059907, 1697552061708]"
413,413,609,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072660,1697552074776,120,,,"[55, 1340]","[1697552072715, 1697552074055]"
414,414,283,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067542,1697552068961,120,,,"[46, 1032, 151, 140]","[1697552067588, 1697552068620, 1697552068771, 1697552068911]"
415,415,13,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062311,1697552063765,120,,,"[11, 1333]","[1697552062322, 1697552063655]"
416,416,597,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063771,1697552064878,120,,,[111],[1697552063882]
417,417,345,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064883,1697552066162,120,,,"[70, 1192]","[1697552064953, 1697552066145]"
418,418,52,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068964,1697552073394,120,,,"[26, 1041, 595, 698, 687, 683]","[1697552068990, 1697552070031, 1697552070626, 1697552071324, 1697552072011, 1697552072694]"
419,419,590,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063771,1697552064878,120,,,[42],[1697552063813]
420,420,281,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063660,1697552064541,120,,,[24],[1697552063684]
421,421,872,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064545,1697552066163,120,,,"[92, 916]","[1697552064637, 1697552065553]"
422,422,646,11,[],200,llama-13b,64,1,1195.0,1.0,1,A100,1697552066167,1697552067362,120,14.0,1.0,"[105, 1090]","[1697552066272, 1697552067362]"
423,423,927,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066165,1697552067381,120,,,"[72, 1125]","[1697552066237, 1697552067362]"
424,424,611,16,[],200,llama-13b,64,1,1357.0,1.0,1,A100,1697552073400,1697552074757,120,14.0,1.0,"[52, 1305]","[1697552073452, 1697552074757]"
425,425,300,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067366,1697552067819,120,,,[43],[1697552067409]
426,426,732,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073400,1697552076890,120,,,"[65, 1712, 309, 869]","[1697552073465, 1697552075177, 1697552075486, 1697552076355]"
427,427,48,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067821,1697552068962,120,,,"[21, 930, 139]","[1697552067842, 1697552068772, 1697552068911]"
428,428,377,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074762,1697552075452,120,,,[25],[1697552074787]
429,429,702,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067384,1697552068960,120,,,"[104, 1132, 151, 140]","[1697552067488, 1697552068620, 1697552068771, 1697552068911]"
430,430,38,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075457,1697552076890,120,,,"[11, 753, 135]","[1697552075468, 1697552076221, 1697552076356]"
431,431,745,14,[],200,llama-13b,64,1,1066.0,1.0,1,A100,1697552068966,1697552070032,120,17.0,1.0,"[87, 979]","[1697552069053, 1697552070032]"
432,432,212,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071974,1697552072657,120,,,[6],[1697552071980]
433,433,31,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049238,1697552051367,120,,,[36],[1697552049274]
434,434,396,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076898,1697552078117,120,,,[19],[1697552076917]
435,435,405,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070034,1697552071281,120,,,[15],[1697552070049]
436,436,228,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047595,1697552049233,120,,,"[28, 732, 54]","[1697552047623, 1697552048355, 1697552048409]"
437,437,175,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071285,1697552072656,120,,,[30],[1697552071315]
438,438,166,19,[],200,llama-13b,64,1,1126.0,1.0,1,A100,1697552078122,1697552079248,120,14.0,1.0,"[54, 1072]","[1697552078176, 1697552079248]"
439,439,301,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049239,1697552051365,120,,,[105],[1697552049344]
440,440,760,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072662,1697552074776,120,,,"[99, 1294]","[1697552072761, 1697552074055]"
441,441,266,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049239,1697552051368,120,,,[51],[1697552049290]
442,442,532,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074781,1697552075457,120,,,[70],[1697552074851]
443,443,926,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049242,1697552051366,120,,,[112],[1697552049354]
444,444,572,8,[],200,llama-13b,64,1,1453.0,1.0,1,A100,1697552059172,1697552060625,120,16.0,1.0,"[13, 1437]","[1697552059185, 1697552060622]"
445,445,673,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051375,1697552053353,120,,,[105],[1697552051480]
446,446,524,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552065557,1697552067381,120,,,"[24, 1079]","[1697552065581, 1697552066660]"
447,447,38,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051374,1697552053353,120,,,"[101, 1816]","[1697552051475, 1697552053291]"
448,448,186,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075466,1697552079387,120,,,"[90, 1720, 874, 483]","[1697552075556, 1697552077276, 1697552078150, 1697552078633]"
449,449,807,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051374,1697552053353,120,,,"[179, 1737]","[1697552051553, 1697552053290]"
450,450,892,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079393,1697552082119,120,,,"[59, 2057]","[1697552079452, 1697552081509]"
451,451,342,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060636,1697552062308,120,,,"[9, 1063]","[1697552060645, 1697552061708]"
452,452,578,3,[],200,llama-13b,64,1,1254.0,1.0,1,A100,1697552053357,1697552054611,120,31.0,1.0,"[7, 1247]","[1697552053364, 1697552054611]"
453,453,544,21,[],200,llama-13b,64,1,1236.0,1.0,1,A100,1697552082123,1697552083359,120,26.0,1.0,"[7, 1229]","[1697552082130, 1697552083359]"
454,454,291,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083362,1697552083673,120,,,[22],[1697552083384]
455,455,926,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062314,1697552064541,120,,,[66],[1697552062380]
456,456,239,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054614,1697552055781,120,,,[25],[1697552054639]
457,457,874,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083680,1697552084682,120,,,[94],[1697552083774]
458,458,620,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053358,1697552054789,120,,,"[32, 1221]","[1697552053390, 1697552054611]"
459,459,294,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067384,1697552067819,120,,,[77],[1697552067461]
460,460,9,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055786,1697552057502,120,,,[40],[1697552055826]
461,461,398,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054794,1697552056509,120,,,[32],[1697552054826]
462,462,567,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057509,1697552059168,120,,,"[47, 1453]","[1697552057556, 1697552059009]"
463,463,854,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071285,1697552072656,120,,,[35],[1697552071320]
464,464,837,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552050152,1697552053353,120,,,"[103, 1631, 809]","[1697552050255, 1697552051886, 1697552052695]"
465,465,87,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062310,1697552063763,120,,,"[32, 1313]","[1697552062342, 1697552063655]"
466,466,510,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072659,1697552073396,120,,,"[24, 692]","[1697552072683, 1697552073375]"
467,467,794,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063774,1697552064879,120,,,[110],[1697552063884]
468,468,287,18,[],200,llama-13b,64,1,1776.0,1.0,1,A100,1697552073402,1697552075178,120,10.0,1.0,"[145, 1631]","[1697552073547, 1697552075178]"
469,469,375,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055786,1697552057502,120,,,[60],[1697552055846]
470,470,66,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055787,1697552057503,120,,,[81],[1697552055868]
471,471,386,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049237,1697552051365,120,,,[8],[1697552049245]
472,472,492,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053357,1697552054789,120,,,"[80, 1174]","[1697552053437, 1697552054611]"
473,473,408,10,[],200,llama-13b,64,1,1342.0,1.0,1,A100,1697552062313,1697552063655,120,16.0,1.0,"[58, 1284]","[1697552062371, 1697552063655]"
474,474,398,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051374,1697552052660,120,,,[96],[1697552051470]
475,475,177,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063661,1697552064541,120,,,[28],[1697552063689]
476,476,645,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057509,1697552059167,120,,,"[37, 1463]","[1697552057546, 1697552059009]"
477,477,452,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552077282,1697552079385,120,,,"[24, 1276, 51]","[1697552077306, 1697552078582, 1697552078633]"
478,478,24,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054793,1697552056509,120,,,[10],[1697552054803]
479,479,762,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064544,1697552066163,120,,,"[48, 960]","[1697552064592, 1697552065552]"
480,480,422,7,[],200,llama-13b,64,1,1451.0,1.0,1,A100,1697552059175,1697552060626,120,26.0,1.0,"[83, 1367]","[1697552059258, 1697552060625]"
481,481,543,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066169,1697552067382,120,,,"[177, 1016]","[1697552066346, 1697552067362]"
482,482,74,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060636,1697552062308,120,,,"[16, 1056]","[1697552060652, 1697552061708]"
483,483,515,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051373,1697552052660,120,,,[48],[1697552051421]
484,484,266,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054795,1697552056510,120,,,[49],[1697552054844]
485,485,195,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074784,1697552075457,120,,,[98],[1697552074882]
486,486,196,14,[],200,llama-13b,64,1,1226.0,1.0,1,A100,1697552067395,1697552068621,120,13.0,1.0,"[172, 1054]","[1697552067567, 1697552068621]"
487,487,169,3,[],200,llama-13b,64,1,628.0,1.0,1,A100,1697552052663,1697552053291,120,10.0,1.0,"[27, 601]","[1697552052690, 1697552053291]"
488,488,900,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068623,1697552069275,120,,,[21],[1697552068644]
489,489,865,4,[],200,llama-13b,64,1,693.0,1.0,1,A100,1697552053294,1697552053987,120,9.0,1.0,"[20, 672]","[1697552053314, 1697552053986]"
490,490,553,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069283,1697552071286,120,,,[154],[1697552069437]
491,491,780,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062311,1697552063763,120,,,"[36, 1308]","[1697552062347, 1697552063655]"
492,492,778,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075468,1697552076892,120,,,[97],[1697552075565]
493,493,606,5,[],200,llama-13b,64,1,1668.0,1.0,1,A100,1697552056517,1697552058185,120,9.0,1.0,"[61, 1607]","[1697552056578, 1697552058185]"
494,494,549,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076900,1697552078118,120,,,[71],[1697552076971]
495,495,849,5,[],200,llama-13b,64,1,1669.0,1.0,1,A100,1697552056517,1697552058186,120,10.0,1.0,"[68, 1600]","[1697552056585, 1697552058185]"
496,496,433,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063770,1697552064878,120,,,[33],[1697552063803]
497,497,210,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078121,1697552079383,120,,,"[36, 1091]","[1697552078157, 1697552079248]"
498,498,384,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552058188,1697552060882,120,,,"[16, 1693]","[1697552058204, 1697552059897]"
499,499,908,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079394,1697552080744,120,,,"[68, 1163]","[1697552079462, 1697552080625]"
500,500,567,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080751,1697552082121,120,,,"[104, 1147]","[1697552080855, 1697552082002]"
501,501,331,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071292,1697552072657,120,,,[87],[1697552071379]
502,502,914,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072660,1697552074776,120,,,"[58, 1337]","[1697552072718, 1697552074055]"
503,503,333,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082125,1697552083671,120,,,[65],[1697552082190]
504,504,629,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552058193,1697552060883,120,,,"[36, 1669]","[1697552058229, 1697552059898]"
505,505,69,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047597,1697552049233,120,,,"[91, 1351]","[1697552047688, 1697552049039]"
506,506,897,8,[],200,llama-13b,64,1,1297.0,1.0,1,A100,1697552060889,1697552062186,120,9.0,1.0,"[38, 1259]","[1697552060927, 1697552062186]"
507,507,284,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060889,1697552063764,120,,,"[78, 2084]","[1697552060967, 1697552063051]"
508,508,910,14,[],200,llama-13b,64,1,1394.0,1.0,1,A100,1697552072661,1697552074055,120,8.0,1.0,"[100, 1294]","[1697552072761, 1697552074055]"
509,509,659,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049243,1697552053353,120,,,"[140, 2502, 810]","[1697552049383, 1697552051885, 1697552052695]"
510,510,670,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062188,1697552063765,120,,,"[11, 806, 46]","[1697552062199, 1697552063005, 1697552063051]"
511,511,54,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063771,1697552064878,120,,,[98],[1697552063869]
512,512,570,15,[],200,llama-13b,64,1,1120.0,1.0,1,A100,1697552074058,1697552075178,120,18.0,1.0,"[15, 1105]","[1697552074073, 1697552075178]"
513,513,643,9,[],200,llama-13b,64,1,1261.0,1.0,1,A100,1697552064883,1697552066144,120,18.0,1.0,"[21, 1240]","[1697552064904, 1697552066144]"
514,514,119,0,[],200,llama-13b,64,1,1441.0,1.0,1,A100,1697552047598,1697552049039,120,31.0,1.0,"[154, 1287]","[1697552047752, 1697552049039]"
515,515,339,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075181,1697552076892,120,,,"[20, 1021, 133]","[1697552075201, 1697552076222, 1697552076355]"
516,516,412,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066147,1697552067382,120,,,"[6, 507]","[1697552066153, 1697552066660]"
517,517,690,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055786,1697552057503,120,,,[67],[1697552055853]
518,518,928,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076904,1697552078118,120,,,[87],[1697552076991]
519,519,460,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057511,1697552059169,120,,,"[80, 1418]","[1697552057591, 1697552059009]"
520,520,698,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078122,1697552079384,120,,,"[60, 1066]","[1697552078182, 1697552079248]"
521,521,430,2,[],200,llama-13b,64,1,1253.0,1.0,1,A100,1697552053358,1697552054611,120,15.0,1.0,"[89, 1164]","[1697552053447, 1697552054611]"
522,522,350,19,[],200,llama-13b,64,1,1237.0,1.0,1,A100,1697552079388,1697552080625,120,216.0,1.0,"[18, 1219]","[1697552079406, 1697552080625]"
523,523,120,7,[],200,llama-13b,64,1,1450.0,1.0,1,A100,1697552059172,1697552060622,120,17.0,1.0,"[25, 1424]","[1697552059197, 1697552060621]"
524,524,452,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053360,1697552055780,120,,,[107],[1697552053467]
525,525,43,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067384,1697552067819,120,,,[84],[1697552067468]
526,526,754,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079250,1697552080744,120,,,[16],[1697552079266]
527,527,684,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064887,1697552066163,120,,,"[93, 1164]","[1697552064980, 1697552066144]"
528,528,567,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071975,1697552073395,120,,,"[23, 1377]","[1697552071998, 1697552073375]"
529,529,624,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060890,1697552063764,120,,,"[87, 2029, 45]","[1697552060977, 1697552063006, 1697552063051]"
530,530,229,16,[],200,llama-13b,64,1,1776.0,1.0,1,A100,1697552073402,1697552075178,120,15.0,1.0,"[146, 1630]","[1697552073548, 1697552075178]"
531,531,100,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063771,1697552064878,120,,,[40],[1697552063811]
532,532,449,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064887,1697552067381,120,,,"[155, 1618]","[1697552065042, 1697552066660]"
533,533,655,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049238,1697552051367,120,,,[32],[1697552049270]
534,534,286,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063775,1697552064879,120,,,[167],[1697552063942]
535,535,337,7,[],200,llama-13b,64,1,1447.0,1.0,1,A100,1697552059179,1697552060626,120,12.0,1.0,"[170, 1276]","[1697552059349, 1697552060625]"
536,536,75,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057509,1697552059168,120,,,"[37, 1463]","[1697552057546, 1697552059009]"
537,537,927,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060637,1697552062307,120,,,"[35, 1037]","[1697552060672, 1697552061709]"
538,538,29,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057509,1697552059168,120,,,"[52, 1448]","[1697552057561, 1697552059009]"
539,539,928,17,[],200,llama-13b,64,1,1039.0,1.0,1,A100,1697552075183,1697552076222,120,20.0,1.0,"[34, 1005]","[1697552075217, 1697552076222]"
540,540,435,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054796,1697552056510,120,,,[62],[1697552054858]
541,541,477,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055784,1697552057501,120,,,[22],[1697552055806]
542,542,708,8,[],200,llama-13b,64,1,1294.0,1.0,1,A100,1697552061712,1697552063006,120,140.0,1.0,"[33, 1261]","[1697552061745, 1697552063006]"
543,543,777,7,[],200,llama-13b,64,1,1449.0,1.0,1,A100,1697552059176,1697552060625,120,9.0,1.0,"[173, 1276]","[1697552059349, 1697552060625]"
544,544,212,4,[],200,llama-13b,64,1,1669.0,1.0,1,A100,1697552056516,1697552058185,120,31.0,1.0,"[57, 1612]","[1697552056573, 1697552058185]"
545,545,582,18,[],200,llama-13b,64,1,1052.0,1.0,1,A100,1697552076225,1697552077277,120,19.0,1.0,"[21, 1031]","[1697552076246, 1697552077277]"
546,546,355,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552077280,1697552079384,120,,,"[6, 1295, 53]","[1697552077286, 1697552078581, 1697552078634]"
547,547,705,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059176,1697552060884,120,,,"[105, 1342]","[1697552059281, 1697552060623]"
548,548,129,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057513,1697552059169,120,,,"[136, 1361]","[1697552057649, 1697552059010]"
549,549,358,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060889,1697552062307,120,,,"[43, 1253]","[1697552060932, 1697552062185]"
550,550,792,5,[],200,llama-13b,64,1,1709.0,1.0,1,A100,1697552058189,1697552059898,120,11.0,1.0,"[25, 1683]","[1697552058214, 1697552059897]"
551,551,134,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062311,1697552063763,120,,,"[25, 1319]","[1697552062336, 1697552063655]"
552,552,7,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079395,1697552082119,120,,,"[80, 2034]","[1697552079475, 1697552081509]"
553,553,684,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082124,1697552083469,120,,,"[21, 1213]","[1697552082145, 1697552083358]"
554,554,432,8,[],200,llama-13b,64,1,1073.0,1.0,1,A100,1697552060636,1697552061709,120,13.0,1.0,"[35, 1037]","[1697552060671, 1697552061708]"
555,555,717,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063770,1697552064877,120,,,[23],[1697552063793]
556,556,453,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083472,1697552083904,120,,,[41],[1697552083513]
557,557,225,21,[],200,llama-13b,64,1,2114.0,1.0,1,A100,1697552079396,1697552081510,120,23.0,1.0,"[90, 2024]","[1697552079486, 1697552081510]"
558,558,809,22,[],200,llama-13b,64,1,1325.0,1.0,1,A100,1697552081513,1697552082838,120,16.0,1.0,"[10, 1314]","[1697552081523, 1697552082837]"
559,559,645,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051370,1697552052660,120,,,[35],[1697552051405]
560,560,362,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063014,1697552064541,120,,,[21],[1697552063035]
561,561,492,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064880,1697552066163,120,,,"[17, 1247]","[1697552064897, 1697552066144]"
562,562,615,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060890,1697552063764,120,,,"[92, 2069]","[1697552060982, 1697552063051]"
563,563,139,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064544,1697552066163,120,,,"[23, 985]","[1697552064567, 1697552065552]"
564,564,414,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552052664,1697552054789,120,,,"[71, 1252]","[1697552052735, 1697552053987]"
565,565,271,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063774,1697552064878,120,,,[100],[1697552063874]
566,566,109,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083906,1697552084996,120,,,[36],[1697552083942]
567,567,723,11,[],200,llama-13b,64,1,1194.0,1.0,1,A100,1697552066168,1697552067362,120,14.0,1.0,"[169, 1025]","[1697552066337, 1697552067362]"
568,568,492,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067365,1697552067819,120,,,[28],[1697552067393]
569,569,814,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085000,1697552086533,120,,,[11],[1697552085011]
570,570,40,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064883,1697552066164,120,,,"[56, 1205]","[1697552064939, 1697552066144]"
571,571,154,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067824,1697552069276,120,,,[67],[1697552067891]
572,572,716,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066167,1697552067382,120,,,"[102, 1093]","[1697552066269, 1697552067362]"
573,573,152,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066165,1697552067382,120,,,"[31, 1167]","[1697552066196, 1697552067363]"
574,574,586,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082840,1697552083673,120,,,[17],[1697552082857]
575,575,370,11,[],200,llama-13b,64,1,1233.0,1.0,1,A100,1697552067388,1697552068621,120,31.0,1.0,"[166, 1067]","[1697552067554, 1697552068621]"
576,576,240,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083679,1697552084683,120,,,[62],[1697552083741]
577,577,923,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083675,1697552084681,120,,,[18],[1697552083693]
578,578,468,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086538,1697552087781,120,,,[25],[1697552086563]
579,579,850,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069283,1697552071278,120,,,[81],[1697552069364]
580,580,821,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049042,1697552050147,120,,,[23],[1697552049065]
581,581,247,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087790,1697552089317,120,,,"[53, 1456]","[1697552087843, 1697552089299]"
582,582,821,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060636,1697552062308,120,,,"[20, 1052]","[1697552060656, 1697552061708]"
583,583,514,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071285,1697552072656,120,,,[46],[1697552071331]
584,584,490,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049238,1697552051366,120,,,[22],[1697552049260]
585,585,84,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054616,1697552055781,120,,,[38],[1697552054654]
586,586,284,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072659,1697552073396,120,,,[21],[1697552072680]
587,587,789,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055788,1697552057502,120,,,[161],[1697552055949]
588,588,325,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053358,1697552054789,120,,,"[26, 1227]","[1697552053384, 1697552054611]"
589,589,267,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051369,1697552052660,120,,,[16],[1697552051385]
590,590,894,8,[],200,llama-13b,64,1,646.0,1.0,1,A100,1697552063009,1697552063655,120,14.0,1.0,"[11, 635]","[1697552063020, 1697552063655]"
591,591,849,3,[],200,llama-13b,64,1,1323.0,1.0,1,A100,1697552052664,1697552053987,120,10.0,1.0,"[56, 1267]","[1697552052720, 1697552053987]"
592,592,778,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059175,1697552060883,120,,,[86],[1697552059261]
593,593,625,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053991,1697552055780,120,,,[25],[1697552054016]
594,594,278,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055786,1697552057502,120,,,[92],[1697552055878]
595,595,432,8,[],200,llama-13b,64,1,1300.0,1.0,1,A100,1697552060886,1697552062186,120,13.0,1.0,"[26, 1273]","[1697552060912, 1697552062185]"
596,596,868,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073400,1697552074777,120,,,"[60, 1297]","[1697552073460, 1697552074757]"
597,597,55,6,[],200,llama-13b,64,1,1498.0,1.0,1,A100,1697552057511,1697552059009,120,12.0,1.0,"[75, 1423]","[1697552057586, 1697552059009]"
598,598,764,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049238,1697552051365,120,,,[11],[1697552049249]
599,599,635,7,[],200,llama-13b,64,1,884.0,1.0,1,A100,1697552059013,1697552059897,120,23.0,1.0,"[23, 861]","[1697552059036, 1697552059897]"
600,600,254,12,[],200,llama-13b,64,1,1227.0,1.0,1,A100,1697552067395,1697552068622,120,58.0,1.0,"[174, 1053]","[1697552067569, 1697552068622]"
601,601,443,5,[],200,llama-13b,64,1,1501.0,1.0,1,A100,1697552057509,1697552059010,120,19.0,1.0,"[57, 1444]","[1697552057566, 1697552059010]"
602,602,836,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068625,1697552069276,120,,,[44],[1697552068669]
603,603,218,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059013,1697552060883,120,,,[20],[1697552059033]
604,604,616,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074784,1697552076890,120,,,"[163, 1274, 134]","[1697552074947, 1697552076221, 1697552076355]"
605,605,608,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069283,1697552071278,120,,,[86],[1697552069369]
606,606,536,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051371,1697552052661,120,,,[65],[1697552051436]
607,607,356,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071285,1697552071972,120,,,[20],[1697552071305]
608,608,9,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071975,1697552073395,120,,,"[19, 1381]","[1697552071994, 1697552073375]"
609,609,189,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552052665,1697552054788,120,,,"[78, 1244]","[1697552052743, 1697552053987]"
610,610,715,17,[],200,llama-13b,64,1,1776.0,1.0,1,A100,1697552073402,1697552075178,120,20.0,1.0,"[140, 1636]","[1697552073542, 1697552075178]"
611,611,405,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062189,1697552063765,120,,,"[10, 806, 46]","[1697552062199, 1697552063005, 1697552063051]"
612,612,835,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059175,1697552060883,120,,,"[91, 1359]","[1697552059266, 1697552060625]"
613,613,193,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055787,1697552057502,120,,,[95],[1697552055882]
614,614,450,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066166,1697552067381,120,,,"[32, 1164]","[1697552066198, 1697552067362]"
615,615,869,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057510,1697552059169,120,,,"[65, 1434]","[1697552057575, 1697552059009]"
616,616,110,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067384,1697552067819,120,,,[69],[1697552067453]
617,617,488,8,[],200,llama-13b,64,1,2117.0,1.0,1,A100,1697552060889,1697552063006,120,6.0,1.0,"[146, 1971]","[1697552061035, 1697552063006]"
618,618,259,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063009,1697552064541,120,,,[25],[1697552063034]
619,619,54,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063773,1697552064879,120,,,[63],[1697552063836]
620,620,246,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064884,1697552066163,120,,,"[84, 1177]","[1697552064968, 1697552066145]"
621,621,849,10,[],200,llama-13b,64,1,1008.0,1.0,1,A100,1697552064545,1697552065553,120,10.0,1.0,"[107, 901]","[1697552064652, 1697552065553]"
622,622,22,11,[],200,llama-13b,64,1,1198.0,1.0,1,A100,1697552066165,1697552067363,120,16.0,1.0,"[23, 1175]","[1697552066188, 1697552067363]"
623,623,638,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059175,1697552060882,120,,,"[76, 1374]","[1697552059251, 1697552060625]"
624,624,331,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063771,1697552064877,120,,,[88],[1697552063859]
625,625,615,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552065556,1697552067381,120,,,[21],[1697552065577]
626,626,643,9,[],200,llama-13b,64,1,1261.0,1.0,1,A100,1697552064884,1697552066145,120,18.0,1.0,"[81, 1180]","[1697552064965, 1697552066145]"
627,627,99,11,[],200,llama-13b,64,1,1262.0,1.0,1,A100,1697552064883,1697552066145,120,10.0,1.0,"[70, 1192]","[1697552064953, 1697552066145]"
628,628,601,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067366,1697552067820,120,,,[41],[1697552067407]
629,629,689,12,[],200,llama-13b,64,1,1214.0,1.0,1,A100,1697552066149,1697552067363,120,15.0,1.0,"[37, 1177]","[1697552066186, 1697552067363]"
630,630,738,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076898,1697552078118,120,,,[24],[1697552076922]
631,631,458,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067368,1697552067820,120,,,[75],[1697552067443]
632,632,391,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078122,1697552079384,120,,,[65],[1697552078187]
633,633,274,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067384,1697552067820,120,,,[99],[1697552067483]
634,634,114,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067824,1697552069274,120,,,[111],[1697552067935]
635,635,299,8,[],200,llama-13b,64,1,2117.0,1.0,1,A100,1697552060889,1697552063006,120,14.0,1.0,"[73, 2044]","[1697552060962, 1697552063006]"
636,636,44,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067825,1697552069274,120,,,[112],[1697552067937]
637,637,820,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 6.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069279,1697552070586,120,,,[22],[1697552069301]
638,638,70,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063010,1697552064541,120,,,[19],[1697552063029]
639,639,169,21,[],200,llama-13b,64,1,1225.0,1.0,1,A100,1697552079401,1697552080626,120,10.0,1.0,"[151, 1074]","[1697552079552, 1697552080626]"
640,640,751,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080629,1697552082120,120,,,[20],[1697552080649]
641,641,656,10,[],200,llama-13b,64,1,1005.0,1.0,1,A100,1697552064548,1697552065553,120,26.0,1.0,"[109, 896]","[1697552064657, 1697552065553]"
642,642,476,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552050151,1697552053353,120,,,"[90, 1645, 809]","[1697552050241, 1697552051886, 1697552052695]"
643,643,434,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552065556,1697552067381,120,,,"[26, 1078]","[1697552065582, 1697552066660]"
644,644,721,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 6.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069279,1697552070586,120,,,[17],[1697552069296]
645,645,526,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082124,1697552083467,120,,,"[41, 1194]","[1697552082165, 1697552083359]"
646,646,183,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083472,1697552083904,120,,,[67],[1697552083539]
647,647,860,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083911,1697552084997,120,,,[141],[1697552084052]
648,648,376,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070591,1697552071972,120,,,[44],[1697552070635]
649,649,85,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067384,1697552067819,120,,,[79],[1697552067463]
650,650,631,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085001,1697552086534,120,,,[36],[1697552085037]
651,651,392,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085000,1697552086533,120,,,[7],[1697552085007]
652,652,180,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062188,1697552063764,120,,,"[6, 812, 45]","[1697552062194, 1697552063006, 1697552063051]"
653,653,674,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063660,1697552064541,120,,,[19],[1697552063679]
654,654,146,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071976,1697552073395,120,,,"[37, 1362]","[1697552072013, 1697552073375]"
655,655,791,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067823,1697552069276,120,,,[64],[1697552067887]
656,656,880,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063770,1697552064877,120,,,[17],[1697552063787]
657,657,47,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086538,1697552087780,120,,,[35],[1697552086573]
658,658,444,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 6.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069279,1697552070587,120,,,[41],[1697552069320]
659,659,723,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087783,1697552088518,120,,,[6],[1697552087789]
660,660,328,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064544,1697552066163,120,,,"[34, 974]","[1697552064578, 1697552065552]"
661,661,253,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053359,1697552055780,120,,,[118],[1697552053477]
662,662,493,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552088520,1697552089317,120,,,"[16, 762]","[1697552088536, 1697552089298]"
663,663,99,11,[],200,llama-13b,64,1,1193.0,1.0,1,A100,1697552066170,1697552067363,120,10.0,1.0,"[181, 1011]","[1697552066351, 1697552067362]"
664,664,836,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055787,1697552057502,120,,,[149],[1697552055936]
665,665,689,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067367,1697552067819,120,,,[71],[1697552067438]
666,666,801,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060888,1697552062307,120,,,"[38, 1259]","[1697552060926, 1697552062185]"
667,667,645,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084687,1697552085754,120,,,[64],[1697552084751]
668,668,631,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053358,1697552055780,120,,,[94],[1697552053452]
669,669,9,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055787,1697552057502,120,,,[86],[1697552055873]
670,670,883,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067822,1697552069274,120,,,[35],[1697552067857]
671,671,148,29,[],200,llama-13b,64,1,1261.0,1.0,1,A100,1697552089322,1697552090583,120,16.0,1.0,"[118, 1143]","[1697552089440, 1697552090583]"
672,672,655,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 6.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069279,1697552070586,120,,,[11],[1697552069290]
673,673,309,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085758,1697552089317,120,,,"[30, 1339, 694, 735]","[1697552085788, 1697552087127, 1697552087821, 1697552088556]"
674,674,537,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053992,1697552055780,120,,,[34],[1697552054026]
675,675,304,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070588,1697552071278,120,,,[21],[1697552070609]
676,676,679,10,[],200,llama-13b,64,1,1262.0,1.0,1,A100,1697552064883,1697552066145,120,15.0,1.0,"[80, 1182]","[1697552064963, 1697552066145]"
677,677,869,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075181,1697552076892,120,,,"[25, 1016, 133]","[1697552075206, 1697552076222, 1697552076355]"
678,678,451,11,[],200,llama-13b,64,1,514.0,1.0,1,A100,1697552066147,1697552066661,120,286.0,1.0,"[11, 503]","[1697552066158, 1697552066661]"
679,679,695,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062311,1697552063766,120,,,"[20, 1324]","[1697552062331, 1697552063655]"
680,680,38,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051371,1697552052660,120,,,[40],[1697552051411]
681,681,52,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071285,1697552071973,120,,,[36],[1697552071321]
682,682,111,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066663,1697552068960,120,,,"[14, 862, 307, 925, 140]","[1697552066677, 1697552067539, 1697552067846, 1697552068771, 1697552068911]"
683,683,348,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063775,1697552064879,120,,,[162],[1697552063937]
684,684,635,18,[],200,llama-13b,64,1,1400.0,1.0,1,A100,1697552071976,1697552073376,120,23.0,1.0,"[42, 1357]","[1697552072018, 1697552073375]"
685,685,168,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055786,1697552057502,120,,,[92],[1697552055878]
686,686,747,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552052664,1697552054789,120,,,"[46, 1276]","[1697552052710, 1697552053986]"
687,687,180,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552061711,1697552063763,120,,,"[19, 1275, 46]","[1697552061730, 1697552063005, 1697552063051]"
688,688,280,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552048412,1697552050146,120,,,[7],[1697552048419]
689,689,869,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057510,1697552059168,120,,,"[41, 1458]","[1697552057551, 1697552059009]"
690,690,401,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054793,1697552056509,120,,,[26],[1697552054819]
691,691,540,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059901,1697552062308,120,,,"[26, 1781]","[1697552059927, 1697552061708]"
692,692,864,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552050151,1697552053353,120,,,"[40, 1695, 809]","[1697552050191, 1697552051886, 1697552052695]"
693,693,612,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051373,1697552052661,120,,,[84],[1697552051457]
694,694,635,3,[],200,llama-13b,64,1,1256.0,1.0,1,A100,1697552053355,1697552054611,120,23.0,1.0,"[14, 1242]","[1697552053369, 1697552054611]"
695,695,175,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552047639,1697552050146,120,,,[220],[1697552047859]
696,696,522,7,[],200,llama-13b,64,1,1450.0,1.0,1,A100,1697552059175,1697552060625,120,20.0,1.0,"[61, 1389]","[1697552059236, 1697552060625]"
697,697,684,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074781,1697552075452,120,,,[21],[1697552074802]
698,698,295,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054613,1697552055781,120,,,[21],[1697552054634]
699,699,299,8,[],200,llama-13b,64,1,1072.0,1.0,1,A100,1697552060636,1697552061708,120,14.0,1.0,"[26, 1046]","[1697552060662, 1697552061708]"
700,700,312,20,[],200,llama-13b,64,1,1314.0,1.0,1,A100,1697552075468,1697552076782,120,23.0,1.0,"[92, 1222]","[1697552075560, 1697552076782]"
701,701,880,9,[],200,llama-13b,64,1,1340.0,1.0,1,A100,1697552061711,1697552063051,120,84.0,2.0,"[24, 1270, 46]","[1697552061735, 1697552063005, 1697552063051]"
702,702,764,1,[],200,llama-13b,64,1,1736.0,1.0,1,A100,1697552050151,1697552051887,120,39.0,1.0,"[48, 1687]","[1697552050199, 1697552051886]"
703,703,660,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063053,1697552064541,120,,,[9],[1697552063062]
704,704,80,21,[],200,llama-13b,64,1,493.0,1.0,1,A100,1697552076784,1697552077277,120,13.0,1.0,"[17, 476]","[1697552076801, 1697552077277]"
705,705,534,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051890,1697552053353,120,,,"[23, 1378]","[1697552051913, 1697552053291]"
706,706,742,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067822,1697552069275,120,,,[45],[1697552067867]
707,707,469,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070589,1697552071278,120,,,[34],[1697552070623]
708,708,670,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552077280,1697552079384,120,,,"[20, 1281, 52]","[1697552077300, 1697552078581, 1697552078633]"
709,709,215,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071288,1697552072658,120,,,[67],[1697552071355]
710,710,314,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064544,1697552066164,120,,,"[39, 969]","[1697552064583, 1697552065552]"
711,711,913,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072662,1697552074777,120,,,"[108, 1285]","[1697552072770, 1697552074055]"
712,712,694,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084688,1697552085754,120,,,[73],[1697552084761]
713,713,348,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085757,1697552089317,120,,,"[19, 1350, 695, 735]","[1697552085776, 1697552087126, 1697552087821, 1697552088556]"
714,714,575,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074781,1697552075453,120,,,[62],[1697552074843]
715,715,164,3,[],200,llama-13b,64,1,1253.0,1.0,1,A100,1697552053358,1697552054611,120,15.0,1.0,"[79, 1174]","[1697552053437, 1697552054611]"
716,716,346,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075457,1697552076890,120,,,"[25, 740, 134]","[1697552075482, 1697552076222, 1697552076356]"
717,717,85,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066166,1697552067382,120,,,"[93, 1103]","[1697552066259, 1697552067362]"
718,718,675,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067384,1697552067819,120,,,[86],[1697552067470]
719,719,25,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.65 GiB. GPU 0 has a total capacty of 39.39 GiB of which 484.06 MiB is free. Process 1449637 has 38.92 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049044,1697552050146,120,,,[36],[1697552049080]
720,720,127,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080628,1697552082120,120,,,"[16, 866]","[1697552080644, 1697552081510]"
721,721,405,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059900,1697552062307,120,,,"[17, 1790]","[1697552059917, 1697552061707]"
722,722,701,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552050150,1697552053353,120,,,"[44, 1691, 810]","[1697552050194, 1697552051885, 1697552052695]"
723,723,37,9,[],200,llama-13b,64,1,1340.0,1.0,1,A100,1697552062315,1697552063655,120,20.0,1.0,"[66, 1274]","[1697552062381, 1697552063655]"
724,724,469,3,[],200,llama-13b,64,1,1253.0,1.0,1,A100,1697552053358,1697552054611,120,17.0,1.0,"[89, 1164]","[1697552053447, 1697552054611]"
725,725,709,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082129,1697552083672,120,,,[136],[1697552082265]
726,726,734,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063657,1697552064541,120,,,[7],[1697552063664]
727,727,457,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083678,1697552084681,120,,,[20],[1697552083698]
728,728,130,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054614,1697552055781,120,,,[10],[1697552054624]
729,729,611,5,[],200,llama-13b,64,1,1499.0,1.0,1,A100,1697552057511,1697552059010,120,14.0,1.0,"[79, 1419]","[1697552057590, 1697552059009]"
730,730,216,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070589,1697552071972,120,,,[40],[1697552070629]
731,731,108,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084686,1697552085754,120,,,[25],[1697552084711]
732,732,593,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057506,1697552059169,120,,,"[25, 1477]","[1697552057531, 1697552059008]"
733,733,264,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059014,1697552060883,120,,,"[32, 852]","[1697552059046, 1697552059898]"
734,734,814,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085758,1697552089317,120,,,"[77, 1292, 694, 735]","[1697552085835, 1697552087127, 1697552087821, 1697552088556]"
735,735,332,5,[],200,llama-13b,64,1,1499.0,1.0,1,A100,1697552057510,1697552059009,120,39.0,1.0,"[70, 1429]","[1697552057580, 1697552059009]"
736,736,421,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053992,1697552055781,120,,,[34],[1697552054026]
737,737,169,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055787,1697552057502,120,,,[152],[1697552055939]
738,738,385,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076898,1697552078118,120,,,[19],[1697552076917]
739,739,394,11,[],200,llama-13b,64,1,1008.0,1.0,1,A100,1697552064545,1697552065553,120,11.0,1.0,"[107, 900]","[1697552064652, 1697552065552]"
740,740,12,7,[],200,llama-13b,64,1,2117.0,1.0,1,A100,1697552060889,1697552063006,120,11.0,1.0,"[83, 2034]","[1697552060972, 1697552063006]"
741,741,52,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552056513,1697552059168,120,,,"[37, 1636]","[1697552056550, 1697552058186]"
742,742,709,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063015,1697552064541,120,,,[34],[1697552063049]
743,743,868,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057510,1697552059169,120,,,"[75, 1424]","[1697552057585, 1697552059009]"
744,744,360,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074781,1697552075458,120,,,[76],[1697552074857]
745,745,60,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552052662,1697552053353,120,,,[18],[1697552052680]
746,746,756,4,[],200,llama-13b,64,1,1253.0,1.0,1,A100,1697552053358,1697552054611,120,19.0,1.0,"[50, 1203]","[1697552053408, 1697552054611]"
747,747,527,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059179,1697552062307,120,,,"[180, 2349]","[1697552059359, 1697552061708]"
748,748,296,8,[],200,llama-13b,64,1,1343.0,1.0,1,A100,1697552062312,1697552063655,120,6.0,1.0,"[39, 1304]","[1697552062351, 1697552063655]"
749,749,886,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063658,1697552064541,120,,,[11],[1697552063669]
750,750,417,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054614,1697552055781,120,,,[30],[1697552054644]
751,751,102,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059012,1697552060883,120,,,"[15, 871]","[1697552059027, 1697552059898]"
752,752,691,7,[],200,llama-13b,64,1,2114.0,1.0,1,A100,1697552060892,1697552063006,120,47.0,1.0,"[148, 1965]","[1697552061040, 1697552063005]"
753,753,660,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064544,1697552066164,120,,,"[44, 964]","[1697552064588, 1697552065552]"
754,754,747,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059175,1697552060883,120,,,"[81, 1369]","[1697552059256, 1697552060625]"
755,755,186,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055785,1697552057501,120,,,[31],[1697552055816]
756,756,461,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063011,1697552064541,120,,,[33],[1697552063044]
757,757,771,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057506,1697552059169,120,,,"[15, 1488]","[1697552057521, 1697552059009]"
758,758,617,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076899,1697552078119,120,,,[48],[1697552076947]
759,759,218,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067384,1697552068961,120,,,"[114, 1273, 140]","[1697552067498, 1697552068771, 1697552068911]"
760,760,551,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059175,1697552060883,120,,,"[88, 1362]","[1697552059263, 1697552060625]"
761,761,388,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078122,1697552079384,120,,,"[70, 1056]","[1697552078192, 1697552079248]"
762,762,408,8,[],200,llama-13b,64,1,1300.0,1.0,1,A100,1697552060886,1697552062186,120,16.0,1.0,"[30, 1269]","[1697552060916, 1697552062185]"
763,763,120,9,[],200,llama-13b,64,1,1008.0,1.0,1,A100,1697552064545,1697552065553,120,17.0,1.0,"[92, 916]","[1697552064637, 1697552065553]"
764,764,70,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054796,1697552056509,120,,,[61],[1697552054857]
765,765,808,11,[],200,llama-13b,64,1,1660.0,1.0,1,A100,1697552068967,1697552070627,120,286.0,2.0,"[81, 983, 596]","[1697552069048, 1697552070031, 1697552070627]"
766,766,49,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079395,1697552082119,120,,,"[65, 2049]","[1697552079460, 1697552081509]"
767,767,60,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063775,1697552064878,120,,,[104],[1697552063879]
768,768,737,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064883,1697552066164,120,,,"[36, 1225]","[1697552064919, 1697552066144]"
769,769,748,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082123,1697552083469,120,,,[12],[1697552082135]
770,770,175,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062188,1697552063765,120,,,"[6, 857]","[1697552062194, 1697552063051]"
771,771,193,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062312,1697552063764,120,,,[54],[1697552062366]
772,772,581,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070629,1697552071973,120,,,[13],[1697552070642]
773,773,811,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067823,1697552069274,120,,,[44],[1697552067867]
774,774,389,3,[],200,llama-13b,64,1,1323.0,1.0,1,A100,1697552052664,1697552053987,120,8.0,1.0,"[76, 1247]","[1697552052740, 1697552053987]"
775,775,211,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071984,1697552073396,120,,,"[54, 1338]","[1697552072038, 1697552073376]"
776,776,776,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552056512,1697552059167,120,,,"[7, 1666]","[1697552056519, 1697552058185]"
777,777,464,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069283,1697552071281,120,,,[161],[1697552069444]
778,778,910,14,[],200,llama-13b,64,1,1356.0,1.0,1,A100,1697552073402,1697552074758,120,8.0,1.0,"[78, 1278]","[1697552073480, 1697552074758]"
779,779,213,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071284,1697552071974,120,,,[11],[1697552071295]
780,780,571,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074760,1697552075452,120,,,[22],[1697552074782]
781,781,911,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071978,1697552073396,120,,,"[46, 1351]","[1697552072024, 1697552073375]"
782,782,703,11,[],200,llama-13b,64,1,1008.0,1.0,1,A100,1697552064545,1697552065553,120,12.0,1.0,"[102, 905]","[1697552064647, 1697552065552]"
783,783,103,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054796,1697552056509,120,,,[56],[1697552054852]
784,784,690,5,[],200,llama-13b,64,1,1672.0,1.0,1,A100,1697552056515,1697552058187,120,39.0,1.0,"[48, 1623]","[1697552056563, 1697552058186]"
785,785,545,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062311,1697552063763,120,,,"[46, 1298]","[1697552062357, 1697552063655]"
786,786,866,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054795,1697552056509,120,,,[45],[1697552054840]
787,787,637,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552056512,1697552059167,120,,,"[11, 1662]","[1697552056523, 1697552058185]"
788,788,534,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064884,1697552066162,120,,,"[75, 1185]","[1697552064959, 1697552066144]"
789,789,298,6,[],200,llama-13b,64,1,1453.0,1.0,1,A100,1697552059172,1697552060625,120,17.0,1.0,"[35, 1417]","[1697552059207, 1697552060624]"
790,790,200,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063770,1697552064877,120,,,[13],[1697552063783]
791,791,311,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066164,1697552067382,120,,,[27],[1697552066191]
792,792,899,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064883,1697552066163,120,,,"[11, 1250]","[1697552064894, 1697552066144]"
793,793,893,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067387,1697552067820,120,,,[93],[1697552067480]
794,794,456,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053357,1697552054789,120,,,"[17, 1237]","[1697552053374, 1697552054611]"
795,795,825,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055786,1697552057502,120,,,[53],[1697552055839]
796,796,116,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054793,1697552056509,120,,,[46],[1697552054839]
797,797,480,6,[],200,llama-13b,64,1,1498.0,1.0,1,A100,1697552057512,1697552059010,120,26.0,1.0,"[142, 1356]","[1697552057654, 1697552059010]"
798,798,460,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552058190,1697552060883,120,,,"[35, 1673]","[1697552058225, 1697552059898]"
799,799,125,11,[],200,llama-13b,64,1,1773.0,1.0,1,A100,1697552064887,1697552066660,120,13.0,1.0,"[158, 1615]","[1697552065045, 1697552066660]"
800,800,430,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051374,1697552052661,120,,,[81],[1697552051455]
801,801,68,7,[],200,llama-13b,64,1,1073.0,1.0,1,A100,1697552060636,1697552061709,120,12.0,1.0,"[30, 1042]","[1697552060666, 1697552061708]"
802,802,847,30,[],200,llama-13b,64,1,1259.0,1.0,1,A100,1697552090587,1697552091846,120,10.0,1.0,"[29, 1230]","[1697552090616, 1697552091846]"
803,803,468,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089321,1697552090605,120,,,"[61, 1202]","[1697552089382, 1697552090584]"
804,804,38,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060886,1697552062307,120,,,"[15, 1284]","[1697552060901, 1697552062185]"
805,805,652,8,[],200,llama-13b,64,1,1294.0,1.0,1,A100,1697552061712,1697552063006,120,14.0,1.0,"[38, 1256]","[1697552061750, 1697552063006]"
806,806,257,7,[],200,llama-13b,64,1,883.0,1.0,1,A100,1697552059015,1697552059898,120,14.0,1.0,"[36, 847]","[1697552059051, 1697552059898]"
807,807,733,8,[],200,llama-13b,64,1,1344.0,1.0,1,A100,1697552062311,1697552063655,120,31.0,1.0,"[26, 1318]","[1697552062337, 1697552063655]"
808,808,840,8,[],200,llama-13b,64,1,1805.0,1.0,1,A100,1697552059903,1697552061708,120,17.0,1.0,"[19, 1786]","[1697552059922, 1697552061708]"
809,809,42,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053992,1697552055781,120,,,[29],[1697552054021]
810,810,242,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090608,1697552093264,120,,,"[148, 1982]","[1697552090756, 1697552092738]"
811,811,349,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067823,1697552069275,120,,,[49],[1697552067872]
812,812,884,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051371,1697552052660,120,,,[40],[1697552051411]
813,813,742,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055786,1697552057502,120,,,[52],[1697552055838]
814,814,404,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057509,1697552059167,120,,,"[32, 1468]","[1697552057541, 1697552059009]"
815,815,84,3,[],200,llama-13b,64,1,1320.0,1.0,1,A100,1697552052666,1697552053986,120,26.0,1.0,"[95, 1225]","[1697552052761, 1697552053986]"
816,816,173,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059175,1697552060882,120,,,"[70, 1380]","[1697552059245, 1697552060625]"
817,817,1,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069283,1697552071281,120,,,[156],[1697552069439]
818,818,474,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062309,1697552063765,120,,,[7],[1697552062316]
819,819,707,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071289,1697552072656,120,,,[81],[1697552071370]
820,820,219,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055785,1697552057502,120,,,[41],[1697552055826]
821,821,96,27,[],200,llama-13b,64,1,1870.0,1.0,1,A100,1697552089324,1697552091194,120,31.0,1.0,"[150, 1720]","[1697552089474, 1697552091194]"
822,822,251,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063774,1697552064879,120,,,[83],[1697552063857]
823,823,678,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091197,1697552093264,120,,,"[6, 1535]","[1697552091203, 1697552092738]"
824,824,570,17,[],200,llama-13b,64,1,1776.0,1.0,1,A100,1697552073402,1697552075178,120,18.0,1.0,"[141, 1635]","[1697552073543, 1697552075178]"
825,825,453,29,[],200,llama-13b,64,1,1098.0,1.0,1,A100,1697552093269,1697552094367,120,26.0,1.0,"[44, 1054]","[1697552093313, 1697552094367]"
826,826,832,11,[],200,llama-13b,64,1,1262.0,1.0,1,A100,1697552064883,1697552066145,120,15.0,1.0,"[75, 1187]","[1697552064958, 1697552066145]"
827,827,110,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094370,1697552096114,120,,,"[17, 1048]","[1697552094387, 1697552095435]"
828,828,343,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075181,1697552076892,120,,,"[11, 1029, 134]","[1697552075192, 1697552076221, 1697552076355]"
829,829,816,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096120,1697552098825,120,,,"[138, 1970]","[1697552096258, 1697552098228]"
830,830,866,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054614,1697552055781,120,,,[25],[1697552054639]
831,831,576,12,[],200,llama-13b,64,1,514.0,1.0,1,A100,1697552066147,1697552066661,120,14.0,1.0,"[10, 503]","[1697552066157, 1697552066660]"
832,832,24,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552052662,1697552053353,120,,,[23],[1697552052685]
833,833,346,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066663,1697552068960,120,,,"[6, 870, 307, 925, 140]","[1697552066669, 1697552067539, 1697552067846, 1697552068771, 1697552068911]"
834,834,401,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055785,1697552057501,120,,,[26],[1697552055811]
835,835,669,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067824,1697552069276,120,,,[63],[1697552067887]
836,836,527,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055788,1697552057503,120,,,[166],[1697552055954]
837,837,318,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 6.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069283,1697552070587,120,,,[80],[1697552069363]
838,838,298,6,[],200,llama-13b,64,1,1499.0,1.0,1,A100,1697552057511,1697552059010,120,17.0,1.0,"[128, 1371]","[1697552057639, 1697552059010]"
839,839,94,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070589,1697552071278,120,,,[29],[1697552070618]
840,840,679,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071288,1697552072657,120,,,[72],[1697552071360]
841,841,448,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072659,1697552074777,120,,,"[26, 1369]","[1697552072685, 1697552074054]"
842,842,881,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059014,1697552060883,120,,,"[34, 850]","[1697552059048, 1697552059898]"
843,843,149,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057510,1697552060882,120,,,"[66, 2321]","[1697552057576, 1697552059897]"
844,844,657,8,[],200,llama-13b,64,1,1297.0,1.0,1,A100,1697552060889,1697552062186,120,10.0,1.0,"[56, 1241]","[1697552060945, 1697552062186]"
845,845,81,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074781,1697552075456,120,,,[80],[1697552074861]
846,846,704,4,[],200,llama-13b,64,1,1253.0,1.0,1,A100,1697552053358,1697552054611,120,14.0,1.0,"[37, 1216]","[1697552053395, 1697552054611]"
847,847,777,20,[],200,llama-13b,64,1,764.0,1.0,1,A100,1697552075458,1697552076222,120,9.0,1.0,"[20, 744]","[1697552075478, 1697552076222]"
848,848,474,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054614,1697552055781,120,,,[15],[1697552054629]
849,849,129,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055793,1697552057502,120,,,[166],[1697552055959]
850,850,438,21,[],200,llama-13b,64,1,1051.0,1.0,1,A100,1697552076226,1697552077277,120,9.0,1.0,"[25, 1026]","[1697552076251, 1697552077277]"
851,851,1,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068963,1697552073394,120,,,"[12, 1055, 596, 698, 686, 684]","[1697552068975, 1697552070030, 1697552070626, 1697552071324, 1697552072010, 1697552072694]"
852,852,121,7,[],200,llama-13b,64,1,2116.0,1.0,1,A100,1697552060890,1697552063006,120,13.0,1.0,"[82, 2034]","[1697552060972, 1697552063006]"
853,853,818,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063010,1697552064541,120,,,[29],[1697552063039]
854,854,211,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552077286,1697552079384,120,,,"[30, 1266, 51]","[1697552077316, 1697552078582, 1697552078633]"
855,855,835,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057508,1697552059169,120,,,"[28, 1473]","[1697552057536, 1697552059009]"
856,856,341,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059175,1697552060884,120,,,"[93, 1357]","[1697552059268, 1697552060625]"
857,857,110,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060892,1697552063763,120,,,"[153, 1960, 46]","[1697552061045, 1697552063005, 1697552063051]"
858,858,489,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059175,1697552060882,120,,,"[179, 1271]","[1697552059354, 1697552060625]"
859,859,506,11,[],200,llama-13b,64,1,1194.0,1.0,1,A100,1697552066168,1697552067362,120,16.0,1.0,"[115, 1079]","[1697552066283, 1697552067362]"
860,860,707,15,[],200,llama-13b,64,1,1777.0,1.0,1,A100,1697552073402,1697552075179,120,8.0,1.0,"[155, 1622]","[1697552073557, 1697552075179]"
861,861,145,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068624,1697552069275,120,,,[30],[1697552068654]
862,862,167,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067365,1697552067818,120,,,[16],[1697552067381]
863,863,80,26,[],200,llama-13b,64,1,1262.0,1.0,1,A100,1697552089321,1697552090583,120,13.0,1.0,"[26, 1236]","[1697552089347, 1697552090583]"
864,864,864,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067822,1697552069274,120,,,[30],[1697552067852]
865,865,667,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090587,1697552091869,120,,,"[14, 593]","[1697552090601, 1697552091194]"
866,866,819,10,[],200,llama-13b,64,1,1104.0,1.0,1,A100,1697552065557,1697552066661,120,13.0,1.0,"[30, 1073]","[1697552065587, 1697552066660]"
867,867,810,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068964,1697552073394,120,,,"[11, 1056, 595, 698, 686, 684]","[1697552068975, 1697552070031, 1697552070626, 1697552071324, 1697552072010, 1697552072694]"
868,868,528,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 6.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069279,1697552070586,120,,,[27],[1697552069306]
869,869,708,12,[],200,llama-13b,64,1,876.0,1.0,1,A100,1697552066663,1697552067539,120,140.0,1.0,"[19, 857]","[1697552066682, 1697552067539]"
870,870,298,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070589,1697552071278,120,,,[19],[1697552070608]
871,871,882,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071286,1697552072656,120,,,[49],[1697552071335]
872,872,659,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072666,1697552074777,120,,,"[100, 1289]","[1697552072766, 1697552074055]"
873,873,483,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066664,1697552068960,120,,,"[23, 853, 306, 925, 140]","[1697552066687, 1697552067540, 1697552067846, 1697552068771, 1697552068911]"
874,874,763,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063770,1697552064877,120,,,[19],[1697552063789]
875,875,482,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067541,1697552068961,120,,,"[42, 1037, 151, 140]","[1697552067583, 1697552068620, 1697552068771, 1697552068911]"
876,876,312,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074784,1697552075456,120,,,[178],[1697552074962]
877,877,437,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091872,1697552093476,120,,,[106],[1697552091978]
878,878,59,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075460,1697552076892,120,,,"[91, 1231]","[1697552075551, 1697552076782]"
879,879,508,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091863,1697552093264,120,,,"[23, 1277]","[1697552091886, 1697552093163]"
880,880,641,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076899,1697552078118,120,,,[28],[1697552076927]
881,881,97,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093483,1697552096114,120,,,"[73, 1879]","[1697552093556, 1697552095435]"
882,882,414,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078124,1697552079385,120,,,"[124, 1000]","[1697552078248, 1697552079248]"
883,883,70,22,[],200,llama-13b,64,1,2110.0,1.0,1,A100,1697552079400,1697552081510,120,39.0,1.0,"[147, 1963]","[1697552079547, 1697552081510]"
884,884,280,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093270,1697552094764,120,,,"[81, 1016]","[1697552093351, 1697552094367]"
885,885,851,12,[],200,llama-13b,64,1,1229.0,1.0,1,A100,1697552067392,1697552068621,120,23.0,1.0,"[167, 1062]","[1697552067559, 1697552068621]"
886,886,862,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094770,1697552096115,120,,,[35],[1697552094805]
887,887,429,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063009,1697552064541,120,,,[6],[1697552063015]
888,888,798,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096118,1697552097350,120,,,[16],[1697552096134]
889,889,82,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064544,1697552066164,120,,,"[38, 970]","[1697552064582, 1697552065552]"
890,890,511,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068624,1697552069275,120,,,[34],[1697552068658]
891,891,833,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093267,1697552094765,120,,,"[21, 1079]","[1697552093288, 1697552094367]"
892,892,481,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063659,1697552064542,120,,,[20],[1697552063679]
893,893,451,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097354,1697552099702,120,,,[105],[1697552097459]
894,894,788,11,[],200,llama-13b,64,1,1195.0,1.0,1,A100,1697552066168,1697552067363,120,31.0,1.0,"[179, 1015]","[1697552066347, 1697552067362]"
895,895,659,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.30 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552052669,1697552054789,120,,,"[97, 1220]","[1697552052766, 1697552053986]"
896,896,280,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069283,1697552071278,120,,,[90],[1697552069373]
897,897,27,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071288,1697552072656,120,,,[77],[1697552071365]
898,898,436,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067366,1697552067819,120,,,[38],[1697552067404]
899,899,789,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053991,1697552055781,120,,,[20],[1697552054011]
900,900,199,32,[],200,llama-13b,64,1,1375.0,1.0,1,A100,1697552099715,1697552101090,120,13.0,1.0,"[47, 1328]","[1697552099762, 1697552101090]"
901,901,360,16,[],200,llama-13b,64,1,1395.0,1.0,1,A100,1697552072660,1697552074055,120,16.0,1.0,"[91, 1304]","[1697552072751, 1697552074055]"
902,902,602,28,[],200,llama-13b,64,1,1219.0,1.0,1,A100,1697552094772,1697552095991,120,15.0,1.0,"[90, 1129]","[1697552094862, 1697552095991]"
903,903,132,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074058,1697552076890,120,,,"[6, 1113, 309, 869]","[1697552074064, 1697552075177, 1697552075486, 1697552076355]"
904,904,610,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072659,1697552074778,120,,,"[54, 1342]","[1697552072713, 1697552074055]"
905,905,893,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101092,1697552102448,120,,,"[15, 1239]","[1697552101107, 1697552102346]"
906,906,810,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057506,1697552059169,120,,,"[20, 1482]","[1697552057526, 1697552059008]"
907,907,377,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074784,1697552075456,120,,,[175],[1697552074959]
908,908,553,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102452,1697552103819,120,,,"[40, 1203]","[1697552102492, 1697552103695]"
909,909,261,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552095995,1697552097350,120,,,[31],[1697552096026]
910,910,38,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075460,1697552076891,120,,,"[77, 1245]","[1697552075537, 1697552076782]"
911,911,356,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552065555,1697552067381,120,,,"[10, 1095]","[1697552065565, 1697552066660]"
912,912,0,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076899,1697552078119,120,,,[38],[1697552076937]
913,913,323,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103825,1697552105088,120,,,"[58, 1184]","[1697552103883, 1697552105067]"
914,914,285,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086538,1697552088517,120,,,[104],[1697552086642]
915,915,705,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078125,1697552079388,120,,,"[130, 993]","[1697552078255, 1697552079248]"
916,916,62,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552088520,1697552089317,120,,,"[21, 757]","[1697552088541, 1697552089298]"
917,917,642,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089321,1697552090604,120,,,"[36, 1226]","[1697552089357, 1697552090583]"
918,918,30,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097355,1697552099703,120,,,[94],[1697552097449]
919,919,579,5,[],200,llama-13b,64,1,1448.0,1.0,1,A100,1697552059177,1697552060625,120,19.0,1.0,"[109, 1339]","[1697552059286, 1697552060625]"
920,920,419,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090607,1697552091870,120,,,"[52, 1188]","[1697552090659, 1697552091847]"
921,921,737,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076899,1697552078119,120,,,[43],[1697552076942]
922,922,234,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060636,1697552062308,120,,,"[6, 1066]","[1697552060642, 1697552061708]"
923,923,395,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078122,1697552079384,120,,,"[64, 1062]","[1697552078186, 1697552079248]"
924,924,69,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091873,1697552093477,120,,,[165],[1697552092038]
925,925,707,31,[],200,llama-13b,64,1,2036.0,1.0,1,A100,1697552099716,1697552101752,120,8.0,1.0,"[69, 1967]","[1697552099785, 1697552101752]"
926,926,907,36,[],200,llama-13b,64,1,1398.0,1.0,1,A100,1697552105092,1697552106490,120,10.0,1.0,"[57, 1341]","[1697552105149, 1697552106490]"
927,927,363,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101755,1697552103818,120,,,"[19, 1527]","[1697552101774, 1697552103301]"
928,928,165,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079395,1697552082120,120,,,"[147, 1968]","[1697552079542, 1697552081510]"
929,929,770,32,[],200,llama-13b,64,1,1952.0,1.0,1,A100,1697552093484,1697552095436,120,13.0,1.0,"[154, 1798]","[1697552093638, 1697552095436]"
930,930,684,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106493,1697552107867,120,,,"[25, 1235]","[1697552106518, 1697552107753]"
931,931,128,33,[],200,llama-13b,64,1,1244.0,1.0,1,A100,1697552103823,1697552105067,120,9.0,1.0,"[12, 1232]","[1697552103835, 1697552105067]"
932,932,337,38,[],200,llama-13b,64,1,1329.0,1.0,1,A100,1697552107876,1697552109205,120,12.0,1.0,"[85, 1244]","[1697552107961, 1697552109205]"
933,933,114,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109210,1697552110136,120,,,[31],[1697552109241]
934,934,719,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105070,1697552106519,120,,,[10],[1697552105080]
935,935,524,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080748,1697552082119,120,,,"[20, 1233]","[1697552080768, 1697552082001]"
936,936,11,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062312,1697552063763,120,,,"[39, 1303]","[1697552062351, 1697552063654]"
937,937,699,40,[],200,llama-13b,64,1,973.0,1.0,1,A100,1697552110140,1697552111113,120,39.0,1.0,"[33, 940]","[1697552110173, 1697552111113]"
938,938,597,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063770,1697552064877,120,,,[22],[1697552063792]
939,939,430,33,[],200,llama-13b,64,1,1264.0,1.0,1,A100,1697552095439,1697552096703,120,15.0,1.0,"[23, 1241]","[1697552095462, 1697552096703]"
940,940,486,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106526,1697552109322,120,,,"[147, 2017]","[1697552106673, 1697552108690]"
941,941,343,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064883,1697552066164,120,,,"[63, 1199]","[1697552064946, 1697552066145]"
942,942,147,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109334,1697552110462,120,,,[21],[1697552109355]
943,943,113,10,[],200,llama-13b,64,1,1195.0,1.0,1,A100,1697552066168,1697552067363,120,13.0,1.0,"[173, 1021]","[1697552066341, 1697552067362]"
944,944,200,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096706,1697552098825,120,,,"[6, 1516]","[1697552096712, 1697552098228]"
945,945,845,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110468,1697552111925,120,,,"[82, 1265]","[1697552110550, 1697552111815]"
946,946,735,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073399,1697552074777,120,,,"[13, 1345]","[1697552073412, 1697552074757]"
947,947,501,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111931,1697552113424,120,,,[125],[1697552112056]
948,948,703,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067368,1697552067820,120,,,[78],[1697552067446]
949,949,458,13,[],200,llama-13b,64,1,799.0,1.0,1,A100,1697552067822,1697552068621,120,11.0,1.0,"[10, 789]","[1697552067832, 1697552068621]"
950,950,471,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098828,1697552101106,120,,,"[27, 1675, 51]","[1697552098855, 1697552100530, 1697552100581]"
951,951,447,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111119,1697552112677,120,,,[35],[1697552111154]
952,952,508,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074784,1697552076891,120,,,"[168, 1269, 134]","[1697552074952, 1697552076221, 1697552076355]"
953,953,241,33,[],200,llama-13b,64,1,1235.0,1.0,1,A100,1697552101112,1697552102347,120,19.0,1.0,"[33, 1202]","[1697552101145, 1697552102347]"
954,954,278,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113431,1697552115114,120,,,[122],[1697552113553]
955,955,100,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112681,1697552114139,120,,,[9],[1697552112690]
956,956,800,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552114145,1697552116440,120,,,[35],[1697552114180]
957,957,474,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067822,1697552069274,120,,,[35],[1697552067857]
958,958,461,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116446,1697552117622,120,,,[45],[1697552116491]
959,959,831,34,[],200,llama-13b,64,1,950.0,1.0,1,A100,1697552102351,1697552103301,120,11.0,1.0,"[15, 935]","[1697552102366, 1697552103301]"
960,960,127,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 6.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069279,1697552070586,120,,,[12],[1697552069291]
961,961,599,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103305,1697552105087,120,,,"[32, 1169]","[1697552103337, 1697552104506]"
962,962,117,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068623,1697552069275,120,,,[25],[1697552068648]
963,963,230,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117626,1697552118449,120,,,[18],[1697552117644]
964,964,816,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 6.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069279,1697552070586,120,,,[26],[1697552069305]
965,965,834,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070587,1697552071277,120,,,[6],[1697552070593]
966,966,811,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552056514,1697552059168,120,,,"[39, 1633]","[1697552056553, 1697552058186]"
967,967,483,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071287,1697552072657,120,,,[59],[1697552071346]
968,968,819,46,[],200,llama-13b,64,1,1495.0,1.0,1,A100,1697552118455,1697552119950,120,13.0,1.0,"[109, 1386]","[1697552118564, 1697552119950]"
969,969,479,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064544,1697552066163,120,,,"[43, 965]","[1697552064587, 1697552065552]"
970,970,467,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059173,1697552060882,120,,,[33],[1697552059206]
971,971,403,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083473,1697552083904,120,,,[82],[1697552083555]
972,972,243,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060889,1697552062307,120,,,"[50, 1247]","[1697552060939, 1697552062186]"
973,973,204,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064883,1697552066164,120,,,"[26, 1235]","[1697552064909, 1697552066144]"
974,974,248,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066167,1697552067382,120,,,"[97, 1098]","[1697552066264, 1697552067362]"
975,975,826,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062311,1697552063763,120,,,"[30, 1314]","[1697552062341, 1697552063655]"
976,976,833,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067387,1697552068960,120,,,"[98, 1135, 151, 140]","[1697552067485, 1697552068620, 1697552068771, 1697552068911]"
977,977,584,47,[],200,llama-13b,64,1,728.0,1.0,1,A100,1697552119953,1697552120681,120,10.0,1.0,"[33, 695]","[1697552119986, 1697552120681]"
978,978,164,12,[],200,llama-13b,64,1,1103.0,1.0,1,A100,1697552065558,1697552066661,120,15.0,1.0,"[34, 1069]","[1697552065592, 1697552066661]"
979,979,180,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083910,1697552084996,120,,,[74],[1697552083984]
980,980,881,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066167,1697552067381,120,,,"[87, 1108]","[1697552066254, 1697552067362]"
981,981,573,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063770,1697552064877,120,,,[13],[1697552063783]
982,982,694,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063771,1697552064879,120,,,[73],[1697552063844]
983,983,576,12,[],200,llama-13b,64,1,1068.0,1.0,1,A100,1697552068964,1697552070032,120,14.0,1.0,"[36, 1031]","[1697552069000, 1697552070031]"
984,984,246,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120684,1697552122073,120,,,[31],[1697552120715]
985,985,464,10,[],200,llama-13b,64,1,1773.0,1.0,1,A100,1697552064887,1697552066660,120,12.0,1.0,"[154, 1619]","[1697552065041, 1697552066660]"
986,986,230,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070035,1697552071277,120,,,[24],[1697552070059]
987,987,538,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067387,1697552068961,120,,,"[113, 1120, 151, 141]","[1697552067500, 1697552068620, 1697552068771, 1697552068912]"
988,988,342,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064882,1697552066163,120,,,"[20, 1242]","[1697552064902, 1697552066144]"
989,989,748,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066663,1697552068960,120,,,"[11, 1172, 925, 140]","[1697552066674, 1697552067846, 1697552068771, 1697552068911]"
990,990,17,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122077,1697552123844,120,,,[33],[1697552122110]
991,991,528,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068963,1697552073394,120,,,"[17, 1051, 595, 698, 686, 684]","[1697552068980, 1697552070031, 1697552070626, 1697552071324, 1697552072010, 1697552072694]"
992,992,7,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071286,1697552072657,120,,,[54],[1697552071340]
993,993,599,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123847,1697552125687,120,,,[43],[1697552123890]
994,994,588,15,[],200,llama-13b,64,1,1394.0,1.0,1,A100,1697552072661,1697552074055,120,11.0,1.0,"[44, 1349]","[1697552072705, 1697552074054]"
995,995,172,5,[],200,llama-13b,64,1,1669.0,1.0,1,A100,1697552056517,1697552058186,120,19.0,1.0,"[121, 1547]","[1697552056638, 1697552058185]"
996,996,347,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125691,1697552127341,120,,,[53],[1697552125744]
997,997,2,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066166,1697552067381,120,,,"[81, 1115]","[1697552066247, 1697552067362]"
998,998,364,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074064,1697552076890,120,,,"[10, 1104, 308, 869]","[1697552074074, 1697552075178, 1697552075486, 1697552076355]"
999,999,12,18,[],200,llama-13b,64,1,1315.0,1.0,1,A100,1697552075468,1697552076783,120,11.0,1.0,"[93, 1221]","[1697552075561, 1697552076782]"
1000,1000,17,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076901,1697552078118,120,,,[75],[1697552076976]
1001,1001,718,19,[],200,llama-13b,64,1,491.0,1.0,1,A100,1697552076786,1697552077277,120,13.0,1.0,"[11, 480]","[1697552076797, 1697552077277]"
1002,1002,371,20,[],200,llama-13b,64,1,1300.0,1.0,1,A100,1697552077282,1697552078582,120,13.0,1.0,"[38, 1261]","[1697552077320, 1697552078581]"
1003,1003,718,18,[],200,llama-13b,64,1,1126.0,1.0,1,A100,1697552078122,1697552079248,120,13.0,1.0,"[59, 1067]","[1697552078181, 1697552079248]"
1004,1004,55,10,[],200,llama-13b,64,1,1261.0,1.0,1,A100,1697552064883,1697552066144,120,12.0,1.0,"[46, 1215]","[1697552064929, 1697552066144]"
1005,1005,45,20,[],200,llama-13b,64,1,1125.0,1.0,1,A100,1697552078124,1697552079249,120,19.0,1.0,"[135, 989]","[1697552078259, 1697552079248]"
1006,1006,382,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079251,1697552080743,120,,,"[40, 860]","[1697552079291, 1697552080151]"
1007,1007,743,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079251,1697552080743,120,,,"[35, 865]","[1697552079286, 1697552080151]"
1008,1008,480,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055788,1697552057502,120,,,[153],[1697552055941]
1009,1009,404,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080747,1697552082121,120,,,"[12, 1242]","[1697552080759, 1697552082001]"
1010,1010,646,11,[],200,llama-13b,64,1,1214.0,1.0,1,A100,1697552066148,1697552067362,120,14.0,1.0,"[19, 1195]","[1697552066167, 1697552067362]"
1011,1011,256,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057509,1697552059169,120,,,"[62, 1438]","[1697552057571, 1697552059009]"
1012,1012,152,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080748,1697552082119,120,,,"[21, 1232]","[1697552080769, 1697552082001]"
1013,1013,840,8,[],200,llama-13b,64,1,1446.0,1.0,1,A100,1697552059179,1697552060625,120,17.0,1.0,"[185, 1261]","[1697552059364, 1697552060625]"
1014,1014,416,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067365,1697552067818,120,,,[28],[1697552067393]
1015,1015,48,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067821,1697552068961,120,,,"[6, 945, 139]","[1697552067827, 1697552068772, 1697552068911]"
1016,1016,172,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082129,1697552083673,120,,,[141],[1697552082270]
1017,1017,143,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078584,1697552079389,120,,,"[6, 659]","[1697552078590, 1697552079249]"
1018,1018,610,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060636,1697552062308,120,,,"[15, 1057]","[1697552060651, 1697552061708]"
1019,1019,754,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083681,1697552084682,120,,,[98],[1697552083779]
1020,1020,537,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064883,1697552066163,120,,,"[24, 1237]","[1697552064907, 1697552066144]"
1021,1021,531,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084686,1697552085754,120,,,[58],[1697552084744]
1022,1022,184,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085759,1697552089317,120,,,"[44, 1324, 694, 735]","[1697552085803, 1697552087127, 1697552087821, 1697552088556]"
1023,1023,860,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089321,1697552090604,120,,,"[51, 1212]","[1697552089372, 1697552090584]"
1024,1024,737,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063771,1697552064879,120,,,[83],[1697552063854]
1025,1025,513,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090606,1697552091869,120,,,"[62, 1179]","[1697552090668, 1697552091847]"
1026,1026,191,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066167,1697552067382,120,,,"[107, 1088]","[1697552066274, 1697552067362]"
1027,1027,290,29,[],200,llama-13b,64,1,1293.0,1.0,1,A100,1697552091871,1697552093164,120,14.0,1.0,"[68, 1224]","[1697552091939, 1697552093163]"
1028,1028,748,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068965,1697552073395,120,,,"[35, 1626, 698, 687, 683]","[1697552069000, 1697552070626, 1697552071324, 1697552072011, 1697552072694]"
1029,1029,897,13,[],200,llama-13b,64,1,1234.0,1.0,1,A100,1697552067387,1697552068621,120,9.0,1.0,"[155, 1078]","[1697552067542, 1697552068620]"
1030,1030,401,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073400,1697552074776,120,,,"[70, 1288]","[1697552073470, 1697552074758]"
1031,1031,638,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096120,1697552097349,120,,,"[39, 1091]","[1697552096159, 1697552097250]"
1032,1032,15,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084687,1697552085754,120,,,[28],[1697552084715]
1033,1033,878,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093167,1697552093476,120,,,[20],[1697552093187]
1034,1034,292,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097354,1697552099703,120,,,[85],[1697552097439]
1035,1035,807,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063770,1697552064878,120,,,[38],[1697552063808]
1036,1036,647,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093483,1697552096115,120,,,"[82, 1871]","[1697552093565, 1697552095436]"
1037,1037,41,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099715,1697552102447,120,,,"[62, 1975]","[1697552099777, 1697552101752]"
1038,1038,179,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074781,1697552075452,120,,,[16],[1697552074797]
1039,1039,597,26,[],200,llama-13b,64,1,1368.0,1.0,1,A100,1697552085760,1697552087128,120,39.0,1.0,"[89, 1279]","[1697552085849, 1697552087128]"
1040,1040,308,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096120,1697552098825,120,,,"[148, 1960]","[1697552096268, 1697552098228]"
1041,1041,576,10,[],200,llama-13b,64,1,1262.0,1.0,1,A100,1697552064882,1697552066144,120,14.0,1.0,"[7, 1255]","[1697552064889, 1697552066144]"
1042,1042,75,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098829,1697552101107,120,,,"[51, 1651, 50]","[1697552098880, 1697552100531, 1697552100581]"
1043,1043,324,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066148,1697552067382,120,,,"[33, 1182]","[1697552066181, 1697552067363]"
1044,1044,759,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075468,1697552079383,120,,,"[102, 1706, 874, 483]","[1697552075570, 1697552077276, 1697552078150, 1697552078633]"
1045,1045,445,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055786,1697552057502,120,,,[87],[1697552055873]
1046,1046,312,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 28.51 GiB is allocated by PyTorch, and 8.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552054797,1697552056510,120,,,[65],[1697552054862]
1047,1047,440,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079389,1697552080743,120,,,"[23, 1213]","[1697552079412, 1697552080625]"
1048,1048,908,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067395,1697552068960,120,,,"[177, 1049, 150, 140]","[1697552067572, 1697552068621, 1697552068771, 1697552068911]"
1049,1049,95,24,[],200,llama-13b,64,1,1251.0,1.0,1,A100,1697552080751,1697552082002,120,12.0,1.0,"[84, 1166]","[1697552080835, 1697552082001]"
1050,1050,800,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082004,1697552083468,120,,,[22],[1697552082026]
1051,1051,536,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079389,1697552080743,120,,,"[15, 1221]","[1697552079404, 1697552080625]"
1052,1052,454,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083472,1697552083902,120,,,[20],[1697552083492]
1053,1053,234,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083908,1697552084997,120,,,[47],[1697552083955]
1054,1054,89,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552056514,1697552059168,120,,,"[34, 1638]","[1697552056548, 1697552058186]"
1055,1055,815,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085000,1697552086533,120,,,[27],[1697552085027]
1056,1056,4,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076900,1697552078118,120,,,[67],[1697552076967]
1057,1057,186,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080748,1697552082120,120,,,"[36, 1218]","[1697552080784, 1697552082002]"
1058,1058,679,13,[],200,llama-13b,64,1,1066.0,1.0,1,A100,1697552068966,1697552070032,120,15.0,1.0,"[91, 975]","[1697552069057, 1697552070032]"
1059,1059,863,40,[],200,llama-13b,64,1,1189.0,1.0,1,A100,1697552115119,1697552116308,120,10.0,1.0,"[27, 1162]","[1697552115146, 1697552116308]"
1060,1060,677,6,[],200,llama-13b,64,1,1452.0,1.0,1,A100,1697552059175,1697552060627,120,9.0,1.0,"[71, 1379]","[1697552059246, 1697552060625]"
1061,1061,729,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060886,1697552062307,120,,,[31],[1697552060917]
1062,1062,704,20,[],200,llama-13b,64,1,1123.0,1.0,1,A100,1697552078125,1697552079248,120,14.0,1.0,"[135, 988]","[1697552078260, 1697552079248]"
1063,1063,886,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082127,1697552083672,120,,,[128],[1697552082255]
1064,1064,444,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070589,1697552071972,120,,,[24],[1697552070613]
1065,1065,216,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071975,1697552073395,120,,,"[28, 1372]","[1697552072003, 1697552073375]"
1066,1066,358,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079251,1697552080745,120,,,"[25, 875]","[1697552079276, 1697552080151]"
1067,1067,798,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073400,1697552074776,120,,,[37],[1697552073437]
1068,1068,497,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053990,1697552055781,120,,,[26],[1697552054016]
1069,1069,547,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083678,1697552084681,120,,,[22],[1697552083700]
1070,1070,316,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084685,1697552085753,120,,,[14],[1697552084699]
1071,1071,135,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080748,1697552082120,120,,,"[35, 1218]","[1697552080783, 1697552082001]"
1072,1072,63,23,[],200,llama-13b,64,1,1366.0,1.0,1,A100,1697552085762,1697552087128,120,39.0,1.0,"[104, 1262]","[1697552085866, 1697552087128]"
1073,1073,645,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087132,1697552088518,120,,,[14],[1697552087146]
1074,1074,575,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074781,1697552075453,120,,,[30],[1697552074811]
1075,1075,228,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075461,1697552076892,120,,,"[85, 1236]","[1697552075546, 1697552076782]"
1076,1076,266,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055787,1697552057502,120,,,[157],[1697552055944]
1077,1077,422,25,[],200,llama-13b,64,1,1272.0,1.0,1,A100,1697552088523,1697552089795,120,26.0,1.0,"[67, 1205]","[1697552088590, 1697552089795]"
1078,1078,410,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073379,1697552074777,120,,,"[24, 1354]","[1697552073403, 1697552074757]"
1079,1079,265,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060889,1697552062307,120,,,"[42, 1255]","[1697552060931, 1697552062186]"
1080,1080,63,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074784,1697552075456,120,,,[160],[1697552074944]
1081,1081,715,23,[],200,llama-13b,64,1,1234.0,1.0,1,A100,1697552082125,1697552083359,120,20.0,1.0,"[60, 1174]","[1697552082185, 1697552083359]"
1082,1082,446,7,[],200,llama-13b,64,1,1071.0,1.0,1,A100,1697552060638,1697552061709,120,26.0,1.0,"[39, 1032]","[1697552060677, 1697552061709]"
1083,1083,846,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062311,1697552063763,120,,,"[45, 1299]","[1697552062356, 1697552063655]"
1084,1084,463,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083362,1697552083672,120,,,[10],[1697552083372]
1085,1085,81,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089798,1697552091870,120,,,"[15, 1381]","[1697552089813, 1697552091194]"
1086,1086,763,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085001,1697552086535,120,,,[50],[1697552085051]
1087,1087,107,8,[],200,llama-13b,64,1,1340.0,1.0,1,A100,1697552061711,1697552063051,120,216.0,2.0,"[14, 1326]","[1697552061725, 1697552063051]"
1088,1088,779,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091872,1697552093476,120,,,[116],[1697552091988]
1089,1089,769,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075460,1697552076891,120,,,"[47, 1275]","[1697552075507, 1697552076782]"
1090,1090,425,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076900,1697552078117,120,,,[61],[1697552076961]
1091,1091,701,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067387,1697552068960,120,,,"[165, 1068, 152, 139]","[1697552067552, 1697552068620, 1697552068772, 1697552068911]"
1092,1092,113,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083679,1697552084682,120,,,[92],[1697552083771]
1093,1093,855,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057509,1697552059168,120,,,"[57, 1443]","[1697552057566, 1697552059009]"
1094,1094,624,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059175,1697552060882,120,,,"[66, 1385]","[1697552059241, 1697552060626]"
1095,1095,285,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060886,1697552062307,120,,,"[25, 1274]","[1697552060911, 1697552062185]"
1096,1096,362,9,[],200,llama-13b,64,1,1008.0,1.0,1,A100,1697552064545,1697552065553,120,14.0,1.0,"[102, 905]","[1697552064647, 1697552065552]"
1097,1097,440,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093480,1697552094764,120,,,"[66, 1201]","[1697552093546, 1697552094747]"
1098,1098,139,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552065556,1697552067381,120,,,"[16, 1088]","[1697552065572, 1697552066660]"
1099,1099,720,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067384,1697552067819,120,,,[74],[1697552067458]
1100,1100,496,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067822,1697552068961,120,,,"[15, 784, 151, 139]","[1697552067837, 1697552068621, 1697552068772, 1697552068911]"
1101,1101,56,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062312,1697552064541,120,,,[58],[1697552062370]
1102,1102,639,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064543,1697552066163,120,,,"[10, 999]","[1697552064553, 1697552065552]"
1103,1103,439,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073399,1697552074776,120,,,"[19, 1339]","[1697552073418, 1697552074757]"
1104,1104,149,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068966,1697552073395,120,,,"[74, 991, 595, 698, 687, 683]","[1697552069040, 1697552070031, 1697552070626, 1697552071324, 1697552072011, 1697552072694]"
1105,1105,419,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066165,1697552067382,120,,,"[28, 1170]","[1697552066193, 1697552067363]"
1106,1106,71,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067387,1697552067820,120,,,[88],[1697552067475]
1107,1107,506,11,[],200,llama-13b,64,1,1258.0,1.0,1,A100,1697552064887,1697552066145,120,16.0,1.0,"[95, 1162]","[1697552064982, 1697552066144]"
1108,1108,63,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055787,1697552057503,120,,,[76],[1697552055863]
1109,1109,393,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069280,1697552071282,120,,,[45],[1697552069325]
1110,1110,649,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057510,1697552059168,120,,,"[46, 1453]","[1697552057556, 1697552059009]"
1111,1111,615,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552061711,1697552063764,120,,,"[19, 1321]","[1697552061730, 1697552063051]"
1112,1112,171,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071289,1697552072656,120,,,[86],[1697552071375]
1113,1113,753,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072659,1697552074777,120,,,"[41, 1354]","[1697552072700, 1697552074054]"
1114,1114,136,14,[],200,llama-13b,64,1,1067.0,1.0,1,A100,1697552068965,1697552070032,120,31.0,1.0,"[30, 1036]","[1697552068995, 1697552070031]"
1115,1115,162,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066148,1697552067382,120,,,"[15, 1199]","[1697552066163, 1697552067362]"
1116,1116,430,6,[],200,llama-13b,64,1,1449.0,1.0,1,A100,1697552059176,1697552060625,120,15.0,1.0,"[100, 1347]","[1697552059276, 1697552060623]"
1117,1117,624,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102454,1697552105087,120,,,"[93, 1959]","[1697552102547, 1697552104506]"
1118,1118,734,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060889,1697552063764,120,,,"[62, 2055, 45]","[1697552060951, 1697552063006, 1697552063051]"
1119,1119,184,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067823,1697552069275,120,,,[49],[1697552067872]
1120,1120,813,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070035,1697552071277,120,,,[29],[1697552070064]
1121,1121,175,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060636,1697552062307,120,,,[25],[1697552060661]
1122,1122,587,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071286,1697552072656,120,,,[39],[1697552071325]
1123,1123,241,17,[],200,llama-13b,64,1,1395.0,1.0,1,A100,1697552072660,1697552074055,120,19.0,1.0,"[38, 1356]","[1697552072698, 1697552074054]"
1124,1124,342,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075456,1697552076890,120,,,"[12, 753, 135]","[1697552075468, 1697552076221, 1697552076356]"
1125,1125,874,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062314,1697552064541,120,,,[62],[1697552062376]
1126,1126,131,13,[],200,llama-13b,64,1,1234.0,1.0,1,A100,1697552067387,1697552068621,120,8.0,1.0,"[157, 1076]","[1697552067544, 1697552068620]"
1127,1127,867,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067388,1697552068961,120,,,"[151, 1081, 151, 141]","[1697552067539, 1697552068620, 1697552068771, 1697552068912]"
1128,1128,714,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068622,1697552069274,120,,,[16],[1697552068638]
1129,1129,531,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064544,1697552066163,120,,,"[28, 980]","[1697552064572, 1697552065552]"
1130,1130,303,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066167,1697552067382,120,,,"[111, 1084]","[1697552066278, 1697552067362]"
1131,1131,924,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076898,1697552078117,120,,,[9],[1697552076907]
1132,1132,755,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082127,1697552083672,120,,,[117],[1697552082244]
1133,1133,445,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067823,1697552069275,120,,,[39],[1697552067862]
1134,1134,759,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098829,1697552101106,120,,,"[48, 1654, 50]","[1697552098877, 1697552100531, 1697552100581]"
1135,1135,701,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078121,1697552079392,120,,,"[26, 435, 52]","[1697552078147, 1697552078582, 1697552078634]"
1136,1136,885,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067387,1697552068961,120,,,"[103, 1130, 151, 140]","[1697552067490, 1697552068620, 1697552068771, 1697552068911]"
1137,1137,728,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069283,1697552071281,120,,,[70],[1697552069353]
1138,1138,415,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066148,1697552067382,120,,,[28],[1697552066176]
1139,1139,559,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066165,1697552067382,120,,,"[18, 1180]","[1697552066183, 1697552067363]"
1140,1140,4,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076900,1697552078118,120,,,[72],[1697552076972]
1141,1141,328,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067387,1697552068960,120,,,"[162, 1071, 152, 139]","[1697552067549, 1697552068620, 1697552068772, 1697552068911]"
1142,1142,68,11,[],200,llama-13b,64,1,1233.0,1.0,1,A100,1697552067388,1697552068621,120,12.0,1.0,"[169, 1064]","[1697552067557, 1697552068621]"
1143,1143,501,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071288,1697552072658,120,,,[72],[1697552071360]
1144,1144,814,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084686,1697552085755,120,,,[49],[1697552084735]
1145,1145,209,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074782,1697552075453,120,,,[90],[1697552074872]
1146,1146,799,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075457,1697552076890,120,,,"[30, 1295]","[1697552075487, 1697552076782]"
1147,1147,156,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072661,1697552074776,120,,,"[95, 1299]","[1697552072756, 1697552074055]"
1148,1148,474,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085762,1697552089318,120,,,"[101, 1958, 735]","[1697552085863, 1697552087821, 1697552088556]"
1149,1149,586,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078123,1697552079384,120,,,"[119, 1006]","[1697552078242, 1697552079248]"
1150,1150,243,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089321,1697552090604,120,,,"[46, 1216]","[1697552089367, 1697552090583]"
1151,1151,272,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062312,1697552063764,120,,,"[49, 1294]","[1697552062361, 1697552063655]"
1152,1152,41,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063774,1697552064877,120,,,[88],[1697552063862]
1153,1153,851,14,[],200,llama-13b,64,1,1776.0,1.0,1,A100,1697552073402,1697552075178,120,23.0,1.0,"[135, 1641]","[1697552073537, 1697552075178]"
1154,1154,548,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068623,1697552069274,120,,,[19],[1697552068642]
1155,1155,748,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067823,1697552069274,120,,,[39],[1697552067862]
1156,1156,517,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 6.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069280,1697552070587,120,,,[40],[1697552069320]
1157,1157,855,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074782,1697552075458,120,,,[94],[1697552074876]
1158,1158,515,17,[],200,llama-13b,64,1,1314.0,1.0,1,A100,1697552075469,1697552076783,120,11.0,1.0,"[102, 1212]","[1697552075571, 1697552076783]"
1159,1159,917,13,[],200,llama-13b,64,1,1663.0,1.0,1,A100,1697552068963,1697552070626,120,123.0,2.0,"[7, 1060, 596]","[1697552068970, 1697552070030, 1697552070626]"
1160,1160,514,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075182,1697552076893,120,,,"[34, 1006, 133]","[1697552075216, 1697552076222, 1697552076355]"
1161,1161,318,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 6.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069279,1697552070586,120,,,[21],[1697552069300]
1162,1162,285,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076904,1697552078119,120,,,[132],[1697552077036]
1163,1163,284,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076786,1697552079383,120,,,"[20, 1344, 483]","[1697552076806, 1697552078150, 1697552078633]"
1164,1164,845,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078124,1697552080744,120,,,"[130, 1896]","[1697552078254, 1697552080150]"
1165,1165,844,19,[],200,llama-13b,64,1,1235.0,1.0,1,A100,1697552079390,1697552080625,120,10.0,1.0,"[27, 1208]","[1697552079417, 1697552080625]"
1166,1166,687,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070629,1697552071973,120,,,[21],[1697552070650]
1167,1167,832,29,[],200,llama-13b,64,1,1238.0,1.0,1,A100,1697552090609,1697552091847,120,15.0,1.0,"[152, 1086]","[1697552090761, 1697552091847]"
1168,1168,173,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070591,1697552071973,120,,,[54],[1697552070645]
1169,1169,878,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071978,1697552073395,120,,,"[59, 1339]","[1697552072037, 1697552073376]"
1170,1170,374,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087130,1697552088518,120,,,[16],[1697552087146]
1171,1171,601,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091863,1697552093265,120,,,"[12, 1288]","[1697552091875, 1697552093163]"
1172,1172,419,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552059172,1697552060881,120,,,"[25, 1424]","[1697552059197, 1697552060621]"
1173,1173,345,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071976,1697552073395,120,,,"[33, 1366]","[1697552072009, 1697552073375]"
1174,1174,529,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074784,1697552075456,120,,,[155],[1697552074939]
1175,1175,123,16,[],200,llama-13b,64,1,1776.0,1.0,1,A100,1697552073402,1697552075178,120,14.0,1.0,"[73, 1703]","[1697552073475, 1697552075178]"
1176,1176,505,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063771,1697552064879,120,,,[164],[1697552063935]
1177,1177,262,31,[],200,llama-13b,64,1,1099.0,1.0,1,A100,1697552093269,1697552094368,120,39.0,1.0,"[70, 1028]","[1697552093339, 1697552094367]"
1178,1178,487,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 6.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069279,1697552070586,120,,,[16],[1697552069295]
1179,1179,705,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075180,1697552076891,120,,,"[7, 1034, 134]","[1697552075187, 1697552076221, 1697552076355]"
1180,1180,165,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064884,1697552066163,120,,,"[89, 1172]","[1697552064973, 1697552066145]"
1181,1181,524,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068964,1697552073395,120,,,"[31, 1036, 595, 698, 687, 683]","[1697552068995, 1697552070031, 1697552070626, 1697552071324, 1697552072011, 1697552072694]"
1182,1182,143,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070588,1697552071278,120,,,[16],[1697552070604]
1183,1183,865,11,[],200,llama-13b,64,1,1194.0,1.0,1,A100,1697552066168,1697552067362,120,9.0,1.0,"[174, 1020]","[1697552066342, 1697552067362]"
1184,1184,841,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071288,1697552072657,120,,,[87],[1697552071375]
1185,1185,519,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067366,1697552067819,120,,,[36],[1697552067402]
1186,1186,589,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072660,1697552073395,120,,,"[18, 697]","[1697552072678, 1697552073375]"
1187,1187,357,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079390,1697552080744,120,,,"[42, 1193]","[1697552079432, 1697552080625]"
1188,1188,240,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073400,1697552076890,120,,,"[138, 1640, 308, 869]","[1697552073538, 1697552075178, 1697552075486, 1697552076355]"
1189,1189,297,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067822,1697552068962,120,,,"[15, 784, 151, 139]","[1697552067837, 1697552068621, 1697552068772, 1697552068911]"
1190,1190,335,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070035,1697552071277,120,,,[29],[1697552070064]
1191,1191,309,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062189,1697552063765,120,,,"[15, 802, 45]","[1697552062204, 1697552063006, 1697552063051]"
1192,1192,138,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080748,1697552082120,120,,,"[41, 1213]","[1697552080789, 1697552082002]"
1193,1193,168,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076905,1697552079384,120,,,"[145, 1531, 52]","[1697552077050, 1697552078581, 1697552078633]"
1194,1194,719,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082124,1697552083469,120,,,[16],[1697552082140]
1195,1195,492,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083473,1697552083903,120,,,[92],[1697552083565]
1196,1196,866,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079389,1697552080744,120,,,[31],[1697552079420]
1197,1197,259,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072660,1697552074777,120,,,"[43, 1351]","[1697552072703, 1697552074054]"
1198,1198,527,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080751,1697552083467,120,,,"[109, 1977]","[1697552080860, 1697552082837]"
1199,1199,298,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083472,1697552083903,120,,,[26],[1697552083498]
1200,1200,841,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074784,1697552076891,120,,,"[170, 1401]","[1697552074954, 1697552076355]"
1201,1201,879,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068967,1697552073395,120,,,"[91, 974, 595, 697, 687, 683]","[1697552069058, 1697552070032, 1697552070627, 1697552071324, 1697552072011, 1697552072694]"
1202,1202,881,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083908,1697552084998,120,,,[67],[1697552083975]
1203,1203,102,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071283,1697552071972,120,,,[18],[1697552071301]
1204,1204,507,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062314,1697552064540,120,,,[62],[1697552062376]
1205,1205,589,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076898,1697552078118,120,,,[24],[1697552076922]
1206,1206,693,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071976,1697552073395,120,,,"[47, 1352]","[1697552072023, 1697552073375]"
1207,1207,654,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073400,1697552074777,120,,,"[62, 1295]","[1697552073462, 1697552074757]"
1208,1208,304,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074781,1697552075456,120,,,[75],[1697552074856]
1209,1209,244,19,[],200,llama-13b,64,1,1126.0,1.0,1,A100,1697552078122,1697552079248,120,9.0,1.0,"[55, 1071]","[1697552078177, 1697552079248]"
1210,1210,160,8,[],200,llama-13b,64,1,1010.0,1.0,1,A100,1697552064542,1697552065552,120,13.0,1.0,"[9, 1001]","[1697552064551, 1697552065552]"
1211,1211,52,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075463,1697552076892,120,,,"[78, 1241]","[1697552075541, 1697552076782]"
1212,1212,860,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552065555,1697552067381,120,,,"[21, 1084]","[1697552065576, 1697552066660]"
1213,1213,14,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079251,1697552080742,120,,,"[30, 870]","[1697552079281, 1697552080151]"
1214,1214,752,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076900,1697552078117,120,,,[57],[1697552076957]
1215,1215,405,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078121,1697552079385,120,,,"[15, 445, 52]","[1697552078136, 1697552078581, 1697552078633]"
1216,1216,183,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079390,1697552080744,120,,,"[32, 1203]","[1697552079422, 1697552080625]"
1217,1217,603,21,[],200,llama-13b,64,1,1254.0,1.0,1,A100,1697552080747,1697552082001,120,9.0,1.0,"[7, 1247]","[1697552080754, 1697552082001]"
1218,1218,628,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085002,1697552086533,120,,,[59],[1697552085061]
1219,1219,806,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063054,1697552064541,120,,,[8],[1697552063062]
1220,1220,517,10,[],200,llama-13b,64,1,1224.0,1.0,1,A100,1697552067396,1697552068620,120,15.0,1.0,"[182, 1042]","[1697552067578, 1697552068620]"
1221,1221,537,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086539,1697552088518,120,,,[118],[1697552086657]
1222,1222,552,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064544,1697552066163,120,,,"[24, 984]","[1697552064568, 1697552065552]"
1223,1223,276,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086539,1697552088518,120,,,[123],[1697552086662]
1224,1224,53,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552088522,1697552090604,120,,,"[48, 1225]","[1697552088570, 1697552089795]"
1225,1225,763,21,[],200,llama-13b,64,1,1252.0,1.0,1,A100,1697552080751,1697552082003,120,20.0,1.0,"[108, 1143]","[1697552080859, 1697552082002]"
1226,1226,636,27,[],200,llama-13b,64,1,1243.0,1.0,1,A100,1697552090607,1697552091850,120,31.0,1.0,"[57, 1183]","[1697552090664, 1697552091847]"
1227,1227,205,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066168,1697552067382,120,,,"[124, 1070]","[1697552066292, 1697552067362]"
1228,1228,374,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082006,1697552083468,120,,,"[25, 807]","[1697552082031, 1697552082838]"
1229,1229,540,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082007,1697552083468,120,,,"[29, 802]","[1697552082036, 1697552082838]"
1230,1230,35,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083473,1697552083904,120,,,[72],[1697552083545]
1231,1231,407,28,[],200,llama-13b,64,1,1301.0,1.0,1,A100,1697552091863,1697552093164,120,16.0,1.0,"[28, 1272]","[1697552091891, 1697552093163]"
1232,1232,68,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093168,1697552093477,120,,,[25],[1697552093193]
1233,1233,734,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083910,1697552084997,120,,,[148],[1697552084058]
1234,1234,390,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085001,1697552086535,120,,,[55],[1697552085056]
1235,1235,287,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068624,1697552069275,120,,,[35],[1697552068659]
1236,1236,911,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067388,1697552068961,120,,,"[107, 1125, 151, 140]","[1697552067495, 1697552068620, 1697552068771, 1697552068911]"
1237,1237,767,30,[],200,llama-13b,64,1,1951.0,1.0,1,A100,1697552093484,1697552095435,120,11.0,1.0,"[154, 1797]","[1697552093638, 1697552095435]"
1238,1238,187,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552088520,1697552089317,120,,,"[20, 758]","[1697552088540, 1697552089298]"
1239,1239,197,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083473,1697552083904,120,,,[50],[1697552083523]
1240,1240,166,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086540,1697552088518,120,,,[122],[1697552086662]
1241,1241,749,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552088523,1697552090604,120,,,"[68, 1204]","[1697552088591, 1697552089795]"
1242,1242,864,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089321,1697552090605,120,,,"[16, 1245]","[1697552089337, 1697552090582]"
1243,1243,494,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090607,1697552091870,120,,,"[41, 1199]","[1697552090648, 1697552091847]"
1244,1244,425,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552095437,1697552097350,120,,,"[20, 1246]","[1697552095457, 1697552096703]"
1245,1245,260,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091874,1697552093476,120,,,[183],[1697552092057]
1246,1246,195,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097357,1697552099702,120,,,[112],[1697552097469]
1247,1247,898,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083910,1697552084996,120,,,[128],[1697552084038]
1248,1248,875,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 6.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069283,1697552070587,120,,,[64],[1697552069347]
1249,1249,644,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070591,1697552071972,120,,,[37],[1697552070628]
1250,1250,558,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085001,1697552086533,120,,,[31],[1697552085032]
1251,1251,875,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099706,1697552101107,120,,,"[24, 1359]","[1697552099730, 1697552101089]"
1252,1252,315,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066166,1697552067381,120,,,"[86, 1110]","[1697552066252, 1697552067362]"
1253,1253,182,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073399,1697552074776,120,,,"[24, 1334]","[1697552073423, 1697552074757]"
1254,1254,745,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068624,1697552069275,120,,,[40],[1697552068664]
1255,1255,276,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071979,1697552073396,120,,,[63],[1697552072042]
1256,1256,732,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.32 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552058188,1697552060882,120,,,"[21, 1688]","[1697552058209, 1697552059897]"
1257,1257,531,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101112,1697552102447,120,,,"[44, 1191]","[1697552101156, 1697552102347]"
1258,1258,509,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 6.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069280,1697552070586,120,,,[35],[1697552069315]
1259,1259,503,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060886,1697552062307,120,,,"[21, 1278]","[1697552060907, 1697552062185]"
1260,1260,886,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074781,1697552075452,120,,,[85],[1697552074866]
1261,1261,170,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070589,1697552071972,120,,,[25],[1697552070614]
1262,1262,540,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075460,1697552076891,120,,,"[38, 1284]","[1697552075498, 1697552076782]"
1263,1263,869,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071975,1697552073394,120,,,"[14, 1386]","[1697552071989, 1697552073375]"
1264,1264,359,14,[],200,llama-13b,64,1,1066.0,1.0,1,A100,1697552068966,1697552070032,120,10.0,1.0,"[86, 980]","[1697552069052, 1697552070032]"
1265,1265,209,29,[],200,llama-13b,64,1,1222.0,1.0,1,A100,1697552094769,1697552095991,120,20.0,1.0,"[18, 1204]","[1697552094787, 1697552095991]"
1266,1266,47,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073400,1697552074775,120,,,"[23, 1334]","[1697552073423, 1697552074757]"
1267,1267,630,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074781,1697552075452,120,,,[10],[1697552074791]
1268,1268,161,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062311,1697552063765,120,,,[10],[1697552062321]
1269,1269,524,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073400,1697552074776,120,,,"[28, 1329]","[1697552073428, 1697552074757]"
1270,1270,269,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063769,1697552064877,120,,,[8],[1697552063777]
1271,1271,613,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080748,1697552082120,120,,,"[40, 1214]","[1697552080788, 1697552082002]"
1272,1272,16,11,[],200,llama-13b,64,1,1258.0,1.0,1,A100,1697552064887,1697552066145,120,9.0,1.0,"[88, 1170]","[1697552064975, 1697552066145]"
1273,1273,603,12,[],200,llama-13b,64,1,1214.0,1.0,1,A100,1697552066149,1697552067363,120,9.0,1.0,"[24, 1189]","[1697552066173, 1697552067362]"
1274,1274,374,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067365,1697552067819,120,,,[32],[1697552067397]
1275,1275,34,14,[],200,llama-13b,64,1,800.0,1.0,1,A100,1697552067821,1697552068621,120,12.0,1.0,"[11, 789]","[1697552067832, 1697552068621]"
1276,1276,733,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068623,1697552069275,120,,,[29],[1697552068652]
1277,1277,666,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101112,1697552103817,120,,,"[59, 2129]","[1697552101171, 1697552103300]"
1278,1278,392,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069283,1697552071278,120,,,[85],[1697552069368]
1279,1279,300,35,[],200,llama-13b,64,1,1242.0,1.0,1,A100,1697552102454,1697552103696,120,9.0,1.0,"[100, 1142]","[1697552102554, 1697552103696]"
1280,1280,435,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103823,1697552105088,120,,,"[22, 1222]","[1697552103845, 1697552105067]"
1281,1281,162,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071286,1697552072656,120,,,[44],[1697552071330]
1282,1282,751,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072658,1697552073396,120,,,[15],[1697552072673]
1283,1283,798,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552095993,1697552097349,120,,,[9],[1697552096002]
1284,1284,91,36,[],200,llama-13b,64,1,1398.0,1.0,1,A100,1697552105093,1697552106491,120,23.0,1.0,"[159, 1238]","[1697552105252, 1697552106490]"
1285,1285,301,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074784,1697552075456,120,,,[153],[1697552074937]
1286,1286,532,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073400,1697552074776,120,,,"[43, 1315]","[1697552073443, 1697552074758]"
1287,1287,764,37,[],200,llama-13b,64,1,1259.0,1.0,1,A100,1697552106494,1697552107753,120,39.0,1.0,"[33, 1226]","[1697552106527, 1697552107753]"
1288,1288,883,18,[],200,llama-13b,64,1,1323.0,1.0,1,A100,1697552075459,1697552076782,120,563.0,1.0,"[38, 1285]","[1697552075497, 1697552076782]"
1289,1289,658,19,[],200,llama-13b,64,1,491.0,1.0,1,A100,1697552076787,1697552077278,120,11.0,1.0,"[15, 475]","[1697552076802, 1697552077277]"
1290,1290,523,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073400,1697552074776,120,,,"[43, 1315]","[1697552073443, 1697552074758]"
1291,1291,534,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107756,1697552109323,120,,,"[22, 913]","[1697552107778, 1697552108691]"
1292,1292,567,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097354,1697552098825,120,,,"[25, 1322]","[1697552097379, 1697552098701]"
1293,1293,315,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552077280,1697552079384,120,,,"[15, 1286, 52]","[1697552077295, 1697552078581, 1697552078633]"
1294,1294,192,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109336,1697552110462,120,,,[127],[1697552109463]
1295,1295,401,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105089,1697552106519,120,,,"[16, 1384]","[1697552105105, 1697552106489]"
1296,1296,305,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074779,1697552075452,120,,,[11],[1697552074790]
1297,1297,721,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076899,1697552078119,120,,,[33],[1697552076932]
1298,1298,886,20,[],200,llama-13b,64,1,765.0,1.0,1,A100,1697552075457,1697552076222,120,17.0,1.0,"[15, 750]","[1697552075472, 1697552076222]"
1299,1299,57,39,[],200,llama-13b,64,1,2165.0,1.0,1,A100,1697552106525,1697552108690,120,13.0,1.0,"[146, 2019]","[1697552106671, 1697552108690]"
1300,1300,63,21,[],200,llama-13b,64,1,2115.0,1.0,1,A100,1697552079395,1697552081510,120,39.0,1.0,"[144, 1971]","[1697552079539, 1697552081510]"
1301,1301,199,32,[],200,llama-13b,64,1,1701.0,1.0,1,A100,1697552098830,1697552100531,120,13.0,1.0,"[116, 1585]","[1697552098946, 1697552100531]"
1302,1302,755,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552108693,1697552110134,120,,,[21],[1697552108714]
1303,1303,663,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076225,1697552079383,120,,,"[21, 1031, 873, 483]","[1697552076246, 1697552077277, 1697552078150, 1697552078633]"
1304,1304,896,33,[],200,llama-13b,64,1,1219.0,1.0,1,A100,1697552100533,1697552101752,120,15.0,1.0,"[26, 1193]","[1697552100559, 1697552101752]"
1305,1305,37,32,[],200,llama-13b,64,1,1063.0,1.0,1,A100,1697552094372,1697552095435,120,20.0,1.0,"[18, 1045]","[1697552094390, 1697552095435]"
1306,1306,491,19,[],200,llama-13b,64,1,1124.0,1.0,1,A100,1697552078125,1697552079249,120,14.0,1.0,"[149, 975]","[1697552078274, 1697552079249]"
1307,1307,620,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552095438,1697552097349,120,,,"[29, 1236]","[1697552095467, 1697552096703]"
1308,1308,153,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079251,1697552080743,120,,,"[35, 865]","[1697552079286, 1697552080151]"
1309,1309,550,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101757,1697552103819,120,,,"[27, 1518]","[1697552101784, 1697552103302]"
1310,1310,416,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110141,1697552111926,120,,,"[96, 876]","[1697552110237, 1697552111113]"
1311,1311,451,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076899,1697552078119,120,,,[43],[1697552076942]
1312,1312,852,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080748,1697552082119,120,,,"[26, 1227]","[1697552080774, 1697552082001]"
1313,1313,367,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097352,1697552098826,120,,,"[11, 1338]","[1697552097363, 1697552098701]"
1314,1314,527,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083675,1697552084681,120,,,[15],[1697552083690]
1315,1315,563,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086538,1697552087781,120,,,[40],[1697552086578]
1316,1316,183,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084686,1697552085754,120,,,[24],[1697552084710]
1317,1317,333,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087783,1697552089316,120,,,"[15, 1500]","[1697552087798, 1697552089298]"
1318,1318,860,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085758,1697552089317,120,,,"[33, 1336, 694, 735]","[1697552085791, 1697552087127, 1697552087821, 1697552088556]"
1319,1319,221,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078125,1697552080744,120,,,"[145, 1880]","[1697552078270, 1697552080150]"
1320,1320,612,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116312,1697552120129,120,,,"[20, 1324, 826, 738]","[1697552116332, 1697552117656, 1697552118482, 1697552119220]"
1321,1321,776,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071975,1697552072657,120,,,[18],[1697552071993]
1322,1322,546,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072661,1697552074777,120,,,[47],[1697552072708]
1323,1323,810,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080751,1697552082121,120,,,"[99, 1152]","[1697552080850, 1697552082002]"
1324,1324,86,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063771,1697552064879,120,,,[76],[1697552063847]
1325,1325,528,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101112,1697552102447,120,,,"[39, 1196]","[1697552101151, 1697552102347]"
1326,1326,300,15,[],200,llama-13b,64,1,1357.0,1.0,1,A100,1697552073400,1697552074757,120,9.0,1.0,"[50, 1307]","[1697552073450, 1697552074757]"
1327,1327,202,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074782,1697552075453,120,,,[85],[1697552074867]
1328,1328,669,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064883,1697552066164,120,,,"[43, 1218]","[1697552064926, 1697552066144]"
1329,1329,437,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066167,1697552067382,120,,,"[120, 1075]","[1697552066287, 1697552067362]"
1330,1330,189,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102451,1697552103819,120,,,"[36, 1208]","[1697552102487, 1697552103695]"
1331,1331,882,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074760,1697552075452,120,,,[16],[1697552074776]
1332,1332,360,16,[],200,llama-13b,64,1,1041.0,1.0,1,A100,1697552075181,1697552076222,120,16.0,1.0,"[26, 1015]","[1697552075207, 1697552076222]"
1333,1333,893,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103825,1697552105088,120,,,"[48, 1195]","[1697552103873, 1697552105068]"
1334,1334,184,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067387,1697552068961,120,,,"[106, 1127, 151, 140]","[1697552067493, 1697552068620, 1697552068771, 1697552068911]"
1335,1335,659,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075472,1697552079383,120,,,"[104, 1701, 873, 483]","[1697552075576, 1697552077277, 1697552078150, 1697552078633]"
1336,1336,314,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079393,1697552082118,120,,,"[64, 2052]","[1697552079457, 1697552081509]"
1337,1337,767,14,[],200,llama-13b,64,1,1065.0,1.0,1,A100,1697552068966,1697552070031,120,11.0,1.0,"[44, 1021]","[1697552069010, 1697552070031]"
1338,1338,547,39,[],200,llama-13b,64,1,1398.0,1.0,1,A100,1697552105092,1697552106490,120,12.0,1.0,"[72, 1326]","[1697552105164, 1697552106490]"
1339,1339,323,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106493,1697552107866,120,,,"[19, 785]","[1697552106512, 1697552107297]"
1340,1340,84,19,[],200,llama-13b,64,1,1235.0,1.0,1,A100,1697552082124,1697552083359,120,26.0,1.0,"[36, 1199]","[1697552082160, 1697552083359]"
1341,1341,314,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068964,1697552073394,120,,,"[16, 1051, 595, 698, 687, 683]","[1697552068980, 1697552070031, 1697552070626, 1697552071324, 1697552072011, 1697552072694]"
1342,1342,462,17,[],200,llama-13b,64,1,1359.0,1.0,1,A100,1697552073399,1697552074758,120,52.0,1.0,"[14, 1344]","[1697552073413, 1697552074757]"
1343,1343,906,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107870,1697552109318,120,,,"[9, 1325]","[1697552107879, 1697552109204]"
1344,1344,136,17,[],200,llama-13b,64,1,1054.0,1.0,1,A100,1697552076223,1697552077277,120,31.0,1.0,"[13, 1041]","[1697552076236, 1697552077277]"
1345,1345,681,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109335,1697552110462,120,,,[121],[1697552109456]
1346,1346,895,15,[],200,llama-13b,64,1,1776.0,1.0,1,A100,1697552073402,1697552075178,120,15.0,1.0,"[150, 1626]","[1697552073552, 1697552075178]"
1347,1347,673,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075182,1697552076892,120,,,"[20, 1153]","[1697552075202, 1697552076355]"
1348,1348,359,14,[],200,llama-13b,64,1,1065.0,1.0,1,A100,1697552068966,1697552070031,120,10.0,1.0,"[43, 1022]","[1697552069009, 1697552070031]"
1349,1349,562,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068964,1697552073395,120,,,"[40, 1028, 594, 698, 687, 683]","[1697552069004, 1697552070032, 1697552070626, 1697552071324, 1697552072011, 1697552072694]"
1350,1350,718,18,[],200,llama-13b,64,1,1300.0,1.0,1,A100,1697552077281,1697552078581,120,13.0,1.0,"[15, 1285]","[1697552077296, 1697552078581]"
1351,1351,118,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074761,1697552076890,120,,,"[11, 406, 308, 869]","[1697552074772, 1697552075178, 1697552075486, 1697552076355]"
1352,1352,823,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076899,1697552078118,120,,,[33],[1697552076932]
1353,1353,328,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076901,1697552078118,120,,,[80],[1697552076981]
1354,1354,255,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068966,1697552073395,120,,,"[49, 1016, 595, 698, 687, 683]","[1697552069015, 1697552070031, 1697552070626, 1697552071324, 1697552072011, 1697552072694]"
1355,1355,98,18,[],200,llama-13b,64,1,1127.0,1.0,1,A100,1697552078122,1697552079249,120,14.0,1.0,"[69, 1057]","[1697552078191, 1697552079248]"
1356,1356,477,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078122,1697552079383,120,,,"[40, 1085]","[1697552078162, 1697552079247]"
1357,1357,227,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079392,1697552080745,120,,,"[48, 1185]","[1697552079440, 1697552080625]"
1358,1358,136,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070035,1697552071277,120,,,[19],[1697552070054]
1359,1359,837,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073400,1697552074777,120,,,"[18, 1339]","[1697552073418, 1697552074757]"
1360,1360,719,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071283,1697552071973,120,,,[9],[1697552071292]
1361,1361,687,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079251,1697552080742,120,,,"[30, 870]","[1697552079281, 1697552080151]"
1362,1362,809,22,[],200,llama-13b,64,1,1250.0,1.0,1,A100,1697552080753,1697552082003,120,16.0,1.0,"[117, 1133]","[1697552080870, 1697552082003]"
1363,1363,584,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074784,1697552075456,120,,,[173],[1697552074957]
1364,1364,91,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067384,1697552067820,120,,,[89],[1697552067473]
1365,1365,586,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082006,1697552083468,120,,,"[20, 812]","[1697552082026, 1697552082838]"
1366,1366,241,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083477,1697552083904,120,,,[162],[1697552083639]
1367,1367,451,20,[],200,llama-13b,64,1,1254.0,1.0,1,A100,1697552080747,1697552082001,120,286.0,1.0,"[16, 1238]","[1697552080763, 1697552082001]"
1368,1368,83,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082004,1697552083467,120,,,"[6, 827]","[1697552082010, 1697552082837]"
1369,1369,672,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067825,1697552069274,120,,,[117],[1697552067942]
1370,1370,11,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083906,1697552084997,120,,,[43],[1697552083949]
1371,1371,419,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 6.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069279,1697552070586,120,,,[32],[1697552069311]
1372,1372,600,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085001,1697552086534,120,,,[45],[1697552085046]
1373,1373,493,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071976,1697552073395,120,,,"[28, 1371]","[1697552072004, 1697552073375]"
1374,1374,237,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075459,1697552076891,120,,,"[34, 1289]","[1697552075493, 1697552076782]"
1375,1375,370,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086542,1697552088518,120,,,[126],[1697552086668]
1376,1376,147,18,[],200,llama-13b,64,1,1777.0,1.0,1,A100,1697552073400,1697552075177,120,182.0,1.0,"[72, 1705]","[1697552073472, 1697552075177]"
1377,1377,827,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082124,1697552083467,120,,,"[26, 1209]","[1697552082150, 1697552083359]"
1378,1378,25,28,[],200,llama-13b,64,1,779.0,1.0,1,A100,1697552088520,1697552089299,120,12.0,1.0,"[31, 747]","[1697552088551, 1697552089298]"
1379,1379,410,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075457,1697552076890,120,,,"[20, 745, 134]","[1697552075477, 1697552076222, 1697552076356]"
1380,1380,481,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083473,1697552083903,120,,,[87],[1697552083560]
1381,1381,724,29,[],200,llama-13b,64,1,1280.0,1.0,1,A100,1697552089303,1697552090583,120,11.0,1.0,"[15, 1265]","[1697552089318, 1697552090583]"
1382,1382,829,27,[],200,llama-13b,64,1,1263.0,1.0,1,A100,1697552089321,1697552090584,120,20.0,1.0,"[56, 1207]","[1697552089377, 1697552090584]"
1383,1383,890,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103698,1697552105088,120,,,[10],[1697552103708]
1384,1384,766,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069284,1697552071284,120,,,[94],[1697552069378]
1385,1385,133,10,[],200,llama-13b,64,1,1006.0,1.0,1,A100,1697552064547,1697552065553,120,15.0,1.0,"[109, 897]","[1697552064656, 1697552065553]"
1386,1386,839,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552065556,1697552067381,120,,,"[15, 1089]","[1697552065571, 1697552066660]"
1387,1387,614,20,[],200,llama-13b,64,1,881.0,1.0,1,A100,1697552080629,1697552081510,120,15.0,1.0,"[25, 856]","[1697552080654, 1697552081510]"
1388,1388,272,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552081513,1697552083469,120,,,"[21, 1303]","[1697552081534, 1697552082837]"
1389,1389,492,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067384,1697552067818,120,,,[72],[1697552067456]
1390,1390,264,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067821,1697552068961,120,,,"[6, 793, 151, 140]","[1697552067827, 1697552068620, 1697552068771, 1697552068911]"
1391,1391,890,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110467,1697552111925,120,,,[77],[1697552110544]
1392,1392,50,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083475,1697552083903,120,,,[105],[1697552083580]
1393,1393,316,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079390,1697552080744,120,,,"[37, 1198]","[1697552079427, 1697552080625]"
1394,1394,824,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075180,1697552076892,120,,,"[17, 1024, 134]","[1697552075197, 1697552076221, 1697552076355]"
1395,1395,184,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111931,1697552113423,120,,,[120],[1697552112051]
1396,1396,346,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105092,1697552106518,120,,,"[77, 1320]","[1697552105169, 1697552106489]"
1397,1397,853,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068964,1697552073394,120,,,"[21, 1046, 595, 698, 686, 684]","[1697552068985, 1697552070031, 1697552070626, 1697552071324, 1697552072010, 1697552072694]"
1398,1398,600,22,[],200,llama-13b,64,1,1235.0,1.0,1,A100,1697552082124,1697552083359,120,23.0,1.0,"[21, 1214]","[1697552082145, 1697552083359]"
1399,1399,925,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106524,1697552109324,120,,,"[142, 2024]","[1697552106666, 1697552108690]"
1400,1400,769,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113431,1697552115113,120,,,[58],[1697552113489]
1401,1401,512,26,[],200,llama-13b,64,1,1263.0,1.0,1,A100,1697552089321,1697552090584,120,11.0,1.0,"[51, 1212]","[1697552089372, 1697552090584]"
1402,1402,539,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115119,1697552116440,120,,,"[39, 1150]","[1697552115158, 1697552116308]"
1403,1403,255,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083364,1697552083673,120,,,[40],[1697552083404]
1404,1404,194,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116445,1697552117621,120,,,[21],[1697552116466]
1405,1405,632,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083908,1697552084998,120,,,[62],[1697552083970]
1406,1406,288,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090587,1697552091869,120,,,[25],[1697552090612]
1407,1407,25,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083682,1697552084682,120,,,[99],[1697552083781]
1408,1408,623,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073399,1697552074777,120,,,[9],[1697552073408]
1409,1409,872,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091872,1697552093475,120,,,[76],[1697552091948]
1410,1410,407,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085004,1697552086534,120,,,[77],[1697552085081]
1411,1411,287,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074781,1697552075453,120,,,[55],[1697552074836]
1412,1412,871,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117627,1697552118449,120,,,[14],[1697552117641]
1413,1413,114,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552127354,1697552128290,120,,,"[14, 759]","[1697552127368, 1697552128127]"
1414,1414,640,47,[],200,llama-13b,64,1,1496.0,1.0,1,A100,1697552118453,1697552119949,120,15.0,1.0,"[82, 1414]","[1697552118535, 1697552119949]"
1415,1415,498,19,[],200,llama-13b,64,1,1566.0,1.0,1,A100,1697552078585,1697552080151,120,9.0,1.0,"[15, 1551]","[1697552078600, 1697552080151]"
1416,1416,333,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073400,1697552074776,120,,,"[36, 1321]","[1697552073436, 1697552074757]"
1417,1417,643,29,[],200,llama-13b,64,1,1267.0,1.0,1,A100,1697552093480,1697552094747,120,18.0,1.0,"[21, 1246]","[1697552093501, 1697552094747]"
1418,1418,519,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090608,1697552091869,120,,,"[133, 1106]","[1697552090741, 1697552091847]"
1419,1419,304,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094750,1697552096114,120,,,"[6, 680]","[1697552094756, 1697552095436]"
1420,1420,69,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096119,1697552097349,120,,,"[30, 1101]","[1697552096149, 1697552097250]"
1421,1421,732,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079395,1697552082119,120,,,"[142, 1973]","[1697552079537, 1697552081510]"
1422,1422,13,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076899,1697552078119,120,,,[52],[1697552076951]
1423,1423,908,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070589,1697552071282,120,,,[30],[1697552070619]
1424,1424,596,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078121,1697552079388,120,,,"[21, 440, 51]","[1697552078142, 1697552078582, 1697552078633]"
1425,1425,18,18,[],200,llama-13b,64,1,1120.0,1.0,1,A100,1697552074058,1697552075178,120,15.0,1.0,"[20, 1100]","[1697552074078, 1697552075178]"
1426,1426,136,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070034,1697552071282,120,,,[20],[1697552070054]
1427,1427,502,23,[],200,llama-13b,64,1,1235.0,1.0,1,A100,1697552082125,1697552083360,120,19.0,1.0,"[45, 1190]","[1697552082170, 1697552083360]"
1428,1428,721,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071286,1697552072656,120,,,[40],[1697552071326]
1429,1429,599,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075182,1697552076893,120,,,"[39, 1001, 133]","[1697552075221, 1697552076222, 1697552076355]"
1430,1430,157,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083363,1697552083673,120,,,[36],[1697552083399]
1431,1431,74,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060886,1697552062307,120,,,"[13, 1286]","[1697552060899, 1697552062185]"
1432,1432,537,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071289,1697552072657,120,,,[96],[1697552071385]
1433,1433,375,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076898,1697552078117,120,,,[9],[1697552076907]
1434,1434,199,16,[],200,llama-13b,64,1,1393.0,1.0,1,A100,1697552072662,1697552074055,120,13.0,1.0,"[104, 1289]","[1697552072766, 1697552074055]"
1435,1435,88,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080749,1697552082121,120,,,"[49, 1203]","[1697552080798, 1697552082001]"
1436,1436,289,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091872,1697552093475,120,,,[91],[1697552091963]
1437,1437,193,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069283,1697552071281,120,,,[71],[1697552069354]
1438,1438,878,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093479,1697552094764,120,,,"[8, 1259]","[1697552093487, 1697552094746]"
1439,1439,780,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552062311,1697552063766,120,,,"[16, 1328]","[1697552062327, 1697552063655]"
1440,1440,647,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094774,1697552096115,120,,,"[90, 1127]","[1697552094864, 1697552095991]"
1441,1441,773,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071283,1697552071972,120,,,[17],[1697552071300]
1442,1442,433,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063775,1697552064880,120,,,[172],[1697552063947]
1443,1443,897,17,[],200,llama-13b,64,1,1119.0,1.0,1,A100,1697552074059,1697552075178,120,9.0,1.0,"[24, 1095]","[1697552074083, 1697552075178]"
1444,1444,30,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078121,1697552079390,120,,,"[25, 488]","[1697552078146, 1697552078634]"
1445,1445,307,34,[],200,llama-13b,64,1,1130.0,1.0,1,A100,1697552096120,1697552097250,120,26.0,1.0,"[122, 1008]","[1697552096242, 1697552097250]"
1446,1446,179,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064887,1697552067381,120,,,"[148, 1625]","[1697552065035, 1697552066660]"
1447,1447,263,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120137,1697552121356,120,,,[115],[1697552120252]
1448,1448,556,18,[],200,llama-13b,64,1,1040.0,1.0,1,A100,1697552075182,1697552076222,120,9.0,1.0,"[30, 1010]","[1697552075212, 1697552076222]"
1449,1449,40,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121362,1697552122933,120,,,[43],[1697552121405]
1450,1450,622,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 458.06 MiB is free. Process 1449637 has 38.94 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122939,1697552124743,120,,,[61],[1697552123000]
1451,1451,329,19,[],200,llama-13b,64,1,1050.0,1.0,1,A100,1697552076227,1697552077277,120,15.0,1.0,"[29, 1021]","[1697552076256, 1697552077277]"
1452,1452,729,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079395,1697552082119,120,,,[81],[1697552079476]
1453,1453,391,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082125,1697552083467,120,,,[60],[1697552082185]
1454,1454,394,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552124746,1697552126521,120,,,[29],[1697552124775]
1455,1455,919,20,[],200,llama-13b,64,1,1301.0,1.0,1,A100,1697552077281,1697552078582,120,14.0,1.0,"[29, 1272]","[1697552077310, 1697552078582]"
1456,1456,762,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067384,1697552067819,120,,,[81],[1697552067465]
1457,1457,690,21,[],200,llama-13b,64,1,1566.0,1.0,1,A100,1697552078585,1697552080151,120,39.0,1.0,"[25, 1541]","[1697552078610, 1697552080151]"
1458,1458,542,13,[],200,llama-13b,64,1,799.0,1.0,1,A100,1697552067822,1697552068621,120,11.0,1.0,"[20, 779]","[1697552067842, 1697552068621]"
1459,1459,156,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083472,1697552083903,120,,,[31],[1697552083503]
1460,1460,715,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083908,1697552084997,120,,,[52],[1697552083960]
1461,1461,546,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071975,1697552073394,120,,,[33],[1697552072008]
1462,1462,344,22,[],200,llama-13b,64,1,1355.0,1.0,1,A100,1697552080155,1697552081510,120,13.0,1.0,"[18, 1336]","[1697552080173, 1697552081509]"
1463,1463,614,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084687,1697552085754,120,,,[69],[1697552084756]
1464,1464,485,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085001,1697552086533,120,,,[31],[1697552085032]
1465,1465,200,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073399,1697552074777,120,,,"[7, 1351]","[1697552073406, 1697552074757]"
1466,1466,92,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552081512,1697552083468,120,,,"[7, 1318]","[1697552081519, 1697552082837]"
1467,1467,145,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086538,1697552087781,120,,,[51],[1697552086589]
1468,1468,900,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074781,1697552075453,120,,,[60],[1697552074841]
1469,1469,900,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075457,1697552076890,120,,,"[35, 1290]","[1697552075492, 1697552076782]"
1470,1470,335,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110468,1697552111926,120,,,"[92, 1255]","[1697552110560, 1697552111815]"
1471,1471,383,26,[],200,llama-13b,64,1,1369.0,1.0,1,A100,1697552085758,1697552087127,120,15.0,1.0,"[25, 1344]","[1697552085783, 1697552087127]"
1472,1472,39,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087130,1697552088517,120,,,[6],[1697552087136]
1473,1473,561,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075460,1697552076891,120,,,"[47, 1275]","[1697552075507, 1697552076782]"
1474,1474,82,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111931,1697552113423,120,,,[120],[1697552112051]
1475,1475,349,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079400,1697552082120,120,,,"[149, 1961]","[1697552079549, 1697552081510]"
1476,1476,561,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076898,1697552078117,120,,,[14],[1697552076912]
1477,1477,126,20,[],200,llama-13b,64,1,1235.0,1.0,1,A100,1697552082124,1697552083359,120,19.0,1.0,"[46, 1189]","[1697552082170, 1697552083359]"
1478,1478,708,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083362,1697552083672,120,,,[15],[1697552083377]
1479,1479,480,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083675,1697552084681,120,,,[20],[1697552083695]
1480,1480,330,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076900,1697552078117,120,,,[62],[1697552076962]
1481,1481,228,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084684,1697552085753,120,,,[7],[1697552084691]
1482,1482,327,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086538,1697552087782,120,,,[99],[1697552086637]
1483,1483,810,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085758,1697552089317,120,,,"[28, 1341, 694, 735]","[1697552085786, 1697552087127, 1697552087821, 1697552088556]"
1484,1484,779,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113428,1697552115112,120,,,[11],[1697552113439]
1485,1485,889,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087784,1697552089316,120,,,"[34, 1480]","[1697552087818, 1697552089298]"
1486,1486,570,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076898,1697552078117,120,,,[14],[1697552076912]
1487,1487,433,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115118,1697552116439,120,,,[13],[1697552115131]
1488,1488,300,48,[],200,llama-13b,64,1,730.0,1.0,1,A100,1697552119952,1697552120682,120,9.0,1.0,"[19, 710]","[1697552119971, 1697552120681]"
1489,1489,585,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089321,1697552090605,120,,,"[22, 1240]","[1697552089343, 1697552090583]"
1490,1490,366,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079391,1697552080745,120,,,"[44, 1190]","[1697552079435, 1697552080625]"
1491,1491,781,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083472,1697552083903,120,,,[30],[1697552083502]
1492,1492,69,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120684,1697552122073,120,,,[26],[1697552120710]
1493,1493,768,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552081515,1697552083467,120,,,"[34, 1288]","[1697552081549, 1697552082837]"
1494,1494,437,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083908,1697552084998,120,,,[62],[1697552083970]
1495,1495,860,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063774,1697552064878,120,,,[93],[1697552063867]
1496,1496,73,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070591,1697552071973,120,,,[48],[1697552070639]
1497,1497,155,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082124,1697552083466,120,,,"[31, 1204]","[1697552082155, 1697552083359]"
1498,1498,214,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 660.06 MiB is free. Process 1449637 has 38.74 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552057506,1697552059169,120,,,"[15, 1487]","[1697552057521, 1697552059008]"
1499,1499,551,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111930,1697552113424,120,,,[52],[1697552111982]
1500,1500,472,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090586,1697552091869,120,,,"[10, 598]","[1697552090596, 1697552091194]"
1501,1501,326,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103827,1697552106517,120,,,"[122, 1954]","[1697552103949, 1697552105903]"
1502,1502,172,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074784,1697552075456,120,,,[165],[1697552074949]
1503,1503,323,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113430,1697552115115,120,,,[54],[1697552113484]
1504,1504,804,7,[],200,llama-13b,64,1,1454.0,1.0,1,A100,1697552059172,1697552060626,120,20.0,1.0,"[19, 1434]","[1697552059191, 1697552060625]"
1505,1505,127,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091871,1697552093475,120,,,[73],[1697552091944]
1506,1506,916,31,[],200,llama-13b,64,1,1264.0,1.0,1,A100,1697552089319,1697552090583,120,8.0,1.0,"[34, 1230]","[1697552089353, 1697552090583]"
1507,1507,906,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106522,1697552107868,120,,,"[30, 1201]","[1697552106552, 1697552107753]"
1508,1508,568,8,[],200,llama-13b,64,1,1070.0,1.0,1,A100,1697552060638,1697552061708,120,11.0,1.0,"[43, 1027]","[1697552060681, 1697552061708]"
1509,1509,694,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090588,1697552091869,120,,,[39],[1697552090627]
1510,1510,849,21,[],200,llama-13b,64,1,1807.0,1.0,1,A100,1697552075470,1697552077277,120,10.0,1.0,"[110, 1697]","[1697552075580, 1697552077277]"
1511,1511,125,11,[],200,llama-13b,64,1,874.0,1.0,1,A100,1697552066665,1697552067539,120,13.0,1.0,"[27, 847]","[1697552066692, 1697552067539]"
1512,1512,617,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552077280,1697552079384,120,,,"[11, 1290, 52]","[1697552077291, 1697552078581, 1697552078633]"
1513,1513,316,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552061711,1697552063764,120,,,"[29, 1265, 46]","[1697552061740, 1697552063005, 1697552063051]"
1514,1514,825,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067540,1697552068960,120,,,"[37, 1043, 151, 140]","[1697552067577, 1697552068620, 1697552068771, 1697552068911]"
1515,1515,55,46,[],200,llama-13b,64,1,1601.0,1.0,1,A100,1697552126527,1697552128128,120,12.0,1.0,"[110, 1490]","[1697552126637, 1697552128127]"
1516,1516,478,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068964,1697552073394,120,,,"[6, 1060, 596, 698, 686, 684]","[1697552068970, 1697552070030, 1697552070626, 1697552071324, 1697552072010, 1697552072694]"
1517,1517,899,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063774,1697552064877,120,,,[90],[1697552063864]
1518,1518,123,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083912,1697552084997,120,,,[145],[1697552084057]
1519,1519,754,47,[],200,llama-13b,64,1,5158.0,1.0,1,A100,1697552128130,1697552133288,120,88.0,7.0,"[21, 1496, 734, 741, 691, 695, 780]","[1697552128151, 1697552129647, 1697552130381, 1697552131122, 1697552131813, 1697552132508, 1697552133288]"
1520,1520,684,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107873,1697552109323,120,,,"[62, 1270]","[1697552107935, 1697552109205]"
1521,1521,895,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063771,1697552064879,120,,,[82],[1697552063853]
1522,1522,337,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109335,1697552110462,120,,,[124],[1697552109459]
1523,1523,559,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064887,1697552067381,120,,,"[150, 1623]","[1697552065037, 1697552066660]"
1524,1524,109,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110467,1697552111925,120,,,"[73, 1275]","[1697552110540, 1697552111815]"
1525,1525,822,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085000,1697552086533,120,,,[16],[1697552085016]
1526,1526,760,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083363,1697552083673,120,,,[24],[1697552083387]
1527,1527,542,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070035,1697552071277,120,,,[34],[1697552070069]
1528,1528,414,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083679,1697552084682,120,,,[67],[1697552083746]
1529,1529,482,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086538,1697552087781,120,,,[35],[1697552086573]
1530,1530,195,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071285,1697552071973,120,,,[25],[1697552071310]
1531,1531,22,24,[],200,llama-13b,64,1,1251.0,1.0,1,A100,1697552080751,1697552082002,120,16.0,1.0,"[98, 1153]","[1697552080849, 1697552082002]"
1532,1532,186,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084687,1697552085754,120,,,[66],[1697552084753]
1533,1533,242,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090608,1697552093264,120,,,"[141, 1989]","[1697552090749, 1697552092738]"
1534,1534,720,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082004,1697552083467,120,,,"[17, 817]","[1697552082021, 1697552082838]"
1535,1535,768,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085758,1697552089318,120,,,"[20, 1349, 694, 735]","[1697552085778, 1697552087127, 1697552087821, 1697552088556]"
1536,1536,19,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093267,1697552094764,120,,,"[36, 1064]","[1697552093303, 1697552094367]"
1537,1537,251,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087784,1697552088518,120,,,[10],[1697552087794]
1538,1538,716,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064883,1697552066164,120,,,"[33, 1228]","[1697552064916, 1697552066144]"
1539,1539,517,10,[],200,llama-13b,64,1,1262.0,1.0,1,A100,1697552064883,1697552066145,120,15.0,1.0,"[63, 1199]","[1697552064946, 1697552066145]"
1540,1540,154,20,[],200,llama-13b,64,1,1353.0,1.0,1,A100,1697552080157,1697552081510,120,13.0,1.0,"[21, 1332]","[1697552080178, 1697552081510]"
1541,1541,258,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083910,1697552084996,120,,,[132],[1697552084042]
1542,1542,856,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083683,1697552084683,120,,,[155],[1697552083838]
1543,1543,488,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084687,1697552085754,120,,,[71],[1697552084758]
1544,1544,289,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552066148,1697552067382,120,,,"[20, 1194]","[1697552066168, 1697552067362]"
1545,1545,842,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085000,1697552086533,120,,,[7],[1697552085007]
1546,1546,273,19,[],200,llama-13b,64,1,1235.0,1.0,1,A100,1697552082125,1697552083360,120,19.0,1.0,"[40, 1194]","[1697552082165, 1697552083359]"
1547,1547,363,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075181,1697552076892,120,,,"[30, 1011, 134]","[1697552075211, 1697552076222, 1697552076356]"
1548,1548,871,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacty of 39.39 GiB of which 726.06 MiB is free. Process 1449637 has 38.68 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067390,1697552068960,120,,,"[183, 1048, 150, 140]","[1697552067573, 1697552068621, 1697552068771, 1697552068911]"
1549,1549,259,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085758,1697552089317,120,,,"[35, 1334, 694, 735]","[1697552085793, 1697552087127, 1697552087821, 1697552088556]"
1550,1550,611,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086538,1697552087781,120,,,[50],[1697552086588]
1551,1551,852,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552081513,1697552083468,120,,,"[15, 1309]","[1697552081528, 1697552082837]"
1552,1552,140,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076899,1697552078119,120,,,[53],[1697552076952]
1553,1553,268,26,[],200,llama-13b,64,1,1513.0,1.0,1,A100,1697552087785,1697552089298,120,19.0,1.0,"[38, 1475]","[1697552087823, 1697552089298]"
1554,1554,484,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083475,1697552083903,120,,,[101],[1697552083576]
1555,1555,43,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083362,1697552083673,120,,,[27],[1697552083389]
1556,1556,36,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089301,1697552090604,120,,,"[16, 1265]","[1697552089317, 1697552090582]"
1557,1557,627,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083678,1697552084681,120,,,[78],[1697552083756]
1558,1558,722,20,[],200,llama-13b,64,1,1124.0,1.0,1,A100,1697552078125,1697552079249,120,39.0,1.0,"[140, 983]","[1697552078265, 1697552079248]"
1559,1559,842,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089321,1697552090604,120,,,"[46, 1216]","[1697552089367, 1697552090583]"
1560,1560,494,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079251,1697552080745,120,,,"[20, 879]","[1697552079271, 1697552080150]"
1561,1561,253,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083910,1697552084996,120,,,[127],[1697552084037]
1562,1562,842,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085001,1697552086535,120,,,[55],[1697552085056]
1563,1563,618,29,[],200,llama-13b,64,1,1239.0,1.0,1,A100,1697552090608,1697552091847,120,9.0,1.0,"[151, 1088]","[1697552090759, 1697552091847]"
1564,1564,272,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091863,1697552093264,120,,,"[17, 1283]","[1697552091880, 1697552093163]"
1565,1565,795,23,[],200,llama-13b,64,1,1231.0,1.0,1,A100,1697552079395,1697552080626,120,12.0,1.0,"[86, 1145]","[1697552079481, 1697552080626]"
1566,1566,63,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076904,1697552078119,120,,,[136],[1697552077040]
1567,1567,611,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086538,1697552087780,120,,,[115],[1697552086653]
1568,1568,768,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078122,1697552079384,120,,,"[49, 1077]","[1697552078171, 1697552079248]"
1569,1569,50,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093269,1697552094764,120,,,"[49, 1049]","[1697552093318, 1697552094367]"
1570,1570,268,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087784,1697552088518,120,,,[19],[1697552087803]
1571,1571,421,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079395,1697552082119,120,,,"[85, 2029]","[1697552079480, 1697552081509]"
1572,1572,826,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093480,1697552094765,120,,,"[16, 1251]","[1697552093496, 1697552094747]"
1573,1573,347,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091874,1697552093475,120,,,[174],[1697552092048]
1574,1574,846,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087784,1697552089316,120,,,"[29, 1485]","[1697552087813, 1697552089298]"
1575,1575,633,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094767,1697552096115,120,,,"[72, 1151]","[1697552094839, 1697552095990]"
1576,1576,193,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082124,1697552083466,120,,,[26],[1697552082150]
1577,1577,55,17,[],200,llama-13b,64,1,1322.0,1.0,1,A100,1697552075460,1697552076782,120,12.0,1.0,"[42, 1280]","[1697552075502, 1697552076782]"
1578,1578,118,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093484,1697552096115,120,,,"[159, 1792]","[1697552093643, 1697552095435]"
1579,1579,616,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076792,1697552079384,120,,,"[15, 470, 873, 483]","[1697552076807, 1697552077277, 1697552078150, 1697552078633]"
1580,1580,380,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 340.06 MiB is free. Process 1449637 has 39.06 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 7.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552049239,1697552051366,120,,,[110],[1697552049349]
1581,1581,782,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083472,1697552083903,120,,,[11],[1697552083483]
1582,1582,552,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083906,1697552084998,120,,,[16],[1697552083922]
1583,1583,409,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133290,1697552134788,120,,,[70],[1697552133360]
1584,1584,296,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085004,1697552086533,120,,,[67],[1697552085071]
1585,1585,661,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068964,1697552073394,120,,,"[21, 1046, 595, 698, 686, 684]","[1697552068985, 1697552070031, 1697552070626, 1697552071324, 1697552072010, 1697552072694]"
1586,1586,877,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086538,1697552087780,120,,,[100],[1697552086638]
1587,1587,919,22,[],200,llama-13b,64,1,1127.0,1.0,1,A100,1697552078121,1697552079248,120,14.0,1.0,"[40, 1086]","[1697552078161, 1697552079247]"
1588,1588,737,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552088520,1697552089317,120,,,"[6, 773]","[1697552088526, 1697552089299]"
1589,1589,178,49,[],200,llama-13b,64,1,1502.0,1.0,1,A100,1697552134793,1697552136295,120,11.0,1.0,"[65, 1436]","[1697552134858, 1697552136294]"
1590,1590,701,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096119,1697552097349,120,,,"[25, 1106]","[1697552096144, 1697552097250]"
1591,1591,688,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079250,1697552080745,120,,,"[16, 885]","[1697552079266, 1697552080151]"
1592,1592,314,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073400,1697552074776,120,,,"[55, 1302]","[1697552073455, 1697552074757]"
1593,1593,287,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076904,1697552078118,120,,,[82],[1697552076986]
1594,1594,855,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136300,1697552137935,120,,,"[21, 1444]","[1697552136321, 1697552137765]"
1595,1595,393,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089321,1697552090605,120,,,"[119, 1143]","[1697552089440, 1697552090583]"
1596,1596,510,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137941,1697552139267,120,,,"[25, 1200]","[1697552137966, 1697552139166]"
1597,1597,603,28,[],200,llama-13b,64,1,1222.0,1.0,1,A100,1697552094769,1697552095991,120,9.0,1.0,"[37, 1185]","[1697552094806, 1697552095991]"
1598,1598,170,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090607,1697552091869,120,,,"[66, 1173]","[1697552090673, 1697552091846]"
1599,1599,209,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116446,1697552117623,120,,,[89],[1697552116535]
1600,1600,545,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089324,1697552090605,120,,,"[125, 1134]","[1697552089449, 1697552090583]"
1601,1601,836,31,[],200,llama-13b,64,1,1274.0,1.0,1,A100,1697552088521,1697552089795,120,11.0,1.0,"[44, 1230]","[1697552088565, 1697552089795]"
1602,1602,374,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552095995,1697552097350,120,,,"[17, 692]","[1697552096012, 1697552096704]"
1603,1603,605,32,[],200,llama-13b,64,1,1393.0,1.0,1,A100,1697552089802,1697552091195,120,8.0,1.0,"[21, 1371]","[1697552089823, 1697552091194]"
1604,1604,261,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091197,1697552093265,120,,,[15],[1697552091212]
1605,1605,34,30,[],200,llama-13b,64,1,1344.0,1.0,1,A100,1697552097358,1697552098702,120,12.0,1.0,"[107, 1237]","[1697552097465, 1697552098702]"
1606,1606,59,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078122,1697552079388,120,,,"[29, 1096]","[1697552078151, 1697552079247]"
1607,1607,733,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098705,1697552099702,120,,,[15],[1697552098720]
1608,1608,468,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083472,1697552083904,120,,,[35],[1697552083507]
1609,1609,38,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093269,1697552094764,120,,,"[29, 1069]","[1697552093298, 1697552094367]"
1610,1610,362,32,[],200,llama-13b,64,1,2037.0,1.0,1,A100,1697552099715,1697552101752,120,14.0,1.0,"[60, 1977]","[1697552099775, 1697552101752]"
1611,1611,280,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139271,1697552142270,120,,,"[36, 2437]","[1697552139307, 1697552141744]"
1612,1612,753,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091872,1697552093475,120,,,[86],[1697552091958]
1613,1613,621,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094773,1697552096115,120,,,"[104, 1114]","[1697552094877, 1697552095991]"
1614,1614,366,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096120,1697552098824,120,,,"[59, 2049]","[1697552096179, 1697552098228]"
1615,1615,25,28,[],200,llama-13b,64,1,1274.0,1.0,1,A100,1697552088521,1697552089795,120,12.0,1.0,"[40, 1233]","[1697552088561, 1697552089794]"
1616,1616,642,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079392,1697552080743,120,,,"[55, 1179]","[1697552079447, 1697552080626]"
1617,1617,869,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142276,1697552143538,120,,,"[17, 1226]","[1697552142293, 1697552143519]"
1618,1618,638,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143540,1697552145220,120,,,"[13, 1638]","[1697552143553, 1697552145191]"
1619,1619,136,37,[],200,llama-13b,64,1,1702.0,1.0,1,A100,1697552098828,1697552100530,120,31.0,1.0,"[32, 1670]","[1697552098860, 1697552100530]"
1620,1620,729,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552100534,1697552102447,120,,,[15],[1697552100549]
1621,1621,302,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145225,1697552146631,120,,,[51],[1697552145276]
1622,1622,71,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146637,1697552150143,120,,,"[41, 1294, 736, 686]","[1697552146678, 1697552147972, 1697552148708, 1697552149394]"
1623,1623,414,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080748,1697552082120,120,,,"[31, 1223]","[1697552080779, 1697552082002]"
1624,1624,128,33,[],200,llama-13b,64,1,1548.0,1.0,1,A100,1697552101754,1697552103302,120,9.0,1.0,"[10, 1537]","[1697552101764, 1697552103301]"
1625,1625,68,22,[],200,llama-13b,64,1,1235.0,1.0,1,A100,1697552082125,1697552083360,120,12.0,1.0,"[50, 1185]","[1697552082175, 1697552083360]"
1626,1626,501,39,[],200,llama-13b,64,1,2052.0,1.0,1,A100,1697552102454,1697552104506,120,19.0,1.0,"[90, 1962]","[1697552102544, 1697552104506]"
1627,1627,772,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083363,1697552083673,120,,,[31],[1697552083394]
1628,1628,426,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083680,1697552084681,120,,,[84],[1697552083764]
1629,1629,202,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084685,1697552085754,120,,,[20],[1697552084705]
1630,1630,656,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150149,1697552152619,120,,,[128],[1697552150277]
1631,1631,724,29,[],200,llama-13b,64,1,1396.0,1.0,1,A100,1697552089799,1697552091195,120,11.0,1.0,"[19, 1377]","[1697552089818, 1697552091195]"
1632,1632,787,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085757,1697552089318,120,,,"[16, 1353, 695, 735]","[1697552085773, 1697552087126, 1697552087821, 1697552088556]"
1633,1633,432,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152623,1697552153790,120,,,[44],[1697552152667]
1634,1634,556,27,[],200,llama-13b,64,1,1260.0,1.0,1,A100,1697552089324,1697552090584,120,9.0,1.0,"[141, 1119]","[1697552089465, 1697552090584]"
1635,1635,718,34,[],200,llama-13b,64,1,1203.0,1.0,1,A100,1697552103304,1697552104507,120,13.0,1.0,"[28, 1174]","[1697552103332, 1697552104506]"
1636,1636,86,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153793,1697552154924,120,,,[14],[1697552153807]
1637,1637,763,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154928,1697552156085,120,,,[52],[1697552154980]
1638,1638,356,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091198,1697552093264,120,,,"[10, 1530]","[1697552091208, 1697552092738]"
1639,1639,415,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156088,1697552157801,120,,,[44],[1697552156132]
1640,1640,154,40,[],200,llama-13b,64,1,1395.0,1.0,1,A100,1697552104509,1697552105904,120,13.0,1.0,"[11, 1384]","[1697552104520, 1697552105904]"
1641,1641,860,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105906,1697552107867,120,,,"[6, 1384]","[1697552105912, 1697552107296]"
1642,1642,119,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083912,1697552084998,120,,,[161],[1697552084073]
1643,1643,188,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157803,1697552159106,120,,,[23],[1697552157826]
1644,1644,826,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085004,1697552086533,120,,,[62],[1697552085066]
1645,1645,191,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090587,1697552091870,120,,,"[19, 1240]","[1697552090606, 1697552091846]"
1646,1646,373,13,[],200,llama-13b,64,1,1196.0,1.0,1,A100,1697552066166,1697552067362,120,15.0,1.0,"[83, 1113]","[1697552066249, 1697552067362]"
1647,1647,150,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067365,1697552067819,120,,,[34],[1697552067399]
1648,1648,124,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093268,1697552094765,120,,,[15],[1697552093283]
1649,1649,479,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086538,1697552088518,120,,,[110],[1697552086648]
1650,1650,512,42,[],200,llama-13b,64,1,1332.0,1.0,1,A100,1697552107873,1697552109205,120,11.0,1.0,"[41, 1291]","[1697552107914, 1697552109205]"
1651,1651,489,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552104510,1697552106518,120,,,"[25, 1368]","[1697552104535, 1697552105903]"
1652,1652,490,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072659,1697552073398,120,,,[31],[1697552072690]
1653,1653,182,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075469,1697552079387,120,,,"[97, 1710, 874, 483]","[1697552075566, 1697552077276, 1697552078150, 1697552078633]"
1654,1654,363,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079393,1697552080743,120,,,"[58, 1174]","[1697552079451, 1697552080625]"
1655,1655,25,19,[],200,llama-13b,64,1,1252.0,1.0,1,A100,1697552080751,1697552082003,120,12.0,1.0,"[114, 1138]","[1697552080865, 1697552082003]"
1656,1656,151,18,[],200,llama-13b,64,1,1776.0,1.0,1,A100,1697552073402,1697552075178,120,39.0,1.0,"[160, 1615]","[1697552073562, 1697552075177]"
1657,1657,400,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084686,1697552085754,120,,,[20],[1697552084706]
1658,1658,887,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079393,1697552080743,120,,,"[52, 1181]","[1697552079445, 1697552080626]"
1659,1659,541,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080748,1697552082119,120,,,"[30, 1223]","[1697552080778, 1697552082001]"
1660,1660,54,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085758,1697552089317,120,,,"[43, 1326, 694, 735]","[1697552085801, 1697552087127, 1697552087821, 1697552088556]"
1661,1661,137,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098829,1697552101107,120,,,"[111, 1591, 50]","[1697552098940, 1697552100531, 1697552100581]"
1662,1662,906,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115120,1697552116439,120,,,"[123, 1065]","[1697552115243, 1697552116308]"
1663,1663,725,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101113,1697552103817,120,,,"[68, 2119]","[1697552101181, 1697552103300]"
1664,1664,17,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076900,1697552078118,120,,,[76],[1697552076976]
1665,1665,686,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116444,1697552117621,120,,,[11],[1697552116455]
1666,1666,758,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089324,1697552090605,120,,,"[121, 1138]","[1697552089445, 1697552090583]"
1667,1667,600,21,[],200,llama-13b,64,1,1126.0,1.0,1,A100,1697552078122,1697552079248,120,23.0,1.0,"[45, 1081]","[1697552078167, 1697552079248]"
1668,1668,375,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079251,1697552080745,120,,,[20],[1697552079271]
1669,1669,36,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080751,1697552083468,120,,,"[94, 1992]","[1697552080845, 1697552082837]"
1670,1670,648,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082127,1697552083467,120,,,"[121, 1111]","[1697552082248, 1697552083359]"
1671,1671,340,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117629,1697552119185,120,,,[37],[1697552117666]
1672,1672,61,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086539,1697552087781,120,,,[118],[1697552086657]
1673,1673,85,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552119189,1697552128290,120,,,"[52, 1440, 711, 718, 860, 915, 894, 941, 834, 820]","[1697552119241, 1697552120681, 1697552121392, 1697552122110, 1697552122970, 1697552123885, 1697552124779, 1697552125720, 1697552126554, 1697552127374]"
1674,1674,734,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083475,1697552083903,120,,,[100],[1697552083575]
1675,1675,494,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103825,1697552105087,120,,,"[40, 1202]","[1697552103865, 1697552105067]"
1676,1676,412,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090608,1697552093263,120,,,"[143, 1987]","[1697552090751, 1697552092738]"
1677,1677,486,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094766,1697552096115,120,,,"[8, 1216]","[1697552094774, 1697552095990]"
1678,1678,254,34,[],200,llama-13b,64,1,2106.0,1.0,1,A100,1697552096122,1697552098228,120,58.0,1.0,"[151, 1955]","[1697552096273, 1697552098228]"
1679,1679,766,26,[],200,llama-13b,64,1,1513.0,1.0,1,A100,1697552087785,1697552089298,120,11.0,1.0,"[43, 1470]","[1697552087828, 1697552089298]"
1680,1680,395,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083912,1697552084998,120,,,[151],[1697552084063]
1681,1681,155,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105092,1697552106519,120,,,"[82, 1315]","[1697552105174, 1697552106489]"
1682,1682,572,24,[],200,llama-13b,64,1,881.0,1.0,1,A100,1697552080629,1697552081510,120,16.0,1.0,"[30, 851]","[1697552080659, 1697552081510]"
1683,1683,328,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067383,1697552067820,120,,,[65],[1697552067448]
1684,1684,702,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111930,1697552113424,120,,,[42],[1697552111972]
1685,1685,847,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098232,1697552099703,120,,,[32],[1697552098264]
1686,1686,422,27,[],200,llama-13b,64,1,1280.0,1.0,1,A100,1697552089303,1697552090583,120,26.0,1.0,"[24, 1256]","[1697552089327, 1697552090583]"
1687,1687,918,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067824,1697552069276,120,,,[68],[1697552067892]
1688,1688,617,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099715,1697552102446,120,,,"[52, 1984]","[1697552099767, 1697552101751]"
1689,1689,187,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090585,1697552091869,120,,,"[7, 602]","[1697552090592, 1697552091194]"
1690,1690,865,29,[],200,llama-13b,64,1,1292.0,1.0,1,A100,1697552091872,1697552093164,120,9.0,1.0,"[111, 1181]","[1697552091983, 1697552093164]"
1691,1691,499,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089319,1697552090605,120,,,"[13, 1251]","[1697552089332, 1697552090583]"
1692,1692,518,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093168,1697552093476,120,,,[20],[1697552093188]
1693,1693,685,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069283,1697552071278,120,,,[76],[1697552069359]
1694,1694,850,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093483,1697552094764,120,,,"[68, 1196]","[1697552093551, 1697552094747]"
1695,1695,472,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113430,1697552115114,120,,,[40],[1697552113470]
1696,1696,621,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094770,1697552096115,120,,,"[68, 1152]","[1697552094838, 1697552095990]"
1697,1697,323,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080753,1697552083468,120,,,"[116, 1968]","[1697552080869, 1697552082837]"
1698,1698,478,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097354,1697552098825,120,,,"[30, 1317]","[1697552097384, 1697552098701]"
1699,1699,901,17,[],200,llama-13b,64,1,1399.0,1.0,1,A100,1697552071977,1697552073376,120,17.0,1.0,"[42, 1356]","[1697552072019, 1697552073375]"
1700,1700,659,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097358,1697552099703,120,,,[112],[1697552097470]
1701,1701,922,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074781,1697552075452,120,,,[15],[1697552074796]
1702,1702,95,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083476,1697552083904,120,,,[162],[1697552083638]
1703,1703,427,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099712,1697552102446,120,,,"[60, 1980]","[1697552099772, 1697552101752]"
1704,1704,790,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117629,1697552119185,120,,,[42],[1697552117671]
1705,1705,567,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552119188,1697552120129,120,,,"[20, 741]","[1697552119208, 1697552119949]"
1706,1706,293,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093483,1697552096114,120,,,"[83, 1870]","[1697552093566, 1697552095436]"
1707,1707,690,16,[],200,llama-13b,64,1,1319.0,1.0,1,A100,1697552075464,1697552076783,120,39.0,1.0,"[77, 1242]","[1697552075541, 1697552076783]"
1708,1708,875,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096119,1697552097349,120,,,"[50, 1081]","[1697552096169, 1697552097250]"
1709,1709,350,17,[],200,llama-13b,64,1,491.0,1.0,1,A100,1697552076786,1697552077277,120,216.0,1.0,"[6, 485]","[1697552076792, 1697552077277]"
1710,1710,220,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120133,1697552121356,120,,,[25],[1697552120158]
1711,1711,734,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067822,1697552069274,120,,,[30],[1697552067852]
1712,1712,120,18,[],200,llama-13b,64,1,1298.0,1.0,1,A100,1697552077283,1697552078581,120,17.0,1.0,"[42, 1256]","[1697552077325, 1697552078581]"
1713,1713,429,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083471,1697552083903,120,,,[7],[1697552083478]
1714,1714,647,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552081513,1697552083469,120,,,"[20, 1304]","[1697552081533, 1697552082837]"
1715,1715,155,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080751,1697552082121,120,,,"[103, 1148]","[1697552080854, 1697552082002]"
1716,1716,697,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109335,1697552110461,120,,,[116],[1697552109451]
1717,1717,40,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552088521,1697552090604,120,,,"[45, 1229]","[1697552088566, 1697552089795]"
1718,1718,670,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064883,1697552066164,120,,,"[28, 1233]","[1697552064911, 1697552066144]"
1719,1719,385,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079392,1697552080743,120,,,"[49, 1185]","[1697552079441, 1697552080626]"
1720,1720,41,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 6.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552051369,1697552052660,120,,,[17],[1697552051386]
1721,1721,225,25,[],200,llama-13b,64,1,1324.0,1.0,1,A100,1697552081514,1697552082838,120,23.0,1.0,"[25, 1299]","[1697552081539, 1697552082838]"
1722,1722,272,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102451,1697552103818,120,,,"[16, 1228]","[1697552102467, 1697552103695]"
1723,1723,255,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073400,1697552074776,120,,,"[57, 1300]","[1697552073457, 1697552074757]"
1724,1724,49,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103824,1697552105088,120,,,"[24, 1219]","[1697552103848, 1697552105067]"
1725,1725,1,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082840,1697552083673,120,,,[21],[1697552082861]
1726,1726,836,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074782,1697552075453,120,,,[25],[1697552074807]
1727,1727,662,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122078,1697552123844,120,,,[61],[1697552122139]
1728,1728,770,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159110,1697552160461,120,,,[38],[1697552159148]
1729,1729,200,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090608,1697552091869,120,,,"[61, 1178]","[1697552090669, 1697552091847]"
1730,1730,921,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121364,1697552122932,120,,,[90],[1697552121454]
1731,1731,676,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071288,1697552072657,120,,,[67],[1697552071355]
1732,1732,585,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 458.06 MiB is free. Process 1449637 has 38.94 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122936,1697552124743,120,,,[35],[1697552122971]
1733,1733,584,16,[],200,llama-13b,64,1,1320.0,1.0,1,A100,1697552075462,1697552076782,120,10.0,1.0,"[41, 1279]","[1697552075503, 1697552076782]"
1734,1734,423,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072661,1697552074776,120,,,"[89, 1304]","[1697552072750, 1697552074054]"
1735,1735,889,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091874,1697552093476,120,,,[189],[1697552092063]
1736,1736,77,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074781,1697552075457,120,,,[71],[1697552074852]
1737,1737,549,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093480,1697552094765,120,,,[26],[1697552093506]
1738,1738,777,20,[],200,llama-13b,64,1,1314.0,1.0,1,A100,1697552075468,1697552076782,120,9.0,1.0,"[83, 1231]","[1697552075551, 1697552076782]"
1739,1739,241,17,[],200,llama-13b,64,1,492.0,1.0,1,A100,1697552076786,1697552077278,120,19.0,1.0,"[25, 467]","[1697552076811, 1697552077278]"
1740,1740,319,31,[],200,llama-13b,64,1,1221.0,1.0,1,A100,1697552094770,1697552095991,120,31.0,1.0,"[73, 1147]","[1697552094843, 1697552095990]"
1741,1741,438,21,[],200,llama-13b,64,1,491.0,1.0,1,A100,1697552076787,1697552077278,120,9.0,1.0,"[29, 462]","[1697552076816, 1697552077278]"
1742,1742,903,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552095993,1697552097350,120,,,"[14, 697]","[1697552096007, 1697552096704]"
1743,1743,212,22,[],200,llama-13b,64,1,1300.0,1.0,1,A100,1697552077282,1697552078582,120,31.0,1.0,"[29, 1271]","[1697552077311, 1697552078582]"
1744,1744,680,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097354,1697552098826,120,,,"[35, 1312]","[1697552097389, 1697552098701]"
1745,1745,12,18,[],200,llama-13b,64,1,1301.0,1.0,1,A100,1697552077281,1697552078582,120,11.0,1.0,"[20, 1281]","[1697552077301, 1697552078582]"
1746,1746,602,19,[],200,llama-13b,64,1,1565.0,1.0,1,A100,1697552078585,1697552080150,120,15.0,1.0,"[10, 1555]","[1697552078595, 1697552080150]"
1747,1747,849,19,[],200,llama-13b,64,1,1039.0,1.0,1,A100,1697552075183,1697552076222,120,10.0,1.0,"[55, 983]","[1697552075238, 1697552076221]"
1748,1748,333,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098828,1697552101108,120,,,"[7, 1695, 51]","[1697552098835, 1697552100530, 1697552100581]"
1749,1749,371,20,[],200,llama-13b,64,1,1357.0,1.0,1,A100,1697552080153,1697552081510,120,13.0,1.0,"[15, 1342]","[1697552080168, 1697552081510]"
1750,1750,480,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076904,1697552078119,120,,,[137],[1697552077041]
1751,1751,595,20,[],200,llama-13b,64,1,1052.0,1.0,1,A100,1697552076225,1697552077277,120,8.0,1.0,"[16, 1036]","[1697552076241, 1697552077277]"
1752,1752,619,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063771,1697552064878,120,,,[35],[1697552063806]
1753,1753,332,21,[],200,llama-13b,64,1,462.0,1.0,1,A100,1697552078120,1697552078582,120,39.0,1.0,"[17, 445]","[1697552078137, 1697552078582]"
1754,1754,743,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.44 GiB is free. Process 1449637 has 37.95 GiB memory in use. Of the allocated memory 28.72 GiB is allocated by PyTorch, and 7.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552052662,1697552053353,120,,,"[18, 611]","[1697552052680, 1697552053291]"
1755,1755,277,30,[],200,llama-13b,64,1,1238.0,1.0,1,A100,1697552090609,1697552091847,120,18.0,1.0,"[156, 1082]","[1697552090765, 1697552091847]"
1756,1756,331,12,[],200,llama-13b,64,1,1194.0,1.0,1,A100,1697552066169,1697552067363,120,26.0,1.0,"[183, 1011]","[1697552066352, 1697552067363]"
1757,1757,404,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.06 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.74 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552053359,1697552055780,120,,,[103],[1697552053462]
1758,1758,862,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091864,1697552093264,120,,,[37],[1697552091901]
1759,1759,172,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 496.06 MiB is free. Process 1449637 has 38.90 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552055787,1697552057503,120,,,[71],[1697552055858]
1760,1760,849,6,[],200,llama-13b,64,1,1498.0,1.0,1,A100,1697552057512,1697552059010,120,10.0,1.0,"[129, 1369]","[1697552057641, 1697552059010]"
1761,1761,217,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115120,1697552116441,120,,,"[61, 1126]","[1697552115181, 1697552116307]"
1762,1762,228,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078121,1697552079388,120,,,"[20, 441, 51]","[1697552078141, 1697552078582, 1697552078633]"
1763,1763,288,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109208,1697552110135,120,,,[21],[1697552109229]
1764,1764,502,7,[],200,llama-13b,64,1,885.0,1.0,1,A100,1697552059013,1697552059898,120,19.0,1.0,"[28, 857]","[1697552059041, 1697552059898]"
1765,1765,273,8,[],200,llama-13b,64,1,1805.0,1.0,1,A100,1697552059903,1697552061708,120,19.0,1.0,"[14, 1791]","[1697552059917, 1697552061708]"
1766,1766,656,28,[],200,llama-13b,64,1,1263.0,1.0,1,A100,1697552089321,1697552090584,120,26.0,1.0,"[65, 1198]","[1697552089386, 1697552090584]"
1767,1767,622,28,[],200,llama-13b,64,1,1241.0,1.0,1,A100,1697552090606,1697552091847,120,20.0,1.0,"[36, 1205]","[1697552090642, 1697552091847]"
1768,1768,399,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091863,1697552093265,120,,,"[11, 1289]","[1697552091874, 1697552093163]"
1769,1769,4,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079394,1697552082119,120,,,"[71, 2044]","[1697552079465, 1697552081509]"
1770,1770,50,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093270,1697552094764,120,,,"[81, 1016]","[1697552093351, 1697552094367]"
1771,1771,727,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094769,1697552096114,120,,,"[22, 1200]","[1697552094791, 1697552095991]"
1772,1772,677,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083906,1697552084996,120,,,[30],[1697552083936]
1773,1773,454,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085001,1697552086534,120,,,[41],[1697552085042]
1774,1774,497,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096118,1697552097350,120,,,"[12, 1120]","[1697552096130, 1697552097250]"
1775,1775,143,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106525,1697552107867,120,,,"[128, 1100]","[1697552106653, 1697552107753]"
1776,1776,153,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097355,1697552099703,120,,,[89],[1697552097444]
1777,1777,652,33,[],200,llama-13b,64,1,1347.0,1.0,1,A100,1697552097354,1697552098701,120,14.0,1.0,"[19, 1328]","[1697552097373, 1697552098701]"
1778,1778,862,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099706,1697552101106,120,,,[21],[1697552099727]
1779,1779,849,37,[],200,llama-13b,64,1,1329.0,1.0,1,A100,1697552107876,1697552109205,120,10.0,1.0,"[75, 1254]","[1697552107951, 1697552109205]"
1780,1780,515,35,[],200,llama-13b,64,1,1234.0,1.0,1,A100,1697552101113,1697552102347,120,11.0,1.0,"[37, 1197]","[1697552101150, 1697552102347]"
1781,1781,308,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098705,1697552099703,120,,,[20],[1697552098725]
1782,1782,501,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109208,1697552110135,120,,,[29],[1697552109237]
1783,1783,175,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102451,1697552103818,120,,,[24],[1697552102475]
1784,1784,355,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552124746,1697552126521,120,,,[34],[1697552124780]
1785,1785,801,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078585,1697552080744,120,,,"[20, 1546]","[1697552078605, 1697552080151]"
1786,1786,626,28,[],200,llama-13b,64,1,1240.0,1.0,1,A100,1697552090607,1697552091847,120,10.0,1.0,"[137, 1103]","[1697552090744, 1697552091847]"
1787,1787,757,35,[],200,llama-13b,64,1,1245.0,1.0,1,A100,1697552103822,1697552105067,120,20.0,1.0,"[11, 1234]","[1697552103833, 1697552105067]"
1788,1788,81,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099715,1697552102446,120,,,"[32, 2004]","[1697552099747, 1697552101751]"
1789,1789,396,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091863,1697552093265,120,,,"[5, 870]","[1697552091868, 1697552092738]"
1790,1790,528,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105069,1697552106518,120,,,"[9, 826]","[1697552105078, 1697552105904]"
1791,1791,671,36,[],200,llama-13b,64,1,1245.0,1.0,1,A100,1697552102450,1697552103695,120,12.0,1.0,"[7, 1238]","[1697552102457, 1697552103695]"
1792,1792,190,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106523,1697552109319,120,,,"[118, 2049]","[1697552106641, 1697552108690]"
1793,1793,438,37,[],200,llama-13b,64,1,808.0,1.0,1,A100,1697552103700,1697552104508,120,9.0,1.0,"[18, 789]","[1697552103718, 1697552104507]"
1794,1794,247,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552088530,1697552090604,120,,,"[111, 1154]","[1697552088641, 1697552089795]"
1795,1795,648,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068966,1697552073395,120,,,"[77, 988, 595, 698, 687, 683]","[1697552069043, 1697552070031, 1697552070626, 1697552071324, 1697552072011, 1697552072694]"
1796,1796,891,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109335,1697552110461,120,,,[104],[1697552109439]
1797,1797,70,38,[],200,llama-13b,64,1,1391.0,1.0,1,A100,1697552104513,1697552105904,120,39.0,1.0,"[32, 1359]","[1697552104545, 1697552105904]"
1798,1798,723,20,[],200,llama-13b,64,1,833.0,1.0,1,A100,1697552082006,1697552082839,120,14.0,1.0,"[35, 797]","[1697552082041, 1697552082838]"
1799,1799,51,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093269,1697552094764,120,,,"[39, 1059]","[1697552093308, 1697552094367]"
1800,1800,301,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073400,1697552076890,120,,,"[67, 1710, 309, 869]","[1697552073467, 1697552075177, 1697552075486, 1697552076355]"
1801,1801,33,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552081513,1697552083469,120,,,"[26, 1299]","[1697552081539, 1697552082838]"
1802,1802,729,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083473,1697552083904,120,,,[39],[1697552083512]
1803,1803,47,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076900,1697552078120,120,,,[56],[1697552076956]
1804,1804,315,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082123,1697552083468,120,,,"[7, 1229]","[1697552082130, 1697552083359]"
1805,1805,768,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105907,1697552107868,120,,,"[19, 1370]","[1697552105926, 1697552107296]"
1806,1806,728,31,[],200,llama-13b,64,1,1222.0,1.0,1,A100,1697552094769,1697552095991,120,20.0,1.0,"[27, 1195]","[1697552094796, 1697552095991]"
1807,1807,746,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078124,1697552080744,120,,,"[140, 1886]","[1697552078264, 1697552080150]"
1808,1808,788,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083477,1697552083904,120,,,[170],[1697552083647]
1809,1809,205,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552060892,1697552063764,120,,,"[85, 2029, 46]","[1697552060977, 1697552063006, 1697552063052]"
1810,1810,424,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107876,1697552109323,120,,,"[68, 1260]","[1697552107944, 1697552109204]"
1811,1811,201,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109335,1697552110463,120,,,[40],[1697552109375]
1812,1812,779,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110468,1697552112674,120,,,[107],[1697552110575]
1813,1813,245,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552077280,1697552079384,120,,,"[25, 1277, 51]","[1697552077305, 1697552078582, 1697552078633]"
1814,1814,555,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112682,1697552114139,120,,,[18],[1697552112700]
1815,1815,871,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110137,1697552111924,120,,,"[15, 961]","[1697552110152, 1697552111113]"
1816,1816,637,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093267,1697552094765,120,,,"[16, 1084]","[1697552093283, 1697552094367]"
1817,1817,275,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096120,1697552098824,120,,,"[127, 1981]","[1697552096247, 1697552098228]"
1818,1818,90,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074780,1697552075452,120,,,[21],[1697552074801]
1819,1819,704,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128293,1697552129608,120,,,[20],[1697552128313]
1820,1820,673,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075457,1697552076890,120,,,"[16, 883]","[1697552075473, 1697552076356]"
1821,1821,477,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129611,1697552131084,120,,,[35],[1697552129646]
1822,1822,134,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098829,1697552101107,120,,,"[56, 1646, 50]","[1697552098885, 1697552100531, 1697552100581]"
1823,1823,133,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131087,1697552132470,120,,,[40],[1697552131127]
1824,1824,800,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116447,1697552118448,120,,,[113],[1697552116560]
1825,1825,831,38,[],200,llama-13b,64,1,2187.0,1.0,1,A100,1697552101114,1697552103301,120,11.0,1.0,"[130, 2057]","[1697552101244, 1697552103301]"
1826,1826,577,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118451,1697552120128,120,,,[50],[1697552118501]
1827,1827,464,39,[],200,llama-13b,64,1,1202.0,1.0,1,A100,1697552103305,1697552104507,120,12.0,1.0,"[35, 1166]","[1697552103340, 1697552104506]"
1828,1828,839,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132472,1697552133253,120,,,[30],[1697552132502]
1829,1829,639,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111930,1697552113426,120,,,[17],[1697552111947]
1830,1830,208,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552114145,1697552116440,120,,,"[21, 1590]","[1697552114166, 1697552115756]"
1831,1831,493,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133258,1697552134788,120,,,[100],[1697552133358]
1832,1832,914,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116444,1697552117621,120,,,[16],[1697552116460]
1833,1833,269,58,[],200,llama-13b,64,1,783.0,1.0,1,A100,1697552134791,1697552135574,120,11.0,1.0,"[15, 768]","[1697552134806, 1697552135574]"
1834,1834,850,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135577,1697552137937,120,,,"[11, 707, 718]","[1697552135588, 1697552136295, 1697552137013]"
1835,1835,231,40,[],200,llama-13b,64,1,1393.0,1.0,1,A100,1697552104511,1697552105904,120,13.0,1.0,"[28, 1365]","[1697552104539, 1697552105904]"
1836,1836,232,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120132,1697552121355,120,,,[11],[1697552120143]
1837,1837,598,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137941,1697552140771,120,,,"[100, 2072, 53, 49, 48]","[1697552138041, 1697552140113, 1697552140166, 1697552140215, 1697552140263]"
1838,1838,2,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121358,1697552122073,120,,,[28],[1697552121386]
1839,1839,774,16,[],200,llama-13b,64,1,1399.0,1.0,1,A100,1697552071977,1697552073376,120,8.0,1.0,"[51, 1348]","[1697552072028, 1697552073376]"
1840,1840,587,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122078,1697552123844,120,,,[60],[1697552122138]
1841,1841,824,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105907,1697552107868,120,,,"[14, 1375]","[1697552105921, 1697552107296]"
1842,1842,654,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087784,1697552089316,120,,,"[24, 1490]","[1697552087808, 1697552089298]"
1843,1843,357,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123847,1697552125686,120,,,[33],[1697552123880]
1844,1844,16,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125693,1697552127341,120,,,[80],[1697552125773]
1845,1845,430,17,[],200,llama-13b,64,1,1378.0,1.0,1,A100,1697552073379,1697552074757,120,15.0,1.0,"[20, 1358]","[1697552073399, 1697552074757]"
1846,1846,200,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074760,1697552076890,120,,,"[7, 411, 308, 869]","[1697552074767, 1697552075178, 1697552075486, 1697552076355]"
1847,1847,715,50,[],200,llama-13b,64,1,1608.0,1.0,1,A100,1697552127358,1697552128966,120,20.0,1.0,"[85, 1522]","[1697552127443, 1697552128965]"
1848,1848,788,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076904,1697552078119,120,,,[141],[1697552077045]
1849,1849,308,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089321,1697552090604,120,,,"[41, 1221]","[1697552089362, 1697552090583]"
1850,1850,558,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078125,1697552080744,120,,,"[144, 1881]","[1697552078269, 1697552080150]"
1851,1851,218,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080748,1697552082119,120,,,[11],[1697552080759]
1852,1852,79,28,[],200,llama-13b,64,1,1239.0,1.0,1,A100,1697552090608,1697552091847,120,12.0,1.0,"[146, 1093]","[1697552090754, 1697552091847]"
1853,1853,290,36,[],200,llama-13b,64,1,951.0,1.0,1,A100,1697552102351,1697552103302,120,14.0,1.0,"[30, 920]","[1697552102381, 1697552103301]"
1854,1854,434,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123847,1697552125687,120,,,[48],[1697552123895]
1855,1855,668,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091863,1697552093264,120,,,"[33, 1267]","[1697552091896, 1697552093163]"
1856,1856,872,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103304,1697552105087,120,,,"[23, 1180]","[1697552103327, 1697552104507]"
1857,1857,704,19,[],200,llama-13b,64,1,1566.0,1.0,1,A100,1697552078585,1697552080151,120,14.0,1.0,"[20, 1546]","[1697552078605, 1697552080151]"
1858,1858,87,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125690,1697552127341,120,,,[58],[1697552125748]
1859,1859,837,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090606,1697552091870,120,,,"[36, 1205]","[1697552090642, 1697552091847]"
1860,1860,913,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552126524,1697552128290,120,,,"[37, 1566]","[1697552126561, 1697552128127]"
1861,1861,683,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128293,1697552129608,120,,,[25],[1697552128318]
1862,1862,853,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082127,1697552083672,120,,,[112],[1697552082239]
1863,1863,650,38,[],200,llama-13b,64,1,1400.0,1.0,1,A100,1697552105090,1697552106490,120,13.0,1.0,"[30, 1370]","[1697552105120, 1697552106490]"
1864,1864,483,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083679,1697552084683,120,,,[68],[1697552083747]
1865,1865,344,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129612,1697552131084,120,,,[46],[1697552129658]
1866,1866,794,53,[],200,llama-13b,64,1,1611.0,1.0,1,A100,1697552127354,1697552128965,120,11.0,1.0,"[35, 1575]","[1697552127389, 1697552128964]"
1867,1867,305,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106493,1697552107867,120,,,"[25, 1235]","[1697552106518, 1697552107753]"
1868,1868,569,24,[],200,llama-13b,64,1,1251.0,1.0,1,A100,1697552080751,1697552082002,120,16.0,1.0,"[93, 1158]","[1697552080844, 1697552082002]"
1869,1869,447,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128970,1697552130343,120,,,[40],[1697552129010]
1870,1870,196,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083910,1697552084997,120,,,[138],[1697552084048]
1871,1871,75,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107876,1697552110134,120,,,[85],[1697552107961]
1872,1872,787,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085001,1697552086534,120,,,[41],[1697552085042]
1873,1873,556,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086542,1697552088518,120,,,[132],[1697552086674]
1874,1874,193,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130345,1697552131084,120,,,[7],[1697552130352]
1875,1875,632,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110138,1697552111924,120,,,"[20, 955]","[1697552110158, 1697552111113]"
1876,1876,215,28,[],200,llama-13b,64,1,1274.0,1.0,1,A100,1697552088522,1697552089796,120,12.0,1.0,"[59, 1214]","[1697552088581, 1697552089795]"
1877,1877,256,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084686,1697552085755,120,,,[53],[1697552084739]
1878,1878,401,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111929,1697552113425,120,,,[13],[1697552111942]
1879,1879,846,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085760,1697552089318,120,,,"[98, 1270, 693, 735]","[1697552085858, 1697552087128, 1697552087821, 1697552088556]"
1880,1880,60,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113430,1697552115113,120,,,[29],[1697552113459]
1881,1881,775,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131088,1697552132469,120,,,[46],[1697552131134]
1882,1882,230,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082004,1697552083467,120,,,"[11, 822]","[1697552082015, 1697552082837]"
1883,1883,552,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132472,1697552133252,120,,,[15],[1697552132487]
1884,1884,617,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089320,1697552090605,120,,,"[22, 1241]","[1697552089342, 1697552090583]"
1885,1885,758,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115119,1697552116440,120,,,"[49, 1140]","[1697552115168, 1697552116308]"
1886,1886,271,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090607,1697552091869,120,,,"[132, 1108]","[1697552090739, 1697552091847]"
1887,1887,668,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128293,1697552129608,120,,,[30],[1697552128323]
1888,1888,419,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116445,1697552117622,120,,,[36],[1697552116481]
1889,1889,582,21,[],200,llama-13b,64,1,1234.0,1.0,1,A100,1697552082125,1697552083359,120,19.0,1.0,"[55, 1179]","[1697552082180, 1697552083359]"
1890,1890,48,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091872,1697552093264,120,,,[86],[1697552091958]
1891,1891,381,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552095994,1697552097350,120,,,"[17, 693]","[1697552096011, 1697552096704]"
1892,1892,161,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097354,1697552098825,120,,,[34],[1697552097388]
1893,1893,742,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098829,1697552101107,120,,,"[127, 1574, 52]","[1697552098956, 1697552100530, 1697552100582]"
1894,1894,0,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083473,1697552083904,120,,,[76],[1697552083549]
1895,1895,191,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117629,1697552119185,120,,,[47],[1697552117676]
1896,1896,519,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101112,1697552103817,120,,,"[58, 2130]","[1697552101170, 1697552103300]"
1897,1897,774,47,[],200,llama-13b,64,1,1492.0,1.0,1,A100,1697552119189,1697552120681,120,8.0,1.0,"[37, 1455]","[1697552119226, 1697552120681]"
1898,1898,583,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083906,1697552084997,120,,,[49],[1697552083955]
1899,1899,554,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120683,1697552122074,120,,,[22],[1697552120705]
1900,1900,206,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122078,1697552123844,120,,,[66],[1697552122144]
1901,1901,332,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085004,1697552086534,120,,,[82],[1697552085086]
1902,1902,882,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123846,1697552125686,120,,,[20],[1697552123866]
1903,1903,910,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086537,1697552087781,120,,,[26],[1697552086563]
1904,1904,418,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083472,1697552083902,120,,,[16],[1697552083488]
1905,1905,197,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078120,1697552079384,120,,,"[46, 1081]","[1697552078166, 1697552079247]"
1906,1906,162,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085004,1697552086533,120,,,[57],[1697552085061]
1907,1907,198,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552068624,1697552069275,120,,,[25],[1697552068649]
1908,1908,896,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069283,1697552071284,120,,,[101],[1697552069384]
1909,1909,80,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083910,1697552084996,120,,,[137],[1697552084047]
1910,1910,787,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079394,1697552082118,120,,,"[61, 2054]","[1697552079455, 1697552081509]"
1911,1911,557,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071287,1697552072657,120,,,[63],[1697552071350]
1912,1912,555,25,[],200,llama-13b,64,1,1235.0,1.0,1,A100,1697552082124,1697552083359,120,11.0,1.0,"[11, 1223]","[1697552082135, 1697552083358]"
1913,1913,302,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083361,1697552083672,120,,,[18],[1697552083379]
1914,1914,852,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106524,1697552109319,120,,,"[132, 2034]","[1697552106656, 1697552108690]"
1915,1915,779,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085001,1697552086534,120,,,[36],[1697552085037]
1916,1916,652,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125689,1697552127341,120,,,[35],[1697552125724]
1917,1917,886,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083678,1697552084682,120,,,[32],[1697552083710]
1918,1918,326,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072660,1697552074777,120,,,"[28, 1366]","[1697552072688, 1697552074054]"
1919,1919,583,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083678,1697552084682,120,,,[57],[1697552083735]
1920,1920,914,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074784,1697552075456,120,,,[158],[1697552074942]
1921,1921,307,52,[],200,llama-13b,64,1,1605.0,1.0,1,A100,1697552127360,1697552128965,120,26.0,1.0,"[95, 1510]","[1697552127455, 1697552128965]"
1922,1922,84,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128969,1697552130343,120,,,[41],[1697552129010]
1923,1923,331,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084690,1697552085755,120,,,[81],[1697552084771]
1924,1924,684,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075465,1697552079392,120,,,"[90, 1721, 874, 483]","[1697552075555, 1697552077276, 1697552078150, 1697552078633]"
1925,1925,500,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093480,1697552094765,120,,,"[26, 1241]","[1697552093506, 1697552094747]"
1926,1926,440,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086537,1697552087782,120,,,[31],[1697552086568]
1927,1927,667,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.11 GiB is allocated by PyTorch, and 7.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130346,1697552131775,120,,,[20],[1697552130366]
1928,1928,915,22,[],200,llama-13b,64,1,1567.0,1.0,1,A100,1697552078584,1697552080151,120,182.0,1.0,"[16, 1551]","[1697552078600, 1697552080151]"
1929,1929,211,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087790,1697552089317,120,,,"[43, 1465]","[1697552087833, 1697552089298]"
1930,1930,428,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079400,1697552082120,120,,,"[144, 1966]","[1697552079544, 1697552081510]"
1931,1931,152,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094770,1697552096115,120,,,"[79, 1141]","[1697552094849, 1697552095990]"
1932,1932,794,30,[],200,llama-13b,64,1,1260.0,1.0,1,A100,1697552089324,1697552090584,120,11.0,1.0,"[145, 1115]","[1697552089469, 1697552090584]"
1933,1933,570,31,[],200,llama-13b,64,1,1260.0,1.0,1,A100,1697552090587,1697552091847,120,18.0,1.0,"[30, 1229]","[1697552090617, 1697552091846]"
1934,1934,100,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067365,1697552067818,120,,,[22],[1697552067387]
1935,1935,84,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082127,1697552083672,120,,,[127],[1697552082254]
1936,1936,223,32,[],200,llama-13b,64,1,1301.0,1.0,1,A100,1697552091863,1697552093164,120,16.0,1.0,"[33, 1268]","[1697552091896, 1697552093164]"
1937,1937,861,34,[],200,llama-13b,64,1,1130.0,1.0,1,A100,1697552096120,1697552097250,120,10.0,1.0,"[59, 1071]","[1697552096179, 1697552097250]"
1938,1938,515,35,[],200,llama-13b,64,1,974.0,1.0,1,A100,1697552097255,1697552098229,120,11.0,1.0,"[19, 954]","[1697552097274, 1697552098228]"
1939,1939,438,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131781,1697552133253,120,,,[31],[1697552131812]
1940,1940,895,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093168,1697552093477,120,,,[24],[1697552093192]
1941,1941,690,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067823,1697552069275,120,,,[54],[1697552067877]
1942,1942,92,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133256,1697552134789,120,,,[49],[1697552133305]
1943,1943,461,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 6.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069279,1697552070587,120,,,[31],[1697552069310]
1944,1944,585,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082124,1697552083467,120,,,"[31, 1204]","[1697552082155, 1697552083359]"
1945,1945,665,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093484,1697552096114,120,,,"[87, 1864]","[1697552093571, 1697552095435]"
1946,1946,122,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070591,1697552071972,120,,,[42],[1697552070633]
1947,1947,286,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098235,1697552099703,120,,,[32],[1697552098267]
1948,1948,320,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096119,1697552097349,120,,,[20],[1697552096139]
1949,1949,876,37,[],200,llama-13b,64,1,1378.0,1.0,1,A100,1697552099711,1697552101089,120,11.0,1.0,"[39, 1339]","[1697552099750, 1697552101089]"
1950,1950,820,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071975,1697552072657,120,,,[10],[1697552071985]
1951,1951,646,38,[],200,llama-13b,64,1,1254.0,1.0,1,A100,1697552101093,1697552102347,120,14.0,1.0,"[18, 1236]","[1697552101111, 1697552102347]"
1952,1952,557,18,[],200,llama-13b,64,1,676.0,1.0,1,A100,1697552073379,1697552074055,120,31.0,1.0,"[14, 662]","[1697552073393, 1697552074055]"
1953,1953,304,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102350,1697552103817,120,,,"[11, 940]","[1697552102361, 1697552103301]"
1954,1954,475,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072660,1697552074776,120,,,"[76, 1319]","[1697552072736, 1697552074055]"
1955,1955,97,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097355,1697552098826,120,,,"[90, 1256]","[1697552097445, 1697552098701]"
1956,1956,863,9,[],200,llama-13b,64,1,1294.0,1.0,1,A100,1697552061712,1697552063006,120,10.0,1.0,"[33, 1261]","[1697552061745, 1697552063006]"
1957,1957,680,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098829,1697552101107,120,,,"[112, 1590, 51]","[1697552098941, 1697552100531, 1697552100582]"
1958,1958,224,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074782,1697552075453,120,,,[89],[1697552074871]
1959,1959,569,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117627,1697552118449,120,,,[24],[1697552117651]
1960,1960,74,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103823,1697552105088,120,,,"[20, 1224]","[1697552103843, 1697552105067]"
1961,1961,456,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101112,1697552102447,120,,,"[29, 1206]","[1697552101141, 1697552102347]"
1962,1962,214,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085004,1697552086533,120,,,[72],[1697552085076]
1963,1963,448,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076901,1697552078119,120,,,[45],[1697552076946]
1964,1964,106,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086537,1697552087781,120,,,[13],[1697552086550]
1965,1965,108,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102451,1697552103818,120,,,"[31, 1213]","[1697552102482, 1697552103695]"
1966,1966,806,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075458,1697552076891,120,,,"[30, 1294]","[1697552075488, 1697552076782]"
1967,1967,797,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086543,1697552088519,120,,,[143],[1697552086686]
1968,1968,812,29,[],200,llama-13b,64,1,1510.0,1.0,1,A100,1697552087789,1697552089299,120,16.0,1.0,"[49, 1461]","[1697552087838, 1697552089299]"
1969,1969,573,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552088521,1697552090604,120,,,[35],[1697552088556]
1970,1970,582,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076901,1697552078118,120,,,[80],[1697552076981]
1971,1971,80,17,[],200,llama-13b,64,1,1124.0,1.0,1,A100,1697552078124,1697552079248,120,13.0,1.0,"[121, 1003]","[1697552078245, 1697552079248]"
1972,1972,465,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089301,1697552090604,120,,,"[7, 488]","[1697552089308, 1697552089796]"
1973,1973,747,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105092,1697552106518,120,,,"[83, 1314]","[1697552105175, 1697552106489]"
1974,1974,237,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090607,1697552091869,120,,,"[72, 1168]","[1697552090679, 1697552091847]"
1975,1975,822,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091871,1697552093475,120,,,[78],[1697552091949]
1976,1976,778,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079252,1697552080743,120,,,[44],[1697552079296]
1977,1977,592,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093480,1697552094765,120,,,"[31, 1236]","[1697552093511, 1697552094747]"
1978,1978,438,19,[],200,llama-13b,64,1,1250.0,1.0,1,A100,1697552080753,1697552082003,120,9.0,1.0,"[121, 1129]","[1697552080874, 1697552082003]"
1979,1979,228,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090607,1697552091870,120,,,"[51, 1189]","[1697552090658, 1697552091847]"
1980,1980,247,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140783,1697552143538,120,,,"[89, 2101]","[1697552140872, 1697552142973]"
1981,1981,6,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091874,1697552093477,120,,,[169],[1697552092043]
1982,1982,207,20,[],200,llama-13b,64,1,832.0,1.0,1,A100,1697552082006,1697552082838,120,10.0,1.0,"[40, 792]","[1697552082046, 1697552082838]"
1983,1983,899,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091872,1697552093476,120,,,[101],[1697552091973]
1984,1984,587,29,[],200,llama-13b,64,1,1952.0,1.0,1,A100,1697552093484,1697552095436,120,13.0,1.0,"[101, 1851]","[1697552093585, 1697552095436]"
1985,1985,919,22,[],200,llama-13b,64,1,1232.0,1.0,1,A100,1697552082127,1697552083359,120,14.0,1.0,"[122, 1110]","[1697552082249, 1697552083359]"
1986,1986,340,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094773,1697552096115,120,,,"[84, 1134]","[1697552094857, 1697552095991]"
1987,1987,572,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083361,1697552083672,120,,,[6],[1697552083367]
1988,1988,796,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082842,1697552083672,120,,,[25],[1697552082867]
1989,1989,559,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093484,1697552096114,120,,,"[91, 1860]","[1697552093575, 1697552095435]"
1990,1990,566,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083680,1697552084681,120,,,[81],[1697552083761]
1991,1991,105,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101112,1697552103817,120,,,"[53, 2135]","[1697552101165, 1697552103300]"
1992,1992,217,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084686,1697552085754,120,,,[35],[1697552084721]
1993,1993,327,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096120,1697552098824,120,,,"[123, 1985]","[1697552096243, 1697552098228]"
1994,1994,891,29,[],200,llama-13b,64,1,1754.0,1.0,1,A100,1697552098828,1697552100582,120,52.0,2.0,"[22, 1680, 51]","[1697552098850, 1697552100530, 1697552100581]"
1995,1995,924,24,[],200,llama-13b,64,1,1368.0,1.0,1,A100,1697552085760,1697552087128,120,9.0,1.0,"[86, 1282]","[1697552085846, 1697552087128]"
1996,1996,577,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087130,1697552088517,120,,,[6],[1697552087136]
1997,1997,661,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552100584,1697552102447,120,,,"[6, 1163]","[1697552100590, 1697552101753]"
1998,1998,390,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083910,1697552084997,120,,,[143],[1697552084053]
1999,1999,323,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552088520,1697552089317,120,,,"[15, 763]","[1697552088535, 1697552089298]"
2000,2000,687,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103822,1697552105088,120,,,"[16, 1228]","[1697552103838, 1697552105066]"
2001,2001,316,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102450,1697552103818,120,,,"[15, 1230]","[1697552102465, 1697552103695]"
2002,2002,156,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085004,1697552086534,120,,,[82],[1697552085086]
2003,2003,204,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133257,1697552134789,120,,,[91],[1697552133348]
2004,2004,93,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103826,1697552106517,120,,,"[121, 1956]","[1697552103947, 1697552105903]"
2005,2005,449,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083912,1697552084997,120,,,[150],[1697552084062]
2006,2006,92,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089321,1697552090604,120,,,"[56, 1207]","[1697552089377, 1697552090584]"
2007,2007,740,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086538,1697552088518,120,,,[114],[1697552086652]
2008,2008,628,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093269,1697552094764,120,,,"[44, 1054]","[1697552093313, 1697552094367]"
2009,2009,215,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085004,1697552086534,120,,,[77],[1697552085081]
2010,2010,880,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.76 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063771,1697552064878,120,,,[31],[1697552063802]
2011,2011,800,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086538,1697552088517,120,,,[109],[1697552086647]
2012,2012,533,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064883,1697552066163,120,,,[16],[1697552064899]
2013,2013,576,28,[],200,llama-13b,64,1,1274.0,1.0,1,A100,1697552088521,1697552089795,120,14.0,1.0,"[39, 1235]","[1697552088560, 1697552089795]"
2014,2014,435,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105093,1697552107867,120,,,"[144, 2059]","[1697552105237, 1697552107296]"
2015,2015,405,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094771,1697552096115,120,,,"[82, 1137]","[1697552094853, 1697552095990]"
2016,2016,488,26,[],200,llama-13b,64,1,777.0,1.0,1,A100,1697552088521,1697552089298,120,6.0,1.0,"[29, 748]","[1697552088550, 1697552089298]"
2017,2017,41,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080747,1697552082121,120,,,"[7, 1247]","[1697552080754, 1697552082001]"
2018,2018,55,32,[],200,llama-13b,64,1,2107.0,1.0,1,A100,1697552096121,1697552098228,120,12.0,1.0,"[136, 1971]","[1697552096257, 1697552098228]"
2019,2019,310,12,[],200,llama-13b,64,1,1196.0,1.0,1,A100,1697552066166,1697552067362,120,26.0,1.0,"[91, 1105]","[1697552066257, 1697552067362]"
2020,2020,257,27,[],200,llama-13b,64,1,1280.0,1.0,1,A100,1697552089303,1697552090583,120,14.0,1.0,"[20, 1260]","[1697552089323, 1697552090583]"
2021,2021,207,38,[],200,llama-13b,64,1,1332.0,1.0,1,A100,1697552107873,1697552109205,120,10.0,1.0,"[36, 1296]","[1697552107909, 1697552109205]"
2022,2022,789,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109210,1697552110136,120,,,[37],[1697552109247]
2023,2023,846,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090585,1697552091869,120,,,"[7, 602]","[1697552090592, 1697552091194]"
2024,2024,894,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067367,1697552067819,120,,,[69],[1697552067436]
2025,2025,566,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110140,1697552111926,120,,,"[107, 866]","[1697552110247, 1697552111113]"
2026,2026,615,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091872,1697552093476,120,,,[96],[1697552091968]
2027,2027,219,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111931,1697552113423,120,,,[124],[1697552112055]
2028,2028,276,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093484,1697552096114,120,,,[92],[1697552093576]
2029,2029,924,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113427,1697552115112,120,,,[10],[1697552113437]
2030,2030,51,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096120,1697552097349,120,,,"[44, 1086]","[1697552096164, 1697552097250]"
2031,2031,581,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115119,1697552116439,120,,,"[24, 1164]","[1697552115143, 1697552116307]"
2032,2032,277,23,[],200,llama-13b,64,1,1236.0,1.0,1,A100,1697552079389,1697552080625,120,18.0,1.0,"[21, 1215]","[1697552079410, 1697552080625]"
2033,2033,357,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116444,1697552117621,120,,,[17],[1697552116461]
2034,2034,656,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084690,1697552085755,120,,,[76],[1697552084766]
2035,2035,634,32,[],200,llama-13b,64,1,1345.0,1.0,1,A100,1697552097357,1697552098702,120,13.0,1.0,"[117, 1228]","[1697552097474, 1697552098702]"
2036,2036,99,29,[],200,llama-13b,64,1,1366.0,1.0,1,A100,1697552085762,1697552087128,120,10.0,1.0,"[111, 1255]","[1697552085873, 1697552087128]"
2037,2037,13,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117626,1697552118448,120,,,[6],[1697552117632]
2038,2038,318,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085759,1697552089317,120,,,"[39, 1328, 695, 735]","[1697552085798, 1697552087126, 1697552087821, 1697552088556]"
2039,2039,682,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087132,1697552088518,120,,,[19],[1697552087151]
2040,2040,83,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089319,1697552090604,120,,,"[9, 1255]","[1697552089328, 1697552090583]"
2041,2041,711,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118451,1697552119185,120,,,[15],[1697552118466]
2042,2042,672,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090606,1697552091870,120,,,[42],[1697552090648]
2043,2043,458,31,[],200,llama-13b,64,1,1273.0,1.0,1,A100,1697552088522,1697552089795,120,11.0,1.0,"[64, 1209]","[1697552088586, 1697552089795]"
2044,2044,343,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552119187,1697552120129,120,,,"[7, 755]","[1697552119194, 1697552119949]"
2045,2045,797,57,[],200,llama-13b,64,1,1499.0,1.0,1,A100,1697552134796,1697552136295,120,26.0,1.0,"[84, 1415]","[1697552134880, 1697552136295]"
2046,2046,362,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083476,1697552083904,120,,,[105],[1697552083581]
2047,2047,110,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120132,1697552121356,120,,,[21],[1697552120153]
2048,2048,15,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083906,1697552084996,120,,,[30],[1697552083936]
2049,2049,441,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091874,1697552093476,120,,,[184],[1697552092058]
2050,2050,101,33,[],200,llama-13b,64,1,1952.0,1.0,1,A100,1697552093483,1697552095435,120,13.0,1.0,"[160, 1792]","[1697552093643, 1697552095435]"
2051,2051,606,28,[],200,llama-13b,64,1,1260.0,1.0,1,A100,1697552090587,1697552091847,120,9.0,1.0,"[20, 1239]","[1697552090607, 1697552091846]"
2052,2052,111,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089797,1697552091870,120,,,"[6, 1391]","[1697552089803, 1697552091194]"
2053,2053,816,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091873,1697552093476,120,,,[165],[1697552092038]
2054,2054,262,29,[],200,llama-13b,64,1,1300.0,1.0,1,A100,1697552091864,1697552093164,120,39.0,1.0,"[37, 1263]","[1697552091901, 1697552093164]"
2055,2055,453,58,[],200,llama-13b,64,1,1465.0,1.0,1,A100,1697552136300,1697552137765,120,26.0,1.0,"[16, 1449]","[1697552136316, 1697552137765]"
2056,2056,469,34,[],200,llama-13b,64,1,1267.0,1.0,1,A100,1697552093480,1697552094747,120,17.0,1.0,"[21, 1246]","[1697552093501, 1697552094747]"
2057,2057,222,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137768,1697552139266,120,,,"[10, 835]","[1697552137778, 1697552138613]"
2058,2058,31,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093167,1697552093476,120,,,[12],[1697552093179]
2059,2059,246,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094751,1697552096114,120,,,"[6, 679]","[1697552094757, 1697552095436]"
2060,2060,802,34,[],200,llama-13b,64,1,1267.0,1.0,1,A100,1697552095437,1697552096704,120,9.0,1.0,"[15, 1251]","[1697552095452, 1697552096703]"
2061,2061,834,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096119,1697552098825,120,,,"[129, 1980]","[1697552096248, 1697552098228]"
2062,2062,591,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093480,1697552096114,120,,,"[66, 1889]","[1697552093546, 1697552095435]"
2063,2063,716,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085001,1697552086534,120,,,[46],[1697552085047]
2064,2064,464,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086543,1697552088519,120,,,[136],[1697552086679]
2065,2065,604,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098829,1697552101106,120,,,"[36, 1665, 51]","[1697552098865, 1697552100530, 1697552100581]"
2066,2066,783,60,[],200,llama-13b,64,1,2471.0,1.0,1,A100,1697552139273,1697552141744,120,286.0,1.0,"[82, 2389]","[1697552139355, 1697552141744]"
2067,2067,235,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101112,1697552102447,120,,,[54],[1697552101166]
2068,2068,271,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113430,1697552115113,120,,,[108],[1697552113538]
2069,2069,817,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103824,1697552105088,120,,,"[55, 1188]","[1697552103879, 1697552105067]"
2070,2070,40,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115119,1697552116439,120,,,"[29, 1159]","[1697552115148, 1697552116307]"
2071,2071,553,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552141748,1697552143538,120,,,"[18, 1208]","[1697552141766, 1697552142974]"
2072,2072,551,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110468,1697552111926,120,,,"[171, 1177]","[1697552110639, 1697552111816]"
2073,2073,116,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131088,1697552132469,120,,,[49],[1697552131137]
2074,2074,756,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098232,1697552099702,120,,,[20],[1697552098252]
2075,2075,347,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071292,1697552072656,120,,,[88],[1697552071380]
2076,2076,724,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086542,1697552088518,120,,,[126],[1697552086668]
2077,2077,80,35,[],200,llama-13b,64,1,974.0,1.0,1,A100,1697552097255,1697552098229,120,13.0,1.0,"[23, 950]","[1697552097278, 1697552098228]"
2078,2078,410,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096118,1697552097350,120,,,"[7, 1125]","[1697552096125, 1697552097250]"
2079,2079,64,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083476,1697552083904,120,,,[109],[1697552083585]
2080,2080,665,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098232,1697552099702,120,,,[25],[1697552098257]
2081,2081,646,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083912,1697552084997,120,,,[156],[1697552084068]
2082,2082,506,40,[],200,llama-13b,64,1,1778.0,1.0,1,A100,1697552109335,1697552111113,120,16.0,1.0,"[136, 1642]","[1697552109471, 1697552111113]"
2083,2083,442,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099704,1697552101106,120,,,"[13, 1372]","[1697552099717, 1697552101089]"
2084,2084,282,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111116,1697552112674,120,,,[13],[1697552111129]
2085,2085,95,38,[],200,llama-13b,64,1,1234.0,1.0,1,A100,1697552101113,1697552102347,120,12.0,1.0,"[33, 1201]","[1697552101146, 1697552102347]"
2086,2086,664,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067822,1697552069273,120,,,[25],[1697552067847]
2087,2087,421,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085004,1697552086533,120,,,[67],[1697552085071]
2088,2088,863,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112684,1697552114140,120,,,[67],[1697552112751]
2089,2089,771,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102350,1697552103817,120,,,"[21, 930]","[1697552102371, 1697552103301]"
2090,2090,66,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097355,1697552099702,120,,,[85],[1697552097440]
2091,2091,540,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103824,1697552105088,120,,,"[50, 1194]","[1697552103874, 1697552105068]"
2092,2092,682,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090606,1697552091869,120,,,"[58, 1183]","[1697552090664, 1697552091847]"
2093,2093,418,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083475,1697552083903,120,,,[90],[1697552083565]
2094,2094,200,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105092,1697552106518,120,,,"[67, 1331]","[1697552105159, 1697552106490]"
2095,2095,764,35,[],200,llama-13b,64,1,1385.0,1.0,1,A100,1697552099704,1697552101089,120,39.0,1.0,"[11, 1374]","[1697552099715, 1697552101089]"
2096,2096,75,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086538,1697552088517,120,,,[105],[1697552086643]
2097,2097,512,36,[],200,llama-13b,64,1,662.0,1.0,1,A100,1697552101091,1697552101753,120,11.0,1.0,"[9, 653]","[1697552101100, 1697552101753]"
2098,2098,163,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101758,1697552103819,120,,,"[32, 1511]","[1697552101790, 1697552103301]"
2099,2099,78,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083908,1697552084996,120,,,[67],[1697552083975]
2100,2100,865,38,[],200,llama-13b,64,1,1242.0,1.0,1,A100,1697552103826,1697552105068,120,9.0,1.0,"[116, 1126]","[1697552103942, 1697552105068]"
2101,2101,782,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083679,1697552084681,120,,,[87],[1697552083766]
2102,2102,660,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105092,1697552107867,120,,,"[92, 2112]","[1697552105184, 1697552107296]"
2103,2103,899,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106521,1697552107867,120,,,"[11, 1221]","[1697552106532, 1697552107753]"
2104,2104,519,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105071,1697552106519,120,,,"[29, 1389]","[1697552105100, 1697552106489]"
2105,2105,780,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552088522,1697552090604,120,,,"[54, 1219]","[1697552088576, 1697552089795]"
2106,2106,776,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085000,1697552086533,120,,,[22],[1697552085022]
2107,2107,551,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107872,1697552109319,120,,,"[22, 1310]","[1697552107894, 1697552109204]"
2108,2108,290,40,[],200,llama-13b,64,1,2165.0,1.0,1,A100,1697552106525,1697552108690,120,14.0,1.0,"[138, 2027]","[1697552106663, 1697552108690]"
2109,2109,880,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552108694,1697552110135,120,,,[30],[1697552108724]
2110,2110,347,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128971,1697552130343,120,,,[68],[1697552129039]
2111,2111,327,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109335,1697552110463,120,,,[35],[1697552109370]
2112,2112,339,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118453,1697552120129,120,,,"[43, 1453]","[1697552118496, 1697552119949]"
2113,2113,118,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.11 GiB is allocated by PyTorch, and 7.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130346,1697552131775,120,,,[30],[1697552130376]
2114,2114,594,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107876,1697552110134,120,,,[99],[1697552107975]
2115,2115,86,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120132,1697552121355,120,,,[26],[1697552120158]
2116,2116,910,45,[],200,llama-13b,64,1,1347.0,1.0,1,A100,1697552110469,1697552111816,120,8.0,1.0,"[111, 1236]","[1697552110580, 1697552111816]"
2117,2117,361,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096120,1697552097349,120,,,"[44, 1087]","[1697552096164, 1697552097251]"
2118,2118,403,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106522,1697552109318,120,,,"[40, 2128]","[1697552106562, 1697552108690]"
2119,2119,19,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143543,1697552147357,120,,,"[119, 2293, 716]","[1697552143662, 1697552145955, 1697552146671]"
2120,2120,472,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105091,1697552106517,120,,,"[46, 1353]","[1697552105137, 1697552106490]"
2121,2121,215,62,[],200,llama-13b,64,1,2412.0,1.0,1,A100,1697552143543,1697552145955,120,12.0,1.0,"[109, 2303]","[1697552143652, 1697552145955]"
2122,2122,323,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083678,1697552084681,120,,,[25],[1697552083703]
2123,2123,439,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093268,1697552094764,120,,,"[40, 1059]","[1697552093308, 1697552094367]"
2124,2124,173,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103823,1697552105087,120,,,"[27, 1217]","[1697552103850, 1697552105067]"
2125,2125,101,31,[],200,llama-13b,64,1,1222.0,1.0,1,A100,1697552094769,1697552095991,120,13.0,1.0,"[12, 1210]","[1697552094781, 1697552095991]"
2126,2126,242,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106520,1697552107867,120,,,"[18, 1215]","[1697552106538, 1697552107753]"
2127,2127,746,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082125,1697552083672,120,,,[55],[1697552082180]
2128,2128,94,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084690,1697552085755,120,,,[83],[1697552084773]
2129,2129,400,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083675,1697552084683,120,,,[76],[1697552083751]
2130,2130,681,26,[],200,llama-13b,64,1,1367.0,1.0,1,A100,1697552085761,1697552087128,120,23.0,1.0,"[95, 1272]","[1697552085856, 1697552087128]"
2131,2131,171,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084686,1697552085755,120,,,[33],[1697552084719]
2132,2132,753,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085762,1697552089318,120,,,"[99, 1267, 693, 735]","[1697552085861, 1697552087128, 1697552087821, 1697552088556]"
2133,2133,451,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087130,1697552088517,120,,,[11],[1697552087141]
2134,2134,608,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147361,1697552148668,120,,,[14],[1697552147375]
2135,2135,111,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552088520,1697552089318,120,,,"[27, 751]","[1697552088547, 1697552089298]"
2136,2136,531,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089322,1697552090605,120,,,"[113, 1149]","[1697552089435, 1697552090584]"
2137,2137,799,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552095991,1697552097349,120,,,"[6, 706]","[1697552095997, 1697552096703]"
2138,2138,632,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105093,1697552107867,120,,,"[157, 2046]","[1697552105250, 1697552107296]"
2139,2139,873,37,[],200,llama-13b,64,1,1397.0,1.0,1,A100,1697552105093,1697552106490,120,6.0,1.0,"[147, 1250]","[1697552105240, 1697552106490]"
2140,2140,431,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097354,1697552098825,120,,,"[24, 1323]","[1697552097378, 1697552098701]"
2141,2141,378,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148674,1697552149357,120,,,[28],[1697552148702]
2142,2142,534,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106493,1697552107867,120,,,"[14, 790]","[1697552106507, 1697552107297]"
2143,2143,230,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089797,1697552091870,120,,,"[11, 1386]","[1697552089808, 1697552091194]"
2144,2144,303,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107873,1697552109322,120,,,"[36, 1296]","[1697552107909, 1697552109205]"
2145,2145,37,65,[],200,llama-13b,64,1,1589.0,1.0,1,A100,1697552149361,1697552150950,120,20.0,1.0,"[44, 1545]","[1697552149405, 1697552150950]"
2146,2146,503,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099706,1697552101107,120,,,"[29, 1354]","[1697552099735, 1697552101089]"
2147,2147,50,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109334,1697552110462,120,,,[24],[1697552109358]
2148,2148,157,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101113,1697552103818,120,,,"[73, 2114]","[1697552101186, 1697552103300]"
2149,2149,628,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110467,1697552111925,120,,,"[78, 1270]","[1697552110545, 1697552111815]"
2150,2150,245,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078122,1697552079383,120,,,"[34, 1091]","[1697552078156, 1697552079247]"
2151,2151,735,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150953,1697552152619,120,,,[14],[1697552150967]
2152,2152,317,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090588,1697552091869,120,,,"[34, 1224]","[1697552090622, 1697552091846]"
2153,2153,835,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079390,1697552080744,120,,,"[25, 1210]","[1697552079415, 1697552080625]"
2154,2154,902,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134792,1697552137935,120,,,"[41, 1462, 718]","[1697552134833, 1697552136295, 1697552137013]"
2155,2155,397,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152621,1697552153790,120,,,[16],[1697552152637]
2156,2156,863,36,[],200,llama-13b,64,1,1243.0,1.0,1,A100,1697552103825,1697552105068,120,10.0,1.0,"[45, 1198]","[1697552103870, 1697552105068]"
2157,2157,171,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153795,1697552154924,120,,,[47],[1697552153842]
2158,2158,754,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154927,1697552156085,120,,,[39],[1697552154966]
2159,2159,563,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137941,1697552139269,120,,,"[44, 1182]","[1697552137985, 1697552139167]"
2160,2160,515,37,[],200,llama-13b,64,1,1417.0,1.0,1,A100,1697552105072,1697552106489,120,11.0,1.0,"[23, 1394]","[1697552105095, 1697552106489]"
2161,2161,501,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156089,1697552157801,120,,,[53],[1697552156142]
2162,2162,331,61,[],200,llama-13b,64,1,2471.0,1.0,1,A100,1697552139274,1697552141745,120,26.0,1.0,"[91, 2379]","[1697552139365, 1697552141744]"
2163,2163,270,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157803,1697552159106,120,,,[28],[1697552157831]
2164,2164,859,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159110,1697552160461,120,,,[43],[1697552159153]
2165,2165,921,62,[],200,llama-13b,64,1,1225.0,1.0,1,A100,1697552141749,1697552142974,120,31.0,1.0,"[27, 1198]","[1697552141776, 1697552142974]"
2166,2166,629,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160470,1697552162486,120,,,[101],[1697552160571]
2167,2167,284,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162488,1697552163833,120,,,[43],[1697552162531]
2168,2168,57,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163835,1697552164530,120,,,[14],[1697552163849]
2169,2169,291,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106492,1697552107866,120,,,[21],[1697552106513]
2170,2170,877,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107872,1697552109319,120,,,"[12, 1320]","[1697552107884, 1697552109204]"
2171,2171,640,76,[],200,llama-13b,64,1,1429.0,1.0,1,A100,1697552164534,1697552165963,120,15.0,1.0,"[61, 1367]","[1697552164595, 1697552165962]"
2172,2172,649,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109335,1697552110461,120,,,[109],[1697552109444]
2173,2173,83,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091872,1697552093476,120,,,[116],[1697552091988]
2174,2174,690,63,[],200,llama-13b,64,1,1563.0,1.0,1,A100,1697552142981,1697552144544,120,39.0,1.0,"[26, 1537]","[1697552143007, 1697552144544]"
2175,2175,416,77,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165966,1697552167168,120,,,[38],[1697552166004]
2176,2176,68,78,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167174,1697552168555,120,,,[39],[1697552167213]
2177,2177,410,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098704,1697552099702,120,,,[15],[1697552098719]
2178,2178,691,23,[],200,llama-13b,64,1,1354.0,1.0,1,A100,1697552080155,1697552081509,120,47.0,1.0,"[20, 1334]","[1697552080175, 1697552081509]"
2179,2179,436,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086538,1697552087781,120,,,[45],[1697552086583]
2180,2180,62,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099712,1697552102445,120,,,"[53, 1986]","[1697552099765, 1697552101751]"
2181,2181,113,25,[],200,llama-13b,64,1,1272.0,1.0,1,A100,1697552088523,1697552089795,120,13.0,1.0,"[113, 1159]","[1697552088636, 1697552089795]"
2182,2182,345,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552081512,1697552083468,120,,,"[17, 1308]","[1697552081529, 1697552082837]"
2183,2183,819,26,[],200,llama-13b,64,1,1397.0,1.0,1,A100,1697552089798,1697552091195,120,13.0,1.0,"[15, 1382]","[1697552089813, 1697552091195]"
2184,2184,471,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091196,1697552093264,120,,,"[6, 1536]","[1697552091202, 1697552092738]"
2185,2185,346,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552144547,1697552147357,120,,,"[14, 1394, 716]","[1697552144561, 1697552145955, 1697552146671]"
2186,2186,247,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093274,1697552094764,120,,,"[82, 1012]","[1697552093356, 1697552094368]"
2187,2187,714,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094769,1697552096115,120,,,"[32, 1190]","[1697552094801, 1697552095991]"
2188,2188,739,35,[],200,llama-13b,64,1,1246.0,1.0,1,A100,1697552102449,1697552103695,120,216.0,1.0,"[7, 1239]","[1697552102456, 1697552103695]"
2189,2189,830,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094767,1697552096115,120,,,"[33, 1191]","[1697552094800, 1697552095991]"
2190,2190,392,36,[],200,llama-13b,64,1,808.0,1.0,1,A100,1697552103699,1697552104507,120,20.0,1.0,"[24, 784]","[1697552103723, 1697552104507]"
2191,2191,164,37,[],200,llama-13b,64,1,1395.0,1.0,1,A100,1697552104509,1697552105904,120,15.0,1.0,"[6, 1388]","[1697552104515, 1697552105903]"
2192,2192,95,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083476,1697552083904,120,,,[159],[1697552083635]
2193,2193,231,22,[],200,llama-13b,64,1,1124.0,1.0,1,A100,1697552078124,1697552079248,120,13.0,1.0,"[126, 998]","[1697552078250, 1697552079248]"
2194,2194,630,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116446,1697552117622,120,,,[95],[1697552116541]
2195,2195,793,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083910,1697552084996,120,,,[70],[1697552083980]
2196,2196,398,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117629,1697552119185,120,,,[52],[1697552117681]
2197,2197,750,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105905,1697552107868,120,,,"[6, 1385]","[1697552105911, 1697552107296]"
2198,2198,58,50,[],200,llama-13b,64,1,1488.0,1.0,1,A100,1697552119193,1697552120681,120,15.0,1.0,"[75, 1413]","[1697552119268, 1697552120681]"
2199,2199,757,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120687,1697552122073,120,,,[51],[1697552120738]
2200,2200,8,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079251,1697552080742,120,,,"[25, 875]","[1697552079276, 1697552080151]"
2201,2201,416,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122077,1697552123843,120,,,[28],[1697552122105]
2202,2202,520,39,[],200,llama-13b,64,1,1331.0,1.0,1,A100,1697552107874,1697552109205,120,11.0,1.0,"[50, 1281]","[1697552107924, 1697552109205]"
2203,2203,193,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123846,1697552125686,120,,,[25],[1697552123871]
2204,2204,180,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109208,1697552110135,120,,,[19],[1697552109227]
2205,2205,701,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131780,1697552133253,120,,,[37],[1697552131817]
2206,2206,456,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080154,1697552082120,120,,,"[15, 1341]","[1697552080169, 1697552081510]"
2207,2207,454,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085000,1697552086533,120,,,[17],[1697552085017]
2208,2208,592,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080747,1697552082119,120,,,"[17, 1237]","[1697552080764, 1697552082001]"
2209,2209,481,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133258,1697552134789,120,,,[87],[1697552133345]
2210,2210,775,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125692,1697552127341,120,,,[79],[1697552125771]
2211,2211,133,55,[],200,llama-13b,64,1,1502.0,1.0,1,A100,1697552134792,1697552136294,120,15.0,1.0,"[32, 1470]","[1697552134824, 1697552136294]"
2212,2212,838,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136297,1697552137935,120,,,"[7, 1460]","[1697552136304, 1697552137764]"
2213,2213,109,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082124,1697552083467,120,,,"[36, 1199]","[1697552082160, 1697552083359]"
2214,2214,606,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091874,1697552093475,120,,,[179],[1697552092053]
2215,2215,359,30,[],200,llama-13b,64,1,1264.0,1.0,1,A100,1697552095440,1697552096704,120,10.0,1.0,"[27, 1236]","[1697552095467, 1697552096703]"
2216,2216,159,26,[],200,llama-13b,64,1,1100.0,1.0,1,A100,1697552093267,1697552094367,120,31.0,1.0,"[21, 1079]","[1697552093288, 1697552094367]"
2217,2217,381,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082841,1697552083673,120,,,[25],[1697552082866]
2218,2218,172,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109333,1697552110462,120,,,[30],[1697552109363]
2219,2219,7,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091872,1697552093476,120,,,[111],[1697552091983]
2220,2220,762,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110465,1697552111926,120,,,"[26, 1324]","[1697552110491, 1697552111815]"
2221,2221,587,31,[],200,llama-13b,64,1,1266.0,1.0,1,A100,1697552093481,1697552094747,120,13.0,1.0,"[70, 1196]","[1697552093551, 1697552094747]"
2222,2222,405,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111930,1697552113424,120,,,[52],[1697552111982]
2223,2223,530,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111934,1697552113424,120,,,[131],[1697552112065]
2224,2224,151,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083682,1697552084683,120,,,[102],[1697552083784]
2225,2225,61,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113430,1697552115113,120,,,[34],[1697552113464]
2226,2226,335,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094751,1697552096114,120,,,"[11, 674]","[1697552094762, 1697552095436]"
2227,2227,321,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 6.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069279,1697552070586,120,,,[7],[1697552069286]
2228,2228,828,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084690,1697552085754,120,,,[73],[1697552084763]
2229,2229,89,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070588,1697552071278,120,,,[15],[1697552070603]
2230,2230,47,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080628,1697552082120,120,,,"[7, 875]","[1697552080635, 1697552081510]"
2231,2231,484,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085760,1697552089317,120,,,"[81, 1287, 693, 735]","[1697552085841, 1697552087128, 1697552087821, 1697552088556]"
2232,2232,679,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071284,1697552071973,120,,,[27],[1697552071311]
2233,2233,454,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091870,1697552093265,120,,,"[69, 1224]","[1697552091939, 1697552093163]"
2234,2234,443,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084686,1697552085755,120,,,[53],[1697552084739]
2235,2235,759,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115119,1697552116440,120,,,"[34, 1155]","[1697552115153, 1697552116308]"
2236,2236,701,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121359,1697552122933,120,,,[42],[1697552121401]
2237,2237,629,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacty of 39.39 GiB of which 648.06 MiB is free. Process 1449637 has 38.76 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552063015,1697552064541,120,,,[24],[1697552063039]
2238,2238,273,12,[],200,llama-13b,64,1,1261.0,1.0,1,A100,1697552064884,1697552066145,120,19.0,1.0,"[94, 1167]","[1697552064978, 1697552066145]"
2239,2239,521,55,[],200,llama-13b,64,1,1607.0,1.0,1,A100,1697552127358,1697552128965,120,18.0,1.0,"[51, 1556]","[1697552127409, 1697552128965]"
2240,2240,676,33,[],200,llama-13b,64,1,1231.0,1.0,1,A100,1697552106522,1697552107753,120,19.0,1.0,"[26, 1205]","[1697552106548, 1697552107753]"
2241,2241,921,35,[],200,llama-13b,64,1,2108.0,1.0,1,A100,1697552096120,1697552098228,120,31.0,1.0,"[118, 1990]","[1697552096238, 1697552098228]"
2242,2242,44,13,[],200,llama-13b,64,1,1214.0,1.0,1,A100,1697552066149,1697552067363,120,12.0,1.0,"[29, 1185]","[1697552066178, 1697552067363]"
2243,2243,892,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089800,1697552091869,120,,,"[23, 1372]","[1697552089823, 1697552091195]"
2244,2244,450,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107756,1697552109322,120,,,"[17, 918]","[1697552107773, 1697552108691]"
2245,2245,661,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091870,1697552093264,120,,,"[36, 1258]","[1697552091906, 1697552093164]"
2246,2246,914,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145960,1697552147357,120,,,"[38, 1341]","[1697552145998, 1697552147339]"
2247,2247,605,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067367,1697552067820,120,,,[74],[1697552067441]
2248,2248,374,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067823,1697552069275,120,,,[54],[1697552067877]
2249,2249,291,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128968,1697552130344,120,,,[27],[1697552128995]
2250,2250,322,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093267,1697552094764,120,,,[26],[1697552093293]
2251,2251,231,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083363,1697552083673,120,,,[29],[1697552083392]
2252,2252,22,22,[],200,llama-13b,64,1,1235.0,1.0,1,A100,1697552079391,1697552080626,120,16.0,1.0,"[34, 1200]","[1697552079425, 1697552080625]"
2253,2253,445,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129610,1697552130343,120,,,[15],[1697552129625]
2254,2254,606,23,[],200,llama-13b,64,1,881.0,1.0,1,A100,1697552080629,1697552081510,120,9.0,1.0,"[15, 866]","[1697552080644, 1697552081510]"
2255,2255,100,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.11 GiB is allocated by PyTorch, and 7.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130346,1697552131776,120,,,[40],[1697552130386]
2256,2256,799,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131779,1697552133252,120,,,[23],[1697552131802]
2257,2257,320,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111931,1697552113424,120,,,[131],[1697552112062]
2258,2258,574,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147361,1697552148669,120,,,[29],[1697552147390]
2259,2259,493,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552088521,1697552089317,120,,,"[24, 753]","[1697552088545, 1697552089298]"
2260,2260,455,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133255,1697552134060,120,,,[23],[1697552133278]
2261,2261,910,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113430,1697552115114,120,,,[49],[1697552113479]
2262,2262,681,42,[],200,llama-13b,64,1,1732.0,1.0,1,A100,1697552115123,1697552116855,120,23.0,1.0,"[145, 1587]","[1697552115268, 1697552116855]"
2263,2263,33,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069280,1697552071281,120,,,[65],[1697552069345]
2264,2264,346,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148674,1697552150143,120,,,"[163, 1286]","[1697552148837, 1697552150123]"
2265,2265,334,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116859,1697552118448,120,,,[19],[1697552116878]
2266,2266,631,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082129,1697552083672,120,,,[130],[1697552082259]
2267,2267,668,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093483,1697552096115,120,,,"[78, 1875]","[1697552093561, 1697552095436]"
2268,2268,732,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071285,1697552072656,120,,,[51],[1697552071336]
2269,2269,52,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098828,1697552101108,120,,,"[13, 1689, 51]","[1697552098841, 1697552100530, 1697552100581]"
2270,2270,396,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072659,1697552074777,120,,,"[36, 1359]","[1697552072695, 1697552074054]"
2271,2271,3,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102452,1697552105087,120,,,"[50, 2004]","[1697552102502, 1697552104506]"
2272,2272,635,34,[],200,llama-13b,64,1,2188.0,1.0,1,A100,1697552101113,1697552103301,120,23.0,1.0,"[141, 2047]","[1697552101254, 1697552103301]"
2273,2273,593,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105090,1697552106519,120,,,"[10, 1389]","[1697552105100, 1697552106489]"
2274,2274,649,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110138,1697552111925,120,,,"[30, 945]","[1697552110168, 1697552111113]"
2275,2275,362,41,[],200,llama-13b,64,1,2167.0,1.0,1,A100,1697552106523,1697552108690,120,14.0,1.0,"[126, 2041]","[1697552106649, 1697552108690]"
2276,2276,18,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552108694,1697552110135,120,,,[20],[1697552108714]
2277,2277,409,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103304,1697552105087,120,,,"[26, 1177]","[1697552103330, 1697552104507]"
2278,2278,685,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087784,1697552088518,120,,,[24],[1697552087808]
2279,2279,812,29,[],200,llama-13b,64,1,1260.0,1.0,1,A100,1697552089324,1697552090584,120,16.0,1.0,"[136, 1123]","[1697552089460, 1697552090583]"
2280,2280,277,39,[],200,llama-13b,64,1,977.0,1.0,1,A100,1697552110137,1697552111114,120,18.0,1.0,"[16, 960]","[1697552110153, 1697552111113]"
2281,2281,339,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552088523,1697552090604,120,,,"[57, 1215]","[1697552088580, 1697552089795]"
2282,2282,410,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080748,1697552082121,120,,,"[45, 1209]","[1697552080793, 1697552082002]"
2283,2283,63,36,[],200,llama-13b,64,1,2203.0,1.0,1,A100,1697552105094,1697552107297,120,39.0,1.0,"[166, 2036]","[1697552105260, 1697552107296]"
2284,2284,743,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107299,1697552109323,120,,,"[7, 1384]","[1697552107306, 1697552108690]"
2285,2285,685,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111818,1697552112678,120,,,[11],[1697552111829]
2286,2286,877,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110140,1697552111926,120,,,"[102, 871]","[1697552110242, 1697552111113]"
2287,2287,465,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090586,1697552091869,120,,,"[16, 592]","[1697552090602, 1697552091194]"
2288,2288,265,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093480,1697552094765,120,,,"[56, 1211]","[1697552093536, 1697552094747]"
2289,2289,182,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082127,1697552083673,120,,,[133],[1697552082260]
2290,2290,34,34,[],200,llama-13b,64,1,1217.0,1.0,1,A100,1697552094774,1697552095991,120,12.0,1.0,"[100, 1117]","[1697552094874, 1697552095991]"
2291,2291,764,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083678,1697552084683,120,,,[58],[1697552083736]
2292,2292,595,35,[],200,llama-13b,64,1,710.0,1.0,1,A100,1697552095994,1697552096704,120,8.0,1.0,"[22, 688]","[1697552096016, 1697552096704]"
2293,2293,367,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096706,1697552098826,120,,,"[15, 1508]","[1697552096721, 1697552098229]"
2294,2294,107,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096706,1697552098825,120,,,[10],[1697552096716]
2295,2295,21,37,[],200,llama-13b,64,1,1702.0,1.0,1,A100,1697552098828,1697552100530,120,15.0,1.0,"[17, 1685]","[1697552098845, 1697552100530]"
2296,2296,730,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552100533,1697552102447,120,,,"[11, 1208]","[1697552100544, 1697552101752]"
2297,2297,541,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084690,1697552085755,120,,,[78],[1697552084768]
2298,2298,813,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083472,1697552083903,120,,,[25],[1697552083497]
2299,2299,383,39,[],200,llama-13b,64,1,2053.0,1.0,1,A100,1697552102453,1697552104506,120,15.0,1.0,"[89, 1964]","[1697552102542, 1697552104506]"
2300,2300,158,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552104509,1697552106517,120,,,"[6, 1389]","[1697552104515, 1697552105904]"
2301,2301,741,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106522,1697552107868,120,,,"[35, 1196]","[1697552106557, 1697552107753]"
2302,2302,193,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085760,1697552089317,120,,,"[93, 1968, 735]","[1697552085853, 1697552087821, 1697552088556]"
2303,2303,690,32,[],200,llama-13b,64,1,1702.0,1.0,1,A100,1697552098829,1697552100531,120,39.0,1.0,"[41, 1661]","[1697552098870, 1697552100531]"
2304,2304,518,42,[],200,llama-13b,64,1,1329.0,1.0,1,A100,1697552107876,1697552109205,120,23.0,1.0,"[90, 1239]","[1697552107966, 1697552109205]"
2305,2305,172,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109210,1697552110136,120,,,[28],[1697552109238]
2306,2306,872,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110140,1697552111925,120,,,"[38, 935]","[1697552110178, 1697552111113]"
2307,2307,898,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089319,1697552090605,120,,,"[18, 1246]","[1697552089337, 1697552090583]"
2308,2308,615,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111931,1697552113423,120,,,[110],[1697552112041]
2309,2309,464,33,[],200,llama-13b,64,1,1217.0,1.0,1,A100,1697552100535,1697552101752,120,12.0,1.0,"[34, 1183]","[1697552100569, 1697552101752]"
2310,2310,267,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113429,1697552115113,120,,,[26],[1697552113455]
2311,2311,611,43,[],200,llama-13b,64,1,1608.0,1.0,1,A100,1697552114148,1697552115756,120,14.0,1.0,"[98, 1510]","[1697552114246, 1697552115756]"
2312,2312,264,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115759,1697552120129,120,,,"[10, 1086, 801, 826, 738]","[1697552115769, 1697552116855, 1697552117656, 1697552118482, 1697552119220]"
2313,2313,921,33,[],200,llama-13b,64,1,2108.0,1.0,1,A100,1697552096120,1697552098228,120,31.0,1.0,"[64, 2044]","[1697552096184, 1697552098228]"
2314,2314,880,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.11 GiB is allocated by PyTorch, and 7.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130347,1697552131776,120,,,[44],[1697552130391]
2315,2315,118,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101754,1697552103818,120,,,"[10, 1537]","[1697552101764, 1697552103301]"
2316,2316,329,19,[],200,llama-13b,64,1,1119.0,1.0,1,A100,1697552074059,1697552075178,120,15.0,1.0,"[10, 1109]","[1697552074069, 1697552075178]"
2317,2317,820,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103824,1697552105087,120,,,"[36, 1207]","[1697552103860, 1697552105067]"
2318,2318,36,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120135,1697552121355,120,,,[107],[1697552120242]
2319,2319,693,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098235,1697552099703,120,,,[39],[1697552098274]
2320,2320,318,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107872,1697552109319,120,,,"[17, 1315]","[1697552107889, 1697552109204]"
2321,2321,475,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105092,1697552106518,120,,,"[54, 1344]","[1697552105146, 1697552106490]"
2322,2322,245,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106523,1697552109319,120,,,"[128, 2039]","[1697552106651, 1697552108690]"
2323,2323,82,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118452,1697552120129,120,,,"[34, 1463]","[1697552118486, 1697552119949]"
2324,2324,928,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150149,1697552152618,120,,,[104],[1697552150253]
2325,2325,705,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152622,1697552153790,120,,,[24],[1697552152646]
2326,2326,353,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099706,1697552101106,120,,,"[16, 1367]","[1697552099722, 1697552101089]"
2327,2327,835,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109336,1697552111924,120,,,"[145, 1632]","[1697552109481, 1697552111113]"
2328,2328,291,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094772,1697552096115,120,,,[82],[1697552094854]
2329,2329,659,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120139,1697552121356,120,,,[122],[1697552120261]
2330,2330,357,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153794,1697552154924,120,,,[39],[1697552153833]
2331,2331,250,43,[],200,llama-13b,64,1,976.0,1.0,1,A100,1697552110137,1697552111113,120,31.0,1.0,"[25, 951]","[1697552110162, 1697552111113]"
2332,2332,38,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096120,1697552097349,120,,,"[49, 1082]","[1697552096169, 1697552097251]"
2333,2333,437,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121359,1697552122933,120,,,[52],[1697552121411]
2334,2334,455,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096706,1697552098826,120,,,"[11, 1512]","[1697552096717, 1697552098229]"
2335,2335,27,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111117,1697552112679,120,,,[22],[1697552111139]
2336,2336,609,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112685,1697552114140,120,,,[62],[1697552112747]
2337,2337,123,36,[],200,llama-13b,64,1,2187.0,1.0,1,A100,1697552101114,1697552103301,120,14.0,1.0,"[135, 2052]","[1697552101249, 1697552103301]"
2338,2338,739,35,[],200,llama-13b,64,1,1347.0,1.0,1,A100,1697552097354,1697552098701,120,216.0,1.0,"[19, 1328]","[1697552097373, 1697552098701]"
2339,2339,711,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103303,1697552105087,120,,,"[14, 1190]","[1697552103317, 1697552104507]"
2340,2340,603,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111930,1697552113424,120,,,[47],[1697552111977]
2341,2341,386,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552114145,1697552116440,120,,,"[26, 1585]","[1697552114171, 1697552115756]"
2342,2342,480,38,[],200,llama-13b,64,1,1400.0,1.0,1,A100,1697552105090,1697552106490,120,26.0,1.0,"[19, 1380]","[1697552105109, 1697552106489]"
2343,2343,141,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106492,1697552107866,120,,,"[16, 789]","[1697552106508, 1697552107297]"
2344,2344,420,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116445,1697552117621,120,,,[20],[1697552116465]
2345,2345,392,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098705,1697552099702,120,,,[19],[1697552098724]
2346,2346,170,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099707,1697552101107,120,,,"[48, 1334]","[1697552099755, 1697552101089]"
2347,2347,308,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111931,1697552113425,120,,,[110],[1697552112041]
2348,2348,838,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107872,1697552109319,120,,,"[12, 1320]","[1697552107884, 1697552109204]"
2349,2349,79,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113434,1697552115115,120,,,[139],[1697552113573]
2350,2350,746,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101110,1697552102446,120,,,"[30, 1207]","[1697552101140, 1697552102347]"
2351,2351,642,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115120,1697552116439,120,,,"[131, 1057]","[1697552115251, 1697552116308]"
2352,2352,187,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117626,1697552118449,120,,,[11],[1697552117637]
2353,2353,414,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116445,1697552117622,120,,,[30],[1697552116475]
2354,2354,777,47,[],200,llama-13b,64,1,1496.0,1.0,1,A100,1697552118453,1697552119949,120,9.0,1.0,"[87, 1409]","[1697552118540, 1697552119949]"
2355,2355,225,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086538,1697552087781,120,,,[46],[1697552086584]
2356,2356,550,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552119952,1697552128289,120,,,"[20, 709, 711, 718, 860, 916, 893, 942, 833, 820]","[1697552119972, 1697552120681, 1697552121392, 1697552122110, 1697552122970, 1697552123886, 1697552124779, 1697552125721, 1697552126554, 1697552127374]"
2357,2357,523,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102451,1697552103818,120,,,"[26, 1218]","[1697552102477, 1697552103695]"
2358,2358,16,33,[],200,llama-13b,64,1,1345.0,1.0,1,A100,1697552097357,1697552098702,120,9.0,1.0,"[103, 1241]","[1697552097460, 1697552098701]"
2359,2359,715,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098705,1697552099703,120,,,[24],[1697552098729]
2360,2360,808,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087786,1697552089316,120,,,"[47, 1465]","[1697552087833, 1697552089298]"
2361,2361,177,40,[],200,llama-13b,64,1,1244.0,1.0,1,A100,1697552103823,1697552105067,120,14.0,1.0,"[30, 1214]","[1697552103853, 1697552105067]"
2362,2362,339,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112682,1697552114141,120,,,[33],[1697552112715]
2363,2363,877,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105070,1697552106519,120,,,"[15, 819]","[1697552105085, 1697552105904]"
2364,2364,804,43,[],200,llama-13b,64,1,1332.0,1.0,1,A100,1697552107873,1697552109205,120,20.0,1.0,"[46, 1286]","[1697552107919, 1697552109205]"
2365,2365,573,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109208,1697552110136,120,,,[11],[1697552109219]
2366,2366,86,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552114144,1697552116439,120,,,"[7, 1604]","[1697552114151, 1697552115755]"
2367,2367,698,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132472,1697552133252,120,,,[6],[1697552132478]
2368,2368,190,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113430,1697552115114,120,,,[44],[1697552113474]
2369,2369,552,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090606,1697552091869,120,,,"[30, 1211]","[1697552090636, 1697552091847]"
2370,2370,860,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094372,1697552096114,120,,,"[25, 1038]","[1697552094397, 1697552095435]"
2371,2371,320,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091872,1697552093476,120,,,[101],[1697552091973]
2372,2372,376,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552081513,1697552083467,120,,,"[31, 1294]","[1697552081544, 1697552082838]"
2373,2373,513,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096118,1697552097350,120,,,"[7, 1125]","[1697552096125, 1697552097250]"
2374,2374,144,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089321,1697552090605,120,,,"[61, 1202]","[1697552089382, 1697552090584]"
2375,2375,889,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115119,1697552116441,120,,,"[56, 1133]","[1697552115175, 1697552116308]"
2376,2376,293,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097356,1697552099703,120,,,[108],[1697552097464]
2377,2377,548,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116448,1697552118448,120,,,[123],[1697552116571]
2378,2378,224,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134062,1697552135648,120,,,"[43, 1468]","[1697552134105, 1697552135573]"
2379,2379,813,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135653,1697552136976,120,,,[87],[1697552135740]
2380,2380,325,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118452,1697552120129,120,,,"[34, 1463]","[1697552118486, 1697552119949]"
2381,2381,583,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136980,1697552139267,120,,,"[57, 1576]","[1697552137037, 1697552138613]"
2382,2382,907,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120134,1697552121355,120,,,[53],[1697552120187]
2383,2383,409,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083678,1697552084682,120,,,[27],[1697552083705]
2384,2384,875,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099711,1697552101107,120,,,"[31, 1347]","[1697552099742, 1697552101089]"
2385,2385,88,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109334,1697552110461,120,,,[49],[1697552109383]
2386,2386,238,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139271,1697552140779,120,,,"[26, 1448]","[1697552139297, 1697552140745]"
2387,2387,100,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154926,1697552156085,120,,,[24],[1697552154950]
2388,2388,210,24,[],200,llama-13b,64,1,2062.0,1.0,1,A100,1697552085759,1697552087821,120,140.0,2.0,"[80, 1289, 693]","[1697552085839, 1697552087128, 1697552087821]"
2389,2389,674,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110468,1697552111926,120,,,"[105, 1242]","[1697552110573, 1697552111815]"
2390,2390,90,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 458.06 MiB is free. Process 1449637 has 38.94 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122937,1697552124743,120,,,[44],[1697552122981]
2391,2391,672,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121358,1697552122073,120,,,[22],[1697552121380]
2392,2392,448,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122076,1697552123843,120,,,[19],[1697552122095]
2393,2393,800,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087824,1697552089317,120,,,[24],[1697552087848]
2394,2394,915,56,[],200,llama-13b,64,1,2191.0,1.0,1,A100,1697552140783,1697552142974,120,182.0,1.0,"[157, 2034]","[1697552140940, 1697552142974]"
2395,2395,204,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098829,1697552101107,120,,,"[106, 1596, 51]","[1697552098935, 1697552100531, 1697552100582]"
2396,2396,101,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123846,1697552125687,120,,,[40],[1697552123886]
2397,2397,651,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101115,1697552103818,120,,,"[139, 2047]","[1697552101254, 1697552103301]"
2398,2398,288,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552064544,1697552066163,120,,,[48],[1697552064592]
2399,2399,37,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116448,1697552118448,120,,,[137],[1697552116585]
2400,2400,789,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101113,1697552102448,120,,,"[126, 1108]","[1697552101239, 1697552102347]"
2401,2401,601,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096120,1697552098824,120,,,"[64, 2044]","[1697552096184, 1697552098228]"
2402,2402,57,12,[],200,llama-13b,64,1,1195.0,1.0,1,A100,1697552066167,1697552067362,120,13.0,1.0,"[110, 1085]","[1697552066277, 1697552067362]"
2403,2403,503,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 6.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069279,1697552070586,120,,,[36],[1697552069315]
2404,2404,565,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102453,1697552105087,120,,,"[85, 1968]","[1697552102538, 1697552104506]"
2405,2405,218,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105091,1697552106519,120,,,[79],[1697552105170]
2406,2406,165,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552070589,1697552071972,120,,,[35],[1697552070624]
2407,2407,710,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118452,1697552119186,120,,,[29],[1697552118481]
2408,2408,855,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083472,1697552083902,120,,,[15],[1697552083487]
2409,2409,648,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.29 GiB is allocated by PyTorch, and 7.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067364,1697552067819,120,,,[20],[1697552067384]
2410,2410,509,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083906,1697552084997,120,,,[36],[1697552083942]
2411,2411,923,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106523,1697552109319,120,,,"[59, 2108]","[1697552106582, 1697552108690]"
2412,2412,67,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117637,1697552119186,120,,,[64],[1697552117701]
2413,2413,419,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552067822,1697552069273,120,,,[25],[1697552067847]
2414,2414,860,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111117,1697552112678,120,,,[27],[1697552111144]
2415,2415,72,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 6.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552069280,1697552071281,120,,,[58],[1697552069338]
2416,2416,861,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071975,1697552072657,120,,,[25],[1697552072000]
2417,2417,635,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112684,1697552114140,120,,,[72],[1697552112756]
2418,2418,579,41,[],200,llama-13b,64,1,1778.0,1.0,1,A100,1697552109335,1697552111113,120,19.0,1.0,"[141, 1637]","[1697552109476, 1697552111113]"
2419,2419,357,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110466,1697552111926,120,,,"[29, 1320]","[1697552110495, 1697552111815]"
2420,2420,382,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552114145,1697552116441,120,,,"[50, 1561]","[1697552114195, 1697552115756]"
2421,2421,584,30,[],200,llama-13b,64,1,1262.0,1.0,1,A100,1697552089321,1697552090583,120,10.0,1.0,"[26, 1236]","[1697552089347, 1697552090583]"
2422,2422,362,25,[],200,llama-13b,64,1,1235.0,1.0,1,A100,1697552082124,1697552083359,120,14.0,1.0,"[66, 1169]","[1697552082190, 1697552083359]"
2423,2423,186,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090608,1697552091869,120,,,"[66, 1173]","[1697552090674, 1697552091847]"
2424,2424,398,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109335,1697552110461,120,,,[101],[1697552109436]
2425,2425,169,39,[],200,llama-13b,64,1,1350.0,1.0,1,A100,1697552110465,1697552111815,120,10.0,1.0,"[21, 1329]","[1697552110486, 1697552111815]"
2426,2426,885,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091872,1697552093475,120,,,[81],[1697552091953]
2427,2427,758,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111818,1697552112678,120,,,[15],[1697552111833]
2428,2428,23,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083363,1697552083672,120,,,[19],[1697552083382]
2429,2429,719,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083678,1697552084681,120,,,[76],[1697552083754]
2430,2430,236,31,[],200,llama-13b,64,1,1259.0,1.0,1,A100,1697552090588,1697552091847,120,8.0,1.0,"[34, 1224]","[1697552090622, 1697552091846]"
2431,2431,632,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093480,1697552094765,120,,,"[16, 1250]","[1697552093496, 1697552094746]"
2432,2432,526,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112684,1697552114141,120,,,[57],[1697552112741]
2433,2433,284,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094773,1697552096115,120,,,[96],[1697552094869]
2434,2434,9,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091860,1697552093264,120,,,"[8, 870]","[1697552091868, 1697552092738]"
2435,2435,186,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552114145,1697552116441,120,,,"[97, 1514]","[1697552114242, 1697552115756]"
2436,2436,64,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096120,1697552097349,120,,,"[39, 1091]","[1697552096159, 1697552097250]"
2437,2437,592,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093269,1697552094764,120,,,"[49, 1049]","[1697552093318, 1697552094367]"
2438,2438,647,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097352,1697552098825,120,,,"[16, 1333]","[1697552097368, 1697552098701]"
2439,2439,309,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110466,1697552111926,120,,,"[34, 1315]","[1697552110500, 1697552111815]"
2440,2440,104,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109334,1697552110461,120,,,[12],[1697552109346]
2441,2441,419,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098829,1697552101106,120,,,"[137, 1565, 51]","[1697552098966, 1697552100531, 1697552100582]"
2442,2442,44,47,[],200,llama-13b,64,1,1188.0,1.0,1,A100,1697552115120,1697552116308,120,12.0,1.0,"[117, 1071]","[1697552115237, 1697552116308]"
2443,2443,79,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111934,1697552113425,120,,,[133],[1697552112067]
2444,2444,363,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094769,1697552096115,120,,,"[16, 1206]","[1697552094785, 1697552095991]"
2445,2445,880,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093480,1697552094764,120,,,"[61, 1206]","[1697552093541, 1697552094747]"
2446,2446,650,26,[],200,llama-13b,64,1,1220.0,1.0,1,A100,1697552094770,1697552095990,120,13.0,1.0,"[78, 1142]","[1697552094848, 1697552095990]"
2447,2447,626,48,[],200,llama-13b,64,1,544.0,1.0,1,A100,1697552116311,1697552116855,120,10.0,1.0,"[16, 528]","[1697552116327, 1697552116855]"
2448,2448,924,35,[],200,llama-13b,64,1,2107.0,1.0,1,A100,1697552096121,1697552098228,120,9.0,1.0,"[142, 1965]","[1697552096263, 1697552098228]"
2449,2449,638,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113434,1697552115114,120,,,[124],[1697552113558]
2450,2450,652,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131777,1697552133251,120,,,[10],[1697552131787]
2451,2451,806,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110468,1697552111925,120,,,"[86, 1261]","[1697552110554, 1697552111815]"
2452,2452,398,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116858,1697552118448,120,,,[23],[1697552116881]
2453,2453,309,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552095992,1697552097350,120,,,"[13, 699]","[1697552096005, 1697552096704]"
2454,2454,110,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093267,1697552094765,120,,,"[6, 1094]","[1697552093273, 1697552094367]"
2455,2455,919,20,[],200,llama-13b,64,1,1041.0,1.0,1,A100,1697552075181,1697552076222,120,14.0,1.0,"[16, 1025]","[1697552075197, 1697552076222]"
2456,2456,462,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111931,1697552113424,120,,,[129],[1697552112060]
2457,2457,693,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098232,1697552099703,120,,,[27],[1697552098259]
2458,2458,231,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113431,1697552115113,120,,,[112],[1697552113543]
2459,2459,908,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115118,1697552116441,120,,,"[8, 1181]","[1697552115126, 1697552116307]"
2460,2460,302,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133255,1697552134788,120,,,[48],[1697552133303]
2461,2461,689,21,[],200,llama-13b,64,1,1052.0,1.0,1,A100,1697552076226,1697552077278,120,15.0,1.0,"[25, 1026]","[1697552076251, 1697552077277]"
2462,2462,561,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116448,1697552118448,120,,,[122],[1697552116570]
2463,2463,79,60,[],200,llama-13b,64,1,1501.0,1.0,1,A100,1697552134794,1697552136295,120,12.0,1.0,"[79, 1421]","[1697552134873, 1697552136294]"
2464,2464,90,32,[],200,llama-13b,64,1,1222.0,1.0,1,A100,1697552094769,1697552095991,120,19.0,1.0,"[21, 1201]","[1697552094790, 1697552095991]"
2465,2465,37,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083475,1697552083903,120,,,[95],[1697552083570]
2466,2466,733,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083908,1697552084997,120,,,[52],[1697552083960]
2467,2467,680,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552095996,1697552097350,120,,,"[26, 682]","[1697552096022, 1697552096704]"
2468,2468,65,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084686,1697552085754,120,,,[30],[1697552084716]
2469,2469,659,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136313,1697552137935,120,,,"[22, 1430]","[1697552136335, 1697552137765]"
2470,2470,394,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085004,1697552086533,120,,,[72],[1697552085076]
2471,2471,449,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097354,1697552098825,120,,,"[29, 1318]","[1697552097383, 1697552098701]"
2472,2472,105,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098832,1697552101105,120,,,"[154, 1546, 50]","[1697552098986, 1697552100532, 1697552100582]"
2473,2473,167,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086537,1697552087781,120,,,[21],[1697552086558]
2474,2474,769,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085757,1697552089317,120,,,"[87, 1284, 693, 735]","[1697552085844, 1697552087128, 1697552087821, 1697552088556]"
2475,2475,807,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101110,1697552102448,120,,,"[7, 1230]","[1697552101117, 1697552102347]"
2476,2476,444,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096120,1697552098825,120,,,"[118, 1990]","[1697552096238, 1697552098228]"
2477,2477,437,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137942,1697552140771,120,,,"[109, 2062, 53, 49, 48]","[1697552138051, 1697552140113, 1697552140166, 1697552140215, 1697552140263]"
2478,2478,305,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103825,1697552105087,120,,,"[43, 1199]","[1697552103868, 1697552105067]"
2479,2479,76,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105092,1697552106518,120,,,"[48, 1350]","[1697552105140, 1697552106490]"
2480,2480,666,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106523,1697552109319,120,,,"[55, 2112]","[1697552106578, 1697552108690]"
2481,2481,460,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102454,1697552105087,120,,,"[95, 1957]","[1697552102549, 1697552104506]"
2482,2482,752,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087784,1697552089316,120,,,"[39, 1475]","[1697552087823, 1697552089298]"
2483,2483,435,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109324,1697552110461,120,,,[21],[1697552109345]
2484,2484,570,26,[],200,llama-13b,64,1,1260.0,1.0,1,A100,1697552089324,1697552090584,120,18.0,1.0,"[130, 1129]","[1697552089454, 1697552090583]"
2485,2485,97,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147364,1697552148669,120,,,[98],[1697552147462]
2486,2486,229,27,[],200,llama-13b,64,1,1259.0,1.0,1,A100,1697552090588,1697552091847,120,15.0,1.0,"[39, 1219]","[1697552090627, 1697552091846]"
2487,2487,98,33,[],200,llama-13b,64,1,1700.0,1.0,1,A100,1697552098832,1697552100532,120,14.0,1.0,"[149, 1550]","[1697552098981, 1697552100531]"
2488,2488,795,66,[],200,llama-13b,64,1,1449.0,1.0,1,A100,1697552148674,1697552150123,120,12.0,1.0,"[62, 1386]","[1697552148736, 1697552150122]"
2489,2489,263,31,[],200,llama-13b,64,1,1702.0,1.0,1,A100,1697552098829,1697552100531,120,15.0,1.0,"[43, 1659]","[1697552098872, 1697552100531]"
2490,2490,67,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110470,1697552112674,120,,,[174],[1697552110644]
2491,2491,423,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089324,1697552090605,120,,,"[131, 1128]","[1697552089455, 1697552090583]"
2492,2492,455,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150125,1697552151582,120,,,"[10, 814]","[1697552150135, 1697552150949]"
2493,2493,224,68,[],200,llama-13b,64,1,12985.0,1.0,1,A100,1697552151585,1697552164570,120,85.0,20.0,"[30, 1677, 546, 572, 555, 573, 588, 44, 554, 527, 590, 661, 644, 675, 678, 700, 652, 673, 662, 686, 698]","[1697552151615, 1697552153292, 1697552153838, 1697552154410, 1697552154965, 1697552155538, 1697552156126, 1697552156170, 1697552156724, 1697552157251, 1697552157841, 1697552158502, 1697552159146, 1697552159821, 1697552160499, 1697552161199, 1697552161851, 1697552162524, 1697552163186, 1697552163872, 1697552164570]"
2494,2494,802,34,[],200,llama-13b,64,1,1219.0,1.0,1,A100,1697552100533,1697552101752,120,9.0,1.0,"[16, 1203]","[1697552100549, 1697552101752]"
2495,2495,760,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112680,1697552114139,120,,,[15],[1697552112695]
2496,2496,720,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110138,1697552111925,120,,,"[34, 940]","[1697552110172, 1697552111112]"
2497,2497,455,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101756,1697552103818,120,,,"[24, 1522]","[1697552101780, 1697552103302]"
2498,2498,170,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090609,1697552093264,120,,,"[170, 1959]","[1697552090779, 1697552092738]"
2499,2499,35,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552100534,1697552102447,120,,,"[30, 1188]","[1697552100564, 1697552101752]"
2500,2500,203,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103825,1697552105088,120,,,"[53, 1190]","[1697552103878, 1697552105068]"
2501,2501,595,33,[],200,llama-13b,64,1,1244.0,1.0,1,A100,1697552102451,1697552103695,120,8.0,1.0,"[19, 1225]","[1697552102470, 1697552103695]"
2502,2502,755,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093267,1697552094764,120,,,"[26, 1074]","[1697552093293, 1697552094367]"
2503,2503,524,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094774,1697552096115,120,,,"[164, 1053]","[1697552094938, 1697552095991]"
2504,2504,774,48,[],200,llama-13b,64,1,761.0,1.0,1,A100,1697552119188,1697552119949,120,8.0,1.0,"[25, 736]","[1697552119213, 1697552119949]"
2505,2505,907,37,[],200,llama-13b,64,1,1397.0,1.0,1,A100,1697552105094,1697552106491,120,10.0,1.0,"[163, 1233]","[1697552105257, 1697552106490]"
2506,2506,427,49,[],200,llama-13b,64,1,3935.0,1.0,1,A100,1697552119951,1697552123886,120,58.0,5.0,"[6, 724, 711, 718, 860, 915]","[1697552119957, 1697552120681, 1697552121392, 1697552122110, 1697552122970, 1697552123885]"
2507,2507,561,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106493,1697552107867,120,,,"[29, 1231]","[1697552106522, 1697552107753]"
2508,2508,186,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096120,1697552097350,120,,,"[54, 1076]","[1697552096174, 1697552097250]"
2509,2509,364,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103705,1697552105088,120,,,"[23, 779]","[1697552103728, 1697552104507]"
2510,2510,24,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105094,1697552107867,120,,,[161],[1697552105255]
2511,2511,373,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111934,1697552113425,120,,,[137],[1697552112071]
2512,2512,725,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107876,1697552109322,120,,,"[65, 1263]","[1697552107941, 1697552109204]"
2513,2513,148,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113429,1697552115113,120,,,[20],[1697552113449]
2514,2514,880,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097354,1697552098825,120,,,"[39, 1308]","[1697552097393, 1697552098701]"
2515,2515,378,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109334,1697552110463,120,,,[39],[1697552109373]
2516,2516,731,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115119,1697552116440,120,,,"[47, 1142]","[1697552115166, 1697552116308]"
2517,2517,479,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116447,1697552117622,120,,,[98],[1697552116545]
2518,2518,156,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110468,1697552111926,120,,,"[102, 1245]","[1697552110570, 1697552111815]"
2519,2519,540,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098829,1697552101107,120,,,"[46, 1656, 50]","[1697552098875, 1697552100531, 1697552100581]"
2520,2520,522,19,[],200,llama-13b,64,1,717.0,1.0,1,A100,1697552072659,1697552073376,120,20.0,1.0,"[34, 682]","[1697552072693, 1697552073375]"
2521,2521,250,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117630,1697552119185,120,,,[49],[1697552117679]
2522,2522,814,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164572,1697552166085,120,,,"[91, 1299]","[1697552164663, 1697552165962]"
2523,2523,127,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111929,1697552113426,120,,,[8],[1697552111937]
2524,2524,585,70,[],200,llama-13b,64,1,4107.0,1.0,1,A100,1697552166097,1697552170204,120,244.0,50.0,"[51, 1770, 678, 44, 38, 44, 37, 43, 36, 37, 217, 38, 38, 37, 37, 42, 36, 40, 37, 40, 36, 27, 27, 27, 25, 26, 26, 26, 25, 25, 24, 23, 24, 23, 24, 24, 23, 24, 23, 24, 24, 24, 23, 24, 23, 24, 24, 24, 23, 24, 24]","[1697552166148, 1697552167918, 1697552168596, 1697552168640, 1697552168678, 1697552168722, 1697552168759, 1697552168802, 1697552168838, 1697552168875, 1697552169092, 1697552169130, 1697552169168, 1697552169205, 1697552169242, 1697552169284, 1697552169320, 1697552169360, 1697552169397, 1697552169437, 1697552169473, 1697552169500, 1697552169527, 1697552169554, 1697552169579, 1697552169605, 1697552169631, 1697552169657, 1697552169682, 1697552169707, 1697552169731, 1697552169754, 1697552169778, 1697552169801, 1697552169825, 1697552169849, 1697552169872, 1697552169896, 1697552169919, 1697552169943, 1697552169967, 1697552169991, 1697552170014, 1697552170038, 1697552170061, 1697552170085, 1697552170109, 1697552170133, 1697552170156, 1697552170180, 1697552170204]"
2525,2525,538,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111930,1697552113424,120,,,[37],[1697552111967]
2526,2526,483,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096119,1697552097348,120,,,"[25, 1106]","[1697552096144, 1697552097250]"
2527,2527,733,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111934,1697552113425,120,,,[136],[1697552112070]
2528,2528,309,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101113,1697552103818,120,,,"[72, 2115]","[1697552101185, 1697552103300]"
2529,2529,898,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103822,1697552105088,120,,,"[6, 1239]","[1697552103828, 1697552105067]"
2530,2530,671,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116446,1697552117622,120,,,[34],[1697552116480]
2531,2531,444,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117627,1697552118449,120,,,[9],[1697552117636]
2532,2532,104,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118454,1697552120129,120,,,[95],[1697552118549]
2533,2533,670,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105092,1697552106518,120,,,"[63, 1335]","[1697552105155, 1697552106490]"
2534,2534,378,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107872,1697552109319,120,,,[17],[1697552107889]
2535,2535,801,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120135,1697552121355,120,,,[57],[1697552120192]
2536,2536,32,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109335,1697552110460,120,,,[50],[1697552109385]
2537,2537,698,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098232,1697552099703,120,,,[30],[1697552098262]
2538,2538,462,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121359,1697552122932,120,,,[36],[1697552121395]
2539,2539,467,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084686,1697552085755,120,,,[38],[1697552084724]
2540,2540,323,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106523,1697552109319,120,,,"[60, 2107]","[1697552106583, 1697552108690]"
2541,2541,733,42,[],200,llama-13b,64,1,1351.0,1.0,1,A100,1697552110464,1697552111815,120,31.0,1.0,"[16, 1335]","[1697552110480, 1697552111815]"
2542,2542,124,29,[],200,llama-13b,64,1,2063.0,1.0,1,A100,1697552085758,1697552087821,120,83.0,2.0,"[38, 2025]","[1697552085796, 1697552087821]"
2543,2543,389,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111820,1697552112678,120,,,[28],[1697552111848]
2544,2544,71,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109334,1697552110462,120,,,[34],[1697552109368]
2545,2545,771,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110468,1697552111926,120,,,"[96, 1251]","[1697552110564, 1697552111815]"
2546,2546,158,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112682,1697552114140,120,,,[23],[1697552112705]
2547,2547,825,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087824,1697552089317,120,,,"[14, 1461]","[1697552087838, 1697552089299]"
2548,2548,603,23,[],200,llama-13b,64,1,1251.0,1.0,1,A100,1697552080751,1697552082002,120,9.0,1.0,"[88, 1162]","[1697552080839, 1697552082001]"
2549,2549,538,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106525,1697552109322,120,,,"[136, 2029]","[1697552106661, 1697552108690]"
2550,2550,475,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133257,1697552134790,120,,,[93],[1697552133350]
2551,2551,79,33,[],200,llama-13b,64,1,1235.0,1.0,1,A100,1697552101112,1697552102347,120,12.0,1.0,"[63, 1172]","[1697552101175, 1697552102347]"
2552,2552,778,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102351,1697552103817,120,,,[25],[1697552102376]
2553,2553,263,24,[],200,llama-13b,64,1,833.0,1.0,1,A100,1697552082005,1697552082838,120,15.0,1.0,"[15, 818]","[1697552082020, 1697552082838]"
2554,2554,438,35,[],200,llama-13b,64,1,1245.0,1.0,1,A100,1697552103822,1697552105067,120,9.0,1.0,"[11, 1234]","[1697552103833, 1697552105067]"
2555,2555,485,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089321,1697552090605,120,,,"[36, 1226]","[1697552089357, 1697552090583]"
2556,2556,124,60,[],200,llama-13b,64,1,2221.0,1.0,1,A100,1697552134793,1697552137014,120,83.0,2.0,"[60, 2161]","[1697552134853, 1697552137014]"
2557,2557,33,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082840,1697552083673,120,,,[22],[1697552082862]
2558,2558,255,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090609,1697552093264,120,,,"[161, 1968]","[1697552090770, 1697552092738]"
2559,2559,828,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137016,1697552139268,120,,,[49],[1697552137065]
2560,2560,482,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139271,1697552140778,120,,,"[30, 1444]","[1697552139301, 1697552140745]"
2561,2561,845,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093271,1697552094765,120,,,"[85, 1012]","[1697552093356, 1697552094368]"
2562,2562,230,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140781,1697552143537,120,,,"[81, 2111]","[1697552140862, 1697552142973]"
2563,2563,352,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099715,1697552102446,120,,,[55],[1697552099770]
2564,2564,612,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094773,1697552096115,120,,,[99],[1697552094872]
2565,2565,1,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143541,1697552145220,120,,,"[33, 1617]","[1697552143574, 1697552145191]"
2566,2566,201,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087784,1697552089317,120,,,"[29, 1485]","[1697552087813, 1697552089298]"
2567,2567,541,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160464,1697552161812,120,,,[59],[1697552160523]
2568,2568,122,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102451,1697552103818,120,,,"[34, 1210]","[1697552102485, 1697552103695]"
2569,2569,273,35,[],200,llama-13b,64,1,2105.0,1.0,1,A100,1697552096123,1697552098228,120,19.0,1.0,"[145, 1960]","[1697552096268, 1697552098228]"
2570,2570,202,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161814,1697552163147,120,,,[19],[1697552161833]
2571,2571,715,39,[],200,llama-13b,64,1,1242.0,1.0,1,A100,1697552103825,1697552105067,120,20.0,1.0,"[63, 1179]","[1697552103888, 1697552105067]"
2572,2572,901,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163151,1697552164529,120,,,[88],[1697552163239]
2573,2573,559,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164531,1697552166082,120,,,"[19, 850, 152]","[1697552164550, 1697552165400, 1697552165552]"
2574,2574,319,22,[],200,llama-13b,64,1,1302.0,1.0,1,A100,1697552077281,1697552078583,120,31.0,1.0,"[34, 1267]","[1697552077315, 1697552078582]"
2575,2575,39,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098232,1697552099703,120,,,[15],[1697552098247]
2576,2576,330,68,[],200,llama-13b,64,1,3155.0,1.0,1,A100,1697552166088,1697552169243,120,345.0,14.0,"[20, 1809, 679, 44, 38, 44, 37, 42, 37, 37, 217, 38, 38, 37, 37]","[1697552166108, 1697552167917, 1697552168596, 1697552168640, 1697552168678, 1697552168722, 1697552168759, 1697552168801, 1697552168838, 1697552168875, 1697552169092, 1697552169130, 1697552169168, 1697552169205, 1697552169242]"
2577,2577,446,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111930,1697552113423,120,,,[27],[1697552111957]
2578,2578,99,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113430,1697552115114,120,,,[49],[1697552113479]
2579,2579,89,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078585,1697552080744,120,,,"[30, 1536]","[1697552078615, 1697552080151]"
2580,2580,168,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074788,1697552076891,120,,,"[179, 1254, 134]","[1697552074967, 1697552076221, 1697552076355]"
2581,2581,492,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137941,1697552139268,120,,,"[40, 1186]","[1697552137981, 1697552139167]"
2582,2582,776,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115119,1697552116440,120,,,"[64, 1124]","[1697552115183, 1697552116307]"
2583,2583,750,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076900,1697552078117,120,,,[66],[1697552076966]
2584,2584,263,58,[],200,llama-13b,64,1,2471.0,1.0,1,A100,1697552139274,1697552141745,120,15.0,1.0,"[96, 2375]","[1697552139370, 1697552141745]"
2585,2585,337,39,[],200,llama-13b,64,1,1333.0,1.0,1,A100,1697552107872,1697552109205,120,12.0,1.0,"[22, 1310]","[1697552107894, 1697552109204]"
2586,2586,527,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078124,1697552079385,120,,,"[117, 1007]","[1697552078241, 1697552079248]"
2587,2587,115,32,[],200,llama-13b,64,1,1240.0,1.0,1,A100,1697552090607,1697552091847,120,13.0,1.0,"[47, 1193]","[1697552090654, 1697552091847]"
2588,2588,700,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091863,1697552093264,120,,,[23],[1697552091886]
2589,2589,469,34,[],200,llama-13b,64,1,1099.0,1.0,1,A100,1697552093268,1697552094367,120,17.0,1.0,"[30, 1069]","[1697552093298, 1697552094367]"
2590,2590,178,22,[],200,llama-13b,64,1,1232.0,1.0,1,A100,1697552079394,1697552080626,120,11.0,1.0,"[72, 1160]","[1697552079466, 1697552080626]"
2591,2591,428,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116445,1697552117622,120,,,[40],[1697552116485]
2592,2592,288,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073378,1697552074777,120,,,[15],[1697552073393]
2593,2593,918,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109210,1697552110135,120,,,[23],[1697552109233]
2594,2594,833,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552119188,1697552120129,120,,,"[28, 733]","[1697552119216, 1697552119949]"
2595,2595,695,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110139,1697552111925,120,,,"[24, 950]","[1697552110163, 1697552111113]"
2596,2596,204,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117627,1697552119185,120,,,[32],[1697552117659]
2597,2597,348,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111930,1697552113423,120,,,[22],[1697552111952]
2598,2598,238,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091874,1697552093475,120,,,[179],[1697552092053]
2599,2599,120,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113430,1697552115113,120,,,[24],[1697552113454]
2600,2600,787,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552119188,1697552120129,120,,,"[23, 738]","[1697552119211, 1697552119949]"
2601,2601,376,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099709,1697552101107,120,,,"[36, 1344]","[1697552099745, 1697552101089]"
2602,2602,706,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115119,1697552116440,120,,,"[37, 1152]","[1697552115156, 1697552116308]"
2603,2603,820,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093479,1697552094765,120,,,"[12, 1255]","[1697552093491, 1697552094746]"
2604,2604,510,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113430,1697552115114,120,,,[45],[1697552113475]
2605,2605,162,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115120,1697552116441,120,,,"[65, 1122]","[1697552115185, 1697552116307]"
2606,2606,147,36,[],200,llama-13b,64,1,1237.0,1.0,1,A100,1697552101110,1697552102347,120,182.0,1.0,"[16, 1221]","[1697552101126, 1697552102347]"
2607,2607,863,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116448,1697552117623,120,,,[128],[1697552116576]
2608,2608,730,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102350,1697552103819,120,,,"[6, 945]","[1697552102356, 1697552103301]"
2609,2609,203,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098829,1697552101108,120,,,"[132, 1569, 52]","[1697552098961, 1697552100530, 1697552100582]"
2610,2610,562,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120134,1697552121355,120,,,[39],[1697552120173]
2611,2611,232,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122935,1697552123845,120,,,[21],[1697552122956]
2612,2612,476,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116447,1697552117622,120,,,[99],[1697552116546]
2613,2613,223,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121365,1697552122933,120,,,[100],[1697552121465]
2614,2614,748,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552114145,1697552116440,120,,,[31],[1697552114176]
2615,2615,921,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 458.06 MiB is free. Process 1449637 has 38.94 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122937,1697552124743,120,,,[42],[1697552122979]
2616,2616,506,38,[],200,llama-13b,64,1,1243.0,1.0,1,A100,1697552103825,1697552105068,120,16.0,1.0,"[59, 1183]","[1697552103884, 1697552105067]"
2617,2617,580,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552124745,1697552126520,120,,,[10],[1697552124755]
2618,2618,611,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117627,1697552118449,120,,,[19],[1697552117646]
2619,2619,350,51,[],200,llama-13b,64,1,1605.0,1.0,1,A100,1697552126522,1697552128127,120,216.0,1.0,"[11, 1594]","[1697552126533, 1697552128127]"
2620,2620,158,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105070,1697552106519,120,,,"[25, 1394]","[1697552105095, 1697552106489]"
2621,2621,9,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083680,1697552084682,120,,,[89],[1697552083769]
2622,2622,838,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106523,1697552109318,120,,,"[54, 2113]","[1697552106577, 1697552108690]"
2623,2623,591,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084687,1697552085754,120,,,[59],[1697552084746]
2624,2624,264,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118454,1697552120129,120,,,"[105, 1390]","[1697552118559, 1697552119949]"
2625,2625,107,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117630,1697552119186,120,,,[54],[1697552117684]
2626,2626,307,43,[],200,llama-13b,64,1,1778.0,1.0,1,A100,1697552109335,1697552111113,120,26.0,1.0,"[131, 1646]","[1697552109466, 1697552111112]"
2627,2627,804,47,[],200,llama-13b,64,1,1491.0,1.0,1,A100,1697552119190,1697552120681,120,20.0,1.0,"[78, 1413]","[1697552119268, 1697552120681]"
2628,2628,851,30,[],200,llama-13b,64,1,2130.0,1.0,1,A100,1697552090609,1697552092739,120,23.0,1.0,"[165, 1964]","[1697552090774, 1697552092738]"
2629,2629,78,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097354,1697552099703,120,,,[101],[1697552097455]
2630,2630,464,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120685,1697552122073,120,,,[35],[1697552120720]
2631,2631,608,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109322,1697552110462,120,,,[11],[1697552109333]
2632,2632,235,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122077,1697552123844,120,,,[48],[1697552122125]
2633,2633,817,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094769,1697552096115,120,,,"[26, 1196]","[1697552094795, 1697552095991]"
2634,2634,468,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096120,1697552098825,120,,,"[132, 1976]","[1697552096252, 1697552098228]"
2635,2635,668,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099707,1697552101107,120,,,"[25, 1357]","[1697552099732, 1697552101089]"
2636,2636,263,42,[],200,llama-13b,64,1,1349.0,1.0,1,A100,1697552110466,1697552111815,120,15.0,1.0,"[30, 1319]","[1697552110496, 1697552111815]"
2637,2637,41,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111821,1697552112677,120,,,[23],[1697552111844]
2638,2638,504,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552092741,1697552093476,120,,,[7],[1697552092748]
2639,2639,807,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125690,1697552127341,120,,,[48],[1697552125738]
2640,2640,245,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098829,1697552101106,120,,,"[18, 1683, 51]","[1697552098847, 1697552100530, 1697552100581]"
2641,2641,279,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093483,1697552096115,120,,,"[78, 1874]","[1697552093561, 1697552095435]"
2642,2642,827,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101110,1697552102446,120,,,"[13, 1224]","[1697552101123, 1697552102347]"
2643,2643,861,33,[],200,llama-13b,64,1,1131.0,1.0,1,A100,1697552096120,1697552097251,120,10.0,1.0,"[34, 1096]","[1697552096154, 1697552097250]"
2644,2644,639,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097253,1697552098826,120,,,"[9, 966]","[1697552097262, 1697552098228]"
2645,2645,293,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098829,1697552101107,120,,,"[53, 1649, 50]","[1697552098882, 1697552100531, 1697552100581]"
2646,2646,866,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111116,1697552112678,120,,,[18],[1697552111134]
2647,2647,440,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101112,1697552102447,120,,,"[43, 1192]","[1697552101155, 1697552102347]"
2648,2648,96,31,[],200,llama-13b,64,1,2052.0,1.0,1,A100,1697552102454,1697552104506,120,31.0,1.0,"[98, 1954]","[1697552102552, 1697552104506]"
2649,2649,639,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112682,1697552114141,120,,,[39],[1697552112721]
2650,2650,300,46,[],200,llama-13b,64,1,1611.0,1.0,1,A100,1697552114145,1697552115756,120,9.0,1.0,"[31, 1580]","[1697552114176, 1697552115756]"
2651,2651,72,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115758,1697552120129,120,,,"[6, 1091, 801, 826, 738]","[1697552115764, 1697552116855, 1697552117656, 1697552118482, 1697552119220]"
2652,2652,66,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101112,1697552102447,120,,,"[48, 1187]","[1697552101160, 1697552102347]"
2653,2653,803,32,[],200,llama-13b,64,1,1395.0,1.0,1,A100,1697552104509,1697552105904,120,20.0,1.0,"[16, 1379]","[1697552104525, 1697552105904]"
2654,2654,744,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102455,1697552105087,120,,,"[102, 1949]","[1697552102557, 1697552104506]"
2655,2655,456,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105909,1697552107869,120,,,"[18, 1369]","[1697552105927, 1697552107296]"
2656,2656,623,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112682,1697552114140,120,,,[28],[1697552112710]
2657,2657,487,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105069,1697552106518,120,,,[6],[1697552105075]
2658,2658,654,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120132,1697552121355,120,,,[16],[1697552120148]
2659,2659,462,53,[],200,llama-13b,64,1,1608.0,1.0,1,A100,1697552127358,1697552128966,120,52.0,1.0,"[90, 1517]","[1697552127448, 1697552128965]"
2660,2660,398,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552114145,1697552116441,120,,,"[46, 1564]","[1697552114191, 1697552115755]"
2661,2661,232,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128969,1697552130343,120,,,[36],[1697552129005]
2662,2662,206,38,[],200,llama-13b,64,1,1399.0,1.0,1,A100,1697552105090,1697552106489,120,16.0,1.0,"[15, 1384]","[1697552105105, 1697552106489]"
2663,2663,202,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107876,1697552110134,120,,,[80],[1697552107956]
2664,2664,788,39,[],200,llama-13b,64,1,1260.0,1.0,1,A100,1697552106493,1697552107753,120,31.0,1.0,"[35, 1225]","[1697552106528, 1697552107753]"
2665,2665,431,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121358,1697552122073,120,,,[32],[1697552121390]
2666,2666,901,35,[],200,llama-13b,64,1,973.0,1.0,1,A100,1697552110140,1697552111113,120,17.0,1.0,"[97, 876]","[1697552110237, 1697552111113]"
2667,2667,623,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099712,1697552101108,120,,,[48],[1697552099760]
2668,2668,678,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080751,1697552083468,120,,,"[113, 1973]","[1697552080864, 1697552082837]"
2669,2669,853,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552141747,1697552143538,120,,,"[14, 1213]","[1697552141761, 1697552142974]"
2670,2670,84,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122077,1697552123844,120,,,[48],[1697552122125]
2671,2671,623,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143542,1697552147356,120,,,"[95, 3034]","[1697552143637, 1697552146671]"
2672,2672,130,35,[],200,llama-13b,64,1,1065.0,1.0,1,A100,1697552094371,1697552095436,120,14.0,1.0,"[21, 1044]","[1697552094392, 1697552095436]"
2673,2673,789,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123848,1697552125687,120,,,[52],[1697552123900]
2674,2674,562,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111117,1697552112679,120,,,[22],[1697552111139]
2675,2675,365,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147360,1697552148668,120,,,[14],[1697552147374]
2676,2676,450,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083473,1697552083904,120,,,[45],[1697552083518]
2677,2677,19,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148673,1697552150143,120,,,"[34, 1415]","[1697552148707, 1697552150122]"
2678,2678,749,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071285,1697552071973,120,,,[31],[1697552071316]
2679,2679,831,36,[],200,llama-13b,64,1,1263.0,1.0,1,A100,1697552095441,1697552096704,120,11.0,1.0,"[31, 1232]","[1697552095472, 1697552096704]"
2680,2680,404,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071976,1697552073395,120,,,"[39, 1360]","[1697552072015, 1697552073375]"
2681,2681,438,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125692,1697552127341,120,,,[76],[1697552125768]
2682,2682,480,49,[],200,llama-13b,64,1,1488.0,1.0,1,A100,1697552119193,1697552120681,120,26.0,1.0,"[70, 1418]","[1697552119263, 1697552120681]"
2683,2683,333,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112685,1697552114140,120,,,[76],[1697552112761]
2684,2684,186,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552127358,1697552135648,120,,,"[30, 1576, 683, 734, 740, 691, 695, 780, 812, 724]","[1697552127388, 1697552128964, 1697552129647, 1697552130381, 1697552131121, 1697552131812, 1697552132507, 1697552133287, 1697552134099, 1697552134823]"
2685,2685,856,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080631,1697552082120,120,,,"[33, 846]","[1697552080664, 1697552081510]"
2686,2686,99,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083910,1697552084996,120,,,[70],[1697552083980]
2687,2687,724,63,[],200,llama-13b,64,1,1287.0,1.0,1,A100,1697552150148,1697552151435,120,11.0,1.0,"[103, 1184]","[1697552150251, 1697552151435]"
2688,2688,206,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128295,1697552129608,120,,,[49],[1697552128344]
2689,2689,307,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113435,1697552115115,120,,,[138],[1697552113573]
2690,2690,380,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552151441,1697552152619,120,,,[17],[1697552151458]
2691,2691,139,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097353,1697552098825,120,,,"[15, 1333]","[1697552097368, 1697552098701]"
2692,2692,891,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115120,1697552116439,120,,,"[119, 1069]","[1697552115239, 1697552116308]"
2693,2693,36,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116448,1697552118448,120,,,[118],[1697552116566]
2694,2694,149,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152623,1697552153790,120,,,[39],[1697552152662]
2695,2695,740,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118450,1697552119186,120,,,[6],[1697552118456]
2696,2696,625,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082125,1697552083672,120,,,[50],[1697552082175]
2697,2697,848,35,[],200,llama-13b,64,1,1701.0,1.0,1,A100,1697552098829,1697552100530,120,47.0,1.0,"[38, 1663]","[1697552098867, 1697552100530]"
2698,2698,739,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153793,1697552154369,120,,,[15],[1697552153808]
2699,2699,394,45,[],200,llama-13b,64,1,1490.0,1.0,1,A100,1697552119191,1697552120681,120,11.0,1.0,"[82, 1408]","[1697552119273, 1697552120681]"
2700,2700,806,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085000,1697552086533,120,,,[22],[1697552085022]
2701,2701,170,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120684,1697552122074,120,,,[15],[1697552120699]
2702,2702,351,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099708,1697552101107,120,,,"[29, 1352]","[1697552099737, 1697552101089]"
2703,2703,123,38,[],200,llama-13b,64,1,1237.0,1.0,1,A100,1697552101110,1697552102347,120,14.0,1.0,"[26, 1211]","[1697552101136, 1697552102347]"
2704,2704,457,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086538,1697552087781,120,,,[30],[1697552086568]
2705,2705,502,36,[],200,llama-13b,64,1,1218.0,1.0,1,A100,1697552100534,1697552101752,120,19.0,1.0,"[20, 1198]","[1697552100554, 1697552101752]"
2706,2706,716,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102350,1697552103817,120,,,"[14, 937]","[1697552102364, 1697552103301]"
2707,2707,278,37,[],200,llama-13b,64,1,1541.0,1.0,1,A100,1697552101760,1697552103301,120,13.0,1.0,"[29, 1512]","[1697552101789, 1697552103301]"
2708,2708,233,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087783,1697552088518,120,,,[20],[1697552087803]
2709,2709,509,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154371,1697552155496,120,,,[30],[1697552154401]
2710,2710,207,36,[],200,llama-13b,64,1,1419.0,1.0,1,A100,1697552105070,1697552106489,120,10.0,1.0,"[20, 1399]","[1697552105090, 1697552106489]"
2711,2711,408,44,[],200,llama-13b,64,1,1189.0,1.0,1,A100,1697552115119,1697552116308,120,16.0,1.0,"[32, 1157]","[1697552115151, 1697552116308]"
2712,2712,763,37,[],200,llama-13b,64,1,805.0,1.0,1,A100,1697552106492,1697552107297,120,20.0,1.0,"[11, 794]","[1697552106503, 1697552107297]"
2713,2713,68,45,[],200,llama-13b,64,1,544.0,1.0,1,A100,1697552116311,1697552116855,120,12.0,1.0,"[11, 533]","[1697552116322, 1697552116855]"
2714,2714,816,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552088521,1697552089318,120,,,"[34, 743]","[1697552088555, 1697552089298]"
2715,2715,448,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552071974,1697552072657,120,,,[14],[1697552071988]
2716,2716,256,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089321,1697552090605,120,,,"[123, 1139]","[1697552089444, 1697552090583]"
2717,2717,533,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107299,1697552109322,120,,,[7],[1697552107306]
2718,2718,587,31,[],200,llama-13b,64,1,1870.0,1.0,1,A100,1697552089324,1697552091194,120,13.0,1.0,"[146, 1724]","[1697552089470, 1697552091194]"
2719,2719,336,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091197,1697552093264,120,,,"[10, 1531]","[1697552091207, 1697552092738]"
2720,2720,104,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552072661,1697552074776,120,,,[81],[1697552072742]
2721,2721,921,33,[],200,llama-13b,64,1,1097.0,1.0,1,A100,1697552093270,1697552094367,120,31.0,1.0,"[69, 1028]","[1697552093339, 1697552094367]"
2722,2722,697,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094370,1697552096114,120,,,"[10, 1055]","[1697552094380, 1697552095435]"
2723,2723,350,35,[],200,llama-13b,64,1,1131.0,1.0,1,A100,1697552096119,1697552097250,120,216.0,1.0,"[35, 1096]","[1697552096154, 1697552097250]"
2724,2724,188,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109335,1697552110460,120,,,[45],[1697552109380]
2725,2725,780,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074781,1697552075456,120,,,[65],[1697552074846]
2726,2726,126,36,[],200,llama-13b,64,1,975.0,1.0,1,A100,1697552097254,1697552098229,120,19.0,1.0,"[19, 955]","[1697552097273, 1697552098228]"
2727,2727,550,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075462,1697552076892,120,,,"[84, 1236]","[1697552075546, 1697552076782]"
2728,2728,769,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116857,1697552118449,120,,,[11],[1697552116868]
2729,2729,336,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118451,1697552119186,120,,,[25],[1697552118476]
2730,2730,629,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121373,1697552122933,120,,,[100],[1697552121473]
2731,2731,847,26,[],200,llama-13b,64,1,1238.0,1.0,1,A100,1697552090609,1697552091847,120,10.0,1.0,"[160, 1078]","[1697552090769, 1697552091847]"
2732,2732,894,40,[],200,llama-13b,64,1,1350.0,1.0,1,A100,1697552110465,1697552111815,120,14.0,1.0,"[25, 1325]","[1697552110490, 1697552111815]"
2733,2733,214,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076899,1697552078118,120,,,[38],[1697552076937]
2734,2734,912,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078121,1697552079383,120,,,"[31, 1095]","[1697552078152, 1697552079247]"
2735,2735,419,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118454,1697552120129,120,,,"[111, 1385]","[1697552118565, 1697552119950]"
2736,2736,140,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106525,1697552109323,120,,,"[133, 2032]","[1697552106658, 1697552108690]"
2737,2737,919,42,[],200,llama-13b,64,1,1491.0,1.0,1,A100,1697552119190,1697552120681,120,14.0,1.0,"[73, 1418]","[1697552119263, 1697552120681]"
2738,2738,800,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156088,1697552157800,120,,,[28],[1697552156116]
2739,2739,492,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109335,1697552110461,120,,,[106],[1697552109441]
2740,2740,455,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157803,1697552159106,120,,,[20],[1697552157823]
2741,2741,348,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111117,1697552112677,120,,,[32],[1697552111149]
2742,2742,234,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113430,1697552115114,120,,,[39],[1697552113469]
2743,2743,135,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120686,1697552122073,120,,,[39],[1697552120725]
2744,2744,842,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122074,1697552122933,120,,,[6],[1697552122080]
2745,2745,10,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112679,1697552114139,120,,,[7],[1697552112686]
2746,2746,495,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 458.06 MiB is free. Process 1449637 has 38.94 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122937,1697552124743,120,,,[39],[1697552122976]
2747,2747,4,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115119,1697552116440,120,,,"[52, 1137]","[1697552115171, 1697552116308]"
2748,2748,270,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552124746,1697552126520,120,,,[19],[1697552124765]
2749,2749,579,37,[],200,llama-13b,64,1,1522.0,1.0,1,A100,1697552096707,1697552098229,120,19.0,1.0,"[19, 1503]","[1697552096726, 1697552098229]"
2750,2750,613,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120133,1697552121355,120,,,[55],[1697552120188]
2751,2751,232,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098232,1697552099702,120,,,[17],[1697552098249]
2752,2752,467,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083910,1697552084996,120,,,[133],[1697552084043]
2753,2753,267,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121359,1697552122073,120,,,[26],[1697552121385]
2754,2754,592,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116448,1697552118448,120,,,[187],[1697552116635]
2755,2755,368,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118453,1697552120129,120,,,"[97, 1399]","[1697552118550, 1697552119949]"
2756,2756,643,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116446,1697552117623,120,,,[40],[1697552116486]
2757,2757,567,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094773,1697552096115,120,,,"[94, 1124]","[1697552094867, 1697552095991]"
2758,2758,755,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122077,1697552123844,120,,,[38],[1697552122115]
2759,2759,221,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096119,1697552098825,120,,,"[134, 1975]","[1697552096253, 1697552098228]"
2760,2760,22,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120132,1697552121355,120,,,[6],[1697552120138]
2761,2761,413,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117631,1697552119186,120,,,[60],[1697552117691]
2762,2762,243,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085000,1697552086532,120,,,[12],[1697552085012]
2763,2763,828,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086537,1697552087781,120,,,[20],[1697552086557]
2764,2764,597,26,[],200,llama-13b,64,1,1513.0,1.0,1,A100,1697552087785,1697552089298,120,39.0,1.0,"[33, 1480]","[1697552087818, 1697552089298]"
2765,2765,71,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552119187,1697552120129,120,,,"[14, 749]","[1697552119201, 1697552119950]"
2766,2766,728,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121363,1697552122933,120,,,[105],[1697552121468]
2767,2767,380,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122938,1697552125686,120,,,[102],[1697552123040]
2768,2768,521,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123848,1697552125687,120,,,[57],[1697552123905]
2769,2769,97,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128130,1697552135649,120,,,"[16, 819, 682, 734, 740, 692, 695, 780, 811, 724]","[1697552128146, 1697552128965, 1697552129647, 1697552130381, 1697552131121, 1697552131813, 1697552132508, 1697552133288, 1697552134099, 1697552134823]"
2770,2770,181,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125691,1697552127341,120,,,[70],[1697552125761]
2771,2771,770,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120133,1697552121355,120,,,[104],[1697552120237]
2772,2772,59,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118452,1697552120130,120,,,"[44, 1453]","[1697552118496, 1697552119949]"
2773,2773,921,35,[],200,llama-13b,64,1,1703.0,1.0,1,A100,1697552098829,1697552100532,120,31.0,1.0,"[122, 1580]","[1697552098951, 1697552100531]"
2774,2774,758,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120134,1697552121355,120,,,[44],[1697552120178]
2775,2775,682,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135653,1697552136976,120,,,[92],[1697552135745]
2776,2776,156,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125691,1697552127341,120,,,[62],[1697552125753]
2777,2777,41,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120133,1697552121355,120,,,[35],[1697552120168]
2778,2778,739,48,[],200,llama-13b,64,1,1607.0,1.0,1,A100,1697552127358,1697552128965,120,216.0,1.0,"[36, 1571]","[1697552127394, 1697552128965]"
2779,2779,625,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121362,1697552122932,120,,,[82],[1697552121444]
2780,2780,448,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136978,1697552137936,120,,,"[20, 766]","[1697552136998, 1697552137764]"
2781,2781,420,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121358,1697552122073,120,,,[17],[1697552121375]
2782,2782,617,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083681,1697552084682,120,,,[95],[1697552083776]
2783,2783,171,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 6.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552155500,1697552156684,120,,,[53],[1697552155553]
2784,2784,791,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552124749,1697552126520,120,,,[41],[1697552124790]
2785,2785,572,24,[],200,llama-13b,64,1,1231.0,1.0,1,A100,1697552079395,1697552080626,120,16.0,1.0,"[76, 1155]","[1697552079471, 1697552080626]"
2786,2786,822,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130345,1697552131085,120,,,[11],[1697552130356]
2787,2787,870,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156685,1697552157801,120,,,[6],[1697552156691]
2788,2788,499,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089319,1697552090605,120,,,"[14, 1250]","[1697552089333, 1697552090583]"
2789,2789,846,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109334,1697552110461,120,,,[6],[1697552109340]
2790,2790,153,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090607,1697552091869,120,,,"[71, 1169]","[1697552090678, 1697552091847]"
2791,2791,590,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131092,1697552133251,120,,,[64],[1697552131156]
2792,2792,218,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133254,1697552134060,120,,,[11],[1697552133265]
2793,2793,857,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091872,1697552093476,120,,,[121],[1697552091993]
2794,2794,916,58,[],200,llama-13b,64,1,1511.0,1.0,1,A100,1697552134063,1697552135574,120,8.0,1.0,"[52, 1458]","[1697552134115, 1697552135573]"
2795,2795,911,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552114145,1697552116440,120,,,"[26, 1585]","[1697552114171, 1697552115756]"
2796,2796,231,45,[],200,llama-13b,64,1,971.0,1.0,1,A100,1697552110143,1697552111114,120,13.0,1.0,"[108, 862]","[1697552110251, 1697552111113]"
2797,2797,852,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552126522,1697552128289,120,,,"[19, 1586]","[1697552126541, 1697552128127]"
2798,2798,880,50,[],200,llama-13b,64,1,2301.0,1.0,1,A100,1697552127346,1697552129647,120,84.0,2.0,"[32, 1586, 683]","[1697552127378, 1697552128964, 1697552129647]"
2799,2799,3,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099708,1697552101107,120,,,"[32, 1349]","[1697552099740, 1697552101089]"
2800,2800,566,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107756,1697552109323,120,,,"[14, 921]","[1697552107770, 1697552108691]"
2801,2801,1,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111118,1697552112678,120,,,[31],[1697552111149]
2802,2802,431,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121363,1697552122932,120,,,[86],[1697552121449]
2803,2803,202,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 458.06 MiB is free. Process 1449637 has 38.94 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122938,1697552124743,120,,,[56],[1697552122994]
2804,2804,587,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112683,1697552114140,120,,,[32],[1697552112715]
2805,2805,221,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109335,1697552111924,120,,,"[133, 1644]","[1697552109468, 1697552111112]"
2806,2806,359,48,[],200,llama-13b,64,1,1612.0,1.0,1,A100,1697552114144,1697552115756,120,10.0,1.0,"[7, 1604]","[1697552114151, 1697552115755]"
2807,2807,883,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129613,1697552131085,120,,,[63],[1697552129676]
2808,2808,785,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552124748,1697552126520,120,,,[42],[1697552124790]
2809,2809,536,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131088,1697552132471,120,,,[41],[1697552131129]
2810,2810,313,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132476,1697552134060,120,,,[70],[1697552132546]
2811,2811,655,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121358,1697552122073,120,,,[23],[1697552121381]
2812,2812,593,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101112,1697552103817,120,,,"[68, 2120]","[1697552101180, 1697552103300]"
2813,2813,403,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 458.06 MiB is free. Process 1449637 has 38.94 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122935,1697552124743,120,,,[8],[1697552122943]
2814,2814,362,41,[],200,llama-13b,64,1,2077.0,1.0,1,A100,1697552103827,1697552105904,120,14.0,1.0,"[125, 1951]","[1697552103952, 1697552105903]"
2815,2815,56,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552124746,1697552126520,120,,,[24],[1697552124770]
2816,2816,893,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134064,1697552135649,120,,,"[73, 1436]","[1697552134137, 1697552135573]"
2817,2817,436,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090607,1697552091870,120,,,"[47, 1193]","[1697552090654, 1697552091847]"
2818,2818,307,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122081,1697552123844,120,,,[69],[1697552122150]
2819,2819,395,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084686,1697552085755,120,,,[40],[1697552084726]
2820,2820,757,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552126521,1697552127341,120,,,[15],[1697552126536]
2821,2821,417,50,[],200,llama-13b,64,1,1610.0,1.0,1,A100,1697552127355,1697552128965,120,17.0,1.0,"[80, 1530]","[1697552127435, 1697552128965]"
2822,2822,711,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098232,1697552099703,120,,,[22],[1697552098254]
2823,2823,51,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116448,1697552118448,120,,,[195],[1697552116643]
2824,2824,791,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089321,1697552090604,120,,,[41],[1697552089362]
2825,2825,277,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083679,1697552084681,120,,,[80],[1697552083759]
2826,2826,371,38,[],200,llama-13b,64,1,2187.0,1.0,1,A100,1697552101114,1697552103301,120,13.0,1.0,"[145, 2042]","[1697552101259, 1697552103301]"
2827,2827,116,14,[],200,llama-13b,64,1,717.0,1.0,1,A100,1697552072658,1697552073375,120,23.0,1.0,"[17, 700]","[1697552072675, 1697552073375]"
2828,2828,25,39,[],200,llama-13b,64,1,1203.0,1.0,1,A100,1697552103304,1697552104507,120,12.0,1.0,"[16, 1187]","[1697552103320, 1697552104507]"
2829,2829,432,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111930,1697552113423,120,,,[32],[1697552111962]
2830,2830,421,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552114144,1697552116439,120,,,"[12, 1599]","[1697552114156, 1697552115755]"
2831,2831,202,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113431,1697552115113,120,,,[107],[1697552113538]
2832,2832,729,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552104510,1697552106517,120,,,[15],[1697552104525]
2833,2833,786,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115120,1697552116439,120,,,"[133, 1055]","[1697552115253, 1697552116308]"
2834,2834,383,41,[],200,llama-13b,64,1,2167.0,1.0,1,A100,1697552106523,1697552108690,120,15.0,1.0,"[113, 2054]","[1697552106636, 1697552108690]"
2835,2835,563,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116445,1697552117622,120,,,[31],[1697552116476]
2836,2836,159,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552108695,1697552110135,120,,,[24],[1697552108719]
2837,2837,747,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110139,1697552111925,120,,,"[48, 926]","[1697552110187, 1697552111113]"
2838,2838,700,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.10 GiB is free. Process 1449637 has 38.29 GiB memory in use. Of the allocated memory 29.98 GiB is allocated by PyTorch, and 6.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073379,1697552074777,120,,,[19],[1697552073398]
2839,2839,90,63,[],200,llama-13b,64,1,1361.0,1.0,1,A100,1697552140778,1697552142139,120,19.0,1.0,"[30, 1331]","[1697552140808, 1697552142139]"
2840,2840,790,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142142,1697552143537,120,,,"[21, 811]","[1697552142163, 1697552142974]"
2841,2841,444,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074781,1697552075452,120,,,[81],[1697552074862]
2842,2842,422,65,[],200,llama-13b,64,1,2411.0,1.0,1,A100,1697552143544,1697552145955,120,26.0,1.0,"[122, 2289]","[1697552143666, 1697552145955]"
2843,2843,214,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075456,1697552076893,120,,,"[7, 758, 134]","[1697552075463, 1697552076221, 1697552076355]"
2844,2844,859,38,[],200,llama-13b,64,1,1201.0,1.0,1,A100,1697552103306,1697552104507,120,23.0,1.0,"[36, 1164]","[1697552103342, 1697552104506]"
2845,2845,630,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128292,1697552129608,120,,,[11],[1697552128303]
2846,2846,607,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552104510,1697552106517,120,,,"[19, 1374]","[1697552104529, 1697552105903]"
2847,2847,486,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103827,1697552106517,120,,,"[117, 1959]","[1697552103944, 1697552105903]"
2848,2848,144,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106522,1697552107867,120,,,"[20, 1211]","[1697552106542, 1697552107753]"
2849,2849,518,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116448,1697552118448,120,,,[142],[1697552116590]
2850,2850,802,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076904,1697552078118,120,,,[82],[1697552076986]
2851,2851,376,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106522,1697552107867,120,,,"[15, 1216]","[1697552106537, 1697552107753]"
2852,2852,548,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111818,1697552112677,120,,,[6],[1697552111824]
2853,2853,186,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128968,1697552130343,120,,,[27],[1697552128995]
2854,2854,702,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552114145,1697552116439,120,,,"[21, 1590]","[1697552114166, 1697552115756]"
2855,2855,322,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112683,1697552114140,120,,,[27],[1697552112710]
2856,2856,905,43,[],200,llama-13b,64,1,1611.0,1.0,1,A100,1697552114145,1697552115756,120,11.0,1.0,"[36, 1575]","[1697552114181, 1697552115756]"
2857,2857,500,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110466,1697552111926,120,,,"[35, 1314]","[1697552110501, 1697552111815]"
2858,2858,685,44,[],200,llama-13b,64,1,1898.0,1.0,1,A100,1697552115759,1697552117657,120,364.0,2.0,"[6, 1090, 801]","[1697552115765, 1697552116855, 1697552117656]"
2859,2859,54,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084685,1697552085753,120,,,[11],[1697552084696]
2860,2860,451,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116447,1697552118448,120,,,[103],[1697552116550]
2861,2861,636,27,[],200,llama-13b,64,1,1368.0,1.0,1,A100,1697552085760,1697552087128,120,31.0,1.0,"[91, 1277]","[1697552085851, 1697552087128]"
2862,2862,239,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110466,1697552111924,120,,,"[40, 1309]","[1697552110506, 1697552111815]"
2863,2863,341,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117658,1697552119186,120,,,[86],[1697552117744]
2864,2864,413,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087130,1697552088517,120,,,[11],[1697552087141]
2865,2865,715,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113435,1697552115115,120,,,[143],[1697552113578]
2866,2866,64,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552088520,1697552089317,120,,,"[10, 768]","[1697552088530, 1697552089298]"
2867,2867,7,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111930,1697552113423,120,,,[22],[1697552111952]
2868,2868,245,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111930,1697552113424,120,,,[47],[1697552111977]
2869,2869,597,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113430,1697552115113,120,,,[30],[1697552113460]
2870,2870,485,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115119,1697552116441,120,,,"[68, 1120]","[1697552115187, 1697552116307]"
2871,2871,367,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115119,1697552116440,120,,,"[44, 1145]","[1697552115163, 1697552116308]"
2872,2872,22,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116443,1697552117621,120,,,[7],[1697552116450]
2873,2873,731,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117627,1697552118449,120,,,[27],[1697552117654]
2874,2874,110,46,[],200,llama-13b,64,1,3782.0,1.0,1,A100,1697552119188,1697552122970,120,96.0,4.0,"[35, 1458, 711, 718, 860]","[1697552119223, 1697552120681, 1697552121392, 1697552122110, 1697552122970]"
2875,2875,145,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116446,1697552117622,120,,,[44],[1697552116490]
2876,2876,191,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116447,1697552118448,120,,,[114],[1697552116561]
2877,2877,846,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117627,1697552118449,120,,,[22],[1697552117649]
2878,2878,16,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113434,1697552115115,120,,,[129],[1697552113563]
2879,2879,517,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111934,1697552113425,120,,,[142],[1697552112076]
2880,2880,885,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116446,1697552117622,120,,,[90],[1697552116536]
2881,2881,109,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137941,1697552139268,120,,,"[30, 1196]","[1697552137971, 1697552139167]"
2882,2882,177,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113434,1697552115115,120,,,[134],[1697552113568]
2883,2883,537,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117632,1697552119186,120,,,[57],[1697552117689]
2884,2884,601,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115120,1697552120129,120,,,"[136, 1598, 802, 826, 738]","[1697552115256, 1697552116854, 1697552117656, 1697552118482, 1697552119220]"
2885,2885,816,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123847,1697552125687,120,,,[38],[1697552123885]
2886,2886,807,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139272,1697552142271,120,,,"[64, 2407]","[1697552139336, 1697552141743]"
2887,2887,874,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115123,1697552120129,120,,,"[143, 1589, 801, 826, 738]","[1697552115266, 1697552116855, 1697552117656, 1697552118482, 1697552119220]"
2888,2888,593,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125689,1697552127341,120,,,[20],[1697552125709]
2889,2889,242,57,[],200,llama-13b,64,1,7469.0,1.0,1,A100,1697552127354,1697552134823,120,345.0,9.0,"[84, 1527, 682, 734, 740, 691, 695, 780, 812, 724]","[1697552127438, 1697552128965, 1697552129647, 1697552130381, 1697552131121, 1697552131812, 1697552132507, 1697552133287, 1697552134099, 1697552134823]"
2890,2890,373,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120133,1697552121355,120,,,[30],[1697552120163]
2891,2891,313,45,[],200,llama-13b,64,1,1492.0,1.0,1,A100,1697552119189,1697552120681,120,20.0,1.0,"[64, 1428]","[1697552119253, 1697552120681]"
2892,2892,12,49,[],200,llama-13b,64,1,1096.0,1.0,1,A100,1697552115759,1697552116855,120,11.0,1.0,"[15, 1081]","[1697552115774, 1697552116855]"
2893,2893,26,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121359,1697552122933,120,,,[77],[1697552121436]
2894,2894,920,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111930,1697552113423,120,,,[17],[1697552111947]
2895,2895,622,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120136,1697552121355,120,,,[106],[1697552120242]
2896,2896,583,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113428,1697552115112,120,,,[7],[1697552113435]
2897,2897,718,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116860,1697552118448,120,,,[22],[1697552116882]
2898,2898,176,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118453,1697552120129,120,,,[92],[1697552118545]
2899,2899,896,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120684,1697552122074,120,,,[20],[1697552120704]
2900,2900,642,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122076,1697552123844,120,,,[44],[1697552122120]
2901,2901,732,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122937,1697552125686,120,,,[98],[1697552123035]
2902,2902,351,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115119,1697552116439,120,,,"[17, 1171]","[1697552115136, 1697552116307]"
2903,2903,24,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105906,1697552107868,120,,,[10],[1697552105916]
2904,2904,671,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135653,1697552136976,120,,,[97],[1697552135750]
2905,2905,875,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120134,1697552121355,120,,,[44],[1697552120178]
2906,2906,717,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107873,1697552109324,120,,,"[31, 1301]","[1697552107904, 1697552109205]"
2907,2907,584,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145223,1697552146630,120,,,[11],[1697552145234]
2908,2908,51,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085762,1697552089318,120,,,"[106, 1260, 693, 735]","[1697552085868, 1697552087128, 1697552087821, 1697552088556]"
2909,2909,201,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091874,1697552093477,120,,,[169],[1697552092043]
2910,2910,12,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116447,1697552117622,120,,,[108],[1697552116555]
2911,2911,361,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146635,1697552147357,120,,,"[20, 684]","[1697552146655, 1697552147339]"
2912,2912,480,38,[],200,llama-13b,64,1,2037.0,1.0,1,A100,1697552099715,1697552101752,120,26.0,1.0,"[65, 1972]","[1697552099780, 1697552101752]"
2913,2913,710,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117633,1697552119186,120,,,[106],[1697552117739]
2914,2914,320,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136978,1697552137936,120,,,[9],[1697552136987]
2915,2915,142,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101755,1697552103818,120,,,"[20, 1526]","[1697552101775, 1697552103301]"
2916,2916,366,47,[],200,llama-13b,64,1,5591.0,1.0,1,A100,1697552119188,1697552124779,120,85.0,6.0,"[33, 1459, 712, 718, 860, 915, 894]","[1697552119221, 1697552120680, 1697552121392, 1697552122110, 1697552122970, 1697552123885, 1697552124779]"
2917,2917,92,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137940,1697552139267,120,,,"[16, 1210]","[1697552137956, 1697552139166]"
2918,2918,682,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139272,1697552142271,120,,,"[69, 2403]","[1697552139341, 1697552141744]"
2919,2919,341,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080629,1697552082120,120,,,"[20, 861]","[1697552080649, 1697552081510]"
2920,2920,6,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091863,1697552093264,120,,,[28],[1697552091891]
2921,2921,232,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159108,1697552159782,120,,,[15],[1697552159123]
2922,2922,588,29,[],200,llama-13b,64,1,1099.0,1.0,1,A100,1697552093269,1697552094368,120,11.0,1.0,"[34, 1064]","[1697552093303, 1697552094367]"
2923,2923,334,30,[],200,llama-13b,64,1,1064.0,1.0,1,A100,1697552094372,1697552095436,120,15.0,1.0,"[23, 1041]","[1697552094395, 1697552095436]"
2924,2924,616,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091865,1697552093264,120,,,"[41, 1258]","[1697552091906, 1697552093164]"
2925,2925,917,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552095437,1697552097348,120,,,"[20, 1246]","[1697552095457, 1697552096703]"
2926,2926,282,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085001,1697552086534,120,,,[50],[1697552085051]
2927,2927,275,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093267,1697552094765,120,,,"[6, 1093]","[1697552093273, 1697552094366]"
2928,2928,814,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159785,1697552161159,120,,,[38],[1697552159823]
2929,2929,366,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085759,1697552089317,120,,,"[77, 1291, 694, 735]","[1697552085836, 1697552087127, 1697552087821, 1697552088556]"
2930,2930,863,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086542,1697552088518,120,,,[132],[1697552086674]
2931,2931,45,29,[],200,llama-13b,64,1,1217.0,1.0,1,A100,1697552094774,1697552095991,120,19.0,1.0,"[169, 1048]","[1697552094943, 1697552095991]"
2932,2932,694,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097355,1697552099702,120,,,[95],[1697552097450]
2933,2933,775,40,[],200,llama-13b,64,1,1497.0,1.0,1,A100,1697552118452,1697552119949,120,17.0,1.0,"[54, 1443]","[1697552118506, 1697552119949]"
2934,2934,503,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118451,1697552120128,120,,,"[50, 1448]","[1697552118501, 1697552119949]"
2935,2935,589,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161162,1697552162485,120,,,[20],[1697552161182]
2936,2936,385,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118453,1697552120128,120,,,"[86, 1410]","[1697552118539, 1697552119949]"
2937,2937,634,30,[],200,llama-13b,64,1,709.0,1.0,1,A100,1697552095995,1697552096704,120,13.0,1.0,"[26, 683]","[1697552096021, 1697552096704]"
2938,2938,349,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099711,1697552101107,120,,,"[41, 1337]","[1697552099752, 1697552101089]"
2939,2939,250,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120134,1697552121355,120,,,[104],[1697552120238]
2940,2940,552,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552119952,1697552128289,120,,,"[10, 719, 711, 718, 860, 915, 893, 942, 834, 820]","[1697552119962, 1697552120681, 1697552121392, 1697552122110, 1697552122970, 1697552123885, 1697552124778, 1697552125720, 1697552126554, 1697552127374]"
2941,2941,161,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120132,1697552121355,120,,,[11],[1697552120143]
2942,2942,771,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089324,1697552091869,120,,,"[140, 1730]","[1697552089464, 1697552091194]"
2943,2943,833,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121358,1697552122073,120,,,[18],[1697552121376]
2944,2944,424,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091872,1697552093476,120,,,[91],[1697552091963]
2945,2945,608,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122075,1697552122933,120,,,[10],[1697552122085]
2946,2946,742,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121357,1697552122073,120,,,[7],[1697552121364]
2947,2947,198,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093484,1697552096114,120,,,"[96, 1855]","[1697552093580, 1697552095435]"
2948,2948,467,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142276,1697552143538,120,,,[42],[1697552142318]
2949,2949,760,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096120,1697552098825,120,,,"[69, 2039]","[1697552096189, 1697552098228]"
2950,2950,529,34,[],200,llama-13b,64,1,1701.0,1.0,1,A100,1697552098829,1697552100530,120,10.0,1.0,"[33, 1668]","[1697552098862, 1697552100530]"
2951,2951,254,27,[],200,llama-13b,64,1,492.0,1.0,1,A100,1697552089303,1697552089795,120,58.0,1.0,"[10, 482]","[1697552089313, 1697552089795]"
2952,2952,236,58,[],200,llama-13b,64,1,2411.0,1.0,1,A100,1697552143545,1697552145956,120,8.0,1.0,"[126, 2284]","[1697552143671, 1697552145955]"
2953,2953,24,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089797,1697552091870,120,,,[6],[1697552089803]
2954,2954,510,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129649,1697552131084,120,,,[44],[1697552129693]
2955,2955,490,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122077,1697552123844,120,,,[33],[1697552122110]
2956,2956,280,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131087,1697552132470,120,,,[35],[1697552131122]
2957,2957,188,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552100533,1697552102447,120,,,"[21, 1198]","[1697552100554, 1697552101752]"
2958,2958,144,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123846,1697552125686,120,,,[8],[1697552123854]
2959,2959,825,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145960,1697552147357,120,,,"[33, 1346]","[1697552145993, 1697552147339]"
2960,2960,844,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125689,1697552126520,120,,,[10],[1697552125699]
2961,2961,869,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132473,1697552134060,120,,,[44],[1697552132517]
2962,2962,412,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123848,1697552125686,120,,,[96],[1697552123944]
2963,2963,597,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147361,1697552148669,120,,,[26],[1697552147387]
2964,2964,72,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125689,1697552126520,120,,,[10],[1697552125699]
2965,2965,32,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107876,1697552109322,120,,,"[95, 1234]","[1697552107971, 1697552109205]"
2966,2966,641,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134066,1697552135648,120,,,[95],[1697552134161]
2967,2967,572,19,[],200,llama-13b,64,1,1127.0,1.0,1,A100,1697552078122,1697552079249,120,16.0,1.0,"[114, 1013]","[1697552078236, 1697552079249]"
2968,2968,501,54,[],200,llama-13b,64,1,1605.0,1.0,1,A100,1697552126523,1697552128128,120,19.0,1.0,"[33, 1571]","[1697552126556, 1697552128127]"
2969,2969,232,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079251,1697552080743,120,,,[39],[1697552079290]
2970,2970,271,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128130,1697552135649,120,,,"[11, 824, 682, 734, 741, 691, 694, 781, 811, 724]","[1697552128141, 1697552128965, 1697552129647, 1697552130381, 1697552131122, 1697552131813, 1697552132507, 1697552133288, 1697552134099, 1697552134823]"
2971,2971,4,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 3.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552080748,1697552082121,120,,,"[46, 1208]","[1697552080794, 1697552082002]"
2972,2972,734,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109334,1697552110462,120,,,[31],[1697552109365]
2973,2973,586,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082126,1697552083467,120,,,"[113, 1120]","[1697552082239, 1697552083359]"
2974,2974,728,29,[],200,llama-13b,64,1,1260.0,1.0,1,A100,1697552089324,1697552090584,120,20.0,1.0,"[135, 1124]","[1697552089459, 1697552090583]"
2975,2975,496,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090586,1697552091869,120,,,"[11, 597]","[1697552090597, 1697552091194]"
2976,2976,366,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083472,1697552083902,120,,,[21],[1697552083493]
2977,2977,156,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091871,1697552093475,120,,,[73],[1697552091944]
2978,2978,19,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083906,1697552084998,120,,,[14],[1697552083920]
2979,2979,856,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093480,1697552094764,120,,,"[56, 1211]","[1697552093536, 1697552094747]"
2980,2980,695,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085004,1697552086533,120,,,[62],[1697552085066]
2981,2981,773,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552126525,1697552128290,120,,,"[48, 1554]","[1697552126573, 1697552128127]"
2982,2982,349,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086538,1697552087781,120,,,[41],[1697552086579]
2983,2983,430,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128296,1697552130343,120,,,[76],[1697552128372]
2984,2984,388,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110468,1697552111925,120,,,"[81, 1266]","[1697552110549, 1697552111815]"
2985,2985,83,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123846,1697552125686,120,,,[20],[1697552123866]
2986,2986,120,27,[],200,llama-13b,64,1,1511.0,1.0,1,A100,1697552087788,1697552089299,120,17.0,1.0,"[40, 1470]","[1697552087828, 1697552089298]"
2987,2987,710,28,[],200,llama-13b,64,1,1280.0,1.0,1,A100,1697552089303,1697552090583,120,14.0,1.0,"[20, 1259]","[1697552089323, 1697552090582]"
2988,2988,162,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111930,1697552113425,120,,,[57],[1697552111987]
2989,2989,480,29,[],200,llama-13b,64,1,1260.0,1.0,1,A100,1697552090587,1697552091847,120,26.0,1.0,"[24, 1236]","[1697552090611, 1697552091847]"
2990,2990,136,30,[],200,llama-13b,64,1,1301.0,1.0,1,A100,1697552091863,1697552093164,120,31.0,1.0,"[18, 1282]","[1697552091881, 1697552093163]"
2991,2991,833,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093168,1697552093476,120,,,[14],[1697552093182]
2992,2992,744,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113430,1697552115114,120,,,[54],[1697552113484]
2993,2993,666,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125689,1697552126520,120,,,[15],[1697552125704]
2994,2994,522,46,[],200,llama-13b,64,1,1734.0,1.0,1,A100,1697552115120,1697552116854,120,20.0,1.0,"[141, 1593]","[1697552115261, 1697552116854]"
2995,2995,207,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.11 GiB is allocated by PyTorch, and 7.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130347,1697552131775,120,,,[39],[1697552130386]
2996,2996,176,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116857,1697552118448,120,,,[19],[1697552116876]
2997,2997,434,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552126525,1697552128289,120,,,"[66, 1536]","[1697552126591, 1697552128127]"
2998,2998,190,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122075,1697552123843,120,,,[15],[1697552122090]
2999,2999,876,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118451,1697552119186,120,,,[25],[1697552118476]
3000,3000,926,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082124,1697552083469,120,,,"[16, 1218]","[1697552082140, 1697552083358]"
3001,3001,95,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128296,1697552129609,120,,,[57],[1697552128353]
3002,3002,466,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 458.06 MiB is free. Process 1449637 has 38.94 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122936,1697552124743,120,,,[38],[1697552122974]
3003,3003,685,57,[],200,llama-13b,64,1,1620.0,1.0,1,A100,1697552142977,1697552144597,120,364.0,2.0,"[21, 1545, 54]","[1697552142998, 1697552144543, 1697552144597]"
3004,3004,793,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129613,1697552131085,120,,,[65],[1697552129678]
3005,3005,750,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 458.06 MiB is free. Process 1449637 has 38.94 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123846,1697552124744,120,,,[15],[1697552123861]
3006,3006,181,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552073400,1697552076890,120,,,"[77, 1700, 309, 869]","[1697552073477, 1697552075177, 1697552075486, 1697552076355]"
3007,3007,451,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552126522,1697552127341,120,,,[6],[1697552126528]
3008,3008,216,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117626,1697552118449,120,,,[13],[1697552117639]
3009,3009,243,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162487,1697552163147,120,,,[30],[1697552162517]
3010,3010,221,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552127355,1697552128290,120,,,"[19, 754]","[1697552127374, 1697552128128]"
3011,3011,262,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 458.06 MiB is free. Process 1449637 has 38.94 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122938,1697552124743,120,,,[53],[1697552122991]
3012,3012,699,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091873,1697552093475,120,,,[175],[1697552092048]
3013,3013,370,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118453,1697552119186,120,,,[28],[1697552118481]
3014,3014,22,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163150,1697552164529,120,,,[42],[1697552163192]
3015,3015,288,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129612,1697552131084,120,,,[49],[1697552129661]
3016,3016,558,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552126524,1697552128290,120,,,"[42, 1561]","[1697552126566, 1697552128127]"
3017,3017,118,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552119189,1697552128289,120,,,"[51, 1441, 711, 718, 860, 915, 894, 941, 834, 820]","[1697552119240, 1697552120681, 1697552121392, 1697552122110, 1697552122970, 1697552123885, 1697552124779, 1697552125720, 1697552126554, 1697552127374]"
3018,3018,608,77,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164533,1697552166088,120,,,"[40, 1388]","[1697552164573, 1697552165961]"
3019,3019,353,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093484,1697552096114,120,,,"[87, 1865]","[1697552093571, 1697552095436]"
3020,3020,810,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128293,1697552129608,120,,,[31],[1697552128324]
3021,3021,377,78,[],200,llama-13b,64,1,1818.0,1.0,1,A100,1697552166101,1697552167919,120,13.0,1.0,"[139, 1679]","[1697552166240, 1697552167919]"
3022,3022,38,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552124744,1697552126520,120,,,[6],[1697552124750]
3023,3023,623,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552126523,1697552128289,120,,,[25],[1697552126548]
3024,3024,582,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129613,1697552131084,120,,,[70],[1697552129683]
3025,3025,389,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128295,1697552129609,120,,,[34],[1697552128329]
3026,3026,57,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131093,1697552132471,120,,,[66],[1697552131159]
3027,3027,298,55,[],200,llama-13b,64,1,2111.0,1.0,1,A100,1697552135654,1697552137765,120,17.0,1.0,"[121, 1989]","[1697552135775, 1697552137764]"
3028,3028,618,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132475,1697552134060,120,,,[66],[1697552132541]
3029,3029,386,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134062,1697552134789,120,,,[28],[1697552134090]
3030,3030,330,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131086,1697552132469,120,,,[21],[1697552131107]
3031,3031,912,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132473,1697552133253,120,,,[24],[1697552132497]
3032,3032,47,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134792,1697552137935,120,,,"[38, 1464, 719]","[1697552134830, 1697552136294, 1697552137013]"
3033,3033,745,61,[],200,llama-13b,64,1,1227.0,1.0,1,A100,1697552137941,1697552139168,120,17.0,1.0,"[108, 1119]","[1697552138049, 1697552139168]"
3034,3034,401,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139172,1697552140772,120,,,"[24, 918, 53, 49, 47]","[1697552139196, 1697552140114, 1697552140167, 1697552140216, 1697552140263]"
3035,3035,858,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135654,1697552136977,120,,,[96],[1697552135750]
3036,3036,628,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136980,1697552139267,120,,,"[63, 1570]","[1697552137043, 1697552138613]"
3037,3037,174,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140778,1697552142271,120,,,"[22, 1339]","[1697552140800, 1697552142139]"
3038,3038,684,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133256,1697552134789,120,,,[57],[1697552133313]
3039,3039,16,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147364,1697552148670,120,,,[178],[1697552147542]
3040,3040,757,64,[],200,llama-13b,64,1,1243.0,1.0,1,A100,1697552142276,1697552143519,120,20.0,1.0,"[31, 1212]","[1697552142307, 1697552143519]"
3041,3041,842,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107873,1697552109328,120,,,"[31, 1301]","[1697552107904, 1697552109205]"
3042,3042,344,56,[],200,llama-13b,64,1,1502.0,1.0,1,A100,1697552134793,1697552136295,120,13.0,1.0,"[77, 1425]","[1697552134870, 1697552136295]"
3043,3043,562,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090606,1697552091869,120,,,"[30, 1211]","[1697552090636, 1697552091847]"
3044,3044,753,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118454,1697552120129,120,,,"[106, 1389]","[1697552118560, 1697552119949]"
3045,3045,114,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136297,1697552137934,120,,,"[19, 1448]","[1697552136316, 1697552137764]"
3046,3046,409,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120133,1697552121356,120,,,[20],[1697552120153]
3047,3047,701,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137942,1697552140772,120,,,"[137, 2034, 54, 49, 47]","[1697552138079, 1697552140113, 1697552140167, 1697552140216, 1697552140263]"
3048,3048,533,65,[],200,llama-13b,64,1,1076.0,1.0,1,A100,1697552143522,1697552144598,120,216.0,2.0,"[11, 1065]","[1697552143533, 1697552144598]"
3049,3049,121,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552124746,1697552125687,120,,,[14],[1697552124760]
3050,3050,216,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091872,1697552093475,120,,,[96],[1697552091968]
3051,3051,721,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148674,1697552150142,120,,,"[92, 1356]","[1697552148766, 1697552150122]"
3052,3052,892,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093478,1697552094765,120,,,"[8, 1261]","[1697552093486, 1697552094747]"
3053,3053,827,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125691,1697552127341,120,,,[60],[1697552125751]
3054,3054,114,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552124781,1697552126520,120,,,[14],[1697552124795]
3055,3055,185,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552144600,1697552147357,120,,,"[10, 2061]","[1697552144610, 1697552146671]"
3056,3056,862,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147363,1697552148669,120,,,[102],[1697552147465]
3057,3057,660,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094774,1697552097350,120,,,"[163, 1766]","[1697552094937, 1697552096703]"
3058,3058,813,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552126524,1697552128290,120,,,"[34, 1569]","[1697552126558, 1697552128127]"
3059,3059,452,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131092,1697552133251,120,,,[69],[1697552131161]
3060,3060,469,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128295,1697552129609,120,,,[53],[1697552128348]
3061,3061,222,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133256,1697552134789,120,,,[54],[1697552133310]
3062,3062,238,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129611,1697552131083,120,,,[40],[1697552129651]
3063,3063,898,60,[],200,llama-13b,64,1,2221.0,1.0,1,A100,1697552134793,1697552137014,120,79.0,2.0,"[52, 1450, 719]","[1697552134845, 1697552136295, 1697552137014]"
3064,3064,827,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131086,1697552132470,120,,,[19],[1697552131105]
3065,3065,467,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140780,1697552142272,120,,,[64],[1697552140844]
3066,3066,631,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148677,1697552150143,120,,,[106],[1697552148783]
3067,3067,287,69,[],200,llama-13b,64,1,1286.0,1.0,1,A100,1697552150149,1697552151435,120,10.0,1.0,"[107, 1178]","[1697552150256, 1697552151434]"
3068,3068,596,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132474,1697552134060,120,,,[66],[1697552132540]
3069,3069,67,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552151450,1697552152619,120,,,[13],[1697552151463]
3070,3070,375,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150146,1697552151582,120,,,[21],[1697552150167]
3071,3071,252,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134064,1697552135649,120,,,"[80, 1430]","[1697552134144, 1697552135574]"
3072,3072,582,36,[],200,llama-13b,64,1,1217.0,1.0,1,A100,1697552100536,1697552101753,120,19.0,1.0,"[38, 1179]","[1697552100574, 1697552101753]"
3073,3073,872,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.46 GiB is allocated by PyTorch, and 7.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552074784,1697552075453,120,,,[93],[1697552074877]
3074,3074,351,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101755,1697552103819,120,,,"[25, 1522]","[1697552101780, 1697552103302]"
3075,3075,620,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 4.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552075460,1697552076892,120,,,"[76, 1246]","[1697552075536, 1697552076782]"
3076,3076,510,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093483,1697552096114,120,,,"[97, 1855]","[1697552093580, 1697552095435]"
3077,3077,29,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135651,1697552136977,120,,,[16],[1697552135667]
3078,3078,287,34,[],200,llama-13b,64,1,2106.0,1.0,1,A100,1697552096122,1697552098228,120,10.0,1.0,"[141, 1965]","[1697552096263, 1697552098228]"
3079,3079,868,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098233,1697552099703,120,,,[36],[1697552098269]
3080,3080,11,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103825,1697552106517,120,,,"[64, 2014]","[1697552103889, 1697552105903]"
3081,3081,611,56,[],200,llama-13b,64,1,787.0,1.0,1,A100,1697552136978,1697552137765,120,14.0,1.0,"[15, 772]","[1697552136993, 1697552137765]"
3082,3082,129,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096126,1697552098825,120,,,"[152, 1950]","[1697552096278, 1697552098228]"
3083,3083,626,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121363,1697552122932,120,,,[83],[1697552121446]
3084,3084,282,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122935,1697552123844,120,,,[11],[1697552122946]
3085,3085,51,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123847,1697552125687,120,,,[54],[1697552123901]
3086,3086,714,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098829,1697552101106,120,,,"[28, 1673, 51]","[1697552098857, 1697552100530, 1697552100581]"
3087,3087,712,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106522,1697552107868,120,,,"[31, 1200]","[1697552106553, 1697552107753]"
3088,3088,641,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125691,1697552127341,120,,,[67],[1697552125758]
3089,3089,886,36,[],200,llama-13b,64,1,1244.0,1.0,1,A100,1697552102451,1697552103695,120,17.0,1.0,"[29, 1215]","[1697552102480, 1697552103695]"
3090,3090,483,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101112,1697552102447,120,,,"[49, 1186]","[1697552101161, 1697552102347]"
3091,3091,378,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109335,1697552110461,120,,,[111],[1697552109446]
3092,3092,373,40,[],200,llama-13b,64,1,1329.0,1.0,1,A100,1697552107876,1697552109205,120,15.0,1.0,"[61, 1267]","[1697552107937, 1697552109204]"
3093,3093,147,45,[],200,llama-13b,64,1,1347.0,1.0,1,A100,1697552110468,1697552111815,120,182.0,1.0,"[87, 1260]","[1697552110555, 1697552111815]"
3094,3094,731,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111818,1697552112680,120,,,[20],[1697552111838]
3095,3095,548,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103697,1697552105088,120,,,"[6, 804]","[1697552103703, 1697552104507]"
3096,3096,145,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102451,1697552105088,120,,,"[44, 2011]","[1697552102495, 1697552104506]"
3097,3097,479,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112685,1697552114140,120,,,[67],[1697552112752]
3098,3098,845,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105093,1697552106519,120,,,"[149, 1248]","[1697552105242, 1697552106490]"
3099,3099,132,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552114145,1697552116440,120,,,"[41, 1569]","[1697552114186, 1697552115755]"
3100,3100,319,38,[],200,llama-13b,64,1,1398.0,1.0,1,A100,1697552105092,1697552106490,120,31.0,1.0,"[87, 1310]","[1697552105179, 1697552106489]"
3101,3101,384,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125688,1697552126521,120,,,[25],[1697552125713]
3102,3102,902,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106491,1697552107866,120,,,"[7, 799]","[1697552106498, 1697552107297]"
3103,3103,505,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106522,1697552109318,120,,,[46],[1697552106568]
3104,3104,836,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116448,1697552117623,120,,,[127],[1697552116575]
3105,3105,675,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107873,1697552109319,120,,,"[26, 1305]","[1697552107899, 1697552109204]"
3106,3106,493,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117631,1697552119186,120,,,[55],[1697552117686]
3107,3107,145,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109207,1697552110134,120,,,[15],[1697552109222]
3108,3108,160,51,[],200,llama-13b,64,1,1604.0,1.0,1,A100,1697552126524,1697552128128,120,13.0,1.0,"[39, 1564]","[1697552126563, 1697552128127]"
3109,3109,727,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110137,1697552111924,120,,,"[6, 970]","[1697552110143, 1697552111113]"
3110,3110,743,52,[],200,llama-13b,64,1,4378.0,1.0,1,A100,1697552128130,1697552132508,120,123.0,6.0,"[6, 829, 682, 734, 740, 691, 696]","[1697552128136, 1697552128965, 1697552129647, 1697552130381, 1697552131121, 1697552131812, 1697552132508]"
3111,3111,510,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094769,1697552096115,120,,,"[10, 1212]","[1697552094779, 1697552095991]"
3112,3112,518,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132512,1697552134060,120,,,[47],[1697552132559]
3113,3113,150,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134064,1697552135648,120,,,[71],[1697552134135]
3114,3114,699,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120687,1697552122073,120,,,[27],[1697552120714]
3115,3115,475,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111931,1697552113425,120,,,[105],[1697552112036]
3116,3116,746,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130345,1697552131085,120,,,[16],[1697552130361]
3117,3117,244,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113434,1697552115115,120,,,[134],[1697552113568]
3118,3118,789,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131777,1697552132471,120,,,[5],[1697552131782]
3119,3119,355,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122076,1697552123843,120,,,[24],[1697552122100]
3120,3120,398,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 458.06 MiB is free. Process 1449637 has 38.94 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122938,1697552124743,120,,,[58],[1697552122996]
3121,3121,124,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123846,1697552125686,120,,,[30],[1697552123876]
3122,3122,836,40,[],200,llama-13b,64,1,1242.0,1.0,1,A100,1697552103826,1697552105068,120,11.0,1.0,"[68, 1174]","[1697552103894, 1697552105068]"
3123,3123,57,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552124747,1697552126520,120,,,[38],[1697552124785]
3124,3124,702,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083475,1697552083903,120,,,[84],[1697552083559]
3125,3125,511,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131088,1697552132470,120,,,[59],[1697552131147]
3126,3126,714,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125689,1697552126520,120,,,[15],[1697552125704]
3127,3127,129,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142284,1697552145220,120,,,"[100, 2160, 53]","[1697552142384, 1697552144544, 1697552144597]"
3128,3128,480,53,[],200,llama-13b,64,1,1607.0,1.0,1,A100,1697552127358,1697552128965,120,26.0,1.0,"[95, 1511]","[1697552127453, 1697552128964]"
3129,3129,819,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123848,1697552125686,120,,,[91],[1697552123939]
3130,3130,482,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552126523,1697552128289,120,,,"[28, 1576]","[1697552126551, 1697552128127]"
3131,3131,467,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105070,1697552106519,120,,,[20],[1697552105090]
3132,3132,356,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083906,1697552084997,120,,,[44],[1697552083950]
3133,3133,650,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152624,1697552153791,120,,,[52],[1697552152676]
3134,3134,599,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125690,1697552127341,120,,,[43],[1697552125733]
3135,3135,785,35,[],200,llama-13b,64,1,2188.0,1.0,1,A100,1697552101113,1697552103301,120,10.0,1.0,"[131, 2057]","[1697552101244, 1697552103301]"
3136,3136,347,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552144601,1697552147358,120,,,"[14, 2056]","[1697552144615, 1697552146671]"
3137,3137,561,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103304,1697552105087,120,,,"[21, 1182]","[1697552103325, 1697552104507]"
3138,3138,173,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132472,1697552133253,120,,,[25],[1697552132497]
3139,3139,117,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147364,1697552148669,120,,,[118],[1697552147482]
3140,3140,425,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153793,1697552154923,120,,,[29],[1697552153822]
3141,3141,78,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154926,1697552156085,120,,,[19],[1697552154945]
3142,3142,872,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133258,1697552134789,120,,,[105],[1697552133363]
3143,3143,214,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105092,1697552106518,120,,,"[62, 1336]","[1697552105154, 1697552106490]"
3144,3144,253,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552127358,1697552135648,120,,,"[92, 1515, 682, 734, 740, 691, 696, 779, 812, 724]","[1697552127450, 1697552128965, 1697552129647, 1697552130381, 1697552131121, 1697552131812, 1697552132508, 1697552133287, 1697552134099, 1697552134823]"
3145,3145,706,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148674,1697552150143,120,,,"[38, 1410]","[1697552148712, 1697552150122]"
3146,3146,784,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156088,1697552157800,120,,,[24],[1697552156112]
3147,3147,104,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118451,1697552119186,120,,,[20],[1697552118471]
3148,3148,439,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157803,1697552158464,120,,,[15],[1697552157818]
3149,3149,526,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134791,1697552135649,120,,,"[25, 758]","[1697552134816, 1697552135574]"
3150,3150,521,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552124746,1697552126521,120,,,[24],[1697552124770]
3151,3151,303,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135654,1697552137934,120,,,"[106, 2004]","[1697552135760, 1697552137764]"
3152,3152,209,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158467,1697552159783,120,,,[54],[1697552158521]
3153,3153,572,59,[],200,llama-13b,64,1,718.0,1.0,1,A100,1697552135577,1697552136295,120,16.0,1.0,"[26, 692]","[1697552135603, 1697552136295]"
3154,3154,114,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101113,1697552103818,120,,,"[126, 2061]","[1697552101239, 1697552103300]"
3155,3155,884,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137941,1697552139268,120,,,"[30, 1196]","[1697552137971, 1697552139167]"
3156,3156,766,77,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159787,1697552161160,120,,,[71],[1697552159858]
3157,3157,175,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552126523,1697552128289,120,,,[20],[1697552126543]
3158,3158,534,78,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161165,1697552162485,120,,,[22],[1697552161187]
3159,3159,705,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103824,1697552105087,120,,,"[39, 1204]","[1697552103863, 1697552105067]"
3160,3160,195,79,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162489,1697552163833,120,,,[48],[1697552162537]
3161,3161,406,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096707,1697552098826,120,,,"[15, 1507]","[1697552096722, 1697552098229]"
3162,3162,474,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105092,1697552106518,120,,,[68],[1697552105160]
3163,3163,661,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139272,1697552142270,120,,,"[39, 2433]","[1697552139311, 1697552141744]"
3164,3164,273,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076904,1697552078119,120,,,[131],[1697552077035]
3165,3165,894,80,[],200,llama-13b,64,1,1564.0,1.0,1,A100,1697552163837,1697552165401,120,14.0,1.0,"[61, 1503]","[1697552163898, 1697552165401]"
3166,3166,921,47,[],200,llama-13b,64,1,1496.0,1.0,1,A100,1697552118454,1697552119950,120,31.0,1.0,"[100, 1395]","[1697552118554, 1697552119949]"
3167,3167,638,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099715,1697552102447,120,,,"[123, 1914]","[1697552099838, 1697552101752]"
3168,3168,395,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105090,1697552106517,120,,,"[20, 1379]","[1697552105110, 1697552106489]"
3169,3169,298,37,[],200,llama-13b,64,1,1244.0,1.0,1,A100,1697552102452,1697552103696,120,17.0,1.0,"[48, 1196]","[1697552102500, 1697552103696]"
3170,3170,570,48,[],200,llama-13b,64,1,727.0,1.0,1,A100,1697552119954,1697552120681,120,18.0,1.0,"[23, 704]","[1697552119977, 1697552120681]"
3171,3171,317,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142276,1697552143538,120,,,"[12, 1231]","[1697552142288, 1697552143519]"
3172,3172,56,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098829,1697552101106,120,,,"[23, 1678, 51]","[1697552098852, 1697552100530, 1697552100581]"
3173,3173,89,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143541,1697552145220,120,,,"[27, 1623]","[1697552143568, 1697552145191]"
3174,3174,68,38,[],200,llama-13b,64,1,808.0,1.0,1,A100,1697552103699,1697552104507,120,12.0,1.0,"[14, 794]","[1697552103713, 1697552104507]"
3175,3175,733,33,[],200,llama-13b,64,1,2189.0,1.0,1,A100,1697552101112,1697552103301,120,31.0,1.0,"[64, 2124]","[1697552101176, 1697552103300]"
3176,3176,743,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552104510,1697552106518,120,,,"[25, 1368]","[1697552104535, 1697552105903]"
3177,3177,318,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120683,1697552122073,120,,,[6],[1697552120689]
3178,3178,195,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120137,1697552121356,120,,,[120],[1697552120257]
3179,3179,75,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137767,1697552139268,120,,,"[6, 840]","[1697552137773, 1697552138613]"
3180,3180,903,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122077,1697552123844,120,,,[43],[1697552122120]
3181,3181,384,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103304,1697552105087,120,,,"[18, 1185]","[1697552103322, 1697552104507]"
3182,3182,275,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109323,1697552110462,120,,,[10],[1697552109333]
3183,3183,673,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123847,1697552125686,120,,,[29],[1697552123876]
3184,3184,859,38,[],200,llama-13b,64,1,1348.0,1.0,1,A100,1697552110468,1697552111816,120,23.0,1.0,"[117, 1231]","[1697552110585, 1697552111816]"
3185,3185,766,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145227,1697552146632,120,,,[123],[1697552145350]
3186,3186,333,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125689,1697552127341,120,,,[34],[1697552125723]
3187,3187,161,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105089,1697552106517,120,,,[26],[1697552105115]
3188,3188,102,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552127352,1697552128290,120,,,"[21, 755]","[1697552127373, 1697552128128]"
3189,3189,607,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111819,1697552112678,120,,,[24],[1697552111843]
3190,3190,271,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552119189,1697552128290,120,,,"[64, 1428, 711, 717, 861, 915, 894, 941, 834, 820]","[1697552119253, 1697552120681, 1697552121392, 1697552122109, 1697552122970, 1697552123885, 1697552124779, 1697552125720, 1697552126554, 1697552127374]"
3191,3191,288,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096120,1697552097350,120,,,[54],[1697552096174]
3192,3192,866,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097354,1697552098826,120,,,[40],[1697552097394]
3193,3193,691,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128295,1697552129609,120,,,[43],[1697552128338]
3194,3194,463,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129613,1697552131084,120,,,[58],[1697552129671]
3195,3195,420,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146641,1697552150143,120,,,"[111, 1221, 736, 685]","[1697552146752, 1697552147973, 1697552148709, 1697552149394]"
3196,3196,125,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131095,1697552133251,120,,,[69],[1697552131164]
3197,3197,825,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133255,1697552134788,120,,,[35],[1697552133290]
3198,3198,196,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150148,1697552152619,120,,,[118],[1697552150266]
3199,3199,642,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098832,1697552101106,120,,,"[137, 1562, 51]","[1697552098969, 1697552100531, 1697552100582]"
3200,3200,475,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109335,1697552110461,120,,,[114],[1697552109449]
3201,3201,246,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110465,1697552111926,120,,,"[16, 1334]","[1697552110481, 1697552111815]"
3202,3202,260,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112684,1697552114139,120,,,[62],[1697552112746]
3203,3203,479,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134791,1697552135649,120,,,"[22, 761]","[1697552134813, 1697552135574]"
3204,3204,554,61,[],200,llama-13b,64,1,1596.0,1.0,1,A100,1697552137017,1697552138613,120,26.0,1.0,"[53, 1543]","[1697552137070, 1697552138613]"
3205,3205,178,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121363,1697552122932,120,,,[96],[1697552121459]
3206,3206,756,49,[],200,llama-13b,64,1,1603.0,1.0,1,A100,1697552126525,1697552128128,120,19.0,1.0,"[61, 1542]","[1697552126586, 1697552128128]"
3207,3207,327,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552138616,1697552140775,120,,,"[17, 1481, 53, 49, 47]","[1697552138633, 1697552140114, 1697552140167, 1697552140216, 1697552140263]"
3208,3208,226,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135654,1697552137935,120,,,"[126, 1984]","[1697552135780, 1697552137764]"
3209,3209,295,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101110,1697552102446,120,,,"[22, 1215]","[1697552101132, 1697552102347]"
3210,3210,829,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111931,1697552113423,120,,,[115],[1697552112046]
3211,3211,417,50,[],200,llama-13b,64,1,833.0,1.0,1,A100,1697552128132,1697552128965,120,17.0,1.0,"[34, 799]","[1697552128166, 1697552128965]"
3212,3212,42,38,[],200,llama-13b,64,1,2052.0,1.0,1,A100,1697552102455,1697552104507,120,10.0,1.0,"[104, 1948]","[1697552102559, 1697552104507]"
3213,3213,113,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128293,1697552129609,120,,,[35],[1697552128328]
3214,3214,627,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552104510,1697552106517,120,,,[10],[1697552104520]
3215,3215,917,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140778,1697552142272,120,,,"[25, 1336]","[1697552140803, 1697552142139]"
3216,3216,256,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128968,1697552130344,120,,,[22],[1697552128990]
3217,3217,396,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106522,1697552107868,120,,,"[41, 1190]","[1697552106563, 1697552107753]"
3218,3218,812,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129613,1697552131085,120,,,[68],[1697552129681]
3219,3219,57,41,[],200,llama-13b,64,1,1329.0,1.0,1,A100,1697552107876,1697552109205,120,13.0,1.0,"[90, 1239]","[1697552107966, 1697552109205]"
3220,3220,838,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.11 GiB is allocated by PyTorch, and 7.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130347,1697552131776,120,,,[34],[1697552130381]
3221,3221,587,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131782,1697552133253,120,,,[40],[1697552131822]
3222,3222,685,64,[],200,llama-13b,64,1,2320.0,1.0,1,A100,1697552142277,1697552144597,120,364.0,2.0,"[63, 2203, 54]","[1697552142340, 1697552144543, 1697552144597]"
3223,3223,361,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133254,1697552134060,120,,,[6],[1697552133260]
3224,3224,758,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109208,1697552110135,120,,,[24],[1697552109232]
3225,3225,15,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134063,1697552135648,120,,,"[72, 1438]","[1697552134135, 1697552135573]"
3226,3226,98,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085005,1697552086534,120,,,[130],[1697552085135]
3227,3227,419,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110138,1697552111925,120,,,"[29, 946]","[1697552110167, 1697552111113]"
3228,3228,188,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111930,1697552113424,120,,,[42],[1697552111972]
3229,3229,721,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135651,1697552136976,120,,,[28],[1697552135679]
3230,3230,464,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131091,1697552132470,120,,,[58],[1697552131149]
3231,3231,241,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132475,1697552134060,120,,,[79],[1697552132554]
3232,3232,681,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086543,1697552088518,120,,,[135],[1697552086678]
3233,3233,374,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136979,1697552139266,120,,,"[39, 1594]","[1697552137018, 1697552138612]"
3234,3234,458,31,[],200,llama-13b,64,1,1272.0,1.0,1,A100,1697552088523,1697552089795,120,11.0,1.0,"[62, 1210]","[1697552088585, 1697552089795]"
3235,3235,149,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139271,1697552140771,120,,,"[31, 1442]","[1697552139302, 1697552140744]"
3236,3236,823,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134063,1697552135648,120,,,"[44, 1466]","[1697552134107, 1697552135573]"
3237,3237,113,32,[],200,llama-13b,64,1,1396.0,1.0,1,A100,1697552089799,1697552091195,120,13.0,1.0,"[19, 1377]","[1697552089818, 1697552091195]"
3238,3238,640,27,[],200,llama-13b,64,1,1273.0,1.0,1,A100,1697552088522,1697552089795,120,15.0,1.0,"[53, 1220]","[1697552088575, 1697552089795]"
3239,3239,294,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089798,1697552091870,120,,,[10],[1697552089808]
3240,3240,599,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135652,1697552136976,120,,,[93],[1697552135745]
3241,3241,731,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140775,1697552142271,120,,,"[9, 1354]","[1697552140784, 1697552142138]"
3242,3242,252,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136980,1697552139267,120,,,"[48, 1585]","[1697552137028, 1697552138613]"
3243,3243,812,33,[],200,llama-13b,64,1,1539.0,1.0,1,A100,1697552091199,1697552092738,120,16.0,1.0,"[14, 1525]","[1697552091213, 1697552092738]"
3244,3244,478,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150149,1697552152619,120,,,[119],[1697552150268]
3245,3245,509,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142276,1697552143538,120,,,"[22, 1221]","[1697552142298, 1697552143519]"
3246,3246,65,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091872,1697552093265,120,,,"[106, 1185]","[1697552091978, 1697552093163]"
3247,3247,195,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145959,1697552147357,120,,,"[29, 1351]","[1697552145988, 1697552147339]"
3248,3248,51,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078122,1697552079384,120,,,"[115, 1012]","[1697552078237, 1697552079249]"
3249,3249,396,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106523,1697552109319,120,,,"[123, 2044]","[1697552106646, 1697552108690]"
3250,3250,472,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552092741,1697552093476,120,,,[6],[1697552092747]
3251,3251,172,39,[],200,llama-13b,64,1,1232.0,1.0,1,A100,1697552106522,1697552107754,120,19.0,1.0,"[21, 1210]","[1697552106543, 1697552107753]"
3252,3252,655,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139272,1697552142271,120,,,"[45, 2427]","[1697552139317, 1697552141744]"
3253,3253,160,64,[],200,llama-13b,64,1,1650.0,1.0,1,A100,1697552143541,1697552145191,120,13.0,1.0,"[17, 1633]","[1697552143558, 1697552145191]"
3254,3254,210,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128295,1697552129609,120,,,[63],[1697552128358]
3255,3255,240,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093483,1697552096114,120,,,"[73, 1880]","[1697552093556, 1697552095436]"
3256,3256,432,58,[],200,llama-13b,64,1,1243.0,1.0,1,A100,1697552142277,1697552143520,120,13.0,1.0,"[82, 1160]","[1697552142359, 1697552143519]"
3257,3257,886,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129612,1697552131084,120,,,[61],[1697552129673]
3258,3258,859,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145195,1697552146630,120,,,[24],[1697552145219]
3259,3259,833,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096119,1697552097348,120,,,"[20, 1111]","[1697552096139, 1697552097250]"
3260,3260,173,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109333,1697552110463,120,,,[6],[1697552109339]
3261,3261,754,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107757,1697552109319,120,,,[26],[1697552107783]
3262,3262,599,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102451,1697552103819,120,,,"[46, 1199]","[1697552102497, 1697552103696]"
3263,3263,86,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143522,1697552145219,120,,,"[16, 1653]","[1697552143538, 1697552145191]"
3264,3264,786,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145224,1697552146631,120,,,[22],[1697552145246]
3265,3265,848,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135654,1697552136977,120,,,[111],[1697552135765]
3266,3266,689,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116448,1697552118448,120,,,[190],[1697552116638]
3267,3267,340,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118452,1697552120129,120,,,"[54, 1443]","[1697552118506, 1697552119949]"
3268,3268,833,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115120,1697552120129,120,,,"[126, 1608, 802, 826, 738]","[1697552115246, 1697552116854, 1697552117656, 1697552118482, 1697552119220]"
3269,3269,494,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093479,1697552094765,120,,,"[12, 1256]","[1697552093491, 1697552094747]"
3270,3270,598,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120134,1697552121355,120,,,[34],[1697552120168]
3271,3271,490,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146636,1697552150144,120,,,"[44, 2029, 685]","[1697552146680, 1697552148709, 1697552149394]"
3272,3272,264,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094773,1697552096115,120,,,"[86, 1131]","[1697552094859, 1697552095990]"
3273,3273,259,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121358,1697552122073,120,,,[15],[1697552121373]
3274,3274,854,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128295,1697552129609,120,,,[53],[1697552128348]
3275,3275,258,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150149,1697552152619,120,,,[127],[1697552150276]
3276,3276,848,34,[],200,llama-13b,64,1,1131.0,1.0,1,A100,1697552096119,1697552097250,120,47.0,1.0,"[10, 1121]","[1697552096129, 1697552097250]"
3277,3277,117,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120133,1697552121355,120,,,[30],[1697552120163]
3278,3278,848,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152625,1697552154367,120,,,[119],[1697552152744]
3279,3279,596,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097253,1697552098826,120,,,"[15, 960]","[1697552097268, 1697552098228]"
3280,3280,625,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129611,1697552130344,120,,,[30],[1697552129641]
3281,3281,617,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154370,1697552154924,120,,,[11],[1697552154381]
3282,3282,285,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.11 GiB is allocated by PyTorch, and 7.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130348,1697552131775,120,,,[53],[1697552130401]
3283,3283,273,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154927,1697552156086,120,,,[38],[1697552154965]
3284,3284,53,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131777,1697552133252,120,,,[10],[1697552131787]
3285,3285,53,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156089,1697552157801,120,,,[63],[1697552156152]
3286,3286,36,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552114145,1697552116440,120,,,"[40, 1571]","[1697552114185, 1697552115756]"
3287,3287,365,36,[],200,llama-13b,64,1,1700.0,1.0,1,A100,1697552098831,1697552100531,120,23.0,1.0,"[132, 1568]","[1697552098963, 1697552100531]"
3288,3288,636,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157805,1697552159106,120,,,[53],[1697552157858]
3289,3289,451,58,[],200,llama-13b,64,1,1243.0,1.0,1,A100,1697552142276,1697552143519,120,286.0,1.0,"[26, 1217]","[1697552142302, 1697552143519]"
3290,3290,614,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116448,1697552117623,120,,,[133],[1697552116581]
3291,3291,730,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133256,1697552134788,120,,,[52],[1697552133308]
3292,3292,411,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159110,1697552160461,120,,,[54],[1697552159164]
3293,3293,601,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113431,1697552115114,120,,,[117],[1697552113548]
3294,3294,27,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552100534,1697552102447,120,,,"[25, 1193]","[1697552100559, 1697552101752]"
3295,3295,254,47,[],200,llama-13b,64,1,1187.0,1.0,1,A100,1697552115121,1697552116308,120,58.0,1.0,"[40, 1147]","[1697552115161, 1697552116308]"
3296,3296,236,42,[],200,llama-13b,64,1,2166.0,1.0,1,A100,1697552106525,1697552108691,120,8.0,1.0,"[151, 2014]","[1697552106676, 1697552108690]"
3297,3297,726,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102451,1697552103819,120,,,"[39, 1205]","[1697552102490, 1697552103695]"
3298,3298,387,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103823,1697552105088,120,,,"[17, 1227]","[1697552103840, 1697552105067]"
3299,3299,65,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160464,1697552161813,120,,,[34],[1697552160498]
3300,3300,741,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161814,1697552163147,120,,,[14],[1697552161828]
3301,3301,512,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163150,1697552164529,120,,,[37],[1697552163187]
3302,3302,826,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552108693,1697552110135,120,,,[16],[1697552108709]
3303,3303,166,77,[],200,llama-13b,64,1,1430.0,1.0,1,A100,1697552164532,1697552165962,120,14.0,1.0,"[58, 1372]","[1697552164590, 1697552165962]"
3304,3304,159,40,[],200,llama-13b,64,1,1396.0,1.0,1,A100,1697552105094,1697552106490,120,31.0,1.0,"[153, 1243]","[1697552105247, 1697552106490]"
3305,3305,741,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106493,1697552107867,120,,,"[30, 1230]","[1697552106523, 1697552107753]"
3306,3306,391,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117631,1697552119186,120,,,[65],[1697552117696]
3307,3307,518,42,[],200,llama-13b,64,1,1333.0,1.0,1,A100,1697552107871,1697552109204,120,23.0,1.0,"[8, 1325]","[1697552107879, 1697552109204]"
3308,3308,868,78,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165965,1697552167167,120,,,[33],[1697552165998]
3309,3309,169,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109208,1697552110135,120,,,[16],[1697552109224]
3310,3310,829,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145227,1697552146632,120,,,[116],[1697552145343]
3311,3311,597,44,[],200,llama-13b,64,1,974.0,1.0,1,A100,1697552110139,1697552111113,120,39.0,1.0,"[43, 931]","[1697552110182, 1697552111113]"
3312,3312,522,79,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167173,1697552168555,120,,,[65],[1697552167238]
3313,3313,483,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146640,1697552150142,120,,,"[102, 1231, 736, 685]","[1697552146742, 1697552147973, 1697552148709, 1697552149394]"
3314,3314,346,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552144599,1697552147357,120,,,"[6, 1349, 717]","[1697552144605, 1697552145954, 1697552146671]"
3315,3315,321,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097353,1697552099703,120,,,[101],[1697552097454]
3316,3316,773,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113431,1697552115115,120,,,[127],[1697552113558]
3317,3317,507,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128970,1697552130343,120,,,[45],[1697552129015]
3318,3318,915,38,[],200,llama-13b,64,1,2168.0,1.0,1,A100,1697552106522,1697552108690,120,182.0,1.0,"[51, 2117]","[1697552106573, 1697552108690]"
3319,3319,881,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128292,1697552129608,120,,,[16],[1697552128308]
3320,3320,255,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130349,1697552132470,120,,,[90],[1697552130439]
3321,3321,569,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552108693,1697552110135,120,,,[16],[1697552108709]
3322,3322,837,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132474,1697552134059,120,,,[62],[1697552132536]
3323,3323,94,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099707,1697552101108,120,,,"[50, 1332]","[1697552099757, 1697552101089]"
3324,3324,535,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129610,1697552130344,120,,,[23],[1697552129633]
3325,3325,131,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152625,1697552154368,120,,,[121],[1697552152746]
3326,3326,612,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134064,1697552135649,120,,,[75],[1697552134139]
3327,3327,837,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154371,1697552155496,120,,,[20],[1697552154391]
3328,3328,266,53,[],200,llama-13b,64,1,2111.0,1.0,1,A100,1697552135654,1697552137765,120,9.0,1.0,"[111, 2000]","[1697552135765, 1697552137765]"
3329,3329,679,35,[],200,llama-13b,64,1,2188.0,1.0,1,A100,1697552101113,1697552103301,120,15.0,1.0,"[136, 2052]","[1697552101249, 1697552103301]"
3330,3330,455,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103304,1697552105087,120,,,"[31, 1171]","[1697552103335, 1697552104506]"
3331,3331,42,54,[],200,llama-13b,64,1,845.0,1.0,1,A100,1697552137768,1697552138613,120,10.0,1.0,"[6, 839]","[1697552137774, 1697552138613]"
3332,3332,340,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110138,1697552111924,120,,,"[10, 965]","[1697552110148, 1697552111113]"
3333,3333,627,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552138616,1697552140776,120,,,"[11, 1539, 50, 47]","[1697552138627, 1697552140166, 1697552140216, 1697552140263]"
3334,3334,491,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552155500,1697552156085,120,,,[30],[1697552155530]
3335,3335,1,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111930,1697552113424,120,,,[37],[1697552111967]
3336,3336,109,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105092,1697552106519,120,,,"[144, 1254]","[1697552105236, 1697552106490]"
3337,3337,254,61,[],200,llama-13b,64,1,1446.0,1.0,1,A100,1697552148677,1697552150123,120,58.0,1.0,"[175, 1271]","[1697552148852, 1697552150123]"
3338,3338,699,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113430,1697552115113,120,,,[34],[1697552113464]
3339,3339,306,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130347,1697552132469,120,,,[59],[1697552130406]
3340,3340,886,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135651,1697552136976,120,,,[21],[1697552135672]
3341,3341,448,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115119,1697552116440,120,,,"[54, 1135]","[1697552115173, 1697552116308]"
3342,3342,541,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136979,1697552137937,120,,,"[34, 752]","[1697552137013, 1697552137765]"
3343,3343,2,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150126,1697552151582,120,,,"[16, 1291]","[1697552150142, 1697552151433]"
3344,3344,133,37,[],200,llama-13b,64,1,2167.0,1.0,1,A100,1697552106523,1697552108690,120,15.0,1.0,"[120, 2047]","[1697552106643, 1697552108690]"
3345,3345,100,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116445,1697552117621,120,,,[25],[1697552116470]
3346,3346,276,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121363,1697552122933,120,,,[100],[1697552121463]
3347,3347,317,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137942,1697552140772,120,,,"[132, 2039, 54, 49, 47]","[1697552138074, 1697552140113, 1697552140167, 1697552140216, 1697552140263]"
3348,3348,889,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132471,1697552133252,120,,,[6],[1697552132477]
3349,3349,808,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117628,1697552119185,120,,,[33],[1697552117661]
3350,3350,816,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128292,1697552129608,120,,,[12],[1697552128304]
3351,3351,831,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552108694,1697552110135,120,,,[25],[1697552108719]
3352,3352,475,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129611,1697552130344,120,,,[20],[1697552129631]
3353,3353,462,46,[],200,llama-13b,64,1,762.0,1.0,1,A100,1697552119188,1697552119950,120,52.0,1.0,"[10, 752]","[1697552119198, 1697552119950]"
3354,3354,252,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.11 GiB is allocated by PyTorch, and 7.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130347,1697552131776,120,,,[49],[1697552130396]
3355,3355,834,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131779,1697552133252,120,,,[28],[1697552131807]
3356,3356,579,39,[],200,llama-13b,64,1,973.0,1.0,1,A100,1697552110140,1697552111113,120,19.0,1.0,"[48, 925]","[1697552110188, 1697552111113]"
3357,3357,665,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133255,1697552134060,120,,,[25],[1697552133280]
3358,3358,611,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133256,1697552134789,120,,,[82],[1697552133338]
3359,3359,49,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129610,1697552130344,120,,,[18],[1697552129628]
3360,3360,320,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134063,1697552135647,120,,,[39],[1697552134102]
3361,3361,746,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.11 GiB is allocated by PyTorch, and 7.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130348,1697552131776,120,,,[53],[1697552130401]
3362,3362,234,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111115,1697552112675,120,,,[14],[1697552111129]
3363,3363,409,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552127359,1697552135648,120,,,"[81, 1525, 682, 734, 740, 691, 695, 780, 812, 724]","[1697552127440, 1697552128965, 1697552129647, 1697552130381, 1697552131121, 1697552131812, 1697552132507, 1697552133287, 1697552134099, 1697552134823]"
3364,3364,776,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121364,1697552122932,120,,,[96],[1697552121460]
3365,3365,540,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131087,1697552132471,120,,,[38],[1697552131125]
3366,3366,494,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131778,1697552133252,120,,,[24],[1697552131802]
3367,3367,90,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135651,1697552136977,120,,,[6],[1697552135657]
3368,3368,761,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110468,1697552111925,120,,,"[91, 1256]","[1697552110559, 1697552111815]"
3369,3369,766,64,[],200,llama-13b,64,1,1633.0,1.0,1,A100,1697552136981,1697552138614,120,11.0,1.0,"[74, 1558]","[1697552137055, 1697552138613]"
3370,3370,531,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111931,1697552113423,120,,,[115],[1697552112046]
3371,3371,191,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113431,1697552115114,120,,,[122],[1697552113553]
3372,3372,231,36,[],200,llama-13b,64,1,2077.0,1.0,1,A100,1697552103826,1697552105903,120,13.0,1.0,"[111, 1966]","[1697552103937, 1697552105903]"
3373,3373,888,45,[],200,llama-13b,64,1,1189.0,1.0,1,A100,1697552115118,1697552116307,120,19.0,1.0,"[20, 1169]","[1697552115138, 1697552116307]"
3374,3374,419,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552138616,1697552140776,120,,,"[16, 1482, 52, 50, 47]","[1697552138632, 1697552140114, 1697552140166, 1697552140216, 1697552140263]"
3375,3375,508,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136981,1697552139268,120,,,"[69, 1563]","[1697552137050, 1697552138613]"
3376,3376,31,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122076,1697552122934,120,,,[19],[1697552122095]
3377,3377,549,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116310,1697552120129,120,,,"[7, 1339, 826, 738]","[1697552116317, 1697552117656, 1697552118482, 1697552119220]"
3378,3378,925,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105907,1697552107868,120,,,"[15, 1374]","[1697552105922, 1697552107296]"
3379,3379,197,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143522,1697552145219,120,,,"[6, 1016, 53]","[1697552143528, 1697552144544, 1697552144597]"
3380,3380,199,66,[],200,llama-13b,64,1,1355.0,1.0,1,A100,1697552140784,1697552142139,120,13.0,1.0,"[156, 1199]","[1697552140940, 1697552142139]"
3381,3381,613,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 458.06 MiB is free. Process 1449637 has 38.94 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122937,1697552124744,120,,,[52],[1697552122989]
3382,3382,586,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107876,1697552109323,120,,,"[80, 1249]","[1697552107956, 1697552109205]"
3383,3383,354,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109335,1697552110462,120,,,[119],[1697552109454]
3384,3384,189,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128969,1697552130343,120,,,[31],[1697552129000]
3385,3385,15,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110467,1697552111924,120,,,"[43, 1305]","[1697552110510, 1697552111815]"
3386,3386,771,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130345,1697552131084,120,,,[6],[1697552130351]
3387,3387,146,70,[],200,llama-13b,64,1,12983.0,1.0,1,A100,1697552151587,1697552164570,120,96.0,20.0,"[58, 1647, 547, 571, 556, 572, 588, 44, 554, 527, 591, 660, 644, 675, 679, 699, 652, 673, 662, 686, 698]","[1697552151645, 1697552153292, 1697552153839, 1697552154410, 1697552154966, 1697552155538, 1697552156126, 1697552156170, 1697552156724, 1697552157251, 1697552157842, 1697552158502, 1697552159146, 1697552159821, 1697552160500, 1697552161199, 1697552161851, 1697552162524, 1697552163186, 1697552163872, 1697552164570]"
3388,3388,847,44,[],200,llama-13b,64,1,973.0,1.0,1,A100,1697552110140,1697552111113,120,10.0,1.0,"[43, 930]","[1697552110183, 1697552111113]"
3389,3389,30,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116311,1697552120128,120,,,"[6, 1339, 826, 738]","[1697552116317, 1697552117656, 1697552118482, 1697552119220]"
3390,3390,511,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552119190,1697552128290,120,,,"[68, 1423, 711, 718, 860, 916, 892, 942, 834, 820]","[1697552119258, 1697552120681, 1697552121392, 1697552122110, 1697552122970, 1697552123886, 1697552124778, 1697552125720, 1697552126554, 1697552127374]"
3391,3391,496,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111116,1697552112678,120,,,[18],[1697552111134]
3392,3392,250,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111118,1697552112678,120,,,[37],[1697552111155]
3393,3393,713,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111930,1697552113424,120,,,[57],[1697552111987]
3394,3394,267,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112686,1697552114140,120,,,[80],[1697552112766]
3395,3395,28,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112682,1697552114140,120,,,[23],[1697552112705]
3396,3396,858,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552114145,1697552116441,120,,,[96],[1697552114241]
3397,3397,805,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552119190,1697552128290,120,,,"[68, 1423, 711, 718, 860, 916, 892, 942, 834, 820]","[1697552119258, 1697552120681, 1697552121392, 1697552122110, 1697552122970, 1697552123886, 1697552124778, 1697552125720, 1697552126554, 1697552127374]"
3398,3398,27,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135652,1697552136976,120,,,[42],[1697552135694]
3399,3399,41,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122077,1697552122932,120,,,[28],[1697552122105]
3400,3400,626,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116448,1697552118448,120,,,[137],[1697552116585]
3401,3401,654,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093267,1697552094765,120,,,"[11, 1089]","[1697552093278, 1697552094367]"
3402,3402,624,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122940,1697552125686,120,,,[98],[1697552123038]
3403,3403,501,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157804,1697552159107,120,,,[32],[1697552157836]
3404,3404,813,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106523,1697552109319,120,,,"[116, 2051]","[1697552106639, 1697552108690]"
3405,3405,424,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094773,1697552096115,120,,,"[111, 1107]","[1697552094884, 1697552095991]"
3406,3406,273,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159111,1697552160461,120,,,[63],[1697552159174]
3407,3407,288,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118453,1697552120129,120,,,[102],[1697552118555]
3408,3408,855,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160463,1697552161812,120,,,[29],[1697552160492]
3409,3409,173,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096119,1697552097350,120,,,"[15, 1116]","[1697552096134, 1697552097250]"
3410,3410,756,33,[],200,llama-13b,64,1,1349.0,1.0,1,A100,1697552097352,1697552098701,120,19.0,1.0,"[7, 1342]","[1697552097359, 1697552098701]"
3411,3411,467,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109334,1697552110462,120,,,[26],[1697552109360]
3412,3412,533,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098704,1697552099702,120,,,[11],[1697552098715]
3413,3413,189,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099704,1697552101106,120,,,"[21, 1364]","[1697552099725, 1697552101089]"
3414,3414,632,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161813,1697552162486,120,,,[6],[1697552161819]
3415,3415,897,57,[],200,llama-13b,64,1,2190.0,1.0,1,A100,1697552140784,1697552142974,120,9.0,1.0,"[161, 2029]","[1697552140945, 1697552142974]"
3416,3416,887,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101110,1697552102446,120,,,"[11, 1225]","[1697552101121, 1697552102346]"
3417,3417,277,57,[],200,llama-13b,64,1,2471.0,1.0,1,A100,1697552139274,1697552141745,120,18.0,1.0,"[96, 2375]","[1697552139370, 1697552141745]"
3418,3418,791,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093480,1697552094765,120,,,[31],[1697552093511]
3419,3419,379,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134792,1697552137937,120,,,"[36, 2185]","[1697552134828, 1697552137013]"
3420,3420,151,58,[],200,llama-13b,64,1,2168.0,1.0,1,A100,1697552137946,1697552140114,120,39.0,1.0,"[140, 2028]","[1697552138086, 1697552140114]"
3421,3421,369,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113431,1697552115114,120,,,[117],[1697552113548]
3422,3422,779,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145224,1697552146635,120,,,[40],[1697552145264]
3423,3423,146,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115119,1697552116440,120,,,"[59, 1129]","[1697552115178, 1697552116307]"
3424,3424,557,61,[],200,llama-13b,64,1,702.0,1.0,1,A100,1697552146637,1697552147339,120,31.0,1.0,"[31, 671]","[1697552146668, 1697552147339]"
3425,3425,215,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147342,1697552148668,120,,,[17],[1697552147359]
3426,3426,69,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135651,1697552136977,120,,,[11],[1697552135662]
3427,3427,914,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148674,1697552150144,120,,,"[84, 1365]","[1697552148758, 1697552150123]"
3428,3428,731,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116447,1697552118447,120,,,[104],[1697552116551]
3429,3429,574,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150148,1697552152618,120,,,[34],[1697552150182]
3430,3430,478,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118450,1697552119185,120,,,[14],[1697552118464]
3431,3431,247,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552119193,1697552128289,120,,,"[85, 1403, 711, 718, 860, 916, 892, 943, 833, 820]","[1697552119278, 1697552120681, 1697552121392, 1697552122110, 1697552122970, 1697552123886, 1697552124778, 1697552125721, 1697552126554, 1697552127374]"
3432,3432,342,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152621,1697552153790,120,,,[11],[1697552152632]
3433,3433,3,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153792,1697552154368,120,,,[6],[1697552153798]
3434,3434,768,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136979,1697552137936,120,,,"[24, 762]","[1697552137003, 1697552137765]"
3435,3435,837,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128295,1697552129609,120,,,[39],[1697552128334]
3436,3436,608,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129611,1697552131084,120,,,[45],[1697552129656]
3437,3437,701,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154373,1697552156084,120,,,[62],[1697552154435]
3438,3438,357,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156088,1697552157801,120,,,[29],[1697552156117]
3439,3439,262,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131088,1697552132470,120,,,[53],[1697552131141]
3440,3440,401,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125689,1697552127341,120,,,[39],[1697552125728]
3441,3441,38,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132473,1697552134060,120,,,[34],[1697552132507]
3442,3442,215,40,[],200,llama-13b,64,1,1348.0,1.0,1,A100,1697552110468,1697552111816,120,12.0,1.0,"[71, 1276]","[1697552110539, 1697552111815]"
3443,3443,56,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552127358,1697552135648,120,,,"[87, 1520, 682, 734, 740, 691, 695, 780, 812, 724]","[1697552127445, 1697552128965, 1697552129647, 1697552130381, 1697552131121, 1697552131812, 1697552132507, 1697552133287, 1697552134099, 1697552134823]"
3444,3444,47,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122936,1697552123845,120,,,[30],[1697552122966]
3445,3445,795,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111820,1697552112680,120,,,[19],[1697552111839]
3446,3446,420,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137942,1697552140772,120,,,"[127, 2044, 54, 49, 47]","[1697552138069, 1697552140113, 1697552140167, 1697552140216, 1697552140263]"
3447,3447,743,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106522,1697552107868,120,,,"[36, 1195]","[1697552106558, 1697552107753]"
3448,3448,326,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109335,1697552110462,120,,,[126],[1697552109461]
3449,3449,515,37,[],200,llama-13b,64,1,1333.0,1.0,1,A100,1697552107872,1697552109205,120,11.0,1.0,"[27, 1305]","[1697552107899, 1697552109204]"
3450,3450,55,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120137,1697552121355,120,,,[119],[1697552120256]
3451,3451,548,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102451,1697552103818,120,,,"[21, 1223]","[1697552102472, 1697552103695]"
3452,3452,74,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110468,1697552111924,120,,,"[67, 1280]","[1697552110535, 1697552111815]"
3453,3453,772,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111930,1697552113423,120,,,[32],[1697552111962]
3454,3454,317,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103823,1697552105087,120,,,"[32, 1212]","[1697552103855, 1697552105067]"
3455,3455,901,39,[],200,llama-13b,64,1,1397.0,1.0,1,A100,1697552105093,1697552106490,120,17.0,1.0,"[152, 1245]","[1697552105245, 1697552106490]"
3456,3456,565,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112686,1697552114140,120,,,[76],[1697552112762]
3457,3457,645,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121358,1697552122933,120,,,[52],[1697552121410]
3458,3458,418,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 458.06 MiB is free. Process 1449637 has 38.94 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122936,1697552124743,120,,,[25],[1697552122961]
3459,3459,73,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552124744,1697552125687,120,,,[7],[1697552124751]
3460,3460,751,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125691,1697552127341,120,,,[65],[1697552125756]
3461,3461,671,40,[],200,llama-13b,64,1,1259.0,1.0,1,A100,1697552106494,1697552107753,120,12.0,1.0,"[39, 1220]","[1697552106533, 1697552107753]"
3462,3462,303,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107756,1697552109322,120,,,"[20, 915]","[1697552107776, 1697552108691]"
3463,3463,225,43,[],200,llama-13b,64,1,1612.0,1.0,1,A100,1697552114144,1697552115756,120,23.0,1.0,"[17, 1595]","[1697552114161, 1697552115756]"
3464,3464,520,55,[],200,llama-13b,64,1,1610.0,1.0,1,A100,1697552127354,1697552128964,120,11.0,1.0,"[25, 1585]","[1697552127379, 1697552128964]"
3465,3465,179,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128967,1697552130344,120,,,[18],[1697552128985]
3466,3466,74,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109335,1697552110460,120,,,[55],[1697552109390]
3467,3467,28,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139271,1697552140772,120,,,"[35, 1438]","[1697552139306, 1697552140744]"
3468,3468,924,44,[],200,llama-13b,64,1,1096.0,1.0,1,A100,1697552115759,1697552116855,120,9.0,1.0,"[16, 1080]","[1697552115775, 1697552116855]"
3469,3469,657,43,[],200,llama-13b,64,1,1351.0,1.0,1,A100,1697552110464,1697552111815,120,10.0,1.0,"[21, 1330]","[1697552110485, 1697552111815]"
3470,3470,877,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.11 GiB is allocated by PyTorch, and 7.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130347,1697552131775,120,,,[29],[1697552130376]
3471,3471,434,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111820,1697552112678,120,,,[33],[1697552111853]
3472,3472,539,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131777,1697552133252,120,,,[15],[1697552131792]
3473,3473,613,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140776,1697552142271,120,,,"[8, 1354]","[1697552140784, 1697552142138]"
3474,3474,306,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133255,1697552134060,120,,,[8],[1697552133263]
3475,3475,699,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121359,1697552122932,120,,,[82],[1697552121441]
3476,3476,230,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150146,1697552151582,120,,,"[16, 1272]","[1697552150162, 1697552151434]"
3477,3477,889,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134063,1697552135648,120,,,"[49, 1461]","[1697552134112, 1697552135573]"
3478,3478,811,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552151585,1697552166084,120,,,"[30, 1678, 546, 571, 555, 573, 588, 44, 553, 529, 590, 660, 644, 675, 678, 700, 652, 673, 662, 685, 699, 982]","[1697552151615, 1697552153293, 1697552153839, 1697552154410, 1697552154965, 1697552155538, 1697552156126, 1697552156170, 1697552156723, 1697552157252, 1697552157842, 1697552158502, 1697552159146, 1697552159821, 1697552160499, 1697552161199, 1697552161851, 1697552162524, 1697552163186, 1697552163871, 1697552164570, 1697552165552]"
3479,3479,471,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122935,1697552123844,120,,,[14],[1697552122949]
3480,3480,666,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135651,1697552136977,120,,,[38],[1697552135689]
3481,3481,386,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142276,1697552143538,120,,,"[32, 1211]","[1697552142308, 1697552143519]"
3482,3482,583,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116860,1697552118449,120,,,[31],[1697552116891]
3483,3483,102,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123847,1697552125686,120,,,[34],[1697552123881]
3484,3484,514,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131087,1697552132471,120,,,[45],[1697552131132]
3485,3485,348,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136301,1697552137935,120,,,"[25, 1439]","[1697552136326, 1697552137765]"
3486,3486,202,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123888,1697552126520,120,,,[75],[1697552123963]
3487,3487,782,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142142,1697552143538,120,,,"[11, 821]","[1697552142153, 1697552142974]"
3488,3488,317,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136980,1697552137937,120,,,"[28, 757]","[1697552137008, 1697552137765]"
3489,3489,564,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132473,1697552134059,120,,,[49],[1697552132522]
3490,3490,784,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552126523,1697552128289,120,,,"[23, 1581]","[1697552126546, 1697552128127]"
3491,3491,65,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137943,1697552140772,120,,,"[133, 2037, 54, 49, 47]","[1697552138076, 1697552140113, 1697552140167, 1697552140216, 1697552140263]"
3492,3492,740,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140117,1697552142272,120,,,"[21, 1606]","[1697552140138, 1697552141744]"
3493,3493,557,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128296,1697552130343,120,,,[67],[1697552128363]
3494,3494,213,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.11 GiB is allocated by PyTorch, and 7.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130346,1697552131775,120,,,[25],[1697552130371]
3495,3495,920,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134825,1697552137936,120,,,"[60, 1410, 718]","[1697552134885, 1697552136295, 1697552137013]"
3496,3496,510,60,[],200,llama-13b,64,1,2319.0,1.0,1,A100,1697552142278,1697552144597,120,79.0,2.0,"[96, 2170, 53]","[1697552142374, 1697552144544, 1697552144597]"
3497,3497,610,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136978,1697552137936,120,,,"[25, 761]","[1697552137003, 1697552137764]"
3498,3498,911,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131778,1697552133252,120,,,[19],[1697552131797]
3499,3499,400,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140781,1697552143537,120,,,"[83, 2109]","[1697552140864, 1697552142973]"
3500,3500,284,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162489,1697552163832,120,,,[57],[1697552162546]
3501,3501,631,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.28 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552079391,1697552080744,120,,,[40],[1697552079431]
3502,3502,56,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163835,1697552166087,120,,,"[24, 1541, 152]","[1697552163859, 1697552165400, 1697552165552]"
3503,3503,785,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147364,1697552148670,120,,,[173],[1697552147537]
3504,3504,552,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148677,1697552150143,120,,,"[159, 1286]","[1697552148836, 1697552150122]"
3505,3505,408,26,[],200,llama-13b,64,1,1251.0,1.0,1,A100,1697552080751,1697552082002,120,16.0,1.0,"[89, 1162]","[1697552080840, 1697552082002]"
3506,3506,171,61,[],200,llama-13b,64,1,1357.0,1.0,1,A100,1697552144599,1697552145956,120,6.0,1.0,"[5, 1351]","[1697552144604, 1697552145955]"
3507,3507,233,47,[],200,llama-13b,64,1,728.0,1.0,1,A100,1697552119953,1697552120681,120,6.0,1.0,"[28, 700]","[1697552119981, 1697552120681]"
3508,3508,553,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122935,1697552123845,120,,,[16],[1697552122951]
3509,3509,207,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123848,1697552125687,120,,,[105],[1697552123953]
3510,3510,65,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082005,1697552083468,120,,,"[31, 802]","[1697552082036, 1697552082838]"
3511,3511,907,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125693,1697552127342,120,,,[83],[1697552125776]
3512,3512,868,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145958,1697552147358,120,,,"[10, 1370]","[1697552145968, 1697552147338]"
3513,3513,824,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120683,1697552122073,120,,,[11],[1697552120694]
3514,3514,766,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083475,1697552083903,120,,,[96],[1697552083571]
3515,3515,426,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 25.99 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083908,1697552084997,120,,,[57],[1697552083965]
3516,3516,655,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552127358,1697552135649,120,,,"[46, 1561, 682, 734, 740, 691, 695, 780, 812, 724]","[1697552127404, 1697552128965, 1697552129647, 1697552130381, 1697552131121, 1697552131812, 1697552132507, 1697552133287, 1697552134099, 1697552134823]"
3517,3517,593,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122075,1697552123843,120,,,[10],[1697552122085]
3518,3518,529,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147361,1697552148669,120,,,[75],[1697552147436]
3519,3519,252,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123848,1697552125686,120,,,[95],[1697552123943]
3520,3520,301,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148674,1697552150142,120,,,"[89, 1360]","[1697552148763, 1697552150123]"
3521,3521,886,65,[],200,llama-13b,64,1,1288.0,1.0,1,A100,1697552150146,1697552151434,120,17.0,1.0,"[16, 1272]","[1697552150162, 1697552151434]"
3522,3522,634,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552151441,1697552152619,120,,,[12],[1697552151453]
3523,3523,612,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120131,1697552121355,120,,,[7],[1697552120138]
3524,3524,287,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152624,1697552154367,120,,,[57],[1697552152681]
3525,3525,21,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125690,1697552127341,120,,,[39],[1697552125729]
3526,3526,62,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154373,1697552156085,120,,,[76],[1697552154449]
3527,3527,384,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121362,1697552122933,120,,,[44],[1697552121406]
3528,3528,196,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085000,1697552086533,120,,,[27],[1697552085027]
3529,3529,44,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 458.06 MiB is free. Process 1449637 has 38.94 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122939,1697552124744,120,,,[106],[1697552123045]
3530,3530,744,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552124745,1697552126521,120,,,[35],[1697552124780]
3531,3531,578,52,[],200,llama-13b,64,1,1607.0,1.0,1,A100,1697552127358,1697552128965,120,31.0,1.0,"[35, 1572]","[1697552127393, 1697552128965]"
3532,3532,5,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112686,1697552114140,120,,,[71],[1697552112757]
3533,3533,495,53,[],200,llama-13b,64,1,1604.0,1.0,1,A100,1697552126524,1697552128128,120,13.0,1.0,"[57, 1547]","[1697552126581, 1697552128128]"
3534,3534,598,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552114145,1697552116440,120,,,"[45, 1565]","[1697552114190, 1697552115755]"
3535,3535,871,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552086537,1697552087781,120,,,[11],[1697552086548]
3536,3536,147,54,[],200,llama-13b,64,1,834.0,1.0,1,A100,1697552128131,1697552128965,120,182.0,1.0,"[25, 809]","[1697552128156, 1697552128965]"
3537,3537,365,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116448,1697552118448,120,,,[132],[1697552116580]
3538,3538,148,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133258,1697552134790,120,,,[95],[1697552133353]
3539,3539,134,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143541,1697552145220,120,,,"[12, 1638]","[1697552143553, 1697552145191]"
3540,3540,524,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552087784,1697552088518,120,,,[12],[1697552087796]
3541,3541,47,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552119189,1697552120129,120,,,"[29, 731]","[1697552119218, 1697552119949]"
3542,3542,777,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152625,1697552154368,120,,,[124],[1697552152749]
3543,3543,611,47,[],200,llama-13b,64,1,1611.0,1.0,1,A100,1697552114145,1697552115756,120,14.0,1.0,"[92, 1519]","[1697552114237, 1697552115756]"
3544,3544,101,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157805,1697552159107,120,,,[56],[1697552157861]
3545,3545,548,81,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165404,1697552167167,120,,,[24],[1697552165428]
3546,3546,325,82,[],200,llama-13b,64,1,2507.0,1.0,1,A100,1697552167175,1697552169682,120,85.0,20.0,"[88, 1783, 46, 39, 37, 37, 38, 40, 37, 40, 37, 40, 35, 28, 27, 27, 25, 26, 26, 26, 25]","[1697552167263, 1697552169046, 1697552169092, 1697552169131, 1697552169168, 1697552169205, 1697552169243, 1697552169283, 1697552169320, 1697552169360, 1697552169397, 1697552169437, 1697552169472, 1697552169500, 1697552169527, 1697552169554, 1697552169579, 1697552169605, 1697552169631, 1697552169657, 1697552169682]"
3547,3547,263,58,[],200,llama-13b,64,1,1502.0,1.0,1,A100,1697552134793,1697552136295,120,15.0,1.0,"[70, 1431]","[1697552134863, 1697552136294]"
3548,3548,684,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159112,1697552160461,120,,,[72],[1697552159184]
3549,3549,358,55,[],200,llama-13b,64,1,2275.0,1.0,1,A100,1697552137941,1697552140216,120,216.0,3.0,"[118, 2054, 54, 49]","[1697552138059, 1697552140113, 1697552140167, 1697552140216]"
3550,3550,311,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132475,1697552134060,120,,,[73],[1697552132548]
3551,3551,40,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136300,1697552137935,120,,,"[21, 1444]","[1697552136321, 1697552137765]"
3552,3552,130,56,[],200,llama-13b,64,1,1527.0,1.0,1,A100,1697552140218,1697552141745,120,14.0,1.0,"[7, 1519]","[1697552140225, 1697552141744]"
3553,3553,922,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137942,1697552140772,120,,,"[114, 2057, 53, 49, 48]","[1697552138056, 1697552140113, 1697552140166, 1697552140215, 1697552140263]"
3554,3554,901,57,[],200,llama-13b,64,1,1509.0,1.0,1,A100,1697552134065,1697552135574,120,17.0,1.0,"[87, 1422]","[1697552134152, 1697552135574]"
3555,3555,460,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160463,1697552161812,120,,,[45],[1697552160508]
3556,3556,671,58,[],200,llama-13b,64,1,718.0,1.0,1,A100,1697552135577,1697552136295,120,12.0,1.0,"[21, 697]","[1697552135598, 1697552136295]"
3557,3557,289,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139272,1697552142270,120,,,"[40, 2432]","[1697552139312, 1697552141744]"
3558,3558,176,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109207,1697552110135,120,,,[7],[1697552109214]
3559,3559,335,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136307,1697552137935,120,,,"[23, 1435]","[1697552136330, 1697552137765]"
3560,3560,60,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142276,1697552143538,120,,,[41],[1697552142317]
3561,3561,622,60,[],200,llama-13b,64,1,2168.0,1.0,1,A100,1697552137946,1697552140114,120,20.0,1.0,"[196, 1972]","[1697552138142, 1697552140114]"
3562,3562,112,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161815,1697552163147,120,,,[29],[1697552161844]
3563,3563,390,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140117,1697552142272,120,,,"[11, 1617]","[1697552140128, 1697552141745]"
3564,3564,642,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143544,1697552147356,120,,,"[123, 2288, 716]","[1697552143667, 1697552145955, 1697552146671]"
3565,3565,350,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128969,1697552130343,120,,,[36],[1697552129005]
3566,3566,633,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123848,1697552125686,120,,,[101],[1697552123949]
3567,3567,403,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125688,1697552126520,120,,,[6],[1697552125694]
3568,3568,63,52,[],200,llama-13b,64,1,1604.0,1.0,1,A100,1697552126524,1697552128128,120,39.0,1.0,"[44, 1560]","[1697552126568, 1697552128128]"
3569,3569,3,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.11 GiB is allocated by PyTorch, and 7.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130348,1697552131776,120,,,[48],[1697552130396]
3570,3570,534,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146638,1697552150144,120,,,"[54, 1281, 735, 686]","[1697552146692, 1697552147973, 1697552148708, 1697552149394]"
3571,3571,760,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128132,1697552135649,120,,,"[24, 809, 682, 734, 741, 691, 695, 779, 812, 725]","[1697552128156, 1697552128965, 1697552129647, 1697552130381, 1697552131122, 1697552131813, 1697552132508, 1697552133287, 1697552134099, 1697552134824]"
3572,3572,877,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110139,1697552111925,120,,,"[38, 936]","[1697552110177, 1697552111113]"
3573,3573,709,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131785,1697552133252,120,,,[37],[1697552131822]
3574,3574,537,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111929,1697552113425,120,,,[8],[1697552111937]
3575,3575,361,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133254,1697552134060,120,,,[16],[1697552133270]
3576,3576,739,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122935,1697552123844,120,,,[6],[1697552122941]
3577,3577,138,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134062,1697552134789,120,,,[18],[1697552134080]
3578,3578,26,44,[],200,llama-13b,64,1,1496.0,1.0,1,A100,1697552118453,1697552119949,120,18.0,1.0,"[57, 1439]","[1697552118510, 1697552119949]"
3579,3579,725,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552119952,1697552128289,120,,,"[24, 705, 711, 718, 860, 916, 893, 942, 833, 820]","[1697552119976, 1697552120681, 1697552121392, 1697552122110, 1697552122970, 1697552123886, 1697552124779, 1697552125721, 1697552126554, 1697552127374]"
3580,3580,801,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125689,1697552126521,120,,,[25],[1697552125714]
3581,3581,390,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552124747,1697552126521,120,,,[38],[1697552124785]
3582,3582,464,46,[],200,llama-13b,64,1,1603.0,1.0,1,A100,1697552126525,1697552128128,120,12.0,1.0,"[52, 1551]","[1697552126577, 1697552128128]"
3583,3583,41,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552126524,1697552127341,120,,,[29],[1697552126553]
3584,3584,848,57,[],200,llama-13b,64,1,1501.0,1.0,1,A100,1697552134794,1697552136295,120,47.0,1.0,"[84, 1416]","[1697552134878, 1697552136294]"
3585,3585,284,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132474,1697552134060,120,,,[43],[1697552132517]
3586,3586,389,48,[],200,llama-13b,64,1,1096.0,1.0,1,A100,1697552115759,1697552116855,120,8.0,1.0,"[11, 1085]","[1697552115770, 1697552116855]"
3587,3587,465,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128291,1697552129608,120,,,[7],[1697552128298]
3588,3588,509,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136307,1697552137935,120,,,"[24, 1434]","[1697552136331, 1697552137765]"
3589,3589,319,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120137,1697552121355,120,,,[110],[1697552120247]
3590,3590,745,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120134,1697552121356,120,,,[49],[1697552120183]
3591,3591,19,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089324,1697552090605,120,,,"[126, 1133]","[1697552089450, 1697552090583]"
3592,3592,903,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121358,1697552122073,120,,,[33],[1697552121391]
3593,3593,42,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116859,1697552118449,120,,,[14],[1697552116873]
3594,3594,647,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122076,1697552123843,120,,,[24],[1697552122100]
3595,3595,300,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123847,1697552125687,120,,,[44],[1697552123891]
3596,3596,75,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125690,1697552127341,120,,,[28],[1697552125718]
3597,3597,696,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090609,1697552091869,120,,,"[155, 1083]","[1697552090764, 1697552091847]"
3598,3598,234,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129611,1697552130344,120,,,[27],[1697552129638]
3599,3599,823,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.11 GiB is allocated by PyTorch, and 7.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130347,1697552131776,120,,,[44],[1697552130391]
3600,3600,351,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552091872,1697552093475,120,,,[82],[1697552091954]
3601,3601,658,52,[],200,llama-13b,64,1,1610.0,1.0,1,A100,1697552127354,1697552128964,120,11.0,1.0,"[29, 1581]","[1697552127383, 1697552128964]"
3602,3602,125,29,[],200,llama-13b,64,1,1267.0,1.0,1,A100,1697552093480,1697552094747,120,13.0,1.0,"[61, 1206]","[1697552093541, 1697552094747]"
3603,3603,743,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118451,1697552119186,120,,,[20],[1697552118471]
3604,3604,715,30,[],200,llama-13b,64,1,685.0,1.0,1,A100,1697552094751,1697552095436,120,20.0,1.0,"[10, 675]","[1697552094761, 1697552095436]"
3605,3605,482,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552095437,1697552097350,120,,,"[15, 1251]","[1697552095452, 1697552096703]"
3606,3606,595,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131777,1697552133251,120,,,[5],[1697552131782]
3607,3607,143,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097354,1697552098826,120,,,"[81, 1266]","[1697552097435, 1697552098701]"
3608,3608,549,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115120,1697552116439,120,,,[121],[1697552115241]
3609,3609,257,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133256,1697552134060,120,,,[29],[1697552133285]
3610,3610,28,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134065,1697552135648,120,,,"[92, 1417]","[1697552134157, 1697552135574]"
3611,3611,719,52,[],200,llama-13b,64,1,5149.0,1.0,1,A100,1697552127358,1697552132507,120,182.0,6.0,"[40, 2249, 734, 740, 691, 695]","[1697552127398, 1697552129647, 1697552130381, 1697552131121, 1697552131812, 1697552132507]"
3612,3612,202,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116447,1697552117622,120,,,[93],[1697552116540]
3613,3613,434,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128967,1697552130344,120,,,[23],[1697552128990]
3614,3614,375,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132512,1697552134060,120,,,[39],[1697552132551]
3615,3615,879,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117629,1697552119185,120,,,[45],[1697552117674]
3616,3616,90,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130345,1697552131085,120,,,[11],[1697552130356]
3617,3617,788,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131093,1697552132470,120,,,[61],[1697552131154]
3618,3618,490,51,[],200,llama-13b,64,1,4696.0,1.0,1,A100,1697552119190,1697552123886,120,11.0,5.0,"[57, 2145, 718, 860, 915]","[1697552119247, 1697552121392, 1697552122110, 1697552122970, 1697552123885]"
3619,3619,611,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135652,1697552136977,120,,,[30],[1697552135682]
3620,3620,144,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123888,1697552126520,120,,,[70],[1697552123958]
3621,3621,644,49,[],200,llama-13b,64,1,762.0,1.0,1,A100,1697552119187,1697552119949,120,19.0,1.0,"[19, 743]","[1697552119206, 1697552119949]"
3622,3622,358,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136978,1697552139266,120,,,"[40, 1594]","[1697552137018, 1697552138612]"
3623,3623,453,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132472,1697552133253,120,,,[20],[1697552132492]
3624,3624,848,53,[],200,llama-13b,64,1,1605.0,1.0,1,A100,1697552126523,1697552128128,120,47.0,1.0,"[53, 1552]","[1697552126576, 1697552128128]"
3625,3625,218,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134062,1697552134789,120,,,[15],[1697552134077]
3626,3626,11,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139271,1697552140772,120,,,"[15, 1458]","[1697552139286, 1697552140744]"
3627,3627,223,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133258,1697552134788,120,,,[97],[1697552133355]
3628,3628,897,58,[],200,llama-13b,64,1,783.0,1.0,1,A100,1697552134791,1697552135574,120,9.0,1.0,"[28, 755]","[1697552134819, 1697552135574]"
3629,3629,716,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140782,1697552143537,120,,,"[87, 2104]","[1697552140869, 1697552142973]"
3630,3630,551,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135577,1697552137937,120,,,"[6, 712, 718]","[1697552135583, 1697552136295, 1697552137013]"
3631,3631,894,56,[],200,llama-13b,64,1,1502.0,1.0,1,A100,1697552134793,1697552136295,120,14.0,1.0,"[75, 1426]","[1697552134868, 1697552136294]"
3632,3632,550,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136297,1697552137934,120,,,"[8, 1459]","[1697552136305, 1697552137764]"
3633,3633,674,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142979,1697552145221,120,,,"[23, 1541, 54]","[1697552143002, 1697552144543, 1697552144597]"
3634,3634,527,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109334,1697552110461,120,,,[19],[1697552109353]
3635,3635,365,58,[],200,llama-13b,64,1,1651.0,1.0,1,A100,1697552143541,1697552145192,120,23.0,1.0,"[27, 1624]","[1697552143568, 1697552145192]"
3636,3636,187,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110466,1697552111924,120,,,"[39, 1310]","[1697552110505, 1697552111815]"
3637,3637,316,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137941,1697552140771,120,,,"[105, 2067, 53, 49, 48]","[1697552138046, 1697552140113, 1697552140166, 1697552140215, 1697552140263]"
3638,3638,886,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111929,1697552113426,120,,,[13],[1697552111942]
3639,3639,143,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145194,1697552147358,120,,,"[15, 746, 716]","[1697552145209, 1697552145955, 1697552146671]"
3640,3640,542,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113434,1697552115115,120,,,[129],[1697552113563]
3641,3641,726,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147364,1697552148669,120,,,[112],[1697552147476]
3642,3642,310,45,[],200,llama-13b,64,1,1735.0,1.0,1,A100,1697552115120,1697552116855,120,26.0,1.0,"[143, 1591]","[1697552115263, 1697552116854]"
3643,3643,496,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148673,1697552149357,120,,,[24],[1697552148697]
3644,3644,645,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156088,1697552157800,120,,,[39],[1697552156127]
3645,3645,764,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 164.06 MiB is free. Process 1449637 has 39.23 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 7.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552076898,1697552078118,120,,,[29],[1697552076927]
3646,3646,422,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157805,1697552159108,120,,,[51],[1697552157856]
3647,3647,73,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159111,1697552160461,120,,,[72],[1697552159183]
3648,3648,871,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116856,1697552118449,120,,,[7],[1697552116863]
3649,3649,772,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160464,1697552161813,120,,,[58],[1697552160522]
3650,3650,640,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118451,1697552119186,120,,,[10],[1697552118461]
3651,3651,736,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164578,1697552167166,120,,,[91],[1697552164669]
3652,3652,506,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167176,1697552168555,120,,,[97],[1697552167273]
3653,3653,85,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112682,1697552114139,120,,,[18],[1697552112700]
3654,3654,22,62,[],200,llama-13b,64,1,1243.0,1.0,1,A100,1697552142276,1697552143519,120,16.0,1.0,"[11, 1232]","[1697552142287, 1697552143519]"
3655,3655,296,48,[],200,llama-13b,64,1,1492.0,1.0,1,A100,1697552119189,1697552120681,120,6.0,1.0,"[39, 1453]","[1697552119228, 1697552120681]"
3656,3656,720,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143522,1697552145219,120,,,"[11, 1011, 54]","[1697552143533, 1697552144544, 1697552144598]"
3657,3657,553,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143541,1697552145220,120,,,"[22, 1628]","[1697552143563, 1697552145191]"
3658,3658,73,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120684,1697552122073,120,,,[25],[1697552120709]
3659,3659,787,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122972,1697552125686,120,,,[78],[1697552123050]
3660,3660,582,63,[],200,llama-13b,64,1,1706.0,1.0,1,A100,1697552151587,1697552153293,120,19.0,1.0,"[63, 1643]","[1697552151650, 1697552153293]"
3661,3661,61,57,[],200,llama-13b,64,1,1651.0,1.0,1,A100,1697552143541,1697552145192,120,9.0,1.0,"[17, 1633]","[1697552143558, 1697552145191]"
3662,3662,361,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137768,1697552139267,120,,,"[11, 834]","[1697552137779, 1697552138613]"
3663,3663,497,54,[],200,llama-13b,64,1,1516.0,1.0,1,A100,1697552128131,1697552129647,120,67.0,2.0,"[14, 820, 682]","[1697552128145, 1697552128965, 1697552129647]"
3664,3664,660,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133255,1697552134060,120,,,[29],[1697552133284]
3665,3665,328,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137943,1697552140773,120,,,"[141, 2030, 53, 49, 47]","[1697552138084, 1697552140114, 1697552140167, 1697552140216, 1697552140263]"
3666,3666,755,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135651,1697552136977,120,,,[18],[1697552135669]
3667,3667,382,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136982,1697552139268,120,,,"[78, 1553]","[1697552137060, 1697552138613]"
3668,3668,647,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140779,1697552142272,120,,,"[63, 1297]","[1697552140842, 1697552142139]"
3669,3669,151,58,[],200,llama-13b,64,1,1472.0,1.0,1,A100,1697552139273,1697552140745,120,39.0,1.0,"[82, 1390]","[1697552139355, 1697552140745]"
3670,3670,275,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129650,1697552131084,120,,,[41],[1697552129691]
3671,3671,740,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140748,1697552142273,120,,,"[17, 979]","[1697552140765, 1697552141744]"
3672,3672,419,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142277,1697552145220,120,,,"[96, 2171, 53]","[1697552142373, 1697552144544, 1697552144597]"
3673,3673,859,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131092,1697552132470,120,,,[59],[1697552131151]
3674,3674,510,60,[],200,llama-13b,64,1,2320.0,1.0,1,A100,1697552142277,1697552144597,120,79.0,2.0,"[77, 2189, 54]","[1697552142354, 1697552144543, 1697552144597]"
3675,3675,14,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139271,1697552140773,120,,,"[21, 1452]","[1697552139292, 1697552140744]"
3676,3676,912,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140783,1697552143538,120,,,"[99, 2092]","[1697552140882, 1697552142974]"
3677,3677,629,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132473,1697552133253,120,,,[29],[1697552132502]
3678,3678,428,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113429,1697552115112,120,,,[15],[1697552113444]
3679,3679,205,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115119,1697552116439,120,,,"[22, 1166]","[1697552115141, 1697552116307]"
3680,3680,682,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143543,1697552147357,120,,,"[99, 2312, 717]","[1697552143642, 1697552145954, 1697552146671]"
3681,3681,788,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116445,1697552117622,120,,,[26],[1697552116471]
3682,3682,165,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552144600,1697552147357,120,,,"[9, 1345, 717]","[1697552144609, 1697552145954, 1697552146671]"
3683,3683,568,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117628,1697552119185,120,,,[28],[1697552117656]
3684,3684,343,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147360,1697552148668,120,,,[7],[1697552147367]
3685,3685,219,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552119189,1697552128289,120,,,"[46, 1445, 712, 718, 860, 915, 894, 941, 834, 820]","[1697552119235, 1697552120680, 1697552121392, 1697552122110, 1697552122970, 1697552123885, 1697552124779, 1697552125720, 1697552126554, 1697552127374]"
3686,3686,331,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145227,1697552146632,120,,,[121],[1697552145348]
3687,3687,107,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148672,1697552149357,120,,,[21],[1697552148693]
3688,3688,391,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147363,1697552148670,120,,,[93],[1697552147456]
3689,3689,696,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552149358,1697552151582,120,,,"[17, 1574]","[1697552149375, 1697552150949]"
3690,3690,162,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148674,1697552150142,120,,,"[87, 1362]","[1697552148761, 1697552150123]"
3691,3691,103,60,[],200,llama-13b,64,1,1336.0,1.0,1,A100,1697552146637,1697552147973,120,15.0,1.0,"[38, 1297]","[1697552146675, 1697552147972]"
3692,3692,466,66,[],200,llama-13b,64,1,12984.0,1.0,1,A100,1697552151586,1697552164570,120,457.0,20.0,"[34, 1673, 546, 571, 555, 573, 588, 44, 554, 528, 590, 660, 645, 674, 679, 699, 652, 673, 662, 686, 698]","[1697552151620, 1697552153293, 1697552153839, 1697552154410, 1697552154965, 1697552155538, 1697552156126, 1697552156170, 1697552156724, 1697552157252, 1697552157842, 1697552158502, 1697552159147, 1697552159821, 1697552160500, 1697552161199, 1697552161851, 1697552162524, 1697552163186, 1697552163872, 1697552164570]"
3693,3693,751,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150146,1697552151582,120,,,[21],[1697552150167]
3694,3694,693,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147977,1697552149356,120,,,[18],[1697552147995]
3695,3695,463,62,[],200,llama-13b,64,1,1590.0,1.0,1,A100,1697552149360,1697552150950,120,39.0,1.0,"[35, 1555]","[1697552149395, 1697552150950]"
3696,3696,521,64,[],200,llama-13b,64,1,1706.0,1.0,1,A100,1697552151587,1697552153293,120,18.0,1.0,"[63, 1642]","[1697552151650, 1697552153292]"
3697,3697,92,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150952,1697552152619,120,,,[19],[1697552150971]
3698,3698,790,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152625,1697552154368,120,,,[129],[1697552152754]
3699,3699,451,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154371,1697552155496,120,,,[16],[1697552154387]
3700,3700,176,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153295,1697552154368,120,,,[11],[1697552153306]
3701,3701,219,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 6.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552155499,1697552156684,120,,,[15],[1697552155514]
3702,3702,883,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154370,1697552155496,120,,,[12],[1697552154382]
3703,3703,802,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156688,1697552157801,120,,,[38],[1697552156726]
3704,3704,579,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157805,1697552159106,120,,,[58],[1697552157863]
3705,3705,535,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 6.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552155499,1697552156684,120,,,[21],[1697552155520]
3706,3706,232,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159109,1697552160461,120,,,[34],[1697552159143]
3707,3707,313,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156687,1697552157801,120,,,[24],[1697552156711]
3708,3708,559,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552094774,1697552096116,120,,,"[105, 1111]","[1697552094879, 1697552095990]"
3709,3709,720,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134791,1697552135649,120,,,"[19, 764]","[1697552134810, 1697552135574]"
3710,3710,890,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157804,1697552159107,120,,,[44],[1697552157848]
3711,3711,637,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159110,1697552160461,120,,,[34],[1697552159144]
3712,3712,191,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096120,1697552097349,120,,,"[29, 1101]","[1697552096149, 1697552097250]"
3713,3713,492,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135652,1697552136977,120,,,[40],[1697552135692]
3714,3714,872,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134063,1697552135647,120,,,"[38, 1472]","[1697552134101, 1697552135573]"
3715,3715,156,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136981,1697552139268,120,,,"[74, 1558]","[1697552137055, 1697552138613]"
3716,3716,854,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139273,1697552142271,120,,,"[66, 2405]","[1697552139339, 1697552141744]"
3717,3717,233,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 6.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156089,1697552156684,120,,,[48],[1697552156137]
3718,3718,587,65,[],200,llama-13b,64,1,1818.0,1.0,1,A100,1697552166100,1697552167918,120,13.0,1.0,"[73, 1745]","[1697552166173, 1697552167918]"
3719,3719,642,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135652,1697552136976,120,,,[35],[1697552135687]
3720,3720,602,62,[],200,llama-13b,64,1,1242.0,1.0,1,A100,1697552142277,1697552143519,120,15.0,1.0,"[71, 1171]","[1697552142348, 1697552143519]"
3721,3721,302,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136979,1697552139266,120,,,"[44, 1589]","[1697552137023, 1697552138612]"
3722,3722,74,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139271,1697552140773,120,,,"[11, 1462]","[1697552139282, 1697552140744]"
3723,3723,254,63,[],200,llama-13b,64,1,1667.0,1.0,1,A100,1697552143524,1697552145191,120,58.0,1.0,"[25, 1642]","[1697552143549, 1697552145191]"
3724,3724,656,59,[],200,llama-13b,64,1,1359.0,1.0,1,A100,1697552140780,1697552142139,120,26.0,1.0,"[67, 1292]","[1697552140847, 1697552142139]"
3725,3725,31,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145194,1697552147358,120,,,"[20, 742, 716]","[1697552145214, 1697552145956, 1697552146672]"
3726,3726,437,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142142,1697552143539,120,,,"[16, 816]","[1697552142158, 1697552142974]"
3727,3727,359,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153297,1697552154369,120,,,[14],[1697552153311]
3728,3728,613,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147361,1697552148669,120,,,[34],[1697552147395]
3729,3729,13,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154372,1697552155496,120,,,[39],[1697552154411]
3730,3730,385,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148674,1697552150143,120,,,"[40, 1408]","[1697552148714, 1697552150122]"
3731,3731,712,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552141747,1697552143538,120,,,"[14, 1213]","[1697552141761, 1697552142974]"
3732,3732,603,37,[],200,llama-13b,64,1,1349.0,1.0,1,A100,1697552097352,1697552098701,120,9.0,1.0,"[46, 1303]","[1697552097398, 1697552098701]"
3733,3733,584,61,[],200,llama-13b,64,1,1361.0,1.0,1,A100,1697552140779,1697552142140,120,10.0,1.0,"[58, 1302]","[1697552140837, 1697552142139]"
3734,3734,103,60,[],200,llama-13b,64,1,1227.0,1.0,1,A100,1697552137940,1697552139167,120,15.0,1.0,"[22, 1205]","[1697552137962, 1697552139167]"
3735,3735,484,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143544,1697552147356,120,,,"[114, 2297, 716]","[1697552143658, 1697552145955, 1697552146671]"
3736,3736,349,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142142,1697552143537,120,,,"[16, 816]","[1697552142158, 1697552142974]"
3737,3737,866,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552141748,1697552143538,120,,,[23],[1697552141771]
3738,3738,720,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140783,1697552143538,120,,,"[152, 2039]","[1697552140935, 1697552142974]"
3739,3739,42,67,[],200,llama-13b,64,1,1287.0,1.0,1,A100,1697552150148,1697552151435,120,10.0,1.0,"[90, 1196]","[1697552150238, 1697552151434]"
3740,3740,137,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147361,1697552148668,120,,,[19],[1697552147380]
3741,3741,740,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552151441,1697552152619,120,,,[15],[1697552151456]
3742,3742,638,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143543,1697552145221,120,,,"[99, 1549]","[1697552143642, 1697552145191]"
3743,3743,842,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148671,1697552149356,120,,,[12],[1697552148683]
3744,3744,399,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152625,1697552154368,120,,,[61],[1697552152686]
3745,3745,5,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143541,1697552145220,120,,,"[23, 1627]","[1697552143564, 1697552145191]"
3746,3746,169,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154371,1697552155497,120,,,[35],[1697552154406]
3747,3747,157,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552149360,1697552151583,120,,,"[40, 1550]","[1697552149400, 1697552150950]"
3748,3748,375,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143541,1697552145221,120,,,[47],[1697552143588]
3749,3749,145,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145225,1697552146630,120,,,[46],[1697552145271]
3750,3750,734,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146635,1697552147357,120,,,"[13, 691]","[1697552146648, 1697552147339]"
3751,3751,711,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145227,1697552147358,120,,,"[118, 1993]","[1697552145345, 1697552147338]"
3752,3752,288,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145222,1697552146630,120,,,[7],[1697552145229]
3753,3753,730,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552155499,1697552157212,120,,,[26],[1697552155525]
3754,3754,503,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147363,1697552148669,120,,,[114],[1697552147477]
3755,3755,65,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146638,1697552150144,120,,,"[52, 1282, 737, 685]","[1697552146690, 1697552147972, 1697552148709, 1697552149394]"
3756,3756,501,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157215,1697552158464,120,,,[20],[1697552157235]
3757,3757,854,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552151586,1697552166082,120,,,"[44, 1662, 546, 572, 555, 573, 588, 44, 554, 527, 591, 660, 645, 674, 679, 699, 652, 673, 662, 686, 698, 982]","[1697552151630, 1697552153292, 1697552153838, 1697552154410, 1697552154965, 1697552155538, 1697552156126, 1697552156170, 1697552156724, 1697552157251, 1697552157842, 1697552158502, 1697552159147, 1697552159821, 1697552160500, 1697552161199, 1697552161851, 1697552162524, 1697552163186, 1697552163872, 1697552164570, 1697552165552]"
3758,3758,160,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148672,1697552149356,120,,,[6],[1697552148678]
3759,3759,647,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150148,1697552152618,120,,,[88],[1697552150236]
3760,3760,858,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552149361,1697552151583,120,,,[49],[1697552149410]
3761,3761,514,66,[],200,llama-13b,64,1,12982.0,1.0,1,A100,1697552151588,1697552164570,120,85.0,20.0,"[67, 1638, 546, 571, 556, 572, 588, 44, 554, 527, 591, 660, 645, 674, 679, 699, 652, 673, 662, 686, 698]","[1697552151655, 1697552153293, 1697552153839, 1697552154410, 1697552154966, 1697552155538, 1697552156126, 1697552156170, 1697552156724, 1697552157251, 1697552157842, 1697552158502, 1697552159147, 1697552159821, 1697552160500, 1697552161199, 1697552161851, 1697552162524, 1697552163186, 1697552163872, 1697552164570]"
3762,3762,155,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158466,1697552159782,120,,,[30],[1697552158496]
3763,3763,864,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159785,1697552160461,120,,,[27],[1697552159812]
3764,3764,516,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160464,1697552161812,120,,,[48],[1697552160512]
3765,3765,293,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161814,1697552163147,120,,,[20],[1697552161834]
3766,3766,875,77,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163148,1697552163833,120,,,[12],[1697552163160]
3767,3767,647,78,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163836,1697552166087,120,,,"[28, 1536, 152]","[1697552163864, 1697552165400, 1697552165552]"
3768,3768,7,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160464,1697552161161,120,,,[14],[1697552160478]
3769,3769,394,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152625,1697552154367,120,,,[111],[1697552152736]
3770,3770,602,64,[],200,llama-13b,64,1,1820.0,1.0,1,A100,1697552166097,1697552167917,120,15.0,1.0,"[61, 1759]","[1697552166158, 1697552167917]"
3771,3771,590,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161166,1697552162485,120,,,[32],[1697552161198]
3772,3772,337,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162491,1697552163833,120,,,[70],[1697552162561]
3773,3773,233,47,[],200,llama-13b,64,1,834.0,1.0,1,A100,1697552128131,1697552128965,120,6.0,1.0,"[30, 804]","[1697552128161, 1697552128965]"
3774,3774,112,73,[],200,llama-13b,64,1,1717.0,1.0,1,A100,1697552163836,1697552165553,120,16.0,2.0,"[27, 1537, 153]","[1697552163863, 1697552165400, 1697552165553]"
3775,3775,823,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128969,1697552130343,120,,,[31],[1697552129000]
3776,3776,163,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154370,1697552154924,120,,,[7],[1697552154377]
3777,3777,302,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552088521,1697552090604,120,,,"[50, 1224]","[1697552088571, 1697552089795]"
3778,3778,695,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165555,1697552167167,120,,,[17],[1697552165572]
3779,3779,279,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128296,1697552130343,120,,,[72],[1697552128368]
3780,3780,753,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 6.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154928,1697552156684,120,,,[56],[1697552154984]
3781,3781,594,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130349,1697552132469,120,,,[91],[1697552130440]
3782,3782,882,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.26 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 6.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090607,1697552091869,120,,,"[129, 1111]","[1697552090736, 1697552091847]"
3783,3783,816,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156687,1697552158463,120,,,[23],[1697552156710]
3784,3784,640,76,[],200,llama-13b,64,1,1818.0,1.0,1,A100,1697552166101,1697552167919,120,15.0,1.0,"[81, 1737]","[1697552166182, 1697552167919]"
3785,3785,687,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137942,1697552140772,120,,,"[122, 2049, 53, 50, 47]","[1697552138064, 1697552140113, 1697552140166, 1697552140216, 1697552140263]"
3786,3786,889,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097353,1697552098826,120,,,"[10, 1338]","[1697552097363, 1697552098701]"
3787,3787,289,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133256,1697552134788,120,,,[44],[1697552133300]
3788,3788,544,32,[],200,llama-13b,64,1,1699.0,1.0,1,A100,1697552098832,1697552100531,120,26.0,1.0,"[144, 1555]","[1697552098976, 1697552100531]"
3789,3789,83,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145225,1697552146630,120,,,[44],[1697552145269]
3790,3790,818,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163150,1697552164530,120,,,[51],[1697552163201]
3791,3791,782,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146635,1697552147358,120,,,"[18, 686]","[1697552146653, 1697552147339]"
3792,3792,348,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140782,1697552143537,120,,,"[85, 2106]","[1697552140867, 1697552142973]"
3793,3793,183,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150148,1697552151582,120,,,"[93, 1193]","[1697552150241, 1697552151434]"
3794,3794,888,63,[],200,llama-13b,64,1,1706.0,1.0,1,A100,1697552151586,1697552153292,120,19.0,1.0,"[54, 1652]","[1697552151640, 1697552153292]"
3795,3795,471,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164533,1697552166088,120,,,"[42, 1386]","[1697552164575, 1697552165961]"
3796,3796,868,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.11 GiB is allocated by PyTorch, and 7.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130346,1697552131775,120,,,[25],[1697552130371]
3797,3797,472,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167171,1697552168555,120,,,[18],[1697552167189]
3798,3798,2,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137941,1697552139268,120,,,"[35, 1191]","[1697552137976, 1697552139167]"
3799,3799,638,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131780,1697552133252,120,,,[27],[1697552131807]
3800,3800,293,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133255,1697552134788,120,,,[33],[1697552133288]
3801,3801,524,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156687,1697552158463,120,,,[19],[1697552156706]
3802,3802,70,54,[],200,llama-13b,64,1,1499.0,1.0,1,A100,1697552134796,1697552136295,120,39.0,1.0,"[87, 1412]","[1697552134883, 1697552136295]"
3803,3803,653,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136297,1697552137934,120,,,"[15, 1452]","[1697552136312, 1697552137764]"
3804,3804,181,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158465,1697552159782,120,,,[16],[1697552158481]
3805,3805,706,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139273,1697552142271,120,,,"[76, 2395]","[1697552139349, 1697552141744]"
3806,3806,147,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134062,1697552134789,120,,,[20],[1697552134082]
3807,3807,360,63,[],200,llama-13b,64,1,1244.0,1.0,1,A100,1697552142275,1697552143519,120,16.0,1.0,"[7, 1237]","[1697552142282, 1697552143519]"
3808,3808,214,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150146,1697552151582,120,,,"[26, 1262]","[1697552150172, 1697552151434]"
3809,3809,887,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159785,1697552161160,120,,,[47],[1697552159832]
3810,3810,538,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161162,1697552162485,120,,,[10],[1697552161172]
3811,3811,912,70,[],200,llama-13b,64,1,12985.0,1.0,1,A100,1697552151584,1697552164569,120,92.0,20.0,"[6, 1702, 546, 572, 555, 573, 588, 44, 553, 528, 590, 661, 644, 675, 678, 700, 652, 673, 662, 686, 697]","[1697552151590, 1697552153292, 1697552153838, 1697552154410, 1697552154965, 1697552155538, 1697552156126, 1697552156170, 1697552156723, 1697552157251, 1697552157841, 1697552158502, 1697552159146, 1697552159821, 1697552160499, 1697552161199, 1697552161851, 1697552162524, 1697552163186, 1697552163872, 1697552164569]"
3812,3812,140,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143522,1697552145219,120,,,"[17, 1652]","[1697552143539, 1697552145191]"
3813,3813,692,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139170,1697552140772,120,,,"[13, 930, 54, 49, 47]","[1697552139183, 1697552140113, 1697552140167, 1697552140216, 1697552140263]"
3814,3814,316,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162488,1697552163832,120,,,[33],[1697552162521]
3815,3815,89,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143544,1697552147356,120,,,"[113, 2298, 716]","[1697552143657, 1697552145955, 1697552146671]"
3816,3816,724,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145227,1697552146632,120,,,[111],[1697552145338]
3817,3817,494,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146637,1697552150143,120,,,"[45, 1290, 737, 685]","[1697552146682, 1697552147972, 1697552148709, 1697552149394]"
3818,3818,898,71,[],200,llama-13b,64,1,1718.0,1.0,1,A100,1697552163835,1697552165553,120,79.0,2.0,"[18, 1547, 152]","[1697552163853, 1697552165400, 1697552165552]"
3819,3819,765,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147360,1697552148668,120,,,[7],[1697552147367]
3820,3820,197,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140777,1697552142271,120,,,"[13, 1348]","[1697552140790, 1697552142138]"
3821,3821,779,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142276,1697552145220,120,,,"[62, 2205, 54]","[1697552142338, 1697552144543, 1697552144597]"
3822,3822,311,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134062,1697552134789,120,,,[33],[1697552134095]
3823,3823,526,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145224,1697552146632,120,,,[30],[1697552145254]
3824,3824,241,67,[],200,llama-13b,64,1,1289.0,1.0,1,A100,1697552150145,1697552151434,120,19.0,1.0,"[7, 1281]","[1697552150152, 1697552151433]"
3825,3825,88,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134792,1697552137937,120,,,"[33, 1469, 719]","[1697552134825, 1697552136294, 1697552137013]"
3826,3826,567,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164572,1697552166085,120,,,"[81, 1308]","[1697552164653, 1697552165961]"
3827,3827,322,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552100532,1697552102447,120,,,[7],[1697552100539]
3828,3828,907,34,[],200,llama-13b,64,1,1245.0,1.0,1,A100,1697552102451,1697552103696,120,10.0,1.0,"[11, 1234]","[1697552102462, 1697552103696]"
3829,3829,535,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.28 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 3.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552078121,1697552079384,120,,,"[51, 1076]","[1697552078172, 1697552079248]"
3830,3830,179,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146639,1697552150142,120,,,"[98, 1236, 736, 685]","[1697552146737, 1697552147973, 1697552148709, 1697552149394]"
3831,3831,306,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113430,1697552115115,120,,,[59],[1697552113489]
3832,3832,54,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552115120,1697552116438,120,,,"[128, 1060]","[1697552115248, 1697552116308]"
3833,3833,344,72,[],200,llama-13b,64,1,1818.0,1.0,1,A100,1697552166100,1697552167918,120,13.0,1.0,"[68, 1750]","[1697552166168, 1697552167918]"
3834,3834,196,21,[],200,llama-13b,64,1,1231.0,1.0,1,A100,1697552079395,1697552080626,120,13.0,1.0,"[75, 1156]","[1697552079470, 1697552080626]"
3835,3835,852,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128968,1697552130344,120,,,[17],[1697552128985]
3836,3836,243,75,[],200,llama-13b,64,1,2586.0,1.0,1,A100,1697552166093,1697552168679,120,67.0,4.0,"[45, 1780, 678, 44, 39]","[1697552166138, 1697552167918, 1697552168596, 1697552168640, 1697552168679]"
3837,3837,506,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.11 GiB is allocated by PyTorch, and 7.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130348,1697552131776,120,,,[58],[1697552130406]
3838,3838,118,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143541,1697552145220,120,,,"[37, 1613]","[1697552143578, 1697552145191]"
3839,3839,277,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131780,1697552133253,120,,,[37],[1697552131817]
3840,3840,701,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145226,1697552146631,120,,,[63],[1697552145289]
3841,3841,248,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132471,1697552133252,120,,,[11],[1697552132482]
3842,3842,479,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146640,1697552150143,120,,,"[107, 1226, 736, 685]","[1697552146747, 1697552147973, 1697552148709, 1697552149394]"
3843,3843,24,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133255,1697552134788,120,,,[38],[1697552133293]
3844,3844,841,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098829,1697552101107,120,,,"[127, 1626]","[1697552098956, 1697552100582]"
3845,3845,791,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552114145,1697552116441,120,,,[51],[1697552114196]
3846,3846,607,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134792,1697552137936,120,,,"[48, 1455, 719]","[1697552134840, 1697552136295, 1697552137014]"
3847,3847,867,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133256,1697552134789,120,,,[79],[1697552133335]
3848,3848,448,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116447,1697552118448,120,,,[109],[1697552116556]
3849,3849,496,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101110,1697552102446,120,,,"[25, 1212]","[1697552101135, 1697552102347]"
3850,3850,406,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121359,1697552122933,120,,,[41],[1697552121400]
3851,3851,652,35,[],200,llama-13b,64,1,1292.0,1.0,1,A100,1697552091872,1697552093164,120,14.0,1.0,"[121, 1171]","[1697552091993, 1697552093164]"
3852,3852,175,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 458.06 MiB is free. Process 1449637 has 38.94 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122935,1697552124743,120,,,[34],[1697552122969]
3853,3853,220,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118452,1697552120129,120,,,"[39, 1458]","[1697552118491, 1697552119949]"
3854,3854,350,53,[],200,llama-13b,64,1,1226.0,1.0,1,A100,1697552137941,1697552139167,120,216.0,1.0,"[49, 1177]","[1697552137990, 1697552139167]"
3855,3855,312,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093169,1697552093477,120,,,[28],[1697552093197]
3856,3856,851,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552124746,1697552125687,120,,,[19],[1697552124765]
3857,3857,274,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552102450,1697552103818,120,,,"[10, 1235]","[1697552102460, 1697552103695]"
3858,3858,809,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120134,1697552121355,120,,,[49],[1697552120183]
3859,3859,507,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125690,1697552127341,120,,,[48],[1697552125738]
3860,3860,285,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552127358,1697552135649,120,,,"[41, 1566, 681, 735, 740, 691, 695, 780, 812, 724]","[1697552127399, 1697552128965, 1697552129646, 1697552130381, 1697552131121, 1697552131812, 1697552132507, 1697552133287, 1697552134099, 1697552134823]"
3861,3861,282,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137941,1697552139268,120,,,"[45, 1181]","[1697552137986, 1697552139167]"
3862,3862,579,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121363,1697552122932,120,,,[92],[1697552121455]
3863,3863,80,37,[],200,llama-13b,64,1,1952.0,1.0,1,A100,1697552093484,1697552095436,120,13.0,1.0,"[151, 1800]","[1697552093635, 1697552095435]"
3864,3864,852,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103824,1697552105087,120,,,"[34, 1209]","[1697552103858, 1697552105067]"
3865,3865,670,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552095439,1697552097348,120,,,"[23, 1241]","[1697552095462, 1697552096703]"
3866,3866,599,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105092,1697552106518,120,,,"[73, 1324]","[1697552105165, 1697552106489]"
3867,3867,325,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122935,1697552123845,120,,,[20],[1697552122955]
3868,3868,869,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135652,1697552136976,120,,,[25],[1697552135677]
3869,3869,439,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552097352,1697552098826,120,,,"[7, 1342]","[1697552097359, 1697552098701]"
3870,3870,638,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136979,1697552139266,120,,,"[35, 1598]","[1697552137014, 1697552138612]"
3871,3871,95,40,[],200,llama-13b,64,1,1699.0,1.0,1,A100,1697552098832,1697552100531,120,12.0,1.0,"[142, 1557]","[1697552098974, 1697552100531]"
3872,3872,775,41,[],200,llama-13b,64,1,1216.0,1.0,1,A100,1697552100536,1697552101752,120,17.0,1.0,"[28, 1188]","[1697552100564, 1697552101752]"
3873,3873,907,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123848,1697552125686,120,,,[90],[1697552123938]
3874,3874,429,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101756,1697552103819,120,,,"[28, 1517]","[1697552101784, 1697552103301]"
3875,3875,685,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125689,1697552127341,120,,,[30],[1697552125719]
3876,3876,336,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552127342,1697552128290,120,,,"[21, 764]","[1697552127363, 1697552128127]"
3877,3877,258,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 29.88 GiB is allocated by PyTorch, and 7.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098703,1697552099702,120,,,[7],[1697552098710]
3878,3878,616,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134071,1697552135648,120,,,"[95, 1407]","[1697552134166, 1697552135573]"
3879,3879,105,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128293,1697552129608,120,,,[16],[1697552128309]
3880,3880,205,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128295,1697552129609,120,,,[58],[1697552128353]
3881,3881,7,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552099704,1697552101106,120,,,"[17, 1368]","[1697552099721, 1697552101089]"
3882,3882,695,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129612,1697552131084,120,,,[56],[1697552129668]
3883,3883,393,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135651,1697552136976,120,,,[33],[1697552135684]
3884,3884,757,58,[],200,llama-13b,64,1,761.0,1.0,1,A100,1697552145195,1697552145956,120,20.0,1.0,"[19, 742]","[1697552145214, 1697552145956]"
3885,3885,46,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136978,1697552137936,120,,,[20],[1697552136998]
3886,3886,747,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137946,1697552140773,120,,,"[191, 1977, 52, 50, 47]","[1697552138137, 1697552140114, 1697552140166, 1697552140216, 1697552140263]"
3887,3887,824,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552151438,1697552152619,120,,,[11],[1697552151449]
3888,3888,509,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123846,1697552125686,120,,,[25],[1697552123871]
3889,3889,389,59,[],200,llama-13b,64,1,1380.0,1.0,1,A100,1697552145959,1697552147339,120,8.0,1.0,"[24, 1356]","[1697552145983, 1697552147339]"
3890,3890,599,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152623,1697552153791,120,,,[29],[1697552152652]
3891,3891,291,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160464,1697552162485,120,,,[87],[1697552160551]
3892,3892,159,60,[],200,llama-13b,64,1,630.0,1.0,1,A100,1697552147343,1697552147973,120,31.0,1.0,"[13, 617]","[1697552147356, 1697552147973]"
3893,3893,743,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147976,1697552149356,120,,,[10],[1697552147986]
3894,3894,253,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153795,1697552154923,120,,,[48],[1697552153843]
3895,3895,520,62,[],200,llama-13b,64,1,1585.0,1.0,1,A100,1697552149364,1697552150949,120,11.0,1.0,"[72, 1513]","[1697552149436, 1697552150949]"
3896,3896,170,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150951,1697552152619,120,,,[12],[1697552150963]
3897,3897,62,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162489,1697552163833,120,,,[62],[1697552162551]
3898,3898,119,54,[],200,llama-13b,64,1,943.0,1.0,1,A100,1697552139171,1697552140114,120,31.0,1.0,"[20, 923]","[1697552139191, 1697552140114]"
3899,3899,876,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152623,1697552153790,120,,,[43],[1697552152666]
3900,3900,709,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140124,1697552142273,120,,,"[14, 1606]","[1697552140138, 1697552141744]"
3901,3901,380,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128295,1697552129609,120,,,[63],[1697552128358]
3902,3902,480,56,[],200,llama-13b,64,1,2263.0,1.0,1,A100,1697552142281,1697552144544,120,26.0,1.0,"[158, 2105]","[1697552142439, 1697552144544]"
3903,3903,652,73,[],200,llama-13b,64,1,1564.0,1.0,1,A100,1697552163836,1697552165400,120,14.0,1.0,"[37, 1527]","[1697552163873, 1697552165400]"
3904,3904,422,74,[],200,llama-13b,64,1,558.0,1.0,1,A100,1697552165404,1697552165962,120,26.0,1.0,"[34, 524]","[1697552165438, 1697552165962]"
3905,3905,156,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129614,1697552131084,120,,,[74],[1697552129688]
3906,3906,527,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153793,1697552154923,120,,,[30],[1697552153823]
3907,3907,713,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552155499,1697552157211,120,,,[24],[1697552155523]
3908,3908,304,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154925,1697552156085,120,,,[15],[1697552154940]
3909,3909,739,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131086,1697552132469,120,,,[12],[1697552131098]
3910,3910,886,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156089,1697552157801,120,,,[58],[1697552156147]
3911,3911,205,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103826,1697552106517,120,,,"[113, 1964]","[1697552103939, 1697552105903]"
3912,3912,482,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132472,1697552134060,120,,,[35],[1697552132507]
3913,3913,421,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135653,1697552136977,120,,,[44],[1697552135697]
3914,3914,374,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157214,1697552158464,120,,,[11],[1697552157225]
3915,3915,658,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157805,1697552159107,120,,,[48],[1697552157853]
3916,3916,786,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106522,1697552107868,120,,,"[25, 1206]","[1697552106547, 1697552107753]"
3917,3917,406,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159110,1697552160461,120,,,[48],[1697552159158]
3918,3918,63,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160463,1697552161812,120,,,[25],[1697552160488]
3919,3919,140,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158466,1697552159782,120,,,[35],[1697552158501]
3920,3920,871,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147361,1697552148669,120,,,[80],[1697552147441]
3921,3921,135,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134064,1697552135648,120,,,"[71, 1438]","[1697552134135, 1697552135573]"
3922,3922,525,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148674,1697552151582,120,,,"[168, 2107]","[1697552148842, 1697552150949]"
3923,3923,311,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135652,1697552136976,120,,,[83],[1697552135735]
3924,3924,191,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136980,1697552139266,120,,,"[43, 1589]","[1697552137023, 1697552138612]"
3925,3925,88,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136981,1697552139267,120,,,"[61, 1571]","[1697552137042, 1697552138613]"
3926,3926,728,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159785,1697552161160,120,,,[53],[1697552159838]
3927,3927,767,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161814,1697552163147,120,,,[24],[1697552161838]
3928,3928,670,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139271,1697552140773,120,,,"[10, 1463]","[1697552139281, 1697552140744]"
3929,3929,910,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129612,1697552131084,120,,,[41],[1697552129653]
3930,3930,303,64,[],200,llama-13b,64,1,12985.0,1.0,1,A100,1697552151584,1697552164569,120,88.0,20.0,"[11, 1697, 546, 572, 555, 573, 587, 45, 554, 527, 590, 660, 645, 675, 678, 700, 652, 673, 662, 686, 697]","[1697552151595, 1697552153292, 1697552153838, 1697552154410, 1697552154965, 1697552155538, 1697552156125, 1697552156170, 1697552156724, 1697552157251, 1697552157841, 1697552158501, 1697552159146, 1697552159821, 1697552160499, 1697552161199, 1697552161851, 1697552162524, 1697552163186, 1697552163872, 1697552164569]"
3931,3931,566,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131087,1697552132470,120,,,[33],[1697552131120]
3932,3932,314,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132472,1697552133253,120,,,[20],[1697552132492]
3933,3933,86,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133255,1697552134788,120,,,[43],[1697552133298]
3934,3934,420,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163152,1697552164530,120,,,[98],[1697552163250]
3935,3935,906,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140781,1697552142273,120,,,"[73, 1285]","[1697552140854, 1697552142139]"
3936,3936,198,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164533,1697552166085,120,,,"[52, 1377]","[1697552164585, 1697552165962]"
3937,3937,465,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131086,1697552132469,120,,,[17],[1697552131103]
3938,3938,668,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134792,1697552137935,120,,,"[43, 1460, 719]","[1697552134835, 1697552136295, 1697552137014]"
3939,3939,124,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132472,1697552133253,120,,,[15],[1697552132487]
3940,3940,541,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153295,1697552154368,120,,,[7],[1697552153302]
3941,3941,774,56,[],200,llama-13b,64,1,1474.0,1.0,1,A100,1697552139271,1697552140745,120,8.0,1.0,"[25, 1449]","[1697552139296, 1697552140745]"
3942,3942,445,48,[],200,llama-13b,64,1,2226.0,1.0,1,A100,1697552137941,1697552140167,120,457.0,2.0,"[113, 2059, 53]","[1697552138054, 1697552140113, 1697552140166]"
3943,3943,822,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133257,1697552134789,120,,,[83],[1697552133340]
3944,3944,318,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154371,1697552155497,120,,,[36],[1697552154407]
3945,3945,782,74,[],200,llama-13b,64,1,3382.0,1.0,1,A100,1697552166090,1697552169472,120,90.0,20.0,"[23, 1804, 679, 44, 38, 44, 37, 42, 37, 36, 218, 39, 37, 37, 37, 41, 37, 40, 36, 40, 36]","[1697552166113, 1697552167917, 1697552168596, 1697552168640, 1697552168678, 1697552168722, 1697552168759, 1697552168801, 1697552168838, 1697552168874, 1697552169092, 1697552169131, 1697552169168, 1697552169205, 1697552169242, 1697552169283, 1697552169320, 1697552169360, 1697552169396, 1697552169436, 1697552169472]"
3946,3946,903,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552155500,1697552157801,120,,,[48],[1697552155548]
3947,3947,378,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140783,1697552143538,120,,,[96],[1697552140879]
3948,3948,523,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140747,1697552142272,120,,,"[14, 983]","[1697552140761, 1697552141744]"
3949,3949,148,56,[],200,llama-13b,64,1,1650.0,1.0,1,A100,1697552143541,1697552145191,120,16.0,1.0,"[42, 1608]","[1697552143583, 1697552145191]"
3950,3950,737,57,[],200,llama-13b,64,1,1479.0,1.0,1,A100,1697552145193,1697552146672,120,216.0,2.0,"[16, 746, 716]","[1697552145209, 1697552145955, 1697552146671]"
3951,3951,672,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157804,1697552159107,120,,,[42],[1697552157846]
3952,3952,333,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159110,1697552160461,120,,,[44],[1697552159154]
3953,3953,673,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142281,1697552145220,120,,,"[163, 2153]","[1697552142444, 1697552144597]"
3954,3954,106,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160463,1697552161813,120,,,[39],[1697552160502]
3955,3955,685,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.15 GiB is free. Process 1449637 has 38.24 GiB memory in use. Of the allocated memory 30.77 GiB is allocated by PyTorch, and 5.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552103698,1697552105087,120,,,"[20, 789]","[1697552103718, 1697552104507]"
3956,3956,454,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134793,1697552137936,120,,,"[57, 1444, 720]","[1697552134850, 1697552136294, 1697552137014]"
3957,3957,665,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161815,1697552163147,120,,,[38],[1697552161853]
3958,3958,333,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145224,1697552146634,120,,,[42],[1697552145266]
3959,3959,336,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105090,1697552106517,120,,,"[24, 1375]","[1697552105114, 1697552106489]"
3960,3960,229,61,[],200,llama-13b,64,1,1226.0,1.0,1,A100,1697552137942,1697552139168,120,15.0,1.0,"[129, 1097]","[1697552138071, 1697552139168]"
3961,3961,812,62,[],200,llama-13b,64,1,942.0,1.0,1,A100,1697552139172,1697552140114,120,16.0,1.0,"[28, 914]","[1697552139200, 1697552140114]"
3962,3962,104,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146637,1697552150144,120,,,"[51, 2021, 685]","[1697552146688, 1697552148709, 1697552149394]"
3963,3963,113,37,[],200,llama-13b,64,1,1231.0,1.0,1,A100,1697552106523,1697552107754,120,13.0,1.0,"[49, 1181]","[1697552106572, 1697552107753]"
3964,3964,695,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107757,1697552109319,120,,,"[24, 910]","[1697552107781, 1697552108691]"
3965,3965,589,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140117,1697552142272,120,,,"[16, 1611]","[1697552140133, 1697552141744]"
3966,3966,240,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142277,1697552145220,120,,,"[87, 2179, 54]","[1697552142364, 1697552144543, 1697552144597]"
3967,3967,17,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145225,1697552146631,120,,,[49],[1697552145274]
3968,3968,466,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109324,1697552110463,120,,,[11],[1697552109335]
3969,3969,434,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163149,1697552163833,120,,,[23],[1697552163172]
3970,3970,215,40,[],200,llama-13b,64,1,1348.0,1.0,1,A100,1697552110468,1697552111816,120,12.0,1.0,"[110, 1237]","[1697552110578, 1697552111815]"
3971,3971,599,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146638,1697552150144,120,,,"[62, 1273, 736, 685]","[1697552146700, 1697552147973, 1697552148709, 1697552149394]"
3972,3972,793,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111819,1697552112677,120,,,[15],[1697552111834]
3973,3973,307,79,[],200,llama-13b,64,1,1818.0,1.0,1,A100,1697552166100,1697552167918,120,26.0,1.0,"[53, 1765]","[1697552166153, 1697552167918]"
3974,3974,371,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150149,1697552152619,120,,,[112],[1697552150261]
3975,3975,28,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152625,1697552154368,120,,,[126],[1697552152751]
3976,3976,637,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134793,1697552137936,120,,,"[50, 1452, 718]","[1697552134843, 1697552136295, 1697552137013]"
3977,3977,168,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125698,1697552127341,120,,,[83],[1697552125781]
3978,3978,568,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112682,1697552114139,120,,,[13],[1697552112695]
3979,3979,866,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552127354,1697552135648,120,,,"[30, 2263, 734, 740, 691, 695, 780, 812, 724]","[1697552127384, 1697552129647, 1697552130381, 1697552131121, 1697552131812, 1697552132507, 1697552133287, 1697552134099, 1697552134823]"
3980,3980,292,60,[],200,llama-13b,64,1,1227.0,1.0,1,A100,1697552137941,1697552139168,120,286.0,1.0,"[103, 1123]","[1697552138044, 1697552139167]"
3981,3981,737,55,[],200,llama-13b,64,1,2220.0,1.0,1,A100,1697552134794,1697552137014,120,216.0,2.0,"[81, 1419, 719]","[1697552134875, 1697552136294, 1697552137013]"
3982,3982,25,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154928,1697552156085,120,,,[53],[1697552154981]
3983,3983,506,56,[],200,llama-13b,64,1,1595.0,1.0,1,A100,1697552137018,1697552138613,120,16.0,1.0,"[51, 1544]","[1697552137069, 1697552138613]"
3984,3984,554,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154372,1697552155496,120,,,[44],[1697552154416]
3985,3985,870,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139273,1697552142271,120,,,"[72, 2399]","[1697552139345, 1697552141744]"
3986,3986,81,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165965,1697552167167,120,,,[34],[1697552165999]
3987,3987,59,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134793,1697552137936,120,,,"[72, 1429, 719]","[1697552134865, 1697552136294, 1697552137013]"
3988,3988,115,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147364,1697552148670,120,,,[87],[1697552147451]
3989,3989,446,57,[],200,llama-13b,64,1,1360.0,1.0,1,A100,1697552140779,1697552142139,120,26.0,1.0,"[31, 1329]","[1697552140810, 1697552142139]"
3990,3990,100,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142142,1697552143538,120,,,"[6, 826]","[1697552142148, 1697552142974]"
3991,3991,96,49,[],200,llama-13b,64,1,1573.0,1.0,1,A100,1697552140171,1697552141744,120,31.0,1.0,"[7, 1566]","[1697552140178, 1697552141744]"
3992,3992,925,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128293,1697552129608,120,,,[26],[1697552128319]
3993,3993,578,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129612,1697552131084,120,,,[54],[1697552129666]
3994,3994,800,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143543,1697552147357,120,,,"[104, 3024]","[1697552143647, 1697552146671]"
3995,3995,364,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147364,1697552148669,120,,,[108],[1697552147472]
3996,3996,496,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552149360,1697552151583,120,,,"[36, 1554]","[1697552149396, 1697552150950]"
3997,3997,267,62,[],200,llama-13b,64,1,12984.0,1.0,1,A100,1697552151586,1697552164570,120,83.0,20.0,"[59, 1647, 547, 571, 556, 572, 588, 44, 554, 527, 591, 660, 644, 675, 679, 699, 652, 673, 662, 686, 698]","[1697552151645, 1697552153292, 1697552153839, 1697552154410, 1697552154966, 1697552155538, 1697552156126, 1697552156170, 1697552156724, 1697552157251, 1697552157842, 1697552158502, 1697552159146, 1697552159821, 1697552160500, 1697552161199, 1697552161851, 1697552162524, 1697552163186, 1697552163872, 1697552164570]"
3998,3998,670,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137942,1697552140772,120,,,"[119, 2052, 53, 50, 47]","[1697552138061, 1697552140113, 1697552140166, 1697552140216, 1697552140263]"
3999,3999,803,50,[],200,llama-13b,64,1,1227.0,1.0,1,A100,1697552141748,1697552142975,120,20.0,1.0,"[23, 1204]","[1697552141771, 1697552142975]"
4000,4000,180,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142276,1697552143538,120,,,"[47, 1196]","[1697552142323, 1697552143519]"
4001,4001,618,60,[],200,llama-13b,64,1,2168.0,1.0,1,A100,1697552137946,1697552140114,120,9.0,1.0,"[135, 2033]","[1697552138081, 1697552140114]"
4002,4002,461,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147363,1697552148669,120,,,[104],[1697552147467]
4003,4003,350,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131090,1697552132470,120,,,[54],[1697552131144]
4004,4004,227,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148674,1697552150144,120,,,"[82, 1367]","[1697552148756, 1697552150123]"
4005,4005,911,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132473,1697552134060,120,,,[39],[1697552132512]
4006,4006,391,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140117,1697552142272,120,,,[6],[1697552140123]
4007,4007,681,53,[],200,llama-13b,64,1,1508.0,1.0,1,A100,1697552134066,1697552135574,120,23.0,1.0,"[96, 1411]","[1697552134162, 1697552135573]"
4008,4008,52,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142277,1697552143538,120,,,"[69, 1173]","[1697552142346, 1697552143519]"
4009,4009,335,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135577,1697552137937,120,,,"[16, 702, 718]","[1697552135593, 1697552136295, 1697552137013]"
4010,4010,752,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143543,1697552145220,120,,,"[104, 1544]","[1697552143647, 1697552145191]"
4011,4011,786,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150148,1697552152619,120,,,[115],[1697552150263]
4012,4012,555,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152623,1697552153790,120,,,[38],[1697552152661]
4013,4013,215,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153793,1697552154924,120,,,[19],[1697552153812]
4014,4014,406,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145223,1697552146631,120,,,[21],[1697552145244]
4015,4015,916,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154928,1697552156085,120,,,[47],[1697552154975]
4016,4016,182,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146636,1697552147358,120,,,"[22, 680]","[1697552146658, 1697552147338]"
4017,4017,883,59,[],200,llama-13b,64,1,2414.0,1.0,1,A100,1697552143541,1697552145955,120,563.0,1.0,"[94, 2319]","[1697552143635, 1697552145954]"
4018,4018,353,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118452,1697552120130,120,,,"[39, 1458]","[1697552118491, 1697552119949]"
4019,4019,569,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156089,1697552157801,120,,,[48],[1697552156137]
4020,4020,13,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120134,1697552121355,120,,,[39],[1697552120173]
4021,4021,763,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147361,1697552148669,120,,,[81],[1697552147442]
4022,4022,717,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121358,1697552122932,120,,,[38],[1697552121396]
4023,4023,347,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157804,1697552159107,120,,,[47],[1697552157851]
4024,4024,425,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137941,1697552139268,120,,,"[25, 1201]","[1697552137966, 1697552139167]"
4025,4025,136,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150148,1697552152619,120,,,[125],[1697552150273]
4026,4026,222,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552114144,1697552116439,120,,,"[17, 1595]","[1697552114161, 1697552115756]"
4027,4027,537,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145957,1697552147358,120,,,"[15, 1366]","[1697552145972, 1697552147338]"
4028,4028,78,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139272,1697552142271,120,,,"[50, 2422]","[1697552139322, 1697552141744]"
4029,4029,928,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116447,1697552117622,120,,,[118],[1697552116565]
4030,4030,2,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159109,1697552159782,120,,,[15],[1697552159124]
4031,4031,530,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135652,1697552136976,120,,,[88],[1697552135740]
4032,4032,708,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159786,1697552161160,120,,,[62],[1697552159848]
4033,4033,371,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 458.06 MiB is free. Process 1449637 has 38.94 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122937,1697552124744,120,,,[47],[1697552122984]
4034,4034,302,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136979,1697552137936,120,,,"[29, 757]","[1697552137008, 1697552137765]"
4035,4035,121,67,[],200,llama-13b,64,1,1389.0,1.0,1,A100,1697552164573,1697552165962,120,13.0,1.0,"[86, 1303]","[1697552164659, 1697552165962]"
4036,4036,314,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147364,1697552149356,120,,,[183],[1697552147547]
4037,4037,361,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161166,1697552162485,120,,,[47],[1697552161213]
4038,4038,840,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152624,1697552153790,120,,,[48],[1697552152672]
4039,4039,133,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162487,1697552163148,120,,,[19],[1697552162506]
4040,4040,798,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165965,1697552167168,120,,,[19],[1697552165984]
4041,4041,810,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163151,1697552164529,120,,,[84],[1697552163235]
4042,4042,899,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552149359,1697552151582,120,,,"[17, 1573]","[1697552149376, 1697552150949]"
4043,4043,118,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552124746,1697552126521,120,,,[29],[1697552124775]
4044,4044,462,73,[],200,llama-13b,64,1,869.0,1.0,1,A100,1697552164532,1697552165401,120,52.0,1.0,"[26, 843]","[1697552164558, 1697552165401]"
4045,4045,493,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153792,1697552154368,120,,,[5],[1697552153797]
4046,4046,240,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165403,1697552167166,120,,,[20],[1697552165423]
4047,4047,540,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148672,1697552149356,120,,,[16],[1697552148688]
4048,4048,815,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552126525,1697552128290,120,,,"[71, 1531]","[1697552126596, 1697552128127]"
4049,4049,194,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552149361,1697552151583,120,,,"[50, 1538]","[1697552149411, 1697552150949]"
4050,4050,890,69,[],200,llama-13b,64,1,12985.0,1.0,1,A100,1697552151585,1697552164570,120,93.0,20.0,"[20, 2233, 572, 555, 573, 588, 44, 553, 528, 590, 661, 644, 675, 679, 699, 652, 673, 662, 686, 697]","[1697552151605, 1697552153838, 1697552154410, 1697552154965, 1697552155538, 1697552156126, 1697552156170, 1697552156723, 1697552157251, 1697552157841, 1697552158502, 1697552159146, 1697552159821, 1697552160500, 1697552161199, 1697552161851, 1697552162524, 1697552163186, 1697552163872, 1697552164569]"
4051,4051,241,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154374,1697552155497,120,,,[81],[1697552154455]
4052,4052,451,69,[],200,llama-13b,64,1,1873.0,1.0,1,A100,1697552167174,1697552169047,120,286.0,1.0,"[86, 1786]","[1697552167260, 1697552169046]"
4053,4053,62,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139172,1697552140772,120,,,"[23, 919, 53, 49, 47]","[1697552139195, 1697552140114, 1697552140167, 1697552140216, 1697552140263]"
4054,4054,826,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552155500,1697552157212,120,,,[35],[1697552155535]
4055,4055,594,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157216,1697552159106,120,,,[24],[1697552157240]
4056,4056,214,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145223,1697552146631,120,,,[18],[1697552145241]
4057,4057,912,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146637,1697552147358,120,,,"[25, 677]","[1697552146662, 1697552147339]"
4058,4058,256,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159109,1697552160460,120,,,[29],[1697552159138]
4059,4059,655,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122077,1697552123844,120,,,[38],[1697552122115]
4060,4060,20,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160461,1697552161161,120,,,[16],[1697552160477]
4061,4061,165,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552138616,1697552140771,120,,,"[22, 1475, 54, 49, 47]","[1697552138638, 1697552140113, 1697552140167, 1697552140216, 1697552140263]"
4062,4062,442,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147361,1697552148669,120,,,[76],[1697552147437]
4063,4063,610,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161166,1697552162485,120,,,[26],[1697552161192]
4064,4064,210,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148674,1697552150143,120,,,"[48, 1400]","[1697552148722, 1697552150122]"
4065,4065,506,58,[],200,llama-13b,64,1,1300.0,1.0,1,A100,1697552146673,1697552147973,120,16.0,1.0,"[84, 1216]","[1697552146757, 1697552147973]"
4066,4066,592,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158467,1697552159782,120,,,[49],[1697552158516]
4067,4067,379,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162488,1697552163832,120,,,[34],[1697552162522]
4068,4068,248,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159785,1697552160461,120,,,[32],[1697552159817]
4069,4069,782,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167171,1697552168554,120,,,[32],[1697552167203]
4070,4070,17,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160465,1697552161812,120,,,[96],[1697552160561]
4071,4071,170,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147975,1697552149356,120,,,[6],[1697552147981]
4072,4072,35,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163835,1697552166086,120,,,"[34, 1531, 153]","[1697552163869, 1697552165400, 1697552165553]"
4073,4073,868,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552149359,1697552151582,120,,,"[21, 1569]","[1697552149380, 1697552150949]"
4074,4074,800,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150148,1697552152618,120,,,[39],[1697552150187]
4075,4075,741,75,[],200,llama-13b,64,1,2778.0,1.0,1,A100,1697552166097,1697552168875,120,364.0,9.0,"[46, 1775, 678, 44, 39, 43, 37, 42, 37, 37]","[1697552166143, 1697552167918, 1697552168596, 1697552168640, 1697552168679, 1697552168722, 1697552168759, 1697552168801, 1697552168838, 1697552168875]"
4076,4076,569,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152622,1697552153791,120,,,[35],[1697552152657]
4077,4077,225,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153794,1697552154924,120,,,[33],[1697552153827]
4078,4078,497,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161163,1697552162485,120,,,[25],[1697552161188]
4079,4079,898,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154926,1697552156085,120,,,[12],[1697552154938]
4080,4080,245,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162487,1697552163147,120,,,[10],[1697552162497]
4081,4081,668,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156087,1697552157801,120,,,[15],[1697552156102]
4082,4082,829,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163150,1697552164529,120,,,[37],[1697552163187]
4083,4083,445,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140781,1697552142272,120,,,"[76, 1282]","[1697552140857, 1697552142139]"
4084,4084,599,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164531,1697552166082,120,,,"[14, 855, 152]","[1697552164545, 1697552165400, 1697552165552]"
4085,4085,260,74,[],200,llama-13b,64,1,3384.0,1.0,1,A100,1697552166089,1697552169473,120,86.0,20.0,"[39, 1789, 679, 44, 39, 43, 38, 41, 37, 37, 218, 38, 37, 37, 37, 41, 37, 40, 36, 40, 36]","[1697552166128, 1697552167917, 1697552168596, 1697552168640, 1697552168679, 1697552168722, 1697552168760, 1697552168801, 1697552168838, 1697552168875, 1697552169093, 1697552169131, 1697552169168, 1697552169205, 1697552169242, 1697552169283, 1697552169320, 1697552169360, 1697552169396, 1697552169436, 1697552169472]"
4086,4086,326,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157804,1697552159107,120,,,[39],[1697552157843]
4087,4087,106,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142276,1697552143538,120,,,"[36, 1207]","[1697552142312, 1697552143519]"
4088,4088,895,22,[],200,llama-13b,64,1,882.0,1.0,1,A100,1697552080628,1697552081510,120,15.0,1.0,"[12, 870]","[1697552080640, 1697552081510]"
4089,4089,97,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159109,1697552159782,120,,,[25],[1697552159134]
4090,4090,432,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161819,1697552163147,120,,,[45],[1697552161864]
4091,4091,686,77,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159783,1697552160461,120,,,[10],[1697552159793]
4092,4092,804,61,[],200,llama-13b,64,1,2412.0,1.0,1,A100,1697552143543,1697552145955,120,20.0,1.0,"[109, 2303]","[1697552143652, 1697552145955]"
4093,4093,457,78,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160463,1697552161812,120,,,[24],[1697552160487]
4094,4094,95,72,[],200,llama-13b,64,1,1562.0,1.0,1,A100,1697552163838,1697552165400,120,12.0,1.0,"[106, 1456]","[1697552163944, 1697552165400]"
4095,4095,555,23,[],200,llama-13b,64,1,1322.0,1.0,1,A100,1697552081516,1697552082838,120,11.0,1.0,"[28, 1294]","[1697552081544, 1697552082838]"
4096,4096,111,79,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161814,1697552163147,120,,,[15],[1697552161829]
4097,4097,795,73,[],200,llama-13b,64,1,558.0,1.0,1,A100,1697552165404,1697552165962,120,12.0,1.0,"[29, 529]","[1697552165433, 1697552165962]"
4098,4098,319,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.24 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.18 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552082840,1697552083673,120,,,[17],[1697552082857]
4099,4099,820,80,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163149,1697552164529,120,,,[23],[1697552163172]
4100,4100,201,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163150,1697552164529,120,,,[27],[1697552163177]
4101,4101,583,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117629,1697552119185,120,,,[40],[1697552117669]
4102,4102,472,81,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164532,1697552166082,120,,,"[23, 845, 152]","[1697552164555, 1697552165400, 1697552165552]"
4103,4103,877,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164532,1697552166082,120,,,"[28, 841, 151]","[1697552164560, 1697552165401, 1697552165552]"
4104,4104,716,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145225,1697552146631,120,,,[54],[1697552145279]
4105,4105,492,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146634,1697552147357,120,,,"[9, 696]","[1697552146643, 1697552147339]"
4106,4106,353,46,[],200,llama-13b,64,1,3781.0,1.0,1,A100,1697552119189,1697552122970,120,52.0,4.0,"[44, 1447, 712, 718, 860]","[1697552119233, 1697552120680, 1697552121392, 1697552122110, 1697552122970]"
4107,4107,67,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacty of 39.39 GiB of which 570.06 MiB is free. Process 1449637 has 38.83 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 7.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552083691,1697552084682,120,,,[146],[1697552083837]
4108,4108,885,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137941,1697552139268,120,,,"[35, 1191]","[1697552137976, 1697552139167]"
4109,4109,145,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147364,1697552148670,120,,,[181],[1697552147545]
4110,4110,649,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.08 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.01 GiB is allocated by PyTorch, and 8.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552084685,1697552085753,120,,,[16],[1697552084701]
4111,4111,850,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148675,1697552150143,120,,,"[64, 1383]","[1697552148739, 1697552150122]"
4112,4112,220,82,[],200,llama-13b,64,1,2500.0,1.0,1,A100,1697552166097,1697552168597,120,67.0,2.0,"[66, 1755, 679]","[1697552166163, 1697552167918, 1697552168597]"
4113,4113,506,63,[],200,llama-13b,64,1,1287.0,1.0,1,A100,1697552150148,1697552151435,120,16.0,1.0,"[44, 1242]","[1697552150192, 1697552151434]"
4114,4114,817,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167171,1697552168554,120,,,[28],[1697552167199]
4115,4115,272,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552151442,1697552152619,120,,,[19],[1697552151461]
4116,4116,662,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139274,1697552142272,120,,,"[86, 2384]","[1697552139360, 1697552141744]"
4117,4117,13,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 458.06 MiB is free. Process 1449637 has 38.94 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122973,1697552124744,120,,,[69],[1697552123042]
4118,4118,714,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552124745,1697552126520,120,,,[10],[1697552124755]
4119,4119,313,58,[],200,llama-13b,64,1,1243.0,1.0,1,A100,1697552142277,1697552143520,120,20.0,1.0,"[92, 1150]","[1697552142369, 1697552143519]"
4120,4120,668,63,[],200,llama-13b,64,1,4540.0,1.0,1,A100,1697552151586,1697552156126,120,109.0,6.0,"[44, 1663, 545, 572, 555, 573, 588]","[1697552151630, 1697552153293, 1697552153838, 1697552154410, 1697552154965, 1697552155538, 1697552156126]"
4121,4121,862,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152621,1697552153789,120,,,[6],[1697552152627]
4122,4122,134,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552144547,1697552147357,120,,,"[15, 1393, 716]","[1697552144562, 1697552145955, 1697552146671]"
4123,4123,839,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147364,1697552148670,120,,,[97],[1697552147461]
4124,4124,346,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552126523,1697552128288,120,,,"[15, 1589]","[1697552126538, 1697552128127]"
4125,4125,629,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153796,1697552155496,120,,,[51],[1697552153847]
4126,4126,492,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148675,1697552150143,120,,,"[103, 1344]","[1697552148778, 1697552150122]"
4127,4127,61,59,[],200,llama-13b,64,1,1668.0,1.0,1,A100,1697552143523,1697552145191,120,9.0,1.0,"[20, 1648]","[1697552143543, 1697552145191]"
4128,4128,299,53,[],200,llama-13b,64,1,1473.0,1.0,1,A100,1697552139271,1697552140744,120,14.0,1.0,"[16, 1457]","[1697552139287, 1697552140744]"
4129,4129,272,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150146,1697552151582,120,,,"[26, 1262]","[1697552150172, 1697552151434]"
4130,4130,855,61,[],200,llama-13b,64,1,12983.0,1.0,1,A100,1697552151587,1697552164570,120,83.0,20.0,"[48, 1657, 547, 571, 555, 573, 588, 44, 554, 527, 591, 660, 645, 674, 679, 699, 652, 673, 662, 686, 697]","[1697552151635, 1697552153292, 1697552153839, 1697552154410, 1697552154965, 1697552155538, 1697552156126, 1697552156170, 1697552156724, 1697552157251, 1697552157842, 1697552158502, 1697552159147, 1697552159821, 1697552160500, 1697552161199, 1697552161851, 1697552162524, 1697552163186, 1697552163872, 1697552164569]"
4131,4131,670,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165555,1697552167167,120,,,[6],[1697552165561]
4132,4132,301,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167173,1697552168555,120,,,[75],[1697552167248]
4133,4133,67,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140754,1697552142271,120,,,"[17, 1367]","[1697552140771, 1697552142138]"
4134,4134,115,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128292,1697552129608,120,,,[7],[1697552128299]
4135,4135,700,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129611,1697552131083,120,,,[32],[1697552129643]
4136,4136,476,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131087,1697552132470,120,,,[30],[1697552131117]
4137,4137,261,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 6.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552155498,1697552156684,120,,,[7],[1697552155505]
4138,4138,626,62,[],200,llama-13b,64,1,1390.0,1.0,1,A100,1697552164572,1697552165962,120,10.0,1.0,"[72, 1317]","[1697552164644, 1697552165961]"
4139,4139,31,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156685,1697552157801,120,,,[15],[1697552156700]
4140,4140,257,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165966,1697552167167,120,,,[37],[1697552166003]
4141,4141,615,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157803,1697552159106,120,,,[10],[1697552157813]
4142,4142,305,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552119952,1697552128289,120,,,"[15, 714, 711, 718, 860, 915, 894, 941, 834, 820]","[1697552119967, 1697552120681, 1697552121392, 1697552122110, 1697552122970, 1697552123885, 1697552124779, 1697552125720, 1697552126554, 1697552127374]"
4143,4143,329,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156129,1697552157801,120,,,[28],[1697552156157]
4144,4144,93,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157804,1697552159107,120,,,[37],[1697552157841]
4145,4145,462,62,[],200,llama-13b,64,1,2191.0,1.0,1,A100,1697552140783,1697552142974,120,52.0,1.0,"[91, 2100]","[1697552140874, 1697552142974]"
4146,4146,769,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159109,1697552159782,120,,,[24],[1697552159133]
4147,4147,563,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacty of 39.39 GiB of which 110.06 MiB is free. Process 1449637 has 39.28 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107876,1697552110134,120,,,[74],[1697552107950]
4148,4148,700,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148674,1697552150143,120,,,[102],[1697552148776]
4149,4149,863,58,[],200,llama-13b,64,1,1361.0,1.0,1,A100,1697552140778,1697552142139,120,10.0,1.0,"[20, 1341]","[1697552140798, 1697552142139]"
4150,4150,392,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159111,1697552160461,120,,,[67],[1697552159178]
4151,4151,524,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142142,1697552143538,120,,,"[11, 821]","[1697552142153, 1697552142974]"
4152,4152,117,63,[],200,llama-13b,64,1,1620.0,1.0,1,A100,1697552142977,1697552144597,120,364.0,2.0,"[16, 1551, 53]","[1697552142993, 1697552144544, 1697552144597]"
4153,4153,292,60,[],200,llama-13b,64,1,2414.0,1.0,1,A100,1697552143541,1697552145955,120,286.0,1.0,"[96, 2317]","[1697552143637, 1697552145954]"
4154,4154,875,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145958,1697552147359,120,,,"[20, 1360]","[1697552145978, 1697552147338]"
4155,4155,216,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110137,1697552111925,120,,,"[20, 956]","[1697552110157, 1697552111113]"
4156,4156,49,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160463,1697552161160,120,,,[10],[1697552160473]
4157,4157,917,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111931,1697552113425,120,,,[105],[1697552112036]
4158,4158,622,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147365,1697552148670,120,,,[185],[1697552147550]
4159,4159,574,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113429,1697552115113,120,,,[21],[1697552113450]
4160,4160,392,63,[],200,llama-13b,64,1,1449.0,1.0,1,A100,1697552148674,1697552150123,120,20.0,1.0,"[69, 1380]","[1697552148743, 1697552150123]"
4161,4161,344,49,[],200,llama-13b,64,1,1189.0,1.0,1,A100,1697552115118,1697552116307,120,13.0,1.0,"[13, 1176]","[1697552115131, 1697552116307]"
4162,4162,139,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148674,1697552150143,120,,,"[99, 1349]","[1697552148773, 1697552150122]"
4163,4163,476,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150148,1697552151582,120,,,"[100, 1186]","[1697552150248, 1697552151434]"
4164,4164,722,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150148,1697552152618,120,,,[123],[1697552150271]
4165,4165,753,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161166,1697552162485,120,,,[37],[1697552161203]
4166,4166,470,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152621,1697552153790,120,,,[11],[1697552152632]
4167,4167,128,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153793,1697552154369,120,,,[10],[1697552153803]
4168,4168,89,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116310,1697552120129,120,,,"[12, 532, 802, 826, 738]","[1697552116322, 1697552116854, 1697552117656, 1697552118482, 1697552119220]"
4169,4169,406,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162487,1697552163832,120,,,[20],[1697552162507]
4170,4170,827,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154372,1697552156084,120,,,[66],[1697552154438]
4171,4171,672,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120132,1697552121356,120,,,[16],[1697552120148]
4172,4172,452,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142980,1697552145219,120,,,"[28, 1536, 53]","[1697552143008, 1697552144544, 1697552144597]"
4173,4173,183,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163836,1697552166085,120,,,"[53, 1512, 152]","[1697552163889, 1697552165401, 1697552165553]"
4174,4174,224,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145223,1697552146631,120,,,[16],[1697552145239]
4175,4175,768,75,[],200,llama-13b,64,1,2669.0,1.0,1,A100,1697552166091,1697552168760,120,47.0,6.0,"[32, 1794, 679, 44, 39, 43, 38]","[1697552166123, 1697552167917, 1697552168596, 1697552168640, 1697552168679, 1697552168722, 1697552168760]"
4176,4176,814,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146638,1697552150144,120,,,"[60, 1275, 736, 685]","[1697552146698, 1697552147973, 1697552148709, 1697552149394]"
4177,4177,126,69,[],200,llama-13b,64,1,1708.0,1.0,1,A100,1697552151585,1697552153293,120,19.0,1.0,"[40, 1668]","[1697552151625, 1697552153293]"
4178,4178,449,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121358,1697552122073,120,,,[10],[1697552121368]
4179,4179,583,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150148,1697552152618,120,,,[133],[1697552150281]
4180,4180,857,63,[],200,llama-13b,64,1,1390.0,1.0,1,A100,1697552164572,1697552165962,120,18.0,1.0,"[73, 1316]","[1697552164645, 1697552165961]"
4181,4181,627,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165965,1697552167168,120,,,[13],[1697552165978]
4182,4182,215,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152622,1697552153791,120,,,[35],[1697552152657]
4183,4183,259,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167173,1697552168554,120,,,[70],[1697552167243]
4184,4184,449,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165964,1697552167167,120,,,[13],[1697552165977]
4185,4185,226,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167171,1697552168555,120,,,[23],[1697552167194]
4186,4186,911,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153794,1697552154924,120,,,[34],[1697552153828]
4187,4187,421,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552085757,1697552089317,120,,,"[24, 1346, 694, 735]","[1697552085781, 1697552087127, 1697552087821, 1697552088556]"
4188,4188,610,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156086,1697552157212,120,,,[11],[1697552156097]
4189,4189,82,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 540.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 30.19 GiB is allocated by PyTorch, and 6.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552089321,1697552090605,120,,,"[31, 1231]","[1697552089352, 1697552090583]"
4190,4190,573,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 6.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154926,1697552156684,120,,,[35],[1697552154961]
4191,4191,380,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157215,1697552158463,120,,,[15],[1697552157230]
4192,4192,345,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156687,1697552158463,120,,,[28],[1697552156715]
4193,4193,40,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158466,1697552159782,120,,,[40],[1697552158506]
4194,4194,737,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159785,1697552161160,120,,,[33],[1697552159818]
4195,4195,759,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145192,1697552147358,120,,,"[7, 756, 716]","[1697552145199, 1697552145955, 1697552146671]"
4196,4196,781,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552090608,1697552093264,120,,,"[138, 1992]","[1697552090746, 1697552092738]"
4197,4197,27,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167173,1697552168555,120,,,[66],[1697552167239]
4198,4198,1,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158465,1697552159107,120,,,[6],[1697552158471]
4199,4199,707,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159111,1697552160461,120,,,[48],[1697552159159]
4200,4200,360,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160465,1697552161812,120,,,[75],[1697552160540]
4201,4201,415,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147364,1697552148669,120,,,[107],[1697552147471]
4202,4202,135,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161814,1697552163147,120,,,[10],[1697552161824]
4203,4203,368,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161168,1697552162485,120,,,[75],[1697552161243]
4204,4204,138,77,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162487,1697552163832,120,,,[15],[1697552162502]
4205,4205,439,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 446.06 MiB is free. Process 1449637 has 38.95 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552093267,1697552094765,120,,,"[11, 1089]","[1697552093278, 1697552094367]"
4206,4206,726,78,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163835,1697552166086,120,,,"[23, 1542, 152]","[1697552163858, 1697552165400, 1697552165552]"
4207,4207,212,31,[],200,llama-13b,64,1,1221.0,1.0,1,A100,1697552094770,1697552095991,120,31.0,1.0,"[74, 1147]","[1697552094844, 1697552095991]"
4208,4208,503,79,[],200,llama-13b,64,1,3384.0,1.0,1,A100,1697552166088,1697552169472,120,109.0,20.0,"[25, 1804, 679, 44, 38, 44, 37, 42, 37, 36, 218, 39, 37, 37, 37, 41, 37, 40, 36, 40, 36]","[1697552166113, 1697552167917, 1697552168596, 1697552168640, 1697552168678, 1697552168722, 1697552168759, 1697552168801, 1697552168838, 1697552168874, 1697552169092, 1697552169131, 1697552169168, 1697552169205, 1697552169242, 1697552169283, 1697552169320, 1697552169360, 1697552169396, 1697552169436, 1697552169472]"
4209,4209,639,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142276,1697552143538,120,,,"[37, 1206]","[1697552142313, 1697552143519]"
4210,4210,188,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148674,1697552150143,120,,,"[43, 1405]","[1697552148717, 1697552150122]"
4211,4211,803,32,[],200,llama-13b,64,1,708.0,1.0,1,A100,1697552095996,1697552096704,120,20.0,1.0,"[21, 687]","[1697552096017, 1697552096704]"
4212,4212,574,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 3.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552096705,1697552098825,120,,,"[6, 1517]","[1697552096711, 1697552098228]"
4213,4213,227,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacty of 39.39 GiB of which 236.06 MiB is free. Process 1449637 has 39.16 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552098829,1697552101106,120,,,"[142, 1560, 51]","[1697552098971, 1697552100531, 1697552100582]"
4214,4214,770,63,[],200,llama-13b,64,1,1286.0,1.0,1,A100,1697552150148,1697552151434,120,13.0,1.0,"[39, 1247]","[1697552150187, 1697552151434]"
4215,4215,705,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101110,1697552102446,120,,,"[20, 1217]","[1697552101130, 1697552102347]"
4216,4216,365,41,[],200,llama-13b,64,1,2052.0,1.0,1,A100,1697552102455,1697552104507,120,23.0,1.0,"[107, 1945]","[1697552102562, 1697552104507]"
4217,4217,546,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552151439,1697552152619,120,,,[12],[1697552151451]
4218,4218,199,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152625,1697552154367,120,,,[116],[1697552152741]
4219,4219,423,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159783,1697552160461,120,,,[12],[1697552159795]
4220,4220,524,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552151584,1697552166084,120,,,"[6, 1702, 546, 572, 555, 573, 588, 44, 554, 527, 591, 660, 644, 675, 678, 700, 652, 673, 662, 686, 697, 983]","[1697552151590, 1697552153292, 1697552153838, 1697552154410, 1697552154965, 1697552155538, 1697552156126, 1697552156170, 1697552156724, 1697552157251, 1697552157842, 1697552158502, 1697552159146, 1697552159821, 1697552160499, 1697552161199, 1697552161851, 1697552162524, 1697552163186, 1697552163872, 1697552164569, 1697552165552]"
4221,4221,607,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161815,1697552163147,120,,,[33],[1697552161848]
4222,4222,134,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.27 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1022.06 MiB is free. Process 1449637 has 38.39 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552104510,1697552106518,120,,,"[30, 1364]","[1697552104540, 1697552105904]"
4223,4223,375,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163148,1697552164529,120,,,[12],[1697552163160]
4224,4224,905,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154371,1697552154924,120,,,[20],[1697552154391]
4225,4225,488,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 6.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156088,1697552156684,120,,,[34],[1697552156122]
4226,4226,257,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156688,1697552158464,120,,,[42],[1697552156730]
4227,4227,38,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164531,1697552166082,120,,,"[22, 847, 152]","[1697552164553, 1697552165400, 1697552165552]"
4228,4228,719,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106522,1697552109318,120,,,[45],[1697552106567]
4229,4229,738,73,[],200,llama-13b,64,1,2660.0,1.0,1,A100,1697552166100,1697552168760,120,79.0,6.0,"[68, 2428, 44, 39, 43, 38]","[1697552166168, 1697552168596, 1697552168640, 1697552168679, 1697552168722, 1697552168760]"
4230,4230,845,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158466,1697552159781,120,,,[10],[1697552158476]
4231,4231,489,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109330,1697552110461,120,,,[20],[1697552109350]
4232,4232,560,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 6.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154928,1697552156684,120,,,[58],[1697552154986]
4233,4233,144,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 3.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110468,1697552111926,120,,,"[97, 1250]","[1697552110565, 1697552111815]"
4234,4234,330,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156685,1697552158463,120,,,[16],[1697552156701]
4235,4235,894,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158469,1697552159782,120,,,[52],[1697552158521]
4236,4236,851,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 7.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111932,1697552113423,120,,,[25],[1697552111957]
4237,4237,663,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159784,1697552160461,120,,,[29],[1697552159813]
4238,4238,688,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150148,1697552152619,120,,,[110],[1697552150258]
4239,4239,638,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116442,1697552117621,120,,,[9],[1697552116451]
4240,4240,408,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117629,1697552119185,120,,,[35],[1697552117664]
4241,4241,504,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 174.06 MiB is free. Process 1449637 has 39.22 GiB memory in use. Of the allocated memory 29.69 GiB is allocated by PyTorch, and 7.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552113431,1697552115113,120,,,[112],[1697552113543]
4242,4242,323,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160462,1697552161812,120,,,[20],[1697552160482]
4243,4243,92,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161817,1697552163147,120,,,[42],[1697552161859]
4244,4244,465,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152621,1697552153790,120,,,[16],[1697552152637]
4245,4245,250,48,[],200,llama-13b,64,1,1188.0,1.0,1,A100,1697552115120,1697552116308,120,31.0,1.0,"[138, 1050]","[1697552115258, 1697552116308]"
4246,4246,832,49,[],200,llama-13b,64,1,543.0,1.0,1,A100,1697552116312,1697552116855,120,15.0,1.0,"[15, 528]","[1697552116327, 1697552116855]"
4247,4247,682,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163149,1697552164529,120,,,[18],[1697552163167]
4248,4248,464,62,[],200,llama-13b,64,1,1379.0,1.0,1,A100,1697552145960,1697552147339,120,12.0,1.0,"[28, 1350]","[1697552145988, 1697552147338]"
4249,4249,612,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116856,1697552118449,120,,,[13],[1697552116869]
4250,4250,233,63,[],200,llama-13b,64,1,633.0,1.0,1,A100,1697552147340,1697552147973,120,6.0,1.0,"[6, 627]","[1697552147346, 1697552147973]"
4251,4251,122,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153795,1697552154924,120,,,[42],[1697552153837]
4252,4252,268,51,[],200,llama-13b,64,1,1496.0,1.0,1,A100,1697552118453,1697552119949,120,19.0,1.0,"[91, 1405]","[1697552118544, 1697552119949]"
4253,4253,69,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552119187,1697552120129,120,,,"[16, 746]","[1697552119203, 1697552119949]"
4254,4254,797,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 6.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154931,1697552156684,120,,,[58],[1697552154989]
4255,4255,566,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156687,1697552158463,120,,,[33],[1697552156720]
4256,4256,37,52,[],200,llama-13b,64,1,731.0,1.0,1,A100,1697552119951,1697552120682,120,20.0,1.0,"[12, 719]","[1697552119963, 1697552120682]"
4257,4257,227,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158466,1697552159781,120,,,[20],[1697552158486]
4258,4258,928,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159785,1697552161160,120,,,[37],[1697552159822]
4259,4259,453,74,[],200,llama-13b,64,1,869.0,1.0,1,A100,1697552164532,1697552165401,120,26.0,1.0,"[33, 836]","[1697552164565, 1697552165401]"
4260,4260,581,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161162,1697552162485,120,,,[17],[1697552161179]
4261,4261,627,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120687,1697552122073,120,,,[32],[1697552120719]
4262,4262,107,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165403,1697552167166,120,,,[13],[1697552165416]
4263,4263,809,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167172,1697552168555,120,,,[36],[1697552167208]
4264,4264,763,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120137,1697552121356,120,,,[111],[1697552120248]
4265,4265,395,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122078,1697552123844,120,,,[52],[1697552122130]
4266,4266,754,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142276,1697552143538,120,,,[21],[1697552142297]
4267,4267,368,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552106524,1697552109330,120,,,"[144, 2022]","[1697552106668, 1697552108690]"
4268,4268,203,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 6.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552155499,1697552156684,120,,,[10],[1697552155509]
4269,4269,571,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147361,1697552148669,120,,,[31],[1697552147392]
4270,4270,656,55,[],200,llama-13b,64,1,1243.0,1.0,1,A100,1697552142276,1697552143519,120,26.0,1.0,"[27, 1216]","[1697552142303, 1697552143519]"
4271,4271,56,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123847,1697552125687,120,,,[49],[1697552123896]
4272,4272,904,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156688,1697552158463,120,,,[33],[1697552156721]
4273,4273,341,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148674,1697552149357,120,,,[30],[1697552148704]
4274,4274,754,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125690,1697552127341,120,,,[76],[1697552125766]
4275,4275,406,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552127349,1697552128290,120,,,"[20, 759]","[1697552127369, 1697552128128]"
4276,4276,358,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162487,1697552163832,120,,,[29],[1697552162516]
4277,4277,897,73,[],200,llama-13b,64,1,1590.0,1.0,1,A100,1697552149360,1697552150950,120,9.0,1.0,"[41, 1549]","[1697552149401, 1697552150950]"
4278,4278,7,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163837,1697552166085,120,,,"[56, 1508, 151]","[1697552163893, 1697552165401, 1697552165552]"
4279,4279,669,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150953,1697552152619,120,,,[23],[1697552150976]
4280,4280,712,73,[],200,llama-13b,64,1,3381.0,1.0,1,A100,1697552166091,1697552169472,120,88.0,20.0,"[27, 1799, 679, 44, 38, 44, 37, 42, 37, 37, 217, 39, 37, 37, 37, 41, 37, 40, 36, 40, 36]","[1697552166118, 1697552167917, 1697552168596, 1697552168640, 1697552168678, 1697552168722, 1697552168759, 1697552168801, 1697552168838, 1697552168875, 1697552169092, 1697552169131, 1697552169168, 1697552169205, 1697552169242, 1697552169283, 1697552169320, 1697552169360, 1697552169396, 1697552169436, 1697552169472]"
4281,4281,422,56,[],200,llama-13b,64,1,1668.0,1.0,1,A100,1697552143523,1697552145191,120,26.0,1.0,"[20, 1648]","[1697552143543, 1697552145191]"
4282,4282,524,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143541,1697552145220,120,,,"[32, 1618]","[1697552143573, 1697552145191]"
4283,4283,322,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152622,1697552153791,120,,,[29],[1697552152651]
4284,4284,29,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 26.41 GiB is allocated by PyTorch, and 7.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552109335,1697552110461,120,,,[43],[1697552109378]
4285,4285,78,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145194,1697552147357,120,,,"[10, 751, 716]","[1697552145204, 1697552145955, 1697552146671]"
4286,4286,717,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163150,1697552164529,120,,,[56],[1697552163206]
4287,4287,466,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164532,1697552166085,120,,,"[38, 1391]","[1697552164570, 1697552165961]"
4288,4288,233,65,[],200,llama-13b,64,1,1827.0,1.0,1,A100,1697552166091,1697552167918,120,6.0,1.0,"[52, 1775]","[1697552166143, 1697552167918]"
4289,4289,100,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153793,1697552154368,120,,,[9],[1697552153802]
4290,4290,179,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145225,1697552146631,120,,,[56],[1697552145281]
4291,4291,885,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146636,1697552147358,120,,,"[24, 679]","[1697552146660, 1697552147339]"
4292,4292,754,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147361,1697552148668,120,,,[24],[1697552147385]
4293,4293,51,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150128,1697552151583,120,,,"[24, 1281]","[1697552150152, 1697552151433]"
4294,4294,904,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552101109,1697552102448,120,,,"[8, 1229]","[1697552101117, 1697552102346]"
4295,4295,419,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148672,1697552149356,120,,,[15],[1697552148687]
4296,4296,615,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159784,1697552160461,120,,,[19],[1697552159803]
4297,4297,190,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552149359,1697552151582,120,,,"[22, 1568]","[1697552149381, 1697552150949]"
4298,4298,275,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160464,1697552161812,120,,,[39],[1697552160503]
4299,4299,408,59,[],200,llama-13b,64,1,1448.0,1.0,1,A100,1697552148674,1697552150122,120,16.0,1.0,"[34, 1414]","[1697552148708, 1697552150122]"
4300,4300,539,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147364,1697552148669,120,,,[171],[1697552147535]
4301,4301,183,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150126,1697552151582,120,,,"[21, 1286]","[1697552150147, 1697552151433]"
4302,4302,780,65,[],200,llama-13b,64,1,12985.0,1.0,1,A100,1697552151585,1697552164570,120,85.0,20.0,"[35, 1673, 546, 571, 555, 573, 588, 44, 554, 528, 590, 660, 644, 675, 679, 699, 652, 673, 662, 686, 698]","[1697552151620, 1697552153293, 1697552153839, 1697552154410, 1697552154965, 1697552155538, 1697552156126, 1697552156170, 1697552156724, 1697552157252, 1697552157842, 1697552158502, 1697552159146, 1697552159821, 1697552160500, 1697552161199, 1697552161851, 1697552162524, 1697552163186, 1697552163872, 1697552164570]"
4303,4303,749,65,[],200,llama-13b,64,1,12984.0,1.0,1,A100,1697552151586,1697552164570,120,47.0,20.0,"[54, 1652, 546, 572, 556, 572, 588, 44, 554, 527, 591, 660, 644, 675, 679, 699, 652, 673, 662, 686, 698]","[1697552151640, 1697552153292, 1697552153838, 1697552154410, 1697552154966, 1697552155538, 1697552156126, 1697552156170, 1697552156724, 1697552157251, 1697552157842, 1697552158502, 1697552159146, 1697552159821, 1697552160500, 1697552161199, 1697552161851, 1697552162524, 1697552163186, 1697552163872, 1697552164570]"
4304,4304,803,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153300,1697552154368,120,,,[16],[1697552153316]
4305,4305,556,36,[],200,llama-13b,64,1,1242.0,1.0,1,A100,1697552102454,1697552103696,120,9.0,1.0,"[85, 1157]","[1697552102539, 1697552103696]"
4306,4306,454,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154370,1697552154923,120,,,[7],[1697552154377]
4307,4307,332,37,[],200,llama-13b,64,1,809.0,1.0,1,A100,1697552103698,1697552104507,120,39.0,1.0,"[8, 801]","[1697552103706, 1697552104507]"
4308,4308,423,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121362,1697552122932,120,,,[89],[1697552121451]
4309,4309,794,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147977,1697552149356,120,,,[13],[1697552147990]
4310,4310,915,38,[],200,llama-13b,64,1,1394.0,1.0,1,A100,1697552104509,1697552105903,120,182.0,1.0,"[21, 1373]","[1697552104530, 1697552105903]"
4311,4311,192,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122935,1697552123845,120,,,[29],[1697552122964]
4312,4312,782,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123848,1697552125686,120,,,[58],[1697552123906]
4313,4313,130,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132474,1697552134059,120,,,[53],[1697552132527]
4314,4314,231,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154926,1697552155497,120,,,[30],[1697552154956]
4315,4315,622,62,[],200,llama-13b,64,1,1362.0,1.0,1,A100,1697552140777,1697552142139,120,20.0,1.0,"[18, 1343]","[1697552140795, 1697552142138]"
4316,4316,394,63,[],200,llama-13b,64,1,832.0,1.0,1,A100,1697552142142,1697552142974,120,11.0,1.0,"[6, 826]","[1697552142148, 1697552142974]"
4317,4317,553,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125689,1697552126521,120,,,[20],[1697552125709]
4318,4318,813,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552155499,1697552157211,120,,,[34],[1697552155533]
4319,4319,300,62,[],200,llama-13b,64,1,2411.0,1.0,1,A100,1697552143544,1697552145955,120,9.0,1.0,"[128, 2283]","[1697552143672, 1697552145955]"
4320,4320,585,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157214,1697552158464,120,,,[6],[1697552157220]
4321,4321,154,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128295,1697552129608,120,,,[44],[1697552128339]
4322,4322,207,51,[],200,llama-13b,64,1,1604.0,1.0,1,A100,1697552126524,1697552128128,120,10.0,1.0,"[47, 1556]","[1697552126571, 1697552128127]"
4323,4323,47,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142977,1697552145221,120,,,"[7, 1560, 53]","[1697552142984, 1697552144544, 1697552144597]"
4324,4324,434,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123849,1697552125687,120,,,[99],[1697552123948]
4325,4325,194,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160464,1697552162485,120,,,[92],[1697552160556]
4326,4326,852,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129611,1697552130344,120,,,[25],[1697552129636]
4327,4327,87,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125691,1697552127341,120,,,[52],[1697552125743]
4328,4328,43,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161815,1697552163147,120,,,[34],[1697552161849]
4329,4329,626,77,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163151,1697552164529,120,,,[89],[1697552163240]
4330,4330,885,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150146,1697552151582,120,,,"[11, 1277]","[1697552150157, 1697552151434]"
4331,4331,793,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552127347,1697552128290,120,,,[11],[1697552127358]
4332,4332,373,78,[],200,llama-13b,64,1,1428.0,1.0,1,A100,1697552164534,1697552165962,120,15.0,1.0,"[105, 1323]","[1697552164639, 1697552165962]"
4333,4333,448,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128295,1697552129609,120,,,[38],[1697552128333]
4334,4334,540,62,[],200,llama-13b,64,1,3953.0,1.0,1,A100,1697552151585,1697552155538,120,140.0,5.0,"[50, 1657, 546, 572, 555, 573]","[1697552151635, 1697552153292, 1697552153838, 1697552154410, 1697552154965, 1697552155538]"
4335,4335,106,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137942,1697552140772,120,,,"[124, 2047, 54, 49, 47]","[1697552138066, 1697552140113, 1697552140167, 1697552140216, 1697552140263]"
4336,4336,695,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140779,1697552142272,120,,,"[60, 1300]","[1697552140839, 1697552142139]"
4337,4337,218,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129612,1697552131084,120,,,[51],[1697552129663]
4338,4338,895,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131090,1697552132470,120,,,[49],[1697552131139]
4339,4339,466,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142281,1697552145220,120,,,"[98, 2165, 53]","[1697552142379, 1697552144544, 1697552144597]"
4340,4340,547,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132473,1697552134060,120,,,[49],[1697552132522]
4341,4341,320,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134064,1697552135647,120,,,[92],[1697552134156]
4342,4342,903,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135651,1697552136977,120,,,[7],[1697552135658]
4343,4343,120,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145226,1697552146631,120,,,[60],[1697552145286]
4344,4344,674,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136982,1697552139268,120,,,"[78, 1553]","[1697552137060, 1697552138613]"
4345,4345,313,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 6.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552155542,1697552156684,120,,,[6],[1697552155548]
4346,4346,825,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146636,1697552147358,120,,,"[29, 674]","[1697552146665, 1697552147339]"
4347,4347,835,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134062,1697552134789,120,,,[25],[1697552134087]
4348,4348,439,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125688,1697552126520,120,,,[7],[1697552125695]
4349,4349,334,61,[],200,llama-13b,64,1,1471.0,1.0,1,A100,1697552139274,1697552140745,120,15.0,1.0,"[91, 1380]","[1697552139365, 1697552140745]"
4350,4350,513,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130346,1697552131085,120,,,[15],[1697552130361]
4351,4351,317,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148674,1697552150142,120,,,"[97, 1351]","[1697552148771, 1697552150122]"
4352,4352,483,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134791,1697552135649,120,,,"[18, 765]","[1697552134809, 1697552135574]"
4353,4353,104,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140748,1697552142271,120,,,[22],[1697552140770]
4354,4354,900,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150147,1697552151582,120,,,"[30, 1257]","[1697552150177, 1697552151434]"
4355,4355,281,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131087,1697552132470,120,,,[25],[1697552131112]
4356,4356,693,63,[],200,llama-13b,64,1,2320.0,1.0,1,A100,1697552142277,1697552144597,120,67.0,2.0,"[91, 2176, 53]","[1697552142368, 1697552144544, 1697552144597]"
4357,4357,676,65,[],200,llama-13b,64,1,1705.0,1.0,1,A100,1697552151588,1697552153293,120,19.0,1.0,"[72, 1633]","[1697552151660, 1697552153293]"
4358,4358,332,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153300,1697552154368,120,,,[16],[1697552153316]
4359,4359,462,64,[],200,llama-13b,64,1,1354.0,1.0,1,A100,1697552144601,1697552145955,120,52.0,1.0,"[18, 1336]","[1697552144619, 1697552145955]"
4360,4360,752,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145224,1697552146632,120,,,[35],[1697552145259]
4361,4361,101,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154372,1697552155497,120,,,[49],[1697552154421]
4362,4362,405,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146637,1697552147358,120,,,"[33, 669]","[1697552146670, 1697552147339]"
4363,4363,185,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147364,1697552148670,120,,,[88],[1697552147452]
4364,4364,549,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164575,1697552166085,120,,,[89],[1697552164664]
4365,4365,767,68,[],200,llama-13b,64,1,1448.0,1.0,1,A100,1697552148674,1697552150122,120,11.0,1.0,"[45, 1403]","[1697552148719, 1697552150122]"
4366,4366,539,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150124,1697552151582,120,,,"[11, 814]","[1697552150135, 1697552150949]"
4367,4367,200,70,[],200,llama-13b,64,1,5667.0,1.0,1,A100,1697552151585,1697552157252,120,6.0,9.0,"[15, 1692, 546, 572, 555, 573, 588, 44, 553, 528]","[1697552151600, 1697552153292, 1697552153838, 1697552154410, 1697552154965, 1697552155538, 1697552156126, 1697552156170, 1697552156723, 1697552157251]"
4368,4368,794,64,[],200,llama-13b,64,1,1354.0,1.0,1,A100,1697552144601,1697552145955,120,11.0,1.0,"[13, 1341]","[1697552144614, 1697552145955]"
4369,4369,209,67,[],200,llama-13b,64,1,1829.0,1.0,1,A100,1697552166089,1697552167918,120,20.0,1.0,"[34, 1794]","[1697552166123, 1697552167917]"
4370,4370,898,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157253,1697552158463,120,,,[10],[1697552157263]
4371,4371,564,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158466,1697552159782,120,,,[30],[1697552158496]
4372,4372,335,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159785,1697552161160,120,,,[52],[1697552159837]
4373,4373,565,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552149359,1697552151582,120,,,"[32, 1558]","[1697552149391, 1697552150949]"
4374,4374,765,61,[],200,llama-13b,64,1,2253.0,1.0,1,A100,1697552151585,1697552153838,120,84.0,2.0,"[25, 1682, 546]","[1697552151610, 1697552153292, 1697552153838]"
4375,4375,531,76,[],200,llama-13b,64,1,3372.0,1.0,1,A100,1697552166100,1697552169472,120,52.0,20.0,"[82, 1737, 677, 44, 39, 43, 38, 42, 36, 37, 217, 39, 37, 37, 38, 40, 37, 40, 37, 40, 35]","[1697552166182, 1697552167919, 1697552168596, 1697552168640, 1697552168679, 1697552168722, 1697552168760, 1697552168802, 1697552168838, 1697552168875, 1697552169092, 1697552169131, 1697552169168, 1697552169205, 1697552169243, 1697552169283, 1697552169320, 1697552169360, 1697552169397, 1697552169437, 1697552169472]"
4376,4376,142,79,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165965,1697552167167,120,,,[29],[1697552165994]
4377,4377,729,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552110467,1697552112674,120,,,[102],[1697552110569]
4378,4378,731,80,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167172,1697552168555,120,,,[36],[1697552167208]
4379,4379,646,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158466,1697552159107,120,,,[35],[1697552158501]
4380,4380,542,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153841,1697552154923,120,,,[11],[1697552153852]
4381,4381,219,66,[],200,llama-13b,64,1,12985.0,1.0,1,A100,1697552151585,1697552164570,120,90.0,20.0,"[10, 1697, 546, 572, 555, 573, 588, 44, 553, 528, 590, 661, 644, 675, 679, 699, 652, 673, 662, 686, 697]","[1697552151595, 1697552153292, 1697552153838, 1697552154410, 1697552154965, 1697552155538, 1697552156126, 1697552156170, 1697552156723, 1697552157251, 1697552157841, 1697552158502, 1697552159146, 1697552159821, 1697552160500, 1697552161199, 1697552161851, 1697552162524, 1697552163186, 1697552163872, 1697552164569]"
4382,4382,382,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112684,1697552114139,120,,,[57],[1697552112741]
4383,4383,903,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156688,1697552158464,120,,,[38],[1697552156726]
4384,4384,215,49,[],200,llama-13b,64,1,1602.0,1.0,1,A100,1697552126526,1697552128128,120,12.0,1.0,"[61, 1541]","[1697552126587, 1697552128128]"
4385,4385,298,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159111,1697552160461,120,,,[57],[1697552159168]
4386,4386,672,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158466,1697552159782,120,,,[45],[1697552158511]
4387,4387,160,42,[],200,llama-13b,64,1,1611.0,1.0,1,A100,1697552114145,1697552115756,120,13.0,1.0,"[91, 1520]","[1697552114236, 1697552115756]"
4388,4388,72,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145958,1697552147358,120,,,"[15, 1365]","[1697552145973, 1697552147338]"
4389,4389,71,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160463,1697552161812,120,,,[44],[1697552160507]
4390,4390,332,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159787,1697552161160,120,,,[69],[1697552159856]
4391,4391,745,43,[],200,llama-13b,64,1,1094.0,1.0,1,A100,1697552115760,1697552116854,120,17.0,1.0,"[19, 1075]","[1697552115779, 1697552116854]"
4392,4392,101,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161166,1697552162485,120,,,[42],[1697552161208]
4393,4393,778,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162488,1697552163833,120,,,[38],[1697552162526]
4394,4394,654,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147363,1697552148670,120,,,[94],[1697552147457]
4395,4395,433,69,[],200,llama-13b,64,1,1717.0,1.0,1,A100,1697552163836,1697552165553,120,109.0,2.0,"[38, 1679]","[1697552163874, 1697552165553]"
4396,4396,203,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165556,1697552167167,120,,,[10],[1697552165566]
4397,4397,402,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148674,1697552150144,120,,,"[79, 1370]","[1697552148753, 1697552150123]"
4398,4398,662,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552155499,1697552157212,120,,,[39],[1697552155538]
4399,4399,654,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161815,1697552163147,120,,,[24],[1697552161839]
4400,4400,789,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167173,1697552168555,120,,,[76],[1697552167249]
4401,4401,430,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157215,1697552158464,120,,,[20],[1697552157235]
4402,4402,425,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163150,1697552164530,120,,,[52],[1697552163202]
4403,4403,87,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158466,1697552159782,120,,,[40],[1697552158506]
4404,4404,86,77,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164533,1697552166085,120,,,"[55, 1374]","[1697552164588, 1697552165962]"
4405,4405,564,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145957,1697552147358,120,,,"[20, 1361]","[1697552145977, 1697552147338]"
4406,4406,785,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162490,1697552163833,120,,,[57],[1697552162547]
4407,4407,784,78,[],200,llama-13b,64,1,3383.0,1.0,1,A100,1697552166089,1697552169472,120,89.0,20.0,"[19, 1809, 679, 44, 39, 43, 37, 42, 37, 36, 218, 39, 37, 37, 37, 41, 37, 40, 36, 40, 36]","[1697552166108, 1697552167917, 1697552168596, 1697552168640, 1697552168679, 1697552168722, 1697552168759, 1697552168801, 1697552168838, 1697552168874, 1697552169092, 1697552169131, 1697552169168, 1697552169205, 1697552169242, 1697552169283, 1697552169320, 1697552169360, 1697552169396, 1697552169436, 1697552169472]"
4408,4408,219,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147364,1697552148670,120,,,[187],[1697552147551]
4409,4409,918,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148674,1697552149357,120,,,[24],[1697552148698]
4410,4410,51,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150148,1697552152618,120,,,[98],[1697552150246]
4411,4411,578,68,[],200,llama-13b,64,1,1588.0,1.0,1,A100,1697552149361,1697552150949,120,31.0,1.0,"[54, 1534]","[1697552149415, 1697552150949]"
4412,4412,756,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152622,1697552153790,120,,,[25],[1697552152647]
4413,4413,350,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150951,1697552152619,120,,,[7],[1697552150958]
4414,4414,300,62,[],200,llama-13b,64,1,1821.0,1.0,1,A100,1697552166097,1697552167918,120,9.0,1.0,"[61, 1760]","[1697552166158, 1697552167918]"
4415,4415,246,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158469,1697552159782,120,,,[69],[1697552158538]
4416,4416,682,77,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154372,1697552156084,120,,,[39],[1697552154411]
4417,4417,683,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552105906,1697552107868,120,,,[11],[1697552105917]
4418,4418,786,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159785,1697552160461,120,,,[23],[1697552159808]
4419,4419,727,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154371,1697552155497,120,,,[30],[1697552154401]
4420,4420,343,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.80 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552107873,1697552109322,120,,,"[41, 1291]","[1697552107914, 1697552109205]"
4421,4421,893,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161163,1697552162485,120,,,[16],[1697552161179]
4422,4422,663,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162487,1697552163147,120,,,[10],[1697552162497]
4423,4423,457,78,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156087,1697552157801,120,,,[19],[1697552156106]
4424,4424,113,41,[],200,llama-13b,64,1,1776.0,1.0,1,A100,1697552109337,1697552111113,120,13.0,1.0,"[136, 1640]","[1697552109473, 1697552111113]"
4425,4425,476,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128296,1697552130343,120,,,[77],[1697552128373]
4426,4426,478,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147364,1697552148669,120,,,[176],[1697552147540]
4427,4427,19,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159786,1697552161160,120,,,[61],[1697552159847]
4428,4428,111,79,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157802,1697552158463,120,,,[7],[1697552157809]
4429,4429,323,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163149,1697552164529,120,,,[33],[1697552163182]
4430,4430,820,80,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158465,1697552159107,120,,,[6],[1697552158471]
4431,4431,521,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.09 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 6.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116859,1697552118449,120,,,[27],[1697552116886]
4432,4432,884,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128129,1697552135649,120,,,"[10, 826, 682, 734, 740, 691, 696, 780, 811, 724]","[1697552128139, 1697552128965, 1697552129647, 1697552130381, 1697552131121, 1697552131812, 1697552132508, 1697552133288, 1697552134099, 1697552134823]"
4433,4433,174,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacty of 39.39 GiB of which 256.06 MiB is free. Process 1449637 has 39.14 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 8.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552118454,1697552120129,120,,,"[116, 1380]","[1697552118570, 1697552119950]"
4434,4434,409,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153793,1697552154923,120,,,[24],[1697552153817]
4435,4435,841,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135653,1697552137934,120,,,[107],[1697552135760]
4436,4436,538,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135654,1697552136977,120,,,[101],[1697552135755]
4437,4437,379,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145223,1697552146631,120,,,[10],[1697552145233]
4438,4438,316,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136980,1697552139267,120,,,"[48, 1585]","[1697552137028, 1697552138613]"
4439,4439,186,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154926,1697552156085,120,,,[25],[1697552154951]
4440,4440,770,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156089,1697552157212,120,,,[53],[1697552156142]
4441,4441,149,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146640,1697552150142,120,,,"[100, 1233, 736, 685]","[1697552146740, 1697552147973, 1697552148709, 1697552149394]"
4442,4442,886,65,[],200,llama-13b,64,1,1390.0,1.0,1,A100,1697552164572,1697552165962,120,17.0,1.0,"[77, 1312]","[1697552164649, 1697552165961]"
4443,4443,473,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552155500,1697552157801,120,,,[43],[1697552155543]
4444,4444,540,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157214,1697552158464,120,,,[6],[1697552157220]
4445,4445,496,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137941,1697552139268,120,,,"[39, 1187]","[1697552137980, 1697552139167]"
4446,4446,201,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158466,1697552159782,120,,,[15],[1697552158481]
4447,4447,898,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139269,1697552140772,120,,,"[7, 1468]","[1697552139276, 1697552140744]"
4448,4448,739,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150148,1697552152618,120,,,[95],[1697552150243]
4449,4449,3,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152624,1697552153791,120,,,[53],[1697552152677]
4450,4450,709,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153800,1697552155496,120,,,[48],[1697552153848]
4451,4451,510,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152621,1697552153790,120,,,[21],[1697552152642]
4452,4452,246,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.11 GiB is allocated by PyTorch, and 7.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130346,1697552131775,120,,,[35],[1697552130381]
4453,4453,798,50,[],200,llama-13b,64,1,4377.0,1.0,1,A100,1697552128131,1697552132508,120,79.0,6.0,"[19, 1497, 734, 741, 691, 695]","[1697552128150, 1697552129647, 1697552130381, 1697552131122, 1697552131813, 1697552132508]"
4454,4454,475,81,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159111,1697552160461,120,,,[62],[1697552159173]
4455,4455,164,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153795,1697552154924,120,,,[44],[1697552153839]
4456,4456,245,82,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160465,1697552161812,120,,,[83],[1697552160548]
4457,4457,361,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 6.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552155498,1697552156684,120,,,[10],[1697552155508]
4458,4458,830,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131778,1697552133252,120,,,[14],[1697552131792]
4459,4459,112,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156685,1697552157801,120,,,[11],[1697552156696]
4460,4460,695,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157803,1697552159106,120,,,[18],[1697552157821]
4461,4461,466,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159109,1697552160461,120,,,[19],[1697552159128]
4462,4462,922,83,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161816,1697552163147,120,,,[42],[1697552161858]
4463,4463,127,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160464,1697552161813,120,,,[54],[1697552160518]
4464,4464,873,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154928,1697552156085,120,,,[48],[1697552154976]
4465,4465,98,74,[],200,llama-13b,64,1,1429.0,1.0,1,A100,1697552164534,1697552165963,120,14.0,1.0,"[101, 1327]","[1697552164635, 1697552165962]"
4466,4466,524,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156089,1697552157801,120,,,[58],[1697552156147]
4467,4467,104,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122074,1697552122933,120,,,[6],[1697552122080]
4468,4468,273,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157805,1697552159107,120,,,[61],[1697552157866]
4469,4469,573,84,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163149,1697552164528,120,,,[28],[1697552163177]
4470,4470,803,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122935,1697552123845,120,,,[25],[1697552122960]
4471,4471,74,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128293,1697552129608,120,,,[21],[1697552128314]
4472,4472,351,85,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164531,1697552166082,120,,,"[17, 852, 152]","[1697552164548, 1697552165400, 1697552165552]"
4473,4473,659,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129617,1697552131084,120,,,[69],[1697552129686]
4474,4474,467,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123848,1697552125687,120,,,[106],[1697552123954]
4475,4475,435,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131087,1697552132470,120,,,[28],[1697552131115]
4476,4476,851,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.67 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 6.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120137,1697552121355,120,,,[115],[1697552120252]
4477,4477,42,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159111,1697552160461,120,,,[58],[1697552159169]
4478,4478,566,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132513,1697552134060,120,,,[51],[1697552132564]
4479,4479,88,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132472,1697552133252,120,,,[10],[1697552132482]
4480,4480,506,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 632.06 MiB is free. Process 1449637 has 38.77 GiB memory in use. Of the allocated memory 30.83 GiB is allocated by PyTorch, and 6.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552121362,1697552122933,120,,,[77],[1697552121439]
4481,4481,235,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 6.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552125692,1697552127341,120,,,[71],[1697552125763]
4482,4482,824,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552127351,1697552128290,120,,,"[12, 764]","[1697552127363, 1697552128127]"
4483,4483,227,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134063,1697552135648,120,,,"[47, 1463]","[1697552134110, 1697552135573]"
4484,4484,594,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128296,1697552130343,120,,,[71],[1697552128367]
4485,4485,793,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133255,1697552134788,120,,,[40],[1697552133295]
4486,4486,925,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135654,1697552137934,120,,,"[116, 1994]","[1697552135770, 1697552137764]"
4487,4487,586,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137940,1697552139267,120,,,"[10, 1216]","[1697552137950, 1697552139166]"
4488,4488,249,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.11 GiB is allocated by PyTorch, and 7.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130346,1697552131775,120,,,[20],[1697552130366]
4489,4489,633,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165964,1697552167168,120,,,[19],[1697552165983]
4490,4490,441,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160464,1697552161812,120,,,[53],[1697552160517]
4491,4491,96,65,[],200,llama-13b,64,1,1381.0,1.0,1,A100,1697552145957,1697552147338,120,31.0,1.0,"[6, 1375]","[1697552145963, 1697552147338]"
4492,4492,901,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159786,1697552161160,120,,,[66],[1697552159852]
4493,4493,871,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132473,1697552134060,120,,,[39],[1697552132512]
4494,4494,637,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164573,1697552166085,120,,,"[81, 1307]","[1697552164654, 1697552165961]"
4495,4495,649,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161162,1697552162485,120,,,[9],[1697552161171]
4496,4496,302,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162490,1697552163833,120,,,[61],[1697552162551]
4497,4497,291,71,[],200,llama-13b,64,1,3383.0,1.0,1,A100,1697552166089,1697552169472,120,79.0,20.0,"[29, 2478, 44, 39, 43, 37, 42, 37, 37, 218, 38, 37, 37, 37, 41, 37, 40, 36, 40, 36]","[1697552166118, 1697552168596, 1697552168640, 1697552168679, 1697552168722, 1697552168759, 1697552168801, 1697552168838, 1697552168875, 1697552169093, 1697552169131, 1697552169168, 1697552169205, 1697552169242, 1697552169283, 1697552169320, 1697552169360, 1697552169396, 1697552169436, 1697552169472]"
4498,4498,927,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131778,1697552133252,120,,,[19],[1697552131797]
4499,4499,74,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163838,1697552166084,120,,,"[97, 1466, 151]","[1697552163935, 1697552165401, 1697552165552]"
4500,4500,796,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147340,1697552150143,120,,,"[10, 623, 736, 685]","[1697552147350, 1697552147973, 1697552148709, 1697552149394]"
4501,4501,580,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133255,1697552134061,120,,,[18],[1697552133273]
4502,4502,352,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134065,1697552135648,120,,,[86],[1697552134151]
4503,4503,262,67,[],200,llama-13b,64,1,1388.0,1.0,1,A100,1697552164574,1697552165962,120,39.0,1.0,"[94, 1294]","[1697552164668, 1697552165962]"
4504,4504,31,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165967,1697552167168,120,,,[41],[1697552166008]
4505,4505,5,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135651,1697552136977,120,,,[23],[1697552135674]
4506,4506,663,77,[],200,llama-13b,64,1,3385.0,1.0,1,A100,1697552166087,1697552169472,120,79.0,20.0,"[15, 1815, 679, 44, 38, 44, 37, 42, 37, 36, 218, 38, 38, 37, 37, 41, 37, 40, 36, 41, 35]","[1697552166102, 1697552167917, 1697552168596, 1697552168640, 1697552168678, 1697552168722, 1697552168759, 1697552168801, 1697552168838, 1697552168874, 1697552169092, 1697552169130, 1697552169168, 1697552169205, 1697552169242, 1697552169283, 1697552169320, 1697552169360, 1697552169396, 1697552169437, 1697552169472]"
4507,4507,620,69,[],200,llama-13b,64,1,2144.0,1.0,1,A100,1697552167176,1697552169320,120,100.0,8.0,"[94, 1776, 47, 38, 37, 37, 38, 41, 36]","[1697552167270, 1697552169046, 1697552169093, 1697552169131, 1697552169168, 1697552169205, 1697552169243, 1697552169284, 1697552169320]"
4508,4508,710,64,[],200,llama-13b,64,1,1632.0,1.0,1,A100,1697552136981,1697552138613,120,14.0,1.0,"[67, 1565]","[1697552137048, 1697552138613]"
4509,4509,364,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552138619,1697552140772,120,,,"[18, 1476, 54, 49, 47]","[1697552138637, 1697552140113, 1697552140167, 1697552140216, 1697552140263]"
4510,4510,135,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140783,1697552143538,120,,,"[94, 2097]","[1697552140877, 1697552142974]"
4511,4511,4,86,[],200,llama-13b,64,1,3373.0,1.0,1,A100,1697552166100,1697552169473,120,89.0,20.0,"[48, 1770, 678, 44, 39, 43, 37, 42, 37, 37, 218, 38, 37, 37, 37, 41, 37, 41, 35, 41, 36]","[1697552166148, 1697552167918, 1697552168596, 1697552168640, 1697552168679, 1697552168722, 1697552168759, 1697552168801, 1697552168838, 1697552168875, 1697552169093, 1697552169131, 1697552169168, 1697552169205, 1697552169242, 1697552169283, 1697552169320, 1697552169361, 1697552169396, 1697552169437, 1697552169473]"
4512,4512,553,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163836,1697552166085,120,,,"[43, 1521, 153]","[1697552163879, 1697552165400, 1697552165553]"
4513,4513,215,71,[],200,llama-13b,64,1,1821.0,1.0,1,A100,1697552166097,1697552167918,120,12.0,1.0,"[56, 1764]","[1697552166153, 1697552167917]"
4514,4514,405,67,[],200,llama-13b,64,1,2508.0,1.0,1,A100,1697552167175,1697552169683,120,87.0,20.0,"[90, 1781, 47, 38, 37, 37, 37, 42, 36, 41, 36, 40, 35, 28, 27, 26, 26, 26, 26, 26, 26]","[1697552167265, 1697552169046, 1697552169093, 1697552169131, 1697552169168, 1697552169205, 1697552169242, 1697552169284, 1697552169320, 1697552169361, 1697552169397, 1697552169437, 1697552169472, 1697552169500, 1697552169527, 1697552169553, 1697552169579, 1697552169605, 1697552169631, 1697552169657, 1697552169683]"
4515,4515,229,61,[],200,llama-13b,64,1,1449.0,1.0,1,A100,1697552148674,1697552150123,120,15.0,1.0,"[76, 1373]","[1697552148750, 1697552150123]"
4516,4516,261,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135653,1697552136976,120,,,[48],[1697552135701]
4517,4517,928,62,[],200,llama-13b,64,1,1307.0,1.0,1,A100,1697552150127,1697552151434,120,20.0,1.0,"[20, 1286]","[1697552150147, 1697552151433]"
4518,4518,201,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154926,1697552156085,120,,,[34],[1697552154960]
4519,4519,670,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140777,1697552142271,120,,,"[15, 1346]","[1697552140792, 1697552142138]"
4520,4520,900,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156088,1697552157800,120,,,[39],[1697552156127]
4521,4521,561,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157803,1697552159106,120,,,[25],[1697552157828]
4522,4522,331,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159110,1697552159783,120,,,[29],[1697552159139]
4523,4523,330,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142275,1697552143538,120,,,"[17, 1227]","[1697552142292, 1697552143519]"
4524,4524,607,77,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161166,1697552161812,120,,,[27],[1697552161193]
4525,4525,825,77,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161815,1697552163147,120,,,[39],[1697552161854]
4526,4526,100,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143541,1697552145221,120,,,"[37, 1613]","[1697552143578, 1697552145191]"
4527,4527,688,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145227,1697552146631,120,,,[109],[1697552145336]
4528,4528,376,78,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161815,1697552163147,120,,,[28],[1697552161843]
4529,4529,450,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150148,1697552152618,120,,,[49],[1697552150197]
4530,4530,125,79,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163149,1697552163833,120,,,[18],[1697552163167]
4531,4531,218,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161814,1697552163147,120,,,[10],[1697552161824]
4532,4532,486,78,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163152,1697552164530,120,,,[93],[1697552163245]
4533,4533,76,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159785,1697552161160,120,,,[58],[1697552159843]
4534,4534,800,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163151,1697552164529,120,,,[94],[1697552163245]
4535,4535,843,57,[],200,llama-13b,64,1,1630.0,1.0,1,A100,1697552136983,1697552138613,120,14.0,1.0,"[82, 1548]","[1697552137065, 1697552138613]"
4536,4536,266,53,[],200,llama-13b,64,1,1472.0,1.0,1,A100,1697552139273,1697552140745,120,9.0,1.0,"[87, 1385]","[1697552139360, 1697552140745]"
4537,4537,855,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140748,1697552142270,120,,,"[18, 978]","[1697552140766, 1697552141744]"
4538,4538,227,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152624,1697552153790,120,,,[47],[1697552152671]
4539,4539,625,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142276,1697552143538,120,,,"[7, 1236]","[1697552142283, 1697552143519]"
4540,4540,254,79,[],200,llama-13b,64,1,1429.0,1.0,1,A100,1697552164534,1697552165963,120,58.0,1.0,"[102, 1326]","[1697552164636, 1697552165962]"
4541,4541,577,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164533,1697552166085,120,,,[45],[1697552164578]
4542,4542,844,80,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165968,1697552167168,120,,,[46],[1697552166014]
4543,4543,610,81,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167173,1697552168555,120,,,[82],[1697552167255]
4544,4544,810,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153793,1697552154923,120,,,[25],[1697552153818]
4545,4545,658,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161168,1697552162485,120,,,[49],[1697552161217]
4546,4546,615,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552138616,1697552140773,120,,,"[6, 1544, 49, 48]","[1697552138622, 1697552140166, 1697552140215, 1697552140263]"
4547,4547,436,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162488,1697552163833,120,,,[39],[1697552162527]
4548,4548,87,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163836,1697552166084,120,,,"[42, 1522, 153]","[1697552163878, 1697552165400, 1697552165553]"
4549,4549,229,76,[],200,llama-13b,64,1,1829.0,1.0,1,A100,1697552166088,1697552167917,120,15.0,1.0,"[14, 1815]","[1697552166102, 1697552167917]"
4550,4550,786,71,[],200,llama-13b,64,1,3384.0,1.0,1,A100,1697552166089,1697552169473,120,87.0,20.0,"[49, 1780, 678, 44, 39, 43, 38, 41, 37, 37, 218, 38, 37, 37, 37, 41, 37, 41, 35, 41, 36]","[1697552166138, 1697552167918, 1697552168596, 1697552168640, 1697552168679, 1697552168722, 1697552168760, 1697552168801, 1697552168838, 1697552168875, 1697552169093, 1697552169131, 1697552169168, 1697552169205, 1697552169242, 1697552169283, 1697552169320, 1697552169361, 1697552169396, 1697552169437, 1697552169473]"
4551,4551,449,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134793,1697552137936,120,,,"[62, 1439, 719]","[1697552134855, 1697552136294, 1697552137013]"
4552,4552,702,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.62 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552111117,1697552112677,120,,,[27],[1697552111144]
4553,4553,725,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143540,1697552145219,120,,,"[8, 1643]","[1697552143548, 1697552145191]"
4554,4554,288,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143541,1697552145221,120,,,[42],[1697552143583]
4555,4555,354,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139271,1697552140773,120,,,"[20, 1453]","[1697552139291, 1697552140744]"
4556,4556,126,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157806,1697552159107,120,,,[62],[1697552157868]
4557,4557,708,80,[],200,llama-13b,64,1,1563.0,1.0,1,A100,1697552163838,1697552165401,120,140.0,1.0,"[101, 1462]","[1697552163939, 1697552165401]"
4558,4558,58,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145227,1697552146632,120,,,[113],[1697552145340]
4559,4559,734,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146635,1697552147358,120,,,"[11, 693]","[1697552146646, 1697552147339]"
4560,4560,389,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147362,1697552148670,120,,,[84],[1697552147446]
4561,4561,471,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 544.06 MiB is free. Process 1449637 has 38.86 GiB memory in use. Of the allocated memory 29.09 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552112684,1697552114141,120,,,[36],[1697552112720]
4562,4562,914,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140780,1697552142272,120,,,"[72, 1287]","[1697552140852, 1697552142139]"
4563,4563,198,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137940,1697552139267,120,,,"[21, 1205]","[1697552137961, 1697552139166]"
4564,4564,684,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142277,1697552145220,120,,,"[87, 2180, 53]","[1697552142364, 1697552144544, 1697552144597]"
4565,4565,607,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133256,1697552134789,120,,,[87],[1697552133343]
4566,4566,343,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145224,1697552146631,120,,,[32],[1697552145256]
4567,4567,120,59,[],200,llama-13b,64,1,1335.0,1.0,1,A100,1697552146638,1697552147973,120,17.0,1.0,"[47, 1288]","[1697552146685, 1697552147973]"
4568,4568,256,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 28.64 GiB is allocated by PyTorch, and 8.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134792,1697552135649,120,,,"[28, 754]","[1697552134820, 1697552135574]"
4569,4569,702,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147978,1697552149357,120,,,[18],[1697552147996]
4570,4570,627,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160466,1697552162486,120,,,[91],[1697552160557]
4571,4571,477,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552149362,1697552151582,120,,,"[54, 1533]","[1697552149416, 1697552150949]"
4572,4572,31,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 180.06 MiB is free. Process 1449637 has 39.21 GiB memory in use. Of the allocated memory 29.84 GiB is allocated by PyTorch, and 7.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552135653,1697552136977,120,,,[102],[1697552135755]
4573,4573,614,58,[],200,llama-13b,64,1,1633.0,1.0,1,A100,1697552136980,1697552138613,120,15.0,1.0,"[57, 1576]","[1697552137037, 1697552138613]"
4574,4574,583,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552151435,1697552152619,120,,,[7],[1697552151442]
4575,4575,131,62,[],200,llama-13b,64,1,1709.0,1.0,1,A100,1697552151584,1697552153293,120,8.0,1.0,"[26, 1682]","[1697552151610, 1697552153292]"
4576,4576,359,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152622,1697552153790,120,,,[20],[1697552152642]
4577,4577,837,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153295,1697552154368,120,,,[6],[1697552153301]
4578,4578,403,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162488,1697552163832,120,,,[24],[1697552162512]
4579,4579,362,59,[],200,llama-13b,64,1,1496.0,1.0,1,A100,1697552138618,1697552140114,120,14.0,1.0,"[25, 1470]","[1697552138643, 1697552140113]"
4580,4580,57,75,[],200,llama-13b,64,1,1564.0,1.0,1,A100,1697552163837,1697552165401,120,13.0,1.0,"[51, 1513]","[1697552163888, 1697552165401]"
4581,4581,18,60,[],200,llama-13b,64,1,1627.0,1.0,1,A100,1697552140117,1697552141744,120,15.0,1.0,"[26, 1601]","[1697552140143, 1697552141744]"
4582,4582,492,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154371,1697552155496,120,,,[25],[1697552154396]
4583,4583,759,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165403,1697552167166,120,,,[20],[1697552165423]
4584,4584,13,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153793,1697552154923,120,,,[20],[1697552153813]
4585,4585,719,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154927,1697552156085,120,,,[43],[1697552154970]
4586,4586,258,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552155500,1697552157211,120,,,[39],[1697552155539]
4587,4587,371,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156089,1697552157801,120,,,[63],[1697552156152]
4588,4588,716,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1016.06 MiB is free. Process 1449637 has 38.40 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552141748,1697552143538,120,,,"[18, 1209]","[1697552141766, 1697552142975]"
4589,4589,410,77,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167171,1697552168554,120,,,[17],[1697552167188]
4590,4590,6,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157214,1697552158464,120,,,[11],[1697552157225]
4591,4591,144,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157806,1697552159107,120,,,[65],[1697552157871]
4592,4592,586,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158467,1697552159783,120,,,[49],[1697552158516]
4593,4593,363,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159786,1697552161160,120,,,[56],[1697552159842]
4594,4594,362,59,[],200,llama-13b,64,1,1358.0,1.0,1,A100,1697552140781,1697552142139,120,14.0,1.0,"[78, 1280]","[1697552140859, 1697552142139]"
4595,4595,726,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159110,1697552160461,120,,,[39],[1697552159149]
4596,4596,16,60,[],200,llama-13b,64,1,831.0,1.0,1,A100,1697552142144,1697552142975,120,9.0,1.0,"[24, 806]","[1697552142168, 1697552142974]"
4597,4597,782,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139270,1697552140772,120,,,"[7, 1467]","[1697552139277, 1697552140744]"
4598,4598,497,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160462,1697552161160,120,,,[6],[1697552160468]
4599,4599,218,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 3.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552114144,1697552116439,120,,,[12],[1697552114156]
4600,4600,130,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161167,1697552162485,120,,,[40],[1697552161207]
4601,4601,801,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552116444,1697552117621,120,,,[11],[1697552116455]
4602,4602,377,62,[],200,llama-13b,64,1,2411.0,1.0,1,A100,1697552143544,1697552145955,120,13.0,1.0,"[118, 2293]","[1697552143662, 1697552145955]"
4603,4603,16,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161165,1697552161812,120,,,[32],[1697552161197]
4604,4604,719,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142978,1697552145221,120,,,"[25, 1594]","[1697552143003, 1697552144597]"
4605,4605,149,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145959,1697552147357,120,,,"[34, 1346]","[1697552145993, 1697552147339]"
4606,4606,828,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162490,1697552163834,120,,,[51],[1697552162541]
4607,4607,576,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacty of 39.39 GiB of which 426.06 MiB is free. Process 1449637 has 38.97 GiB memory in use. Of the allocated memory 29.79 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552117631,1697552119186,120,,,[63],[1697552117694]
4608,4608,373,62,[],200,llama-13b,64,1,2110.0,1.0,1,A100,1697552145228,1697552147338,120,15.0,1.0,"[125, 1985]","[1697552145353, 1697552147338]"
4609,4609,681,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165967,1697552167168,120,,,[42],[1697552166009]
4610,4610,236,47,[],200,llama-13b,64,1,1492.0,1.0,1,A100,1697552119189,1697552120681,120,8.0,1.0,"[58, 1434]","[1697552119247, 1697552120681]"
4611,4611,154,63,[],200,llama-13b,64,1,634.0,1.0,1,A100,1697552147340,1697552147974,120,13.0,1.0,"[11, 622]","[1697552147351, 1697552147973]"
4612,4612,457,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167171,1697552168554,120,,,[27],[1697552167198]
4613,4613,6,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacty of 39.39 GiB of which 960.06 MiB is free. Process 1449637 has 38.45 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552120684,1697552122073,120,,,[16],[1697552120700]
4614,4614,486,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163839,1697552166082,120,,,"[101, 1460, 152]","[1697552163940, 1697552165400, 1697552165552]"
4615,4615,594,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 592.06 MiB is free. Process 1449637 has 38.81 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 6.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122075,1697552123843,120,,,[15],[1697552122090]
4616,4616,738,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147360,1697552148668,120,,,[22],[1697552147382]
4617,4617,479,81,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165404,1697552167166,120,,,[29],[1697552165433]
4618,4618,364,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552123854,1697552126520,120,,,[104],[1697552123958]
4619,4619,276,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.15 GiB. GPU 0 has a total capacty of 39.39 GiB of which 458.06 MiB is free. Process 1449637 has 38.94 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552122937,1697552124744,120,,,[49],[1697552122986]
4620,4620,24,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552126524,1697552128289,120,,,[58],[1697552126582]
4621,4621,495,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145224,1697552146632,120,,,[37],[1697552145261]
4622,4622,866,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 410.06 MiB is free. Process 1449637 has 38.99 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 6.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552124746,1697552126520,120,,,[14],[1697552124760]
4623,4623,725,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 7.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128295,1697552129608,120,,,[48],[1697552128343]
4624,4624,257,74,[],200,llama-13b,64,1,1818.0,1.0,1,A100,1697552166101,1697552167919,120,14.0,1.0,"[135, 1683]","[1697552166236, 1697552167919]"
4625,4625,374,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.09 GiB is allocated by PyTorch, and 7.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552129611,1697552131083,120,,,[37],[1697552129648]
4626,4626,123,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.92 GiB is allocated by PyTorch, and 7.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131087,1697552132470,120,,,[23],[1697552131110]
4627,4627,139,82,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167171,1697552168554,120,,,[23],[1697552167194]
4628,4628,241,69,[],200,llama-13b,64,1,1335.0,1.0,1,A100,1697552146637,1697552147972,120,19.0,1.0,"[36, 1299]","[1697552146673, 1697552147972]"
4629,4629,458,60,[],200,llama-13b,64,1,1333.0,1.0,1,A100,1697552146640,1697552147973,120,11.0,1.0,"[105, 1227]","[1697552146745, 1697552147972]"
4630,4630,827,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147975,1697552149356,120,,,[10],[1697552147985]
4631,4631,202,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147975,1697552149356,120,,,[6],[1697552147981]
4632,4632,629,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 7.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552126531,1697552128289,120,,,"[61, 1535]","[1697552126592, 1697552128127]"
4633,4633,603,71,[],200,llama-13b,64,1,1590.0,1.0,1,A100,1697552149359,1697552150949,120,9.0,1.0,"[31, 1559]","[1697552149390, 1697552150949]"
4634,4634,703,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552132474,1697552134059,120,,,[53],[1697552132527]
4635,4635,159,60,[],200,llama-13b,64,1,1446.0,1.0,1,A100,1697552148677,1697552150123,120,31.0,1.0,"[170, 1276]","[1697552148847, 1697552150123]"
4636,4636,480,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134062,1697552134789,120,,,[23],[1697552134085]
4637,4637,291,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.10 GiB is allocated by PyTorch, and 7.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552128295,1697552130343,120,,,[68],[1697552128363]
4638,4638,133,57,[],200,llama-13b,64,1,1502.0,1.0,1,A100,1697552134793,1697552136295,120,15.0,1.0,"[55, 1447]","[1697552134848, 1697552136295]"
4639,4639,748,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150126,1697552151582,120,,,[16],[1697552150142]
4640,4640,517,62,[],200,llama-13b,64,1,1707.0,1.0,1,A100,1697552151585,1697552153292,120,15.0,1.0,"[20, 1687]","[1697552151605, 1697552153292]"
4641,4641,174,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153296,1697552154368,120,,,[10],[1697552153306]
4642,4642,834,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136300,1697552137935,120,,,"[25, 1440]","[1697552136325, 1697552137765]"
4643,4643,717,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161813,1697552163147,120,,,[6],[1697552161819]
4644,4644,738,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147978,1697552149356,120,,,[22],[1697552148000]
4645,4645,378,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163150,1697552164530,120,,,[47],[1697552163197]
4646,4646,832,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159111,1697552160461,120,,,[52],[1697552159163]
4647,4647,487,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160463,1697552161813,120,,,[34],[1697552160497]
4648,4648,495,59,[],200,llama-13b,64,1,1226.0,1.0,1,A100,1697552137941,1697552139167,120,13.0,1.0,"[50, 1176]","[1697552137991, 1697552139167]"
4649,4649,257,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161820,1697552163147,120,,,[49],[1697552161869]
4650,4650,850,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163150,1697552164529,120,,,[42],[1697552163192]
4651,4651,268,60,[],200,llama-13b,64,1,943.0,1.0,1,A100,1697552139171,1697552140114,120,19.0,1.0,"[19, 924]","[1697552139190, 1697552140114]"
4652,4652,786,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552149360,1697552151583,120,,,"[46, 1543]","[1697552149406, 1697552150949]"
4653,4653,556,63,[],200,llama-13b,64,1,1705.0,1.0,1,A100,1697552151588,1697552153293,120,9.0,1.0,"[67, 1638]","[1697552151655, 1697552153293]"
4654,4654,620,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164532,1697552166088,120,,,"[31, 838, 151]","[1697552164563, 1697552165401, 1697552165552]"
4655,4655,507,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148672,1697552149357,120,,,[20],[1697552148692]
4656,4656,921,67,[],200,llama-13b,64,1,1386.0,1.0,1,A100,1697552164576,1697552165962,120,31.0,1.0,"[97, 1289]","[1697552164673, 1697552165962]"
4657,4657,216,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153296,1697552154369,120,,,[15],[1697552153311]
4658,4658,915,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154371,1697552155496,120,,,[15],[1697552154386]
4659,4659,410,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164572,1697552167166,120,,,[86],[1697552164658]
4660,4660,151,72,[],200,llama-13b,64,1,1429.0,1.0,1,A100,1697552164533,1697552165962,120,39.0,1.0,"[60, 1369]","[1697552164593, 1697552165962]"
4661,4661,858,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140118,1697552142272,120,,,[15],[1697552140133]
4662,4662,573,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552155498,1697552157212,120,,,[20],[1697552155518]
4663,4663,574,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165965,1697552167168,120,,,[23],[1697552165988]
4664,4664,873,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154371,1697552154924,120,,,[25],[1697552154396]
4665,4665,259,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150952,1697552152619,120,,,[11],[1697552150963]
4666,4666,60,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 30.11 GiB is allocated by PyTorch, and 7.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552130348,1697552131776,120,,,[87],[1697552130435]
4667,4667,185,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167173,1697552168555,120,,,[80],[1697552167253]
4668,4668,28,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152624,1697552154367,120,,,[115],[1697552152739]
4669,4669,640,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134063,1697552134789,120,,,[29],[1697552134092]
4670,4670,508,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552149359,1697552151582,120,,,"[26, 1564]","[1697552149385, 1697552150949]"
4671,4671,741,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165965,1697552167166,120,,,[28],[1697552165993]
4672,4672,343,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157214,1697552158463,120,,,[16],[1697552157230]
4673,4673,509,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167171,1697552168554,120,,,[33],[1697552167204]
4674,4674,644,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.91 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.87 GiB is allocated by PyTorch, and 7.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552131780,1697552133252,120,,,[32],[1697552131812]
4675,4675,168,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552149368,1697552151582,120,,,"[69, 1512]","[1697552149437, 1697552150949]"
4676,4676,528,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154926,1697552156085,120,,,[29],[1697552154955]
4677,4677,618,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154372,1697552155496,120,,,[44],[1697552154416]
4678,4678,421,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 7.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552133255,1697552134059,120,,,[20],[1697552133275]
4679,4679,552,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552140780,1697552142272,120,,,"[69, 1290]","[1697552140849, 1697552142139]"
4680,4680,168,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552151595,1697552166084,120,,,"[65, 1633, 546, 571, 556, 572, 588, 44, 554, 527, 590, 661, 645, 674, 679, 699, 652, 673, 662, 686, 698, 982]","[1697552151660, 1697552153293, 1697552153839, 1697552154410, 1697552154966, 1697552155538, 1697552156126, 1697552156170, 1697552156724, 1697552157251, 1697552157841, 1697552158502, 1697552159147, 1697552159821, 1697552160500, 1697552161199, 1697552161851, 1697552162524, 1697552163186, 1697552163872, 1697552164570, 1697552165552]"
4681,4681,296,64,[],200,llama-13b,64,1,1501.0,1.0,1,A100,1697552134794,1697552136295,120,6.0,1.0,"[66, 1434]","[1697552134860, 1697552136294]"
4682,4682,386,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 6.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552155499,1697552156684,120,,,[29],[1697552155528]
4683,4683,76,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552136297,1697552137934,120,,,"[15, 1452]","[1697552136312, 1697552137764]"
4684,4684,279,77,[],200,llama-13b,64,1,3296.0,1.0,1,A100,1697552166101,1697552169397,120,67.0,18.0,"[76, 1741, 678, 44, 39, 43, 38, 42, 36, 37, 217, 39, 37, 37, 37, 42, 36, 40, 37]","[1697552166177, 1697552167918, 1697552168596, 1697552168640, 1697552168679, 1697552168722, 1697552168760, 1697552168802, 1697552168838, 1697552168875, 1697552169092, 1697552169131, 1697552169168, 1697552169205, 1697552169242, 1697552169284, 1697552169320, 1697552169360, 1697552169397]"
4685,4685,47,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156688,1697552158463,120,,,[28],[1697552156716]
4686,4686,585,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154926,1697552156085,120,,,[20],[1697552154946]
4687,4687,869,67,[],200,llama-13b,64,1,7561.0,1.0,1,A100,1697552151586,1697552159147,120,244.0,12.0,"[39, 1668, 545, 572, 555, 573, 588, 44, 554, 528, 590, 660, 645]","[1697552151625, 1697552153293, 1697552153838, 1697552154410, 1697552154965, 1697552155538, 1697552156126, 1697552156170, 1697552156724, 1697552157252, 1697552157842, 1697552158502, 1697552159147]"
4688,4688,304,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156088,1697552157212,120,,,[23],[1697552156111]
4689,4689,887,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157215,1697552158464,120,,,[25],[1697552157240]
4690,4690,633,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158466,1697552159781,120,,,[10],[1697552158476]
4691,4691,658,66,[],200,llama-13b,64,1,1226.0,1.0,1,A100,1697552137941,1697552139167,120,11.0,1.0,"[98, 1128]","[1697552138039, 1697552139167]"
4692,4692,287,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159786,1697552161160,120,,,[67],[1697552159853]
4693,4693,7,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158466,1697552159781,120,,,[25],[1697552158491]
4694,4694,350,69,[],200,llama-13b,64,1,1873.0,1.0,1,A100,1697552167174,1697552169047,120,216.0,1.0,"[84, 1788]","[1697552167258, 1697552169046]"
4695,4695,708,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159785,1697552161160,120,,,[48],[1697552159833]
4696,4696,239,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156088,1697552157800,120,,,[33],[1697552156121]
4697,4697,625,62,[],200,llama-13b,64,1,2320.0,1.0,1,A100,1697552142277,1697552144597,120,364.0,2.0,"[77, 2189, 54]","[1697552142354, 1697552144543, 1697552144597]"
4698,4698,67,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161174,1697552162485,120,,,[64],[1697552161238]
4699,4699,405,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 586.06 MiB is free. Process 1449637 has 38.82 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139170,1697552140772,120,,,"[14, 929, 54, 49, 47]","[1697552139184, 1697552140113, 1697552140167, 1697552140216, 1697552140263]"
4700,4700,652,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162489,1697552163833,120,,,[43],[1697552162532]
4701,4701,75,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 296.06 MiB is free. Process 1449637 has 39.10 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 8.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134062,1697552134789,120,,,[35],[1697552134097]
4702,4702,741,77,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158466,1697552159781,120,,,[20],[1697552158486]
4703,4703,11,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157803,1697552159107,120,,,[10],[1697552157813]
4704,4704,212,60,[],200,llama-13b,64,1,1242.0,1.0,1,A100,1697552142278,1697552143520,120,31.0,1.0,"[100, 1141]","[1697552142378, 1697552143519]"
4705,4705,397,78,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159784,1697552160461,120,,,[18],[1697552159802]
4706,4706,596,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159112,1697552160461,120,,,[76],[1697552159188]
4707,4707,362,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161168,1697552162485,120,,,[70],[1697552161238]
4708,4708,750,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.87 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.23 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552134792,1697552137935,120,,,"[46, 1457, 718]","[1697552134838, 1697552136295, 1697552137013]"
4709,4709,145,79,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160464,1697552162485,120,,,[75],[1697552160539]
4710,4710,421,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163836,1697552166085,120,,,"[48, 1516, 153]","[1697552163884, 1697552165400, 1697552165553]"
4711,4711,522,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159150,1697552160461,120,,,[39],[1697552159189]
4712,4712,58,68,[],200,llama-13b,64,1,1360.0,1.0,1,A100,1697552140779,1697552142139,120,15.0,1.0,"[26, 1334]","[1697552140805, 1697552142139]"
4713,4713,365,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160462,1697552161161,120,,,[21],[1697552160483]
4714,4714,764,69,[],200,llama-13b,64,1,832.0,1.0,1,A100,1697552142143,1697552142975,120,39.0,1.0,"[20, 811]","[1697552142163, 1697552142974]"
4715,4715,419,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142977,1697552145221,120,,,"[20, 1547, 53]","[1697552142997, 1697552144544, 1697552144597]"
4716,4716,270,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160464,1697552161813,120,,,[49],[1697552160513]
4717,4717,373,63,[],200,llama-13b,64,1,1354.0,1.0,1,A100,1697552144601,1697552145955,120,15.0,1.0,"[19, 1335]","[1697552144620, 1697552145955]"
4718,4718,909,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552143522,1697552145219,120,,,"[6, 1016, 53]","[1697552143528, 1697552144544, 1697552144597]"
4719,4719,727,80,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162488,1697552163833,120,,,[48],[1697552162536]
4720,4720,27,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.70 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.13 GiB is allocated by PyTorch, and 7.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145959,1697552147357,120,,,"[24, 1355]","[1697552145983, 1697552147338]"
4721,4721,569,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145224,1697552146631,120,,,[25],[1697552145249]
4722,4722,865,67,[],200,llama-13b,64,1,1826.0,1.0,1,A100,1697552166092,1697552167918,120,9.0,1.0,"[41, 1785]","[1697552166133, 1697552167918]"
4723,4723,523,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 29.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552137941,1697552139268,120,,,"[95, 1131]","[1697552138036, 1697552139167]"
4724,4724,34,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161820,1697552163147,120,,,[48],[1697552161868]
4725,4725,114,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161167,1697552162485,120,,,[45],[1697552161212]
4726,4726,727,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147361,1697552148670,120,,,[86],[1697552147447]
4727,4727,109,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162490,1697552163833,120,,,[66],[1697552162556]
4728,4728,690,72,[],200,llama-13b,64,1,1564.0,1.0,1,A100,1697552163836,1697552165400,120,39.0,1.0,"[32, 1532]","[1697552163868, 1697552165400]"
4729,4729,694,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162490,1697552163832,120,,,[66],[1697552162556]
4730,4730,471,77,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163834,1697552166084,120,,,"[13, 1553, 152]","[1697552163847, 1697552165400, 1697552165552]"
4731,4731,624,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163152,1697552166088,120,,,"[99, 2149, 152]","[1697552163251, 1697552165400, 1697552165552]"
4732,4732,335,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146643,1697552150143,120,,,"[107, 1223, 736, 685]","[1697552146750, 1697552147973, 1697552148709, 1697552149394]"
4733,4733,125,78,[],200,llama-13b,64,1,1825.0,1.0,1,A100,1697552166093,1697552167918,120,13.0,1.0,"[40, 1785]","[1697552166133, 1697552167918]"
4734,4734,920,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150147,1697552152618,120,,,[35],[1697552150182]
4735,4735,466,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165403,1697552167166,120,,,[11],[1697552165414]
4736,4736,189,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145225,1697552146631,120,,,[59],[1697552145284]
4737,4737,504,81,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163836,1697552166085,120,,,"[47, 1517, 153]","[1697552163883, 1697552165400, 1697552165553]"
4738,4738,393,72,[],200,llama-13b,64,1,3426.0,1.0,1,A100,1697552166101,1697552169527,120,182.0,22.0,"[76, 1741, 678, 44, 39, 43, 38, 42, 36, 37, 217, 39, 37, 37, 38, 41, 36, 40, 36, 41, 35, 28, 27]","[1697552166177, 1697552167918, 1697552168596, 1697552168640, 1697552168679, 1697552168722, 1697552168760, 1697552168802, 1697552168838, 1697552168875, 1697552169092, 1697552169131, 1697552169168, 1697552169205, 1697552169243, 1697552169284, 1697552169320, 1697552169360, 1697552169396, 1697552169437, 1697552169472, 1697552169500, 1697552169527]"
4739,4739,184,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.32 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.58 GiB is free. Process 1449637 has 35.80 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 3.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552139273,1697552142272,120,,,"[77, 2394]","[1697552139350, 1697552141744]"
4740,4740,121,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167175,1697552168555,120,,,[93],[1697552167268]
4741,4741,696,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152621,1697552153790,120,,,[6],[1697552152627]
4742,4742,350,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552153794,1697552154924,120,,,[38],[1697552153832]
4743,4743,884,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.34 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552142277,1697552145220,120,,,"[82, 2184, 54]","[1697552142359, 1697552144543, 1697552144597]"
4744,4744,98,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154928,1697552156085,120,,,[43],[1697552154971]
4745,4745,795,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 6.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156089,1697552156684,120,,,[43],[1697552156132]
4746,4746,538,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 6.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552145224,1697552146632,120,,,[27],[1697552145251]
4747,4747,456,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156686,1697552158463,120,,,[19],[1697552156705]
4748,4748,314,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552146640,1697552150142,120,,,"[63, 1270, 736, 685]","[1697552146703, 1697552147973, 1697552148709, 1697552149394]"
4749,4749,82,73,[],200,llama-13b,64,1,3372.0,1.0,1,A100,1697552166101,1697552169473,120,67.0,20.0,"[139, 1678, 678, 44, 39, 43, 38, 42, 36, 37, 217, 39, 37, 37, 38, 40, 37, 40, 37, 39, 37]","[1697552166240, 1697552167918, 1697552168596, 1697552168640, 1697552168679, 1697552168722, 1697552168760, 1697552168802, 1697552168838, 1697552168875, 1697552169092, 1697552169131, 1697552169168, 1697552169205, 1697552169243, 1697552169283, 1697552169320, 1697552169360, 1697552169397, 1697552169436, 1697552169473]"
4750,4750,775,72,[],200,llama-13b,64,1,1335.0,1.0,1,A100,1697552146638,1697552147973,120,17.0,1.0,"[57, 1278]","[1697552146695, 1697552147973]"
4751,4751,542,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552147977,1697552149356,120,,,[14],[1697552147991]
4752,4752,897,62,[],200,llama-13b,64,1,1288.0,1.0,1,A100,1697552150146,1697552151434,120,9.0,1.0,"[11, 1277]","[1697552150157, 1697552151434]"
4753,4753,672,63,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552151438,1697552152619,120,,,[11],[1697552151449]
4754,4754,388,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.33 GiB. GPU 0 has a total capacty of 39.39 GiB of which 40.06 MiB is free. Process 1449637 has 39.35 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 7.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552148674,1697552150142,120,,,"[94, 1354]","[1697552148768, 1697552150122]"
4755,4755,153,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 3.85 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 30.04 GiB is allocated by PyTorch, and 3.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552150146,1697552152618,120,,,[31],[1697552150177]
4756,4756,742,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152624,1697552154368,120,,,[63],[1697552152687]
4757,4757,511,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154372,1697552156085,120,,,[49],[1697552154421]
4758,4758,326,64,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 5.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552152625,1697552154368,120,,,[57],[1697552152682]
4759,4759,70,65,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 6.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552154372,1697552156085,120,,,[54],[1697552154426]
4760,4760,156,82,[],200,llama-13b,64,1,3378.0,1.0,1,A100,1697552166095,1697552169473,120,86.0,20.0,"[33, 1790, 678, 44, 39, 43, 38, 41, 37, 37, 218, 38, 37, 37, 37, 41, 37, 40, 36, 41, 36]","[1697552166128, 1697552167918, 1697552168596, 1697552168640, 1697552168679, 1697552168722, 1697552168760, 1697552168801, 1697552168838, 1697552168875, 1697552169093, 1697552169131, 1697552169168, 1697552169205, 1697552169242, 1697552169283, 1697552169320, 1697552169360, 1697552169396, 1697552169437, 1697552169473]"
4761,4761,653,66,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156087,1697552157801,120,,,[20],[1697552156107]
4762,4762,226,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158467,1697552159782,120,,,[44],[1697552158511]
4763,4763,172,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552156090,1697552157801,120,,,[67],[1697552156157]
4764,4764,424,67,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157804,1697552159107,120,,,[34],[1697552157838]
4765,4765,813,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159785,1697552161159,120,,,[42],[1697552159827]
4766,4766,203,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.10 GiB is free. Process 1449637 has 35.29 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552149359,1697552151582,120,,,"[27, 1563]","[1697552149386, 1697552150949]"
4767,4767,590,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161166,1697552162485,120,,,[36],[1697552161202]
4768,4768,902,75,[],200,llama-13b,64,1,6257.0,1.0,1,A100,1697552151585,1697552157842,120,335.0,10.0,"[15, 1692, 546, 572, 555, 573, 588, 44, 553, 528, 591]","[1697552151600, 1697552153292, 1697552153838, 1697552154410, 1697552154965, 1697552155538, 1697552156126, 1697552156170, 1697552156723, 1697552157251, 1697552157842]"
4769,4769,244,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162489,1697552163834,120,,,[52],[1697552162541]
4770,4770,873,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157804,1697552158463,120,,,[29],[1697552157833]
4771,4771,84,68,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159111,1697552160461,120,,,[68],[1697552159179]
4772,4772,781,69,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160463,1697552161812,120,,,[30],[1697552160493]
4773,4773,18,74,[],200,llama-13b,64,1,1564.0,1.0,1,A100,1697552163837,1697552165401,120,15.0,1.0,"[57, 1507]","[1697552163894, 1697552165401]"
4774,4774,601,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165404,1697552167166,120,,,[24],[1697552165428]
4775,4775,349,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167173,1697552168555,120,,,[45],[1697552167218]
4776,4776,557,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.37 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 6.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552157845,1697552159107,120,,,[31],[1697552157876]
4777,4777,526,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552158466,1697552159781,120,,,[25],[1697552158491]
4778,4778,305,77,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.93 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159109,1697552159782,120,,,[20],[1697552159129]
4779,4779,441,70,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161817,1697552163147,120,,,[46],[1697552161863]
4780,4780,212,71,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163150,1697552164529,120,,,[46],[1697552163196]
4781,4781,799,72,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164532,1697552166085,120,,,"[48, 1382]","[1697552164580, 1697552165962]"
4782,4782,576,73,[],200,llama-13b,64,1,1818.0,1.0,1,A100,1697552166100,1697552167918,120,14.0,1.0,"[72, 1746]","[1697552166172, 1697552167918]"
4783,4783,75,78,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159785,1697552161160,120,,,[43],[1697552159828]
4784,4784,274,73,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 29.96 GiB is allocated by PyTorch, and 6.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552159784,1697552160461,120,,,[23],[1697552159807]
4785,4785,668,79,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552161162,1697552162485,120,,,[21],[1697552161183]
4786,4786,436,80,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.03 GiB is allocated by PyTorch, and 6.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162487,1697552163832,120,,,[24],[1697552162511]
4787,4787,858,74,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552160466,1697552162485,120,,,[100],[1697552160566]
4788,4788,97,81,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163835,1697552164530,120,,,[19],[1697552163854]
4789,4789,795,82,[],200,llama-13b,64,1,1429.0,1.0,1,A100,1697552164533,1697552165962,120,12.0,1.0,"[50, 1379]","[1697552164583, 1697552165962]"
4790,4790,635,75,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552162487,1697552163147,120,,,[5],[1697552162492]
4791,4791,288,76,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.24 GiB is free. Process 1449637 has 38.14 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 6.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552163150,1697552164528,120,,,[32],[1697552163182]
4792,4792,451,83,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.03 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.63 GiB is free. Process 1449637 has 35.76 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552165965,1697552167166,120,,,[24],[1697552165989]
4793,4793,227,84,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 39.39 GiB of which 1.30 GiB is free. Process 1449637 has 38.09 GiB memory in use. Of the allocated memory 30.00 GiB is allocated by PyTorch, and 6.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552167172,1697552168555,120,,,[41],[1697552167213]
4794,4794,60,77,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 4.18 GiB. GPU 0 has a total capacty of 39.39 GiB of which 3.81 GiB is free. Process 1449637 has 35.57 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-13b,64,1,,,1,A100,1697552164532,1697552166087,120,,,"[36, 984]","[1697552164568, 1697552165552]"
4795,4795,649,78,[],200,llama-13b,64,1,3372.0,1.0,1,A100,1697552166100,1697552169472,120,244.0,20.0,"[63, 1755, 678, 44, 39, 43, 38, 42, 36, 37, 217, 39, 37, 37, 38, 41, 36, 40, 36, 41, 35]","[1697552166163, 1697552167918, 1697552168596, 1697552168640, 1697552168679, 1697552168722, 1697552168760, 1697552168802, 1697552168838, 1697552168875, 1697552169092, 1697552169131, 1697552169168, 1697552169205, 1697552169243, 1697552169284, 1697552169320, 1697552169360, 1697552169396, 1697552169437, 1697552169472]"
