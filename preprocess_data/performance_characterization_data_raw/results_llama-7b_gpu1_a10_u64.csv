,Unnamed: 0,smpnum,reqnum,errors,status,model,num_users,requests,latency_ms,records,n_gpus,gpu_type,start_timestamp,end_timestamp,experiment_duration_s,n_input_tokens,n_output_tokens,latency_ms_per_token,timestamps_per_token
0,0,444,0,[],200,llama-7b,64,1,5346.0,1.0,1,A10,1697122345435,1697122350781,120,457.0,6.0,"[31, 678, 55, 1232, 1193, 1212, 945]","[1697122345466, 1697122346144, 1697122346199, 1697122347431, 1697122348624, 1697122349836, 1697122350781]"
1,1,208,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345435,1697122353148,120,,,"[27, 682, 54, 1233, 1193, 1212, 945, 1366]","[1697122345462, 1697122346144, 1697122346198, 1697122347431, 1697122348624, 1697122349836, 1697122350781, 1697122352147]"
2,2,11,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345438,1697122347385,120,,,[131],[1697122345569]
3,3,258,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345435,1697122353148,120,,,"[16, 693, 54, 1233, 1193, 1211, 946, 1366]","[1697122345451, 1697122346144, 1697122346198, 1697122347431, 1697122348624, 1697122349835, 1697122350781, 1697122352147]"
4,4,836,0,[],200,llama-7b,64,1,707.0,1.0,1,A10,1697122345437,1697122346144,120,11.0,1.0,"[59, 648]","[1697122345496, 1697122346144]"
5,5,673,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345438,1697122347381,120,,,[106],[1697122345544]
6,6,371,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345478,1697122347385,120,,,[187],[1697122345665]
7,7,394,0,[],200,llama-7b,64,1,706.0,1.0,1,A10,1697122345438,1697122346144,120,11.0,1.0,"[39, 667]","[1697122345477, 1697122346144]"
8,8,93,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345439,1697122347384,120,,,[116],[1697122345555]
9,9,879,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345438,1697122347381,120,,,[96],[1697122345534]
10,10,753,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345438,1697122353148,120,,,"[43, 663, 55, 1232, 1193, 1212, 945, 1366]","[1697122345481, 1697122346144, 1697122346199, 1697122347431, 1697122348624, 1697122349836, 1697122350781, 1697122352147]"
11,11,39,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345478,1697122347385,120,,,[206],[1697122345684]
12,12,202,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345478,1697122348579,120,,,[201],[1697122345679]
13,13,448,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345437,1697122347381,120,,,[98],[1697122345535]
14,14,837,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345437,1697122353148,120,,,"[50, 658, 54, 1232, 1194, 1211, 945, 1366]","[1697122345487, 1697122346145, 1697122346199, 1697122347431, 1697122348625, 1697122349836, 1697122350781, 1697122352147]"
15,15,69,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345439,1697122347385,120,,,[194],[1697122345633]
16,16,921,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345478,1697122347385,120,,,[191],[1697122345669]
17,17,339,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345479,1697122348579,120,,,[196],[1697122345675]
18,18,284,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345438,1697122347381,120,,,[63],[1697122345501]
19,19,262,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345437,1697122347381,120,,,[65],[1697122345502]
20,20,575,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347391,1697122349790,120,,,[53],[1697122347444]
21,21,52,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347387,1697122348579,120,,,[25],[1697122347412]
22,22,744,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347392,1697122349791,120,,,[138],[1697122347530]
23,23,175,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345438,1697122347387,120,,,[116],[1697122345554]
24,24,764,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347394,1697122349791,120,,,[83],[1697122347477]
25,25,928,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 4.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122348583,1697122350736,120,,,[47],[1697122348630]
26,26,231,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345478,1697122347385,120,,,[187],[1697122345665]
27,27,841,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347388,1697122349791,120,,,[41],[1697122347429]
28,28,536,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349794,1697122352103,120,,,[49],[1697122349843]
29,29,536,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345436,1697122353148,120,,,"[21, 687, 54, 1233, 1193, 1212, 945, 1367]","[1697122345457, 1697122346144, 1697122346198, 1697122347431, 1697122348624, 1697122349836, 1697122350781, 1697122352148]"
30,30,822,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347389,1697122349790,120,,,[35],[1697122347424]
31,31,613,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345438,1697122353148,120,,,"[44, 662, 55, 1232, 1194, 1211, 945, 1366]","[1697122345482, 1697122346144, 1697122346199, 1697122347431, 1697122348625, 1697122349836, 1697122350781, 1697122352147]"
32,32,119,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345478,1697122347384,120,,,[167],[1697122345645]
33,33,778,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345439,1697122347381,120,,,[106],[1697122345545]
34,34,630,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347387,1697122348579,120,,,[11],[1697122347398]
35,35,231,0,[],200,llama-7b,64,1,706.0,1.0,1,A10,1697122345438,1697122346144,120,13.0,1.0,"[33, 673]","[1697122345471, 1697122346144]"
36,36,618,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349797,1697122352103,120,,,[148],[1697122349945]
37,37,507,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345438,1697122347381,120,,,[102],[1697122345540]
38,38,550,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347392,1697122349791,120,,,[70],[1697122347462]
39,39,161,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347388,1697122348579,120,,,[19],[1697122347407]
40,40,398,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122348580,1697122349790,120,,,[24],[1697122348604]
41,41,266,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353153,1697122355808,120,,,[39],[1697122353192]
42,42,490,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122346146,1697122347385,120,,,[17],[1697122346163]
43,43,818,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122346146,1697122347385,120,,,[6],[1697122346152]
44,44,60,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349794,1697122352103,120,,,[44],[1697122349838]
45,45,38,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355811,1697122357987,120,,,[17],[1697122355828]
46,46,672,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345437,1697122347386,120,,,[113],[1697122345550]
47,47,267,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347392,1697122349791,120,,,[75],[1697122347467]
48,48,752,0,[],200,llama-7b,64,1,1996.0,1.0,1,A10,1697122345435,1697122347431,120,39.0,3.0,"[17, 692, 54, 1233]","[1697122345452, 1697122346144, 1697122346198, 1697122347431]"
49,49,533,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345440,1697122347384,120,,,[215],[1697122345655]
50,50,96,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345478,1697122347385,120,,,[182],[1697122345660]
51,51,631,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122357991,1697122362056,120,,,"[36, 3103]","[1697122358027, 1697122361130]"
52,52,325,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347393,1697122349791,120,,,[80],[1697122347473]
53,53,791,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347394,1697122349791,120,,,[88],[1697122347482]
54,54,851,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349799,1697122352104,120,,,[156],[1697122349955]
55,55,837,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 4.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122348582,1697122350736,120,,,[43],[1697122348625]
56,56,596,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347391,1697122349790,120,,,[58],[1697122347449]
57,57,621,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352109,1697122354314,120,,,[66],[1697122352175]
58,58,756,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352110,1697122354309,120,,,[135],[1697122352245]
59,59,452,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349795,1697122352104,120,,,[87],[1697122349882]
60,60,72,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349794,1697122352103,120,,,[49],[1697122349843]
61,61,417,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354319,1697122356967,120,,,[57],[1697122354376]
62,62,219,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352106,1697122353148,120,,,"[24, 940]","[1697122352130, 1697122353070]"
63,63,186,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356973,1697122359214,120,,,[29],[1697122357002]
64,64,810,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353152,1697122355809,120,,,[45],[1697122353197]
65,65,221,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122350783,1697122353149,120,,,"[47, 2241]","[1697122350830, 1697122353071]"
66,66,281,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354322,1697122356969,120,,,[127],[1697122354449]
67,67,563,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345438,1697122347383,120,,,[212],[1697122345650]
68,68,718,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345438,1697122347385,120,,,[136],[1697122345574]
69,69,771,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359218,1697122361069,120,,,[54],[1697122359272]
70,70,579,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355816,1697122357988,120,,,[128],[1697122355944]
71,71,424,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345438,1697122353148,120,,,"[54, 652, 55, 1232, 1194, 1211, 945, 1366]","[1697122345492, 1697122346144, 1697122346199, 1697122347431, 1697122348625, 1697122349836, 1697122350781, 1697122352147]"
72,72,39,0,[],200,llama-7b,64,1,705.0,1.0,1,A10,1697122345439,1697122346144,120,8.0,1.0,"[37, 668]","[1697122345476, 1697122346144]"
73,73,234,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122357990,1697122362056,120,,,"[34, 2135, 971]","[1697122358024, 1697122360159, 1697122361130]"
74,74,343,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345437,1697122347385,120,,,[127],[1697122345564]
75,75,551,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361075,1697122363189,120,,,[71],[1697122361146]
76,76,858,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345478,1697122347385,120,,,[177],[1697122345655]
77,77,216,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347386,1697122348579,120,,,[11],[1697122347397]
78,78,698,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345439,1697122347384,120,,,[192],[1697122345631]
79,79,444,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347388,1697122348579,120,,,[15],[1697122347403]
80,80,928,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347390,1697122349791,120,,,[49],[1697122347439]
81,81,553,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345438,1697122347381,120,,,[111],[1697122345549]
82,82,98,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 4.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122348582,1697122350736,120,,,[47],[1697122348629]
83,83,371,0,[],200,llama-7b,64,1,707.0,1.0,1,A10,1697122345438,1697122346145,120,13.0,1.0,"[59, 647]","[1697122345497, 1697122346144]"
84,84,803,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122350740,1697122352105,120,,,[37],[1697122350777]
85,85,85,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353152,1697122355808,120,,,[35],[1697122353187]
86,86,459,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352110,1697122354308,120,,,[130],[1697122352240]
87,87,25,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122346148,1697122347385,120,,,[14],[1697122346162]
88,88,738,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122346146,1697122348579,120,,,[23],[1697122346169]
89,89,781,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355812,1697122357987,120,,,[27],[1697122355839]
90,90,228,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354315,1697122356967,120,,,[17],[1697122354332]
91,91,701,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347394,1697122349791,120,,,[136],[1697122347530]
92,92,175,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345437,1697122347381,120,,,[69],[1697122345506]
93,93,435,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122357990,1697122362056,120,,,"[24, 2145, 971]","[1697122358014, 1697122360159, 1697122361130]"
94,94,99,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345439,1697122347384,120,,,[135],[1697122345574]
95,95,55,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122346147,1697122347385,120,,,[10],[1697122346157]
96,96,427,0,[],200,llama-7b,64,1,4401.0,1.0,1,A10,1697122345435,1697122349836,120,58.0,5.0,"[32, 677, 55, 1232, 1193, 1212]","[1697122345467, 1697122346144, 1697122346199, 1697122347431, 1697122348624, 1697122349836]"
97,97,469,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349795,1697122352105,120,,,[87],[1697122349882]
98,98,400,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122348580,1697122349790,120,,,[19],[1697122348599]
99,99,130,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352111,1697122354312,120,,,[140],[1697122352251]
100,100,81,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349837,1697122352103,120,,,[118],[1697122349955]
101,101,679,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347391,1697122349790,120,,,[56],[1697122347447]
102,102,825,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354319,1697122356969,120,,,[47],[1697122354366]
103,103,757,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347395,1697122349790,120,,,[157],[1697122347552]
104,104,449,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349795,1697122352104,120,,,[78],[1697122349873]
105,105,764,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347392,1697122349791,120,,,[76],[1697122347468]
106,106,818,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356975,1697122359213,120,,,[161],[1697122357136]
107,107,110,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352109,1697122354308,120,,,[78],[1697122352187]
108,108,534,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349796,1697122352103,120,,,[145],[1697122349941]
109,109,169,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349797,1697122352103,120,,,[148],[1697122349945]
110,110,861,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345438,1697122347381,120,,,[101],[1697122345539]
111,111,13,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345439,1697122347385,120,,,[130],[1697122345569]
112,112,854,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345438,1697122347385,120,,,[197],[1697122345635]
113,113,609,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345435,1697122353148,120,,,"[12, 697, 54, 1233, 1193, 1211, 946, 1366]","[1697122345447, 1697122346144, 1697122346198, 1697122347431, 1697122348624, 1697122349835, 1697122350781, 1697122352147]"
114,114,69,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345478,1697122348579,120,,,[192],[1697122345670]
115,115,778,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345438,1697122347385,120,,,[121],[1697122345559]
116,116,711,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347390,1697122349790,120,,,[52],[1697122347442]
117,117,417,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 4.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349793,1697122350736,120,,,[35],[1697122349828]
118,118,280,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347389,1697122349790,120,,,[28],[1697122347417]
119,119,158,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345435,1697122353147,120,,,"[10, 55, 698, 1233, 1193, 1211, 946, 1366]","[1697122345445, 1697122345500, 1697122346198, 1697122347431, 1697122348624, 1697122349835, 1697122350781, 1697122352147]"
120,120,401,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362059,1697122364142,120,,,[7],[1697122362066]
121,121,273,3,[],200,llama-7b,64,1,963.0,1.0,1,A10,1697122352108,1697122353071,120,19.0,1.0,"[34, 929]","[1697122352142, 1697122353071]"
122,122,693,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345438,1697122347385,120,,,[126],[1697122345564]
123,123,626,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347390,1697122349791,120,,,[62],[1697122347452]
124,124,149,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122364149,1697122371105,120,,,"[80, 1810, 994, 985, 1073, 1063]","[1697122364229, 1697122366039, 1697122367033, 1697122368018, 1697122369091, 1697122370154]"
125,125,328,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347386,1697122348578,120,,,[18],[1697122347404]
126,126,697,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349794,1697122352103,120,,,[44],[1697122349838]
127,127,202,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345478,1697122348578,120,,,[197],[1697122345675]
128,128,13,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345439,1697122347381,120,,,[201],[1697122345640]
129,129,462,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347392,1697122349791,120,,,[80],[1697122347472]
130,130,118,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349794,1697122352104,120,,,[78],[1697122349872]
131,131,413,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353153,1697122355809,120,,,[49],[1697122353202]
132,132,430,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347392,1697122349791,120,,,[71],[1697122347463]
133,133,659,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347399,1697122349791,120,,,[136],[1697122347535]
134,134,592,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 4.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349793,1697122350737,120,,,[30],[1697122349823]
135,135,372,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349795,1697122352103,120,,,[58],[1697122349853]
136,136,430,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349794,1697122352103,120,,,[64],[1697122349858]
137,137,627,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347390,1697122349790,120,,,[43],[1697122347433]
138,138,84,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352109,1697122354308,120,,,[126],[1697122352235]
139,139,249,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 4.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349793,1697122350737,120,,,[25],[1697122349818]
140,140,807,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353154,1697122355809,120,,,[80],[1697122353234]
141,141,203,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349795,1697122352104,120,,,[82],[1697122349877]
142,142,43,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353074,1697122354307,120,,,[23],[1697122353097]
143,143,207,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349797,1697122352105,120,,,[143],[1697122349940]
144,144,553,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345435,1697122353148,120,,,"[26, 683, 55, 1232, 1193, 1212, 945, 1366]","[1697122345461, 1697122346144, 1697122346199, 1697122347431, 1697122348624, 1697122349836, 1697122350781, 1697122352147]"
145,145,793,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352111,1697122354314,120,,,[148],[1697122352259]
146,146,781,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352107,1697122353148,120,,,"[30, 933]","[1697122352137, 1697122353070]"
147,147,912,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352110,1697122354308,120,,,[121],[1697122352231]
148,148,920,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122348581,1697122349790,120,,,[24],[1697122348605]
149,149,427,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345439,1697122347383,120,,,[206],[1697122345645]
150,150,795,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347387,1697122348579,120,,,[27],[1697122347414]
151,151,565,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354322,1697122356969,120,,,[131],[1697122354453]
152,152,582,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349795,1697122352103,120,,,[68],[1697122349863]
153,153,199,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347390,1697122349791,120,,,[64],[1697122347454]
154,154,641,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345435,1697122353148,120,,,"[21, 688, 54, 1233, 1193, 1211, 946, 1366]","[1697122345456, 1697122346144, 1697122346198, 1697122347431, 1697122348624, 1697122349835, 1697122350781, 1697122352147]"
155,155,396,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349796,1697122352105,120,,,[135],[1697122349931]
156,156,98,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122348582,1697122349790,120,,,[28],[1697122348610]
157,157,435,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353151,1697122355807,120,,,[20],[1697122353171]
158,158,645,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122348580,1697122349790,120,,,[15],[1697122348595]
159,159,908,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122348581,1697122349790,120,,,[19],[1697122348600]
160,160,533,0,[],200,llama-7b,64,1,760.0,1.0,1,A10,1697122345439,1697122346199,120,216.0,2.0,"[52, 708]","[1697122345491, 1697122346199]"
161,161,189,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352107,1697122353148,120,,,"[21, 942]","[1697122352128, 1697122353070]"
162,162,141,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347392,1697122349791,120,,,[65],[1697122347457]
163,163,144,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352110,1697122354309,120,,,[139],[1697122352249]
164,164,217,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347389,1697122349791,120,,,[38],[1697122347427]
165,165,655,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 4.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122348582,1697122350736,120,,,[33],[1697122348615]
166,166,609,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345437,1697122347381,120,,,[93],[1697122345530]
167,167,823,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352108,1697122354309,120,,,[52],[1697122352160]
168,168,143,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352107,1697122353148,120,,,"[15, 948]","[1697122352122, 1697122353070]"
169,169,493,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122350740,1697122352105,120,,,[32],[1697122350772]
170,170,165,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122346201,1697122348579,120,,,[6],[1697122346207]
171,171,228,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345438,1697122353148,120,,,"[34, 672, 55, 1232, 1194, 1211, 945, 1366]","[1697122345472, 1697122346144, 1697122346199, 1697122347431, 1697122348625, 1697122349836, 1697122350781, 1697122352147]"
172,172,590,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.03 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345438,1697122347385,120,,,[121],[1697122345559]
173,173,806,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354315,1697122356967,120,,,[22],[1697122354337]
174,174,632,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354314,1697122356967,120,,,[22],[1697122354336]
175,175,449,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122348582,1697122349791,120,,,[38],[1697122348620]
176,176,351,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352107,1697122353149,120,,,"[33, 931]","[1697122352140, 1697122353071]"
177,177,414,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349796,1697122352105,120,,,[140],[1697122349936]
178,178,252,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122350740,1697122353149,120,,,"[37, 2293]","[1697122350777, 1697122353070]"
179,179,413,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347432,1697122349790,120,,,[125],[1697122347557]
180,180,70,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352110,1697122354309,120,,,[131],[1697122352241]
181,181,864,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349794,1697122352102,120,,,[54],[1697122349848]
182,182,380,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347388,1697122348579,120,,,[21],[1697122347409]
183,183,262,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352110,1697122354311,120,,,[144],[1697122352254]
184,184,866,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353151,1697122355807,120,,,[25],[1697122353176]
185,185,480,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356975,1697122359215,120,,,[104],[1697122357079]
186,186,287,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349795,1697122352104,120,,,[82],[1697122349877]
187,187,840,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352108,1697122354308,120,,,[47],[1697122352155]
188,188,789,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354318,1697122356969,120,,,[48],[1697122354366]
189,189,400,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356973,1697122359213,120,,,[19],[1697122356992]
190,190,164,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352109,1697122354308,120,,,[76],[1697122352185]
191,191,389,0,[],200,llama-7b,64,1,707.0,1.0,1,A10,1697122345438,1697122346145,120,8.0,1.0,"[48, 659]","[1697122345486, 1697122346145]"
192,192,148,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359217,1697122361069,120,,,[50],[1697122359267]
193,193,301,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347394,1697122349790,120,,,[153],[1697122347547]
194,194,738,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353151,1697122355807,120,,,[10],[1697122353161]
195,195,805,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345478,1697122348579,120,,,[182],[1697122345660]
196,196,591,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122345478,1697122348578,120,,,[172],[1697122345650]
197,197,477,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354322,1697122356969,120,,,[126],[1697122354448]
198,198,578,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355816,1697122357988,120,,,[118],[1697122355934]
199,199,205,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363193,1697122365125,120,,,[26],[1697122363219]
200,200,24,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122350740,1697122353149,120,,,[57],[1697122350797]
201,201,239,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122357991,1697122362056,120,,,"[48, 2120, 971]","[1697122358039, 1697122360159, 1697122361130]"
202,202,606,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353155,1697122355809,120,,,[94],[1697122353249]
203,203,564,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354319,1697122356969,120,,,[42],[1697122354361]
204,204,384,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355813,1697122357987,120,,,[36],[1697122355849]
205,205,252,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356974,1697122359215,120,,,[62],[1697122357036]
206,206,38,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122357990,1697122362056,120,,,"[10, 2158, 971]","[1697122358000, 1697122360158, 1697122361129]"
207,207,212,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362065,1697122364143,120,,,[95],[1697122362160]
208,208,907,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122348582,1697122349790,120,,,[32],[1697122348614]
209,209,733,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362061,1697122364143,120,,,[69],[1697122362130]
210,210,410,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353153,1697122355809,120,,,[86],[1697122353239]
211,211,835,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359220,1697122361069,120,,,[119],[1697122359339]
212,212,792,5,[],200,llama-7b,64,1,1890.0,1.0,1,A10,1697122364149,1697122366039,120,11.0,1.0,"[101, 1789]","[1697122364250, 1697122366039]"
213,213,481,9,[],200,llama-7b,64,1,1887.0,1.0,1,A10,1697122364153,1697122366040,120,10.0,1.0,"[117, 1770]","[1697122364270, 1697122366040]"
214,214,71,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355814,1697122357988,120,,,[62],[1697122355876]
215,215,10,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353155,1697122355809,120,,,[94],[1697122353249]
216,216,708,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355816,1697122357988,120,,,[121],[1697122355937]
217,217,540,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366044,1697122367968,120,,,[27],[1697122366071]
218,218,615,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361071,1697122362056,120,,,"[23, 808]","[1697122361094, 1697122361902]"
219,219,340,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122357991,1697122362056,120,,,"[41, 2127, 971]","[1697122358032, 1697122360159, 1697122361130]"
220,220,866,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354315,1697122356968,120,,,[32],[1697122354347]
221,221,112,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362060,1697122364142,120,,,[7],[1697122362067]
222,222,271,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362060,1697122364142,120,,,[11],[1697122362071]
223,223,695,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122364146,1697122371104,120,,,"[24, 1869, 993, 985, 1073, 1064]","[1697122364170, 1697122366039, 1697122367032, 1697122368017, 1697122369090, 1697122370154]"
224,224,49,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356974,1697122359213,120,,,[75],[1697122357049]
225,225,40,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122364145,1697122371103,120,,,"[14, 1880, 993, 985, 1073, 1064]","[1697122364159, 1697122366039, 1697122367032, 1697122368017, 1697122369090, 1697122370154]"
226,226,220,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 4.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349793,1697122350737,120,,,[25],[1697122349818]
227,227,183,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355813,1697122357987,120,,,[41],[1697122355854]
228,228,635,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359220,1697122361070,120,,,[138],[1697122359358]
229,229,161,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122346148,1697122348579,120,,,[26],[1697122346174]
230,230,304,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353151,1697122355808,120,,,[15],[1697122353166]
231,231,405,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361076,1697122363190,120,,,[81],[1697122361157]
232,232,767,3,[],200,llama-7b,64,1,2167.0,1.0,1,A10,1697122357992,1697122360159,120,11.0,1.0,"[63, 2104]","[1697122358055, 1697122360159]"
233,233,60,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363195,1697122365125,120,,,[57],[1697122363252]
234,234,737,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365129,1697122366981,120,,,[26],[1697122365155]
235,235,716,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371107,1697122373010,120,,,[6],[1697122371113]
236,236,865,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355816,1697122357988,120,,,[124],[1697122355940]
237,237,506,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366988,1697122369039,120,,,[76],[1697122367064]
238,238,537,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122360161,1697122362056,120,,,"[19, 1722]","[1697122360180, 1697122361902]"
239,239,837,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122348582,1697122349790,120,,,[37],[1697122348619]
240,240,634,3,[],200,llama-7b,64,1,2164.0,1.0,1,A10,1697122357995,1697122360159,120,13.0,1.0,"[66, 2098]","[1697122358061, 1697122360159]"
241,241,289,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122360162,1697122362056,120,,,"[28, 1713]","[1697122360190, 1697122361903]"
242,242,492,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 4.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349792,1697122350737,120,,,[16],[1697122349808]
243,243,370,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373014,1697122374082,120,,,[38],[1697122373052]
244,244,467,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371111,1697122374081,120,,,[67],[1697122371178]
245,245,66,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362060,1697122364142,120,,,[26],[1697122362086]
246,246,809,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122350739,1697122352105,120,,,[33],[1697122350772]
247,247,120,11,[],200,llama-7b,64,1,1852.0,1.0,1,A10,1697122374085,1697122375937,120,17.0,1.0,"[50, 1802]","[1697122374135, 1697122375937]"
248,248,776,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354318,1697122356968,120,,,[38],[1697122354356]
249,249,825,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375940,1697122378082,120,,,"[20, 1223]","[1697122375960, 1697122377183]"
250,250,635,3,[],200,llama-7b,64,1,965.0,1.0,1,A10,1697122352106,1697122353071,120,23.0,1.0,"[19, 945]","[1697122352125, 1697122353070]"
251,251,734,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361074,1697122363190,120,,,[77],[1697122361151]
252,252,430,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356975,1697122359214,120,,,[79],[1697122357054]
253,253,506,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363196,1697122365126,120,,,[77],[1697122363273]
254,254,167,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122369041,1697122370101,120,,,[19],[1697122369060]
255,255,600,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347393,1697122349791,120,,,[149],[1697122347542]
256,256,175,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359218,1697122361068,120,,,[39],[1697122359257]
257,257,864,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370105,1697122371105,120,,,"[40, 826]","[1697122370145, 1697122370971]"
258,258,41,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 4.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122348584,1697122350737,120,,,[51],[1697122348635]
259,259,874,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361071,1697122362056,120,,,"[13, 819]","[1697122361084, 1697122361903]"
260,260,478,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378095,1697122380019,120,,,"[38, 1803]","[1697122378133, 1697122379936]"
261,261,743,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122350740,1697122353149,120,,,"[47, 2283]","[1697122350787, 1697122353070]"
262,262,31,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353152,1697122355808,120,,,[44],[1697122353196]
263,263,531,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362062,1697122364142,120,,,[81],[1697122362143]
264,264,404,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353155,1697122355809,120,,,[99],[1697122353254]
265,265,528,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371112,1697122373011,120,,,[56],[1697122371168]
266,266,172,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355816,1697122357988,120,,,[115],[1697122355931]
267,267,298,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373014,1697122374082,120,,,[43],[1697122373057]
268,268,849,6,[],200,llama-7b,64,1,2166.0,1.0,1,A10,1697122357993,1697122360159,120,10.0,1.0,"[71, 2095]","[1697122358064, 1697122360159]"
269,269,255,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380031,1697122381805,120,,,[99],[1697122380130]
270,270,839,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381809,1697122382783,120,,,[19],[1697122381828]
271,271,612,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355811,1697122357987,120,,,[26],[1697122355837]
272,272,609,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122382786,1697122383906,120,,,"[18, 1079]","[1697122382804, 1697122383883]"
273,273,389,3,[],200,llama-7b,64,1,2168.0,1.0,1,A10,1697122357991,1697122360159,120,8.0,1.0,"[31, 2137]","[1697122358022, 1697122360159]"
274,274,42,4,[],200,llama-7b,64,1,1742.0,1.0,1,A10,1697122360161,1697122361903,120,10.0,1.0,"[6, 1735]","[1697122360167, 1697122361902]"
275,275,882,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374085,1697122375086,120,,,[30],[1697122374115]
276,276,659,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375090,1697122378079,120,,,"[47, 2046]","[1697122375137, 1697122377183]"
277,277,369,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 4.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349793,1697122350737,120,,,[14],[1697122349807]
278,278,742,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361906,1697122363190,120,,,[21],[1697122361927]
279,279,312,18,[],200,llama-7b,64,1,1849.0,1.0,1,A10,1697122378087,1697122379936,120,23.0,1.0,"[31, 1818]","[1697122378118, 1697122379936]"
280,280,1,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122350740,1697122353149,120,,,"[42, 2288]","[1697122350782, 1697122353070]"
281,281,404,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363194,1697122365125,120,,,[35],[1697122363229]
282,282,59,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122379939,1697122383905,120,,,"[16, 978, 925, 974]","[1697122379955, 1697122380933, 1697122381858, 1697122382832]"
283,283,502,7,[],200,llama-7b,64,1,1739.0,1.0,1,A10,1697122360164,1697122361903,120,19.0,1.0,"[28, 1711]","[1697122360192, 1697122361903]"
284,284,173,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365133,1697122366982,120,,,[123],[1697122365256]
285,285,641,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383913,1697122385618,120,,,[129],[1697122384042]
286,286,414,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385621,1697122386861,120,,,[14],[1697122385635]
287,287,273,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361907,1697122363190,120,,,[33],[1697122361940]
288,288,70,22,[],200,llama-7b,64,1,2153.0,1.0,1,A10,1697122386866,1697122389019,120,39.0,1.0,"[98, 2055]","[1697122386964, 1697122389019]"
289,289,734,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366985,1697122367969,120,,,[19],[1697122367004]
290,290,863,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363195,1697122365126,120,,,[73],[1697122363268]
291,291,244,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122348580,1697122349790,120,,,[14],[1697122348594]
292,292,768,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389022,1697122391051,120,,,"[19, 998]","[1697122389041, 1697122390039]"
293,293,704,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353154,1697122355808,120,,,[85],[1697122353239]
294,294,21,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 4.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349793,1697122350737,120,,,[35],[1697122349828]
295,295,629,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365136,1697122367968,120,,,[126],[1697122365262]
296,296,505,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367972,1697122370100,120,,,[44],[1697122368016]
297,297,329,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352108,1697122354309,120,,,[57],[1697122352165]
298,298,288,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367970,1697122370100,120,,,[16],[1697122367986]
299,299,600,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122350738,1697122352104,120,,,[19],[1697122350757]
300,300,99,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354315,1697122356968,120,,,[26],[1697122354341]
301,301,211,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355819,1697122357988,120,,,[131],[1697122355950]
302,302,346,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 4.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349793,1697122350737,120,,,[20],[1697122349813]
303,303,165,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370104,1697122371104,120,,,"[13, 854]","[1697122370117, 1697122370971]"
304,304,467,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356973,1697122359213,120,,,[25],[1697122356998]
305,305,926,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353151,1697122355808,120,,,[11],[1697122353162]
306,306,237,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359217,1697122361068,120,,,[20],[1697122359237]
307,307,429,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391057,1697122392786,120,,,[26],[1697122391083]
308,308,796,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122357993,1697122362057,120,,,"[63, 2103, 971]","[1697122358056, 1697122360159, 1697122361130]"
309,309,196,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392792,1697122395177,120,,,[52],[1697122392844]
310,310,57,12,[],200,llama-7b,64,1,1916.0,1.0,1,A10,1697122370106,1697122372022,120,13.0,1.0,"[48, 1868]","[1697122370154, 1697122372022]"
311,311,821,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361071,1697122362057,120,,,"[33, 799]","[1697122361104, 1697122361903]"
312,312,648,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122372026,1697122374082,120,,,[25],[1697122372051]
313,313,565,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362061,1697122364144,120,,,[69],[1697122362130]
314,314,375,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352105,1697122353148,120,,,[11],[1697122352116]
315,315,582,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359221,1697122361070,120,,,[61],[1697122359282]
316,316,313,7,[],200,llama-7b,64,1,1888.0,1.0,1,A10,1697122364153,1697122366041,120,20.0,1.0,"[122, 1765]","[1697122364275, 1697122366040]"
317,317,242,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361078,1697122363191,120,,,[94],[1697122361172]
318,318,894,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366044,1697122367968,120,,,[45],[1697122366089]
319,319,13,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363195,1697122365125,120,,,[68],[1697122363263]
320,320,674,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367974,1697122370102,120,,,[79],[1697122368053]
321,321,597,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365129,1697122366981,120,,,[20],[1697122365149]
322,322,419,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374086,1697122376090,120,,,"[63, 1788]","[1697122374149, 1697122375937]"
323,323,72,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376096,1697122378082,120,,,"[43, 1793]","[1697122376139, 1697122377932]"
324,324,29,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353152,1697122355808,120,,,[39],[1697122353191]
325,325,328,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370105,1697122376091,120,,,"[64, 1853, 1042, 1068, 1005]","[1697122370169, 1697122372022, 1697122373064, 1697122374132, 1697122375137]"
326,326,749,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378087,1697122380020,120,,,"[16, 1833]","[1697122378103, 1697122379936]"
327,327,705,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355811,1697122357987,120,,,[16],[1697122355827]
328,328,609,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347390,1697122349791,120,,,[44],[1697122347434]
329,329,477,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122357991,1697122362057,120,,,"[41, 2127, 970]","[1697122358032, 1697122360159, 1697122361129]"
330,330,262,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349798,1697122352103,120,,,[152],[1697122349950]
331,331,312,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356976,1697122359215,120,,,[54],[1697122357030]
332,332,130,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362062,1697122364142,120,,,[78],[1697122362140]
333,333,38,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352107,1697122353148,120,,,"[10, 954]","[1697122352117, 1697122353071]"
334,334,894,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359220,1697122361070,120,,,[57],[1697122359277]
335,335,404,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380026,1697122381806,120,,,[37],[1697122380063]
336,336,836,9,[],200,llama-7b,64,1,1891.0,1.0,1,A10,1697122364149,1697122366040,120,11.0,1.0,"[82, 1809]","[1697122364231, 1697122366040]"
337,337,666,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361077,1697122363190,120,,,[84],[1697122361161]
338,338,491,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366044,1697122367968,120,,,[40],[1697122366084]
339,339,99,11,[],200,llama-7b,64,1,2821.0,1.0,1,A10,1697122376099,1697122378920,120,10.0,1.0,"[148, 2673]","[1697122376247, 1697122378920]"
340,340,133,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366043,1697122367968,120,,,[31],[1697122366074]
341,341,181,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381811,1697122383904,120,,,"[40, 2031]","[1697122381851, 1697122383882]"
342,342,821,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347390,1697122349791,120,,,[47],[1697122347437]
343,343,527,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356974,1697122359215,120,,,[43],[1697122357017]
344,344,268,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367974,1697122370102,120,,,[79],[1697122368053]
345,345,764,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383914,1697122386860,120,,,[133],[1697122384047]
346,346,851,12,[],200,llama-7b,64,1,1914.0,1.0,1,A10,1697122370108,1697122372022,120,23.0,1.0,"[126, 1788]","[1697122370234, 1697122372022]"
347,347,722,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354318,1697122356968,120,,,[38],[1697122354356]
348,348,724,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349797,1697122352103,120,,,[153],[1697122349950]
349,349,476,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349795,1697122352104,120,,,[72],[1697122349867]
350,350,298,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359221,1697122361070,120,,,[142],[1697122359363]
351,351,253,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352108,1697122354309,120,,,[54],[1697122352162]
352,352,535,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386863,1697122387918,120,,,[32],[1697122386895]
353,353,836,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354322,1697122356968,120,,,[121],[1697122354443]
354,354,196,21,[],200,llama-7b,64,1,2117.0,1.0,1,A10,1697122387922,1697122390039,120,13.0,1.0,"[59, 2058]","[1697122387981, 1697122390039]"
355,355,622,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122372025,1697122374081,120,,,[8],[1697122372033]
356,356,386,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353150,1697122355807,120,,,[6],[1697122353156]
357,357,186,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122350738,1697122352103,120,,,[11],[1697122350749]
358,358,611,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356979,1697122359213,120,,,[153],[1697122357132]
359,359,71,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349794,1697122352103,120,,,[59],[1697122349853]
360,360,264,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359217,1697122361069,120,,,[45],[1697122359262]
361,361,473,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352109,1697122354312,120,,,[63],[1697122352172]
362,362,775,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352109,1697122354313,120,,,[71],[1697122352180]
363,363,12,7,[],200,llama-7b,64,1,828.0,1.0,1,A10,1697122361075,1697122361903,120,11.0,1.0,"[39, 789]","[1697122361114, 1697122361903]"
364,364,547,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354321,1697122356968,120,,,[60],[1697122354381]
365,365,709,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361912,1697122363190,120,,,[35],[1697122361947]
366,366,654,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352105,1697122353148,120,,,"[8, 958]","[1697122352113, 1697122353071]"
367,367,200,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356974,1697122359214,120,,,[30],[1697122357004]
368,368,878,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359218,1697122361068,120,,,[34],[1697122359252]
369,369,362,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363194,1697122365126,120,,,[40],[1697122363234]
370,370,527,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361072,1697122363189,120,,,[59],[1697122361131]
371,371,139,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365133,1697122366983,120,,,[137],[1697122365270]
372,372,302,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363194,1697122365126,120,,,[48],[1697122363242]
373,373,720,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366986,1697122369038,120,,,[59],[1697122367045]
374,374,38,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355812,1697122357987,120,,,[49],[1697122355861]
375,375,126,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354322,1697122356968,120,,,[117],[1697122354439]
376,376,496,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122369042,1697122370102,120,,,[28],[1697122369070]
377,377,432,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353154,1697122355809,120,,,[90],[1697122353244]
378,378,645,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122364147,1697122371104,120,,,"[28, 1864, 994, 984, 1074, 1063]","[1697122364175, 1697122366039, 1697122367033, 1697122368017, 1697122369091, 1697122370154]"
379,379,828,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356975,1697122359214,120,,,[84],[1697122357059]
380,380,85,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355815,1697122357987,120,,,[66],[1697122355881]
381,381,149,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370108,1697122376092,120,,,"[125, 1791, 1040, 1068, 1005]","[1697122370233, 1697122372024, 1697122373064, 1697122374132, 1697122375137]"
382,382,11,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362060,1697122364142,120,,,[16],[1697122362076]
383,383,185,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349795,1697122352105,120,,,[141],[1697122349936]
384,384,422,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371111,1697122373012,120,,,[50],[1697122371161]
385,385,74,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373015,1697122375086,120,,,[47],[1697122373062]
386,386,480,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359222,1697122361070,120,,,[142],[1697122359364]
387,387,360,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383913,1697122385618,120,,,[121],[1697122384034]
388,388,763,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352109,1697122354307,120,,,[73],[1697122352182]
389,389,637,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355811,1697122357987,120,,,[48],[1697122355859]
390,390,780,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375089,1697122376091,120,,,"[28, 820]","[1697122375117, 1697122375937]"
391,391,540,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354316,1697122356968,120,,,[35],[1697122354351]
392,392,298,6,[],200,llama-7b,64,1,2169.0,1.0,1,A10,1697122357990,1697122360159,120,17.0,1.0,"[9, 2159]","[1697122357999, 1697122360158]"
393,393,433,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376096,1697122378082,120,,,[53],[1697122376149]
394,394,204,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378086,1697122380020,120,,,"[11, 1839]","[1697122378097, 1697122379936]"
395,395,12,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385622,1697122387917,120,,,[53],[1697122385675]
396,396,718,19,[],200,llama-7b,64,1,1099.0,1.0,1,A10,1697122387920,1697122389019,120,13.0,1.0,"[26, 1073]","[1697122387946, 1697122389019]"
397,397,193,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356974,1697122359214,120,,,[38],[1697122357012]
398,398,869,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359218,1697122361068,120,,,[24],[1697122359242]
399,399,638,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361075,1697122363189,120,,,[56],[1697122361131]
400,400,575,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122348581,1697122349791,120,,,[28],[1697122348609]
401,401,299,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363194,1697122365126,120,,,[43],[1697122363237]
402,402,881,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380031,1697122382783,120,,,[143],[1697122380174]
403,403,234,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 4.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349794,1697122350737,120,,,[39],[1697122349833]
404,404,852,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354319,1697122356969,120,,,[52],[1697122354371]
405,405,286,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349795,1697122352105,120,,,[136],[1697122349931]
406,406,70,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365131,1697122366981,120,,,[104],[1697122365235]
407,407,57,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352111,1697122354309,120,,,[135],[1697122352246]
408,408,656,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366985,1697122367968,120,,,[35],[1697122367020]
409,409,640,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354319,1697122356968,120,,,[115],[1697122354434]
410,410,434,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367973,1697122370101,120,,,[68],[1697122368041]
411,411,538,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122382786,1697122383906,120,,,"[23, 1074]","[1697122382809, 1697122383883]"
412,412,418,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356974,1697122359213,120,,,[70],[1697122357044]
413,413,625,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356975,1697122359215,120,,,[99],[1697122357074]
414,414,4,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122350739,1697122352104,120,,,[23],[1697122350762]
415,415,85,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370105,1697122376091,120,,,"[54, 1863, 1042, 1068, 1005]","[1697122370159, 1697122372022, 1697122373064, 1697122374132, 1697122375137]"
416,416,787,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395179,1697122396183,120,,,[16],[1697122395195]
417,417,7,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122350739,1697122353149,120,,,"[28, 2303]","[1697122350767, 1697122353070]"
418,418,284,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359220,1697122361069,120,,,[124],[1697122359344]
419,419,572,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362064,1697122364143,120,,,[99],[1697122362163]
420,420,54,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361075,1697122363189,120,,,[61],[1697122361136]
421,421,342,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122364147,1697122371104,120,,,"[33, 1859, 994, 985, 1073, 1063]","[1697122364180, 1697122366039, 1697122367033, 1697122368018, 1697122369091, 1697122370154]"
422,422,556,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396198,1697122398322,120,,,[60],[1697122396258]
423,423,677,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352109,1697122354308,120,,,[48],[1697122352157]
424,424,327,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363193,1697122365125,120,,,[20],[1697122363213]
425,425,689,12,[],200,llama-7b,64,1,2009.0,1.0,1,A10,1697122378925,1697122380934,120,15.0,1.0,"[33, 1976]","[1697122378958, 1697122380934]"
426,426,595,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347388,1697122348579,120,,,[31],[1697122347419]
427,427,193,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367971,1697122370101,120,,,[45],[1697122368016]
428,428,791,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376097,1697122378082,120,,,[58],[1697122376155]
429,429,490,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353151,1697122355807,120,,,[16],[1697122353167]
430,430,702,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353152,1697122355808,120,,,[34],[1697122353186]
431,431,895,8,[],200,llama-7b,64,1,1916.0,1.0,1,A10,1697122370108,1697122372024,120,15.0,1.0,"[81, 1835]","[1697122370189, 1697122372024]"
432,432,267,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355811,1697122357987,120,,,[21],[1697122355832]
433,433,444,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378095,1697122380020,120,,,"[75, 1766]","[1697122378170, 1697122379936]"
434,434,332,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355814,1697122357987,120,,,[65],[1697122355879]
435,435,849,3,[],200,llama-7b,64,1,2165.0,1.0,1,A10,1697122357994,1697122360159,120,10.0,1.0,"[75, 2090]","[1697122358069, 1697122360159]"
436,436,881,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361077,1697122363191,120,,,[90],[1697122361167]
437,437,96,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365131,1697122366981,120,,,[106],[1697122365237]
438,438,657,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363199,1697122365126,120,,,[79],[1697122363278]
439,439,625,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122360162,1697122362058,120,,,"[15, 1725]","[1697122360177, 1697122361902]"
440,440,309,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365130,1697122366982,120,,,[40],[1697122365170]
441,441,86,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366985,1697122369039,120,,,[55],[1697122367040]
442,442,278,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362065,1697122364143,120,,,[100],[1697122362165]
443,443,372,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 4.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122348582,1697122350736,120,,,[42],[1697122348624]
444,444,669,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122369043,1697122371104,120,,,"[46, 1881]","[1697122369089, 1697122370970]"
445,445,25,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353154,1697122355809,120,,,[89],[1697122353243]
446,446,55,6,[],200,llama-7b,64,1,1887.0,1.0,1,A10,1697122364153,1697122366040,120,12.0,1.0,"[112, 1775]","[1697122364265, 1697122366040]"
447,447,145,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374085,1697122375087,120,,,[35],[1697122374120]
448,448,266,4,[],200,llama-7b,64,1,2332.0,1.0,1,A10,1697122350739,1697122353071,120,9.0,1.0,"[49, 2282]","[1697122350788, 1697122353070]"
449,449,684,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366985,1697122367968,120,,,[31],[1697122367016]
450,450,849,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353076,1697122354308,120,,,[26],[1697122353102]
451,451,450,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367973,1697122370101,120,,,[60],[1697122368033]
452,452,606,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355813,1697122357987,120,,,[34],[1697122355847]
453,453,168,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362066,1697122364143,120,,,[107],[1697122362173]
454,454,635,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366044,1697122367968,120,,,[37],[1697122366081]
455,455,383,6,[],200,llama-7b,64,1,2169.0,1.0,1,A10,1697122357990,1697122360159,120,15.0,1.0,"[27, 2142]","[1697122358017, 1697122360159]"
456,456,37,7,[],200,llama-7b,64,1,1740.0,1.0,1,A10,1697122360163,1697122361903,120,20.0,1.0,"[36, 1704]","[1697122360199, 1697122361903]"
457,457,728,13,[],200,llama-7b,64,1,849.0,1.0,1,A10,1697122375089,1697122375938,120,20.0,1.0,"[37, 812]","[1697122375126, 1697122375938]"
458,458,869,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122364149,1697122371105,120,,,"[94, 1796, 994, 985, 1073, 1063]","[1697122364243, 1697122366039, 1697122367033, 1697122368018, 1697122369091, 1697122370154]"
459,459,443,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356975,1697122359214,120,,,[84],[1697122357059]
460,460,218,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359218,1697122361069,120,,,[39],[1697122359257]
461,461,629,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354323,1697122356969,120,,,[131],[1697122354454]
462,462,801,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361075,1697122362057,120,,,"[39, 789]","[1697122361114, 1697122361903]"
463,463,284,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356975,1697122359214,120,,,[94],[1697122357069]
464,464,545,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362061,1697122364142,120,,,[35],[1697122362096]
465,465,54,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359221,1697122361070,120,,,[138],[1697122359359]
466,466,200,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122364147,1697122371104,120,,,"[34, 1858, 994, 985, 1073, 1063]","[1697122364181, 1697122366039, 1697122367033, 1697122368018, 1697122369091, 1697122370154]"
467,467,466,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347391,1697122349791,120,,,[68],[1697122347459]
468,468,522,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371113,1697122374080,120,,,[123],[1697122371236]
469,469,597,8,[],200,llama-7b,64,1,1891.0,1.0,1,A10,1697122364149,1697122366040,120,39.0,1.0,"[80, 1811]","[1697122364229, 1697122366040]"
470,470,810,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349795,1697122352104,120,,,[73],[1697122349868]
471,471,299,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374084,1697122375086,120,,,[26],[1697122374110]
472,472,9,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362060,1697122364141,120,,,[11],[1697122362071]
473,473,256,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361078,1697122363191,120,,,[99],[1697122361177]
474,474,880,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375089,1697122376091,120,,,"[23, 825]","[1697122375112, 1697122375937]"
475,475,567,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122364145,1697122371104,120,,,"[20, 1874, 993, 985, 1073, 1064]","[1697122364165, 1697122366039, 1697122367032, 1697122368017, 1697122369090, 1697122370154]"
476,476,257,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359221,1697122361069,120,,,[127],[1697122359348]
477,477,777,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349794,1697122352103,120,,,[54],[1697122349848]
478,478,840,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363196,1697122365126,120,,,[71],[1697122363267]
479,479,233,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349795,1697122352103,120,,,[63],[1697122349858]
480,480,840,8,[],200,llama-7b,64,1,828.0,1.0,1,A10,1697122361074,1697122361902,120,17.0,1.0,"[30, 798]","[1697122361104, 1697122361902]"
481,481,839,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367970,1697122369039,120,,,[11],[1697122367981]
482,482,880,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365132,1697122366982,120,,,[123],[1697122365255]
483,483,620,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353152,1697122355807,120,,,[25],[1697122353177]
484,484,562,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 4.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349793,1697122350737,120,,,[30],[1697122349823]
485,485,660,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376095,1697122378084,120,,,"[20, 1817]","[1697122376115, 1697122377932]"
486,486,561,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 4.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349793,1697122350737,120,,,[20],[1697122349813]
487,487,895,22,[],200,llama-7b,64,1,1611.0,1.0,1,A10,1697122390043,1697122391654,120,15.0,1.0,"[25, 1586]","[1697122390068, 1697122391654]"
488,488,559,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122372026,1697122374081,120,,,[20],[1697122372046]
489,489,215,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398327,1697122400951,120,,,[111],[1697122398438]
490,490,314,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378096,1697122380020,120,,,"[59, 1782]","[1697122378155, 1697122379937]"
491,491,430,2,[],200,llama-7b,64,1,2330.0,1.0,1,A10,1697122350740,1697122353070,120,15.0,1.0,"[43, 2287]","[1697122350783, 1697122353070]"
492,492,332,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354319,1697122356968,120,,,[115],[1697122354434]
493,493,555,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391658,1697122393972,120,,,[21],[1697122391679]
494,494,102,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356975,1697122359213,120,,,[156],[1697122357131]
495,495,24,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122350737,1697122352104,120,,,[11],[1697122350748]
496,496,328,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374084,1697122376092,120,,,"[41, 1812]","[1697122374125, 1697122375937]"
497,497,84,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353075,1697122354308,120,,,[24],[1697122353099]
498,498,492,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122369043,1697122371104,120,,,"[52, 1875]","[1697122369095, 1697122370970]"
499,499,319,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393975,1697122396183,120,,,[54],[1697122394029]
500,500,789,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354316,1697122356968,120,,,[30],[1697122354346]
501,501,918,11,[],200,llama-7b,64,1,2823.0,1.0,1,A10,1697122376097,1697122378920,120,23.0,1.0,"[148, 2675]","[1697122376245, 1697122378920]"
502,502,704,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352108,1697122354308,120,,,[42],[1697122352150]
503,503,474,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354314,1697122356968,120,,,[28],[1697122354342]
504,504,264,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371111,1697122373012,120,,,[64],[1697122371175]
505,505,691,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359217,1697122361068,120,,,[15],[1697122359232]
506,506,445,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356973,1697122359213,120,,,[24],[1697122356997]
507,507,110,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370105,1697122371105,120,,,"[35, 831]","[1697122370140, 1697122370971]"
508,508,580,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352110,1697122354308,120,,,[126],[1697122352236]
509,509,166,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365133,1697122366982,120,,,[127],[1697122365260]
510,510,129,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356979,1697122359212,120,,,[162],[1697122357141]
511,511,240,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354313,1697122356967,120,,,[11],[1697122354324]
512,512,811,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371113,1697122374081,120,,,[125],[1697122371238]
513,513,461,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361071,1697122362056,120,,,[13],[1697122361084]
514,514,792,6,[],200,llama-7b,64,1,2167.0,1.0,1,A10,1697122357992,1697122360159,120,11.0,1.0,"[45, 2122]","[1697122358037, 1697122360159]"
515,515,884,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365131,1697122366982,120,,,[48],[1697122365179]
516,516,446,7,[],200,llama-7b,64,1,1740.0,1.0,1,A10,1697122360163,1697122361903,120,26.0,1.0,"[32, 1708]","[1697122360195, 1697122361903]"
517,517,120,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362061,1697122364143,120,,,[40],[1697122362101]
518,518,67,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396203,1697122398324,120,,,[134],[1697122396337]
519,519,661,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366985,1697122367969,120,,,[20],[1697122367005]
520,520,819,10,[],200,llama-7b,64,1,1890.0,1.0,1,A10,1697122364149,1697122366039,120,13.0,1.0,"[92, 1798]","[1697122364241, 1697122366039]"
521,521,223,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361909,1697122363190,120,,,[33],[1697122361942]
522,522,835,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359217,1697122361068,120,,,[13],[1697122359230]
523,523,865,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366987,1697122369038,120,,,[68],[1697122367055]
524,524,807,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363194,1697122365126,120,,,[45],[1697122363239]
525,525,317,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367972,1697122370101,120,,,[49],[1697122368021]
526,526,524,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122369040,1697122370102,120,,,[15],[1697122369055]
527,527,649,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398329,1697122400952,120,,,[139],[1697122398468]
528,528,489,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361071,1697122362056,120,,,[23],[1697122361094]
529,529,421,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400959,1697122402610,120,,,"[107, 1511]","[1697122401066, 1697122402577]"
530,530,294,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370106,1697122371105,120,,,[44],[1697122370150]
531,531,577,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365130,1697122366981,120,,,[30],[1697122365160]
532,532,371,20,[],200,llama-7b,64,1,1017.0,1.0,1,A10,1697122389023,1697122390040,120,13.0,1.0,"[38, 979]","[1697122389061, 1697122390040]"
533,533,86,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370104,1697122371104,120,,,"[8, 859]","[1697122370112, 1697122370971]"
534,534,209,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366985,1697122367967,120,,,[26],[1697122367011]
535,535,82,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402615,1697122404423,120,,,[123],[1697122402738]
536,536,781,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404427,1697122407058,120,,,[102],[1697122404529]
537,537,883,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371109,1697122373011,120,,,[32],[1697122371141]
538,538,143,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122390044,1697122402608,120,,,"[24, 1586, 1179, 1185, 1213, 999, 1062, 1079, 1223, 1399, 772]","[1697122390068, 1697122391654, 1697122392833, 1697122394018, 1697122395231, 1697122396230, 1697122397292, 1697122398371, 1697122399594, 1697122400993, 1697122401765]"
539,539,905,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367971,1697122369039,120,,,[20],[1697122367991]
540,540,358,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355811,1697122357987,120,,,[31],[1697122355842]
541,541,655,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373012,1697122374081,120,,,[15],[1697122373027]
542,542,578,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352109,1697122354312,120,,,[68],[1697122352177]
543,543,345,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366984,1697122367968,120,,,[14],[1697122366998]
544,544,439,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407064,1697122409609,120,,,[87],[1697122407151]
545,545,238,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354318,1697122356968,120,,,[58],[1697122354376]
546,546,212,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409615,1697122411708,120,,,[130],[1697122409745]
547,547,562,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122369042,1697122370101,120,,,[23],[1697122369065]
548,548,9,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356975,1697122359215,120,,,[99],[1697122357074]
549,549,304,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374087,1697122376090,120,,,"[67, 1784]","[1697122374154, 1697122375938]"
550,550,301,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353151,1697122355808,120,,,[30],[1697122353181]
551,551,610,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365130,1697122366982,120,,,[44],[1697122365174]
552,552,593,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359218,1697122361069,120,,,[49],[1697122359267]
553,553,312,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356975,1697122359214,120,,,[89],[1697122357064]
554,554,927,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367973,1697122370101,120,,,[60],[1697122368033]
555,555,884,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355814,1697122357988,120,,,[60],[1697122355874]
556,556,341,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361075,1697122362057,120,,,"[44, 784]","[1697122361119, 1697122361903]"
557,557,702,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370105,1697122371105,120,,,"[25, 840]","[1697122370130, 1697122370970]"
558,558,110,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362060,1697122364142,120,,,[21],[1697122362081]
559,559,332,14,[],200,llama-7b,64,1,1916.0,1.0,1,A10,1697122370106,1697122372022,120,39.0,1.0,"[58, 1858]","[1697122370164, 1697122372022]"
560,560,272,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366985,1697122367968,120,,,[36],[1697122367021]
561,561,823,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352107,1697122353148,120,,,"[26, 937]","[1697122352133, 1697122353070]"
562,562,533,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366986,1697122369038,120,,,[59],[1697122367045]
563,563,52,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376095,1697122378083,120,,,"[34, 1803]","[1697122376129, 1697122377932]"
564,564,310,12,[],200,llama-7b,64,1,1926.0,1.0,1,A10,1697122369045,1697122370971,120,26.0,1.0,"[88, 1838]","[1697122369133, 1697122370971]"
565,565,916,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122372026,1697122374081,120,,,[12],[1697122372038]
566,566,694,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122364150,1697122371106,120,,,"[98, 2785, 985, 1073, 1063]","[1697122364248, 1697122367033, 1697122368018, 1697122369091, 1697122370154]"
567,567,894,13,[],200,llama-7b,64,1,1049.0,1.0,1,A10,1697122370974,1697122372023,120,14.0,1.0,"[29, 1020]","[1697122371003, 1697122372023]"
568,568,697,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122350739,1697122352104,120,,,[18],[1697122350757]
569,569,593,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353152,1697122355807,120,,,[20],[1697122353172]
570,570,664,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122372031,1697122374082,120,,,[28],[1697122372059]
571,571,729,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353154,1697122355808,120,,,[80],[1697122353234]
572,572,398,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355811,1697122357987,120,,,[23],[1697122355834]
573,573,437,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371108,1697122373011,120,,,[21],[1697122371129]
574,574,405,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367970,1697122370100,120,,,[21],[1697122367991]
575,575,853,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373014,1697122375086,120,,,[53],[1697122373067]
576,576,184,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373015,1697122375086,120,,,[61],[1697122373076]
577,577,494,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356975,1697122359214,120,,,[79],[1697122357054]
578,578,623,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375091,1697122378085,120,,,[66],[1697122375157]
579,579,155,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359218,1697122361069,120,,,[44],[1697122359262]
580,580,37,9,[],200,llama-7b,64,1,866.0,1.0,1,A10,1697122370105,1697122370971,120,20.0,1.0,"[40, 826]","[1697122370145, 1697122370971]"
581,581,52,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122357990,1697122362056,120,,,"[29, 2140, 971]","[1697122358019, 1697122360159, 1697122361130]"
582,582,734,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370972,1697122376091,120,,,"[26, 1025, 1041, 1068, 1005]","[1697122370998, 1697122372023, 1697122373064, 1697122374132, 1697122375137]"
583,583,85,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380027,1697122381806,120,,,[112],[1697122380139]
584,584,747,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362062,1697122364142,120,,,[86],[1697122362148]
585,585,675,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381809,1697122382784,120,,,[8],[1697122381817]
586,586,854,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361076,1697122363189,120,,,[75],[1697122361151]
587,587,445,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122382787,1697122383904,120,,,"[32, 1064]","[1697122382819, 1697122383883]"
588,588,512,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363196,1697122365125,120,,,[66],[1697122363262]
589,589,193,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383909,1697122385618,120,,,[27],[1697122383936]
590,590,408,8,[],200,llama-7b,64,1,1887.0,1.0,1,A10,1697122364153,1697122366040,120,16.0,1.0,"[115, 1772]","[1697122364268, 1697122366040]"
591,591,394,11,[],200,llama-7b,64,1,2820.0,1.0,1,A10,1697122376099,1697122378919,120,11.0,1.0,"[161, 2659]","[1697122376260, 1697122378919]"
592,592,281,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365129,1697122366981,120,,,[10],[1697122365139]
593,593,767,14,[],200,llama-7b,64,1,2092.0,1.0,1,A10,1697122375092,1697122377184,120,11.0,1.0,"[74, 2018]","[1697122375166, 1697122377184]"
594,594,477,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355813,1697122357987,120,,,[31],[1697122355844]
595,595,872,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366986,1697122369038,120,,,[54],[1697122367040]
596,596,646,11,[],200,llama-7b,64,1,1927.0,1.0,1,A10,1697122369043,1697122370970,120,14.0,1.0,"[42, 1885]","[1697122369085, 1697122370970]"
597,597,175,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366044,1697122367967,120,,,[32],[1697122366076]
598,598,164,12,[],200,llama-7b,64,1,2009.0,1.0,1,A10,1697122378924,1697122380933,120,15.0,1.0,"[20, 1989]","[1697122378944, 1697122380933]"
599,599,129,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122357997,1697122362057,120,,,"[134, 2028, 971]","[1697122358131, 1697122360159, 1697122361130]"
600,600,748,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380936,1697122382783,120,,,[15],[1697122380951]
601,601,528,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122382785,1697122383905,120,,,"[14, 1083]","[1697122382799, 1697122383882]"
602,602,68,7,[],200,llama-7b,64,1,1741.0,1.0,1,A10,1697122360162,1697122361903,120,12.0,1.0,"[10, 1730]","[1697122360172, 1697122361902]"
603,603,737,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367970,1697122369039,120,,,[6],[1697122367976]
604,604,71,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359220,1697122362058,120,,,"[133, 2549]","[1697122359353, 1697122361902]"
605,605,835,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362061,1697122364142,120,,,[30],[1697122362091]
606,606,778,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362063,1697122364142,120,,,[82],[1697122362145]
607,607,300,12,[],200,llama-7b,64,1,1051.0,1.0,1,A10,1697122370972,1697122372023,120,9.0,1.0,"[21, 1030]","[1697122370993, 1697122372023]"
608,608,652,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361905,1697122363189,120,,,[17],[1697122361922]
609,609,314,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383916,1697122385620,120,,,[62],[1697122383978]
610,610,488,8,[],200,llama-7b,64,1,1890.0,1.0,1,A10,1697122364149,1697122366039,120,6.0,1.0,"[89, 1801]","[1697122364238, 1697122366039]"
611,611,506,11,[],200,llama-7b,64,1,1927.0,1.0,1,A10,1697122369043,1697122370970,120,16.0,1.0,"[47, 1880]","[1697122369090, 1697122370970]"
612,612,676,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371109,1697122373011,120,,,[29],[1697122371138]
613,613,432,8,[],200,llama-7b,64,1,1890.0,1.0,1,A10,1697122364149,1697122366039,120,13.0,1.0,"[41, 1849]","[1697122364190, 1697122366039]"
614,614,429,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363195,1697122365125,120,,,[63],[1697122363258]
615,615,180,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366042,1697122367967,120,,,[7],[1697122366049]
616,616,259,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366042,1697122367967,120,,,[14],[1697122366056]
617,617,48,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122372027,1697122374081,120,,,[17],[1697122372044]
618,618,57,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352110,1697122354308,120,,,[120],[1697122352230]
619,619,248,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.96 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122347389,1697122349790,120,,,[33],[1697122347422]
620,620,880,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367970,1697122370099,120,,,[11],[1697122367981]
621,621,745,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374084,1697122375086,120,,,[21],[1697122374105]
622,622,14,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 4.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349793,1697122350737,120,,,[40],[1697122349833]
623,623,447,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373015,1697122375086,120,,,[57],[1697122373072]
624,624,604,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122350739,1697122352104,120,,,[28],[1697122350767]
625,625,337,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371108,1697122373010,120,,,[16],[1697122371124]
626,626,849,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367972,1697122370101,120,,,[49],[1697122368021]
627,627,375,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352108,1697122354308,120,,,[39],[1697122352147]
628,628,927,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373013,1697122374081,120,,,[24],[1697122373037]
629,629,195,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375092,1697122378082,120,,,"[75, 2016]","[1697122375167, 1697122377183]"
630,630,643,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363194,1697122365125,120,,,[33],[1697122363227]
631,631,803,32,[],200,llama-7b,64,1,2184.0,1.0,1,A10,1697122411715,1697122413899,120,20.0,1.0,"[118, 2066]","[1697122411833, 1697122413899]"
632,632,767,3,[],200,llama-7b,64,1,2164.0,1.0,1,A10,1697122357995,1697122360159,120,11.0,1.0,"[79, 2085]","[1697122358074, 1697122360159]"
633,633,615,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370105,1697122376090,120,,,"[50, 1867, 1042, 1068, 1005]","[1697122370155, 1697122372022, 1697122373064, 1697122374132, 1697122375137]"
634,634,29,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354319,1697122356968,120,,,[119],[1697122354438]
635,635,687,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122349795,1697122352103,120,,,[68],[1697122349863]
636,636,415,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365129,1697122366982,120,,,[36],[1697122365165]
637,637,778,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378095,1697122380019,120,,,"[33, 1808]","[1697122378128, 1697122379936]"
638,638,695,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374085,1697122375087,120,,,[15],[1697122374100]
639,639,348,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375091,1697122378083,120,,,"[60, 2032]","[1697122375151, 1697122377183]"
640,640,895,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359221,1697122361069,120,,,[112],[1697122359333]
641,641,574,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122413902,1697122416372,120,,,[29],[1697122413931]
642,642,68,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366987,1697122369038,120,,,[73],[1697122367060]
643,643,705,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356974,1697122359213,120,,,[70],[1697122357044]
644,644,745,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122369041,1697122370101,120,,,[19],[1697122369060]
645,645,549,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380031,1697122382783,120,,,[133],[1697122380164]
646,646,125,11,[],200,llama-7b,64,1,1840.0,1.0,1,A10,1697122378096,1697122379936,120,13.0,1.0,"[69, 1771]","[1697122378165, 1697122379936]"
647,647,210,20,[],200,llama-7b,64,1,2882.0,1.0,1,A10,1697122382788,1697122385670,120,140.0,2.0,"[56, 1901, 925]","[1697122382844, 1697122384745, 1697122385670]"
648,648,227,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416377,1697122418473,120,,,"[26, 1913]","[1697122416403, 1697122418316]"
649,649,615,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361906,1697122363190,120,,,[24],[1697122361930]
650,650,908,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385672,1697122387919,120,,,[68],[1697122385740]
651,651,269,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363193,1697122365124,120,,,[18],[1697122363211]
652,652,671,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361072,1697122363189,120,,,[65],[1697122361137]
653,653,458,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380938,1697122382784,120,,,[19],[1697122380957]
654,654,509,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370106,1697122371105,120,,,"[34, 831]","[1697122370140, 1697122370971]"
655,655,567,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387922,1697122391053,120,,,"[63, 2054]","[1697122387985, 1697122390039]"
656,656,170,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371109,1697122373011,120,,,[42],[1697122371151]
657,657,16,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365133,1697122366982,120,,,[132],[1697122365265]
658,658,904,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418477,1697122420381,120,,,[57],[1697122418534]
659,659,333,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391056,1697122392786,120,,,[7],[1697122391063]
660,660,309,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.87 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122350739,1697122352104,120,,,[23],[1697122350762]
661,661,117,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122382787,1697122383904,120,,,"[37, 1059]","[1697122382824, 1697122383883]"
662,662,324,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363193,1697122365125,120,,,[24],[1697122363217]
663,663,923,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392788,1697122393971,120,,,[21],[1697122392809]
664,664,515,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355812,1697122357987,120,,,[45],[1697122355857]
665,665,556,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420386,1697122423159,120,,,[79],[1697122420465]
666,666,332,37,[],200,llama-7b,64,1,1808.0,1.0,1,A10,1697122423166,1697122424974,120,39.0,1.0,"[166, 1642]","[1697122423332, 1697122424974]"
667,667,332,3,[],200,llama-7b,64,1,2331.0,1.0,1,A10,1697122350740,1697122353071,120,39.0,1.0,"[52, 2279]","[1697122350792, 1697122353071]"
668,668,169,3,[],200,llama-7b,64,1,2169.0,1.0,1,A10,1697122357991,1697122360160,120,10.0,1.0,"[54, 2114]","[1697122358045, 1697122360159]"
669,669,100,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365129,1697122366981,120,,,[15],[1697122365144]
670,670,865,4,[],200,llama-7b,64,1,1739.0,1.0,1,A10,1697122360164,1697122361903,120,9.0,1.0,"[40, 1699]","[1697122360204, 1697122361903]"
671,671,869,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373012,1697122374081,120,,,[20],[1697122373032]
672,672,816,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383909,1697122385618,120,,,[32],[1697122383941]
673,673,694,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393978,1697122396183,120,,,[93],[1697122394071]
674,674,679,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366985,1697122367968,120,,,[40],[1697122367025]
675,675,216,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380026,1697122381807,120,,,[47],[1697122380073]
676,676,451,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367971,1697122370100,120,,,[25],[1697122367996]
677,677,102,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122357990,1697122362056,120,,,"[19, 2149, 971]","[1697122358009, 1697122360158, 1697122361129]"
678,678,348,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396192,1697122397244,120,,,[8],[1697122396200]
679,679,497,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361906,1697122363190,120,,,[29],[1697122361935]
680,680,266,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363196,1697122365126,120,,,[76],[1697122363272]
681,681,776,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381811,1697122383904,120,,,"[55, 2016]","[1697122381866, 1697122383882]"
682,682,501,14,[],200,llama-7b,64,1,1243.0,1.0,1,A10,1697122375942,1697122377185,120,19.0,1.0,"[38, 1204]","[1697122375980, 1697122377184]"
683,683,111,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370104,1697122371105,120,,,[21],[1697122370125]
684,684,855,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365131,1697122366982,120,,,[114],[1697122365245]
685,685,156,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122377188,1697122380019,120,,,"[21, 1711]","[1697122377209, 1697122378920]"
686,686,464,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374085,1697122375087,120,,,[45],[1697122374130]
687,687,213,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375090,1697122376091,120,,,"[41, 807]","[1697122375131, 1697122375938]"
688,688,542,15,[],200,llama-7b,64,1,1731.0,1.0,1,A10,1697122377189,1697122378920,120,11.0,1.0,"[15, 1716]","[1697122377204, 1697122378920]"
689,689,524,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374085,1697122376092,120,,,"[55, 1797]","[1697122374140, 1697122375937]"
690,690,773,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385621,1697122386861,120,,,[11],[1697122385632]
691,691,810,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371112,1697122374080,120,,,[117],[1697122371229]
692,692,851,14,[],200,llama-7b,64,1,2821.0,1.0,1,A10,1697122376098,1697122378919,120,23.0,1.0,"[136, 2685]","[1697122376234, 1697122378919]"
693,693,514,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378922,1697122383905,120,,,"[7, 2004, 925, 973]","[1697122378929, 1697122380933, 1697122381858, 1697122382831]"
694,694,546,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386862,1697122387918,120,,,[18],[1697122386880]
695,695,195,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378923,1697122383905,120,,,"[30, 1980, 925, 973]","[1697122378953, 1697122380933, 1697122381858, 1697122382831]"
696,696,439,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374083,1697122375086,120,,,[17],[1697122374100]
697,697,200,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387920,1697122389102,120,,,"[26, 1073]","[1697122387946, 1697122389019]"
698,698,343,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366043,1697122367967,120,,,[23],[1697122366066]
699,699,900,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389107,1697122391052,120,,,"[55, 1807]","[1697122389162, 1697122390969]"
700,700,546,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383911,1697122385618,120,,,[49],[1697122383960]
701,701,113,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367972,1697122370100,120,,,[39],[1697122368011]
702,702,209,15,[],200,llama-7b,64,1,849.0,1.0,1,A10,1697122375089,1697122375938,120,20.0,1.0,"[32, 817]","[1697122375121, 1697122375938]"
703,703,799,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375941,1697122378082,120,,,"[25, 1218]","[1697122375966, 1697122377184]"
704,704,561,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391059,1697122392786,120,,,[76],[1697122391135]
705,705,330,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392790,1697122395176,120,,,[44],[1697122392834]
706,706,162,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370973,1697122376090,120,,,"[15, 1034, 1042, 1068, 1005]","[1697122370988, 1697122372022, 1697122373064, 1697122374132, 1697122375137]"
707,707,919,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395180,1697122396185,120,,,[45],[1697122395225]
708,708,690,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356973,1697122359213,120,,,[14],[1697122356987]
709,709,732,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402614,1697122404422,120,,,[24],[1697122402638]
710,710,703,11,[],200,llama-7b,64,1,866.0,1.0,1,A10,1697122370105,1697122370971,120,12.0,1.0,"[8, 858]","[1697122370113, 1697122370971]"
711,711,474,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370974,1697122376091,120,,,"[29, 2061, 1068, 1005]","[1697122371003, 1697122373064, 1697122374132, 1697122375137]"
712,712,865,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371113,1697122374081,120,,,[130],[1697122371243]
713,713,460,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359220,1697122361069,120,,,[118],[1697122359338]
714,714,519,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374085,1697122376090,120,,,"[59, 1793]","[1697122374144, 1697122375937]"
715,715,127,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376098,1697122380019,120,,,"[134, 2687]","[1697122376232, 1697122378919]"
716,716,901,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383918,1697122386860,120,,,[144],[1697122384062]
717,717,557,18,[],200,llama-7b,64,1,2154.0,1.0,1,A10,1697122386865,1697122389019,120,31.0,1.0,"[94, 2060]","[1697122386959, 1697122389019]"
718,718,120,7,[],200,llama-7b,64,1,828.0,1.0,1,A10,1697122361075,1697122361903,120,17.0,1.0,"[34, 794]","[1697122361109, 1697122361903]"
719,719,329,19,[],200,llama-7b,64,1,1016.0,1.0,1,A10,1697122389024,1697122390040,120,15.0,1.0,"[38, 978]","[1697122389062, 1697122390040]"
720,720,919,20,[],200,llama-7b,64,1,1610.0,1.0,1,A10,1697122390043,1697122391653,120,14.0,1.0,"[11, 1599]","[1697122390054, 1697122391653]"
721,721,570,17,[],200,llama-7b,64,1,1846.0,1.0,1,A10,1697122378090,1697122379936,120,18.0,1.0,"[32, 1814]","[1697122378122, 1697122379936]"
722,722,821,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361906,1697122363190,120,,,[26],[1697122361932]
723,723,228,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122379939,1697122383904,120,,,"[24, 970, 925, 974]","[1697122379963, 1697122380933, 1697122381858, 1697122382832]"
724,724,834,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380026,1697122381805,120,,,[103],[1697122380129]
725,725,689,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391658,1697122393973,120,,,[29],[1697122391687]
726,726,359,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371114,1697122374081,120,,,[126],[1697122371240]
727,727,4,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383909,1697122385619,120,,,[21],[1697122383930]
728,728,319,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393978,1697122396184,120,,,[90],[1697122394068]
729,729,89,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396189,1697122397244,120,,,[23],[1697122396212]
730,730,41,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367971,1697122370100,120,,,[40],[1697122368011]
731,731,358,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359220,1697122361069,120,,,[114],[1697122359334]
732,732,136,15,[],200,llama-7b,64,1,1852.0,1.0,1,A10,1697122374085,1697122375937,120,31.0,1.0,"[55, 1797]","[1697122374140, 1697122375937]"
733,733,1,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371109,1697122373010,120,,,[27],[1697122371136]
734,734,716,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370105,1697122371105,120,,,[44],[1697122370149]
735,735,134,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361071,1697122362057,120,,,"[18, 813]","[1697122361089, 1697122361902]"
736,736,373,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371114,1697122374081,120,,,[133],[1697122371247]
737,737,693,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374087,1697122376091,120,,,"[77, 1774]","[1697122374164, 1697122375938]"
738,738,150,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374087,1697122376091,120,,,[82],[1697122374169]
739,739,346,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376097,1697122380018,120,,,"[77, 2745]","[1697122376174, 1697122378919]"
740,740,734,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376097,1697122380018,120,,,"[72, 2750]","[1697122376169, 1697122378919]"
741,741,585,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385622,1697122387917,120,,,[61],[1697122385683]
742,742,464,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371112,1697122373011,120,,,[61],[1697122371173]
743,743,445,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352108,1697122354308,120,,,[44],[1697122352152]
744,744,717,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362061,1697122364143,120,,,[45],[1697122362106]
745,745,721,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375940,1697122378082,120,,,"[15, 1228]","[1697122375955, 1697122377183]"
746,746,125,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373016,1697122375087,120,,,[65],[1697122373081]
747,747,678,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397247,1697122398323,120,,,[37],[1697122397284]
748,748,825,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375090,1697122378079,120,,,"[57, 2036]","[1697122375147, 1697122377183]"
749,749,124,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380025,1697122381805,120,,,[13],[1697122380038]
750,750,478,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378089,1697122380020,120,,,"[48, 1799]","[1697122378137, 1697122379936]"
751,751,80,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353074,1697122354308,120,,,[20],[1697122353094]
752,752,704,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381809,1697122382783,120,,,[21],[1697122381830]
753,753,603,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366986,1697122367968,120,,,[45],[1697122367031]
754,754,685,12,[],200,llama-7b,64,1,2937.0,1.0,1,A10,1697122378922,1697122381859,120,364.0,2.0,"[12, 1999, 925]","[1697122378934, 1697122380933, 1697122381858]"
755,755,490,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378086,1697122380021,120,,,"[15, 1835]","[1697122378101, 1697122379936]"
756,756,362,21,[],200,llama-7b,64,1,1101.0,1.0,1,A10,1697122387919,1697122389020,120,14.0,1.0,"[12, 1089]","[1697122387931, 1697122389020]"
757,757,151,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380027,1697122381807,120,,,[41],[1697122380068]
758,758,452,20,[],200,llama-7b,64,1,5177.0,1.0,1,A10,1697122382789,1697122387966,120,216.0,4.0,"[80, 1876, 924, 1238, 1059]","[1697122382869, 1697122384745, 1697122385669, 1697122386907, 1697122387966]"
759,759,374,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367971,1697122370101,120,,,[30],[1697122368001]
760,760,849,19,[],200,llama-7b,64,1,2071.0,1.0,1,A10,1697122381812,1697122383883,120,10.0,1.0,"[70, 2001]","[1697122381882, 1697122383883]"
761,761,34,14,[],200,llama-7b,64,1,1917.0,1.0,1,A10,1697122370106,1697122372023,120,12.0,1.0,"[68, 1849]","[1697122370174, 1697122372023]"
762,762,659,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354323,1697122356969,120,,,[135],[1697122354458]
763,763,691,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362061,1697122364142,120,,,[35],[1697122362096]
764,764,15,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389023,1697122391053,120,,,"[34, 982]","[1697122389057, 1697122390039]"
765,765,733,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122372031,1697122374082,120,,,[25],[1697122372056]
766,766,225,21,[],200,llama-7b,64,1,2071.0,1.0,1,A10,1697122387969,1697122390040,120,23.0,1.0,"[82, 1989]","[1697122388051, 1697122390040]"
767,767,595,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383887,1697122385619,120,,,[22],[1697122383909]
768,768,392,16,[],200,llama-7b,64,1,1851.0,1.0,1,A10,1697122374087,1697122375938,120,20.0,1.0,"[77, 1774]","[1697122374164, 1697122375938]"
769,769,303,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122364147,1697122371104,120,,,"[24, 1868, 994, 984, 1074, 1063]","[1697122364171, 1697122366039, 1697122367033, 1697122368017, 1697122369091, 1697122370154]"
770,770,809,22,[],200,llama-7b,64,1,1611.0,1.0,1,A10,1697122390043,1697122391654,120,16.0,1.0,"[15, 1596]","[1697122390058, 1697122391654]"
771,771,295,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353073,1697122354311,120,,,[14],[1697122353087]
772,772,162,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375941,1697122378082,120,,,"[29, 1214]","[1697122375970, 1697122377184]"
773,773,586,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391656,1697122393972,120,,,[16],[1697122391672]
774,774,716,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391060,1697122393972,120,,,[104],[1697122391164]
775,775,885,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371108,1697122373010,120,,,[16],[1697122371124]
776,776,245,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385622,1697122387918,120,,,[68],[1697122385690]
777,777,240,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393975,1697122395177,120,,,[26],[1697122394001]
778,778,63,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354321,1697122356968,120,,,[123],[1697122354444]
779,779,287,16,[],200,llama-7b,64,1,1841.0,1.0,1,A10,1697122378096,1697122379937,120,10.0,1.0,"[145, 1695]","[1697122378241, 1697122379936]"
780,780,15,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395180,1697122396184,120,,,[39],[1697122395219]
781,781,649,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356974,1697122359215,120,,,[63],[1697122357037]
782,782,483,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366042,1697122367967,120,,,[22],[1697122366064]
783,783,624,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366986,1697122369038,120,,,[49],[1697122367035]
784,784,661,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373014,1697122375086,120,,,[33],[1697122373047]
785,785,285,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122369040,1697122370103,120,,,[15],[1697122369055]
786,786,314,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375090,1697122378079,120,,,"[62, 2032]","[1697122375152, 1697122377184]"
787,787,22,22,[],200,llama-7b,64,1,2117.0,1.0,1,A10,1697122387922,1697122390039,120,16.0,1.0,"[64, 2053]","[1697122387986, 1697122390039]"
788,788,597,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396198,1697122398322,120,,,[61],[1697122396259]
789,789,419,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359221,1697122361069,120,,,[133],[1697122359354]
790,790,255,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367975,1697122370103,120,,,[83],[1697122368058]
791,791,74,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361072,1697122362057,120,,,"[27, 803]","[1697122361099, 1697122361902]"
792,792,837,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370107,1697122376091,120,,,"[73, 1843, 1041, 1068, 1005]","[1697122370180, 1697122372023, 1697122373064, 1697122374132, 1697122375137]"
793,793,90,14,[],200,llama-7b,64,1,1840.0,1.0,1,A10,1697122378096,1697122379936,120,19.0,1.0,"[47, 1793]","[1697122378143, 1697122379936]"
794,794,643,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361076,1697122363190,120,,,[86],[1697122361162]
795,795,374,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398327,1697122400950,120,,,[63],[1697122398390]
796,796,55,17,[],200,llama-7b,64,1,995.0,1.0,1,A10,1697122379938,1697122380933,120,12.0,1.0,"[12, 983]","[1697122379950, 1697122380933]"
797,797,673,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122379939,1697122383905,120,,,"[11, 983, 925, 974]","[1697122379950, 1697122380933, 1697122381858, 1697122382832]"
798,798,673,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355813,1697122357987,120,,,[39],[1697122355852]
799,799,616,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380941,1697122382784,120,,,[25],[1697122380966]
800,800,780,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362064,1697122364143,120,,,[86],[1697122362150]
801,801,385,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122382788,1697122389101,120,,,"[43, 1913, 925, 1237, 1059]","[1697122382831, 1697122384744, 1697122385669, 1697122386906, 1697122387965]"
802,802,82,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365128,1697122366981,120,,,[7],[1697122365135]
803,803,584,14,[],200,llama-7b,64,1,1835.0,1.0,1,A10,1697122376097,1697122377932,120,10.0,1.0,"[57, 1778]","[1697122376154, 1697122377932]"
804,804,41,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389107,1697122391052,120,,,"[60, 1803]","[1697122389167, 1697122390970]"
805,805,285,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383910,1697122385618,120,,,[25],[1697122383935]
806,806,297,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376097,1697122380018,120,,,"[62, 2760]","[1697122376159, 1697122378919]"
807,807,237,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122377935,1697122380020,120,,,"[22, 963]","[1697122377957, 1697122378920]"
808,808,659,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122357997,1697122362057,120,,,"[69, 2093, 971]","[1697122358066, 1697122360159, 1697122361130]"
809,809,879,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380025,1697122381805,120,,,[23],[1697122380048]
810,810,867,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376098,1697122380018,120,,,"[77, 2744]","[1697122376175, 1697122378919]"
811,811,321,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374085,1697122376090,120,,,"[70, 1783]","[1697122374155, 1697122375938]"
812,812,483,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381809,1697122383904,120,,,"[43, 2030]","[1697122381852, 1697122383882]"
813,813,845,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385620,1697122386860,120,,,[20],[1697122385640]
814,814,524,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380024,1697122381805,120,,,[9],[1697122380033]
815,815,613,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386863,1697122387918,120,,,[42],[1697122386905]
816,816,654,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381809,1697122382783,120,,,[24],[1697122381833]
817,817,89,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376096,1697122378084,120,,,"[23, 1813]","[1697122376119, 1697122377932]"
818,818,283,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374084,1697122375087,120,,,[36],[1697122374120]
819,819,300,15,[],200,llama-7b,64,1,2072.0,1.0,1,A10,1697122381811,1697122383883,120,9.0,1.0,"[56, 2015]","[1697122381867, 1697122383882]"
820,820,13,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380030,1697122381807,120,,,[124],[1697122380154]
821,821,273,19,[],200,llama-7b,64,1,2118.0,1.0,1,A10,1697122387920,1697122390038,120,19.0,1.0,"[51, 2067]","[1697122387971, 1697122390038]"
822,822,892,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400957,1697122402608,120,,,"[32, 664, 112]","[1697122400989, 1697122401653, 1697122401765]"
823,823,596,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381813,1697122383905,120,,,"[79, 1991]","[1697122381892, 1697122383883]"
824,824,43,20,[],200,llama-7b,64,1,9551.0,1.0,1,A10,1697122390043,1697122399594,120,732.0,8.0,"[20, 1591, 1179, 1185, 1213, 999, 1062, 1079, 1223]","[1697122390063, 1697122391654, 1697122392833, 1697122394018, 1697122395231, 1697122396230, 1697122397292, 1697122398371, 1697122399594]"
825,825,255,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380031,1697122382783,120,,,[148],[1697122380179]
826,826,788,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353152,1697122355808,120,,,[30],[1697122353182]
827,827,882,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383886,1697122389101,120,,,"[6, 853, 924, 1238, 1059]","[1697122383892, 1697122384745, 1697122385669, 1697122386907, 1697122387966]"
828,828,96,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397249,1697122399547,120,,,[54],[1697122397303]
829,829,463,8,[],200,llama-7b,64,1,1892.0,1.0,1,A10,1697122364147,1697122366039,120,39.0,1.0,"[29, 1863]","[1697122364176, 1697122366039]"
830,830,627,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399596,1697122402610,120,,,"[46, 2011, 112]","[1697122399642, 1697122401653, 1697122401765]"
831,831,708,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361904,1697122363189,120,,,[16],[1697122361920]
832,832,400,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402618,1697122405695,120,,,[136],[1697122402754]
833,833,362,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363195,1697122365125,120,,,[53],[1697122363248]
834,834,836,15,[],200,llama-7b,64,1,1097.0,1.0,1,A10,1697122382786,1697122383883,120,11.0,1.0,"[35, 1062]","[1697122382821, 1697122383883]"
835,835,54,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405698,1697122407057,120,,,[33],[1697122405731]
836,836,606,23,[],200,llama-7b,64,1,1612.0,1.0,1,A10,1697122390042,1697122391654,120,9.0,1.0,"[7, 1604]","[1697122390049, 1697122391653]"
837,837,678,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399550,1697122400950,120,,,[25],[1697122399575]
838,838,116,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366043,1697122367968,120,,,[36],[1697122366079]
839,839,861,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 4.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122348584,1697122350737,120,,,[50],[1697122348634]
840,840,453,29,[],200,llama-7b,64,1,1623.0,1.0,1,A10,1697122400954,1697122402577,120,26.0,1.0,"[40, 1583]","[1697122400994, 1697122402577]"
841,841,911,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376097,1697122380018,120,,,"[53, 2769]","[1697122376150, 1697122378919]"
842,842,110,30,[],200,llama-7b,64,1,4519.0,1.0,1,A10,1697122402580,1697122407099,120,96.0,4.0,"[20, 513, 1352, 1274, 1360]","[1697122402600, 1697122403113, 1697122404465, 1697122405739, 1697122407099]"
843,843,376,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391657,1697122393972,120,,,[7],[1697122391664]
844,844,822,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367971,1697122370100,120,,,[25],[1697122367996]
845,845,301,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376099,1697122380020,120,,,"[153, 2668]","[1697122376252, 1697122378920]"
846,846,37,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393978,1697122396184,120,,,[88],[1697122394066]
847,847,412,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363194,1697122365125,120,,,[30],[1697122363224]
848,848,477,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370105,1697122376091,120,,,"[60, 1857, 1042, 1068, 1005]","[1697122370165, 1697122372022, 1697122373064, 1697122374132, 1697122375137]"
849,849,448,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383911,1697122386860,120,,,[141],[1697122384052]
850,850,758,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407063,1697122409609,120,,,[48],[1697122407111]
851,851,883,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380031,1697122382783,120,,,[138],[1697122380169]
852,852,733,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396195,1697122398323,120,,,[74],[1697122396269]
853,853,265,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362060,1697122364142,120,,,[31],[1697122362091]
854,854,554,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352107,1697122354309,120,,,[63],[1697122352170]
855,855,502,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404429,1697122407057,120,,,[121],[1697122404550]
856,856,534,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370105,1697122371105,120,,,"[30, 836]","[1697122370135, 1697122370971]"
857,857,708,12,[],200,llama-7b,64,1,993.0,1.0,1,A10,1697122379940,1697122380933,120,140.0,1.0,"[25, 968]","[1697122379965, 1697122380933]"
858,858,157,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407065,1697122409610,120,,,[96],[1697122407161]
859,859,856,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409614,1697122411708,120,,,[125],[1697122409739]
860,860,658,19,[],200,llama-7b,64,1,1957.0,1.0,1,A10,1697122382788,1697122384745,120,11.0,1.0,"[46, 1911]","[1697122382834, 1697122384745]"
861,861,488,26,[],200,llama-7b,64,1,2185.0,1.0,1,A10,1697122411714,1697122413899,120,6.0,1.0,"[58, 2126]","[1697122411772, 1697122413898]"
862,862,315,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122384747,1697122386861,120,,,[17],[1697122384764]
863,863,482,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380936,1697122382783,120,,,[11],[1697122380947]
864,864,63,21,[],200,llama-7b,64,1,2154.0,1.0,1,A10,1697122386866,1697122389020,120,39.0,1.0,"[107, 2047]","[1697122386973, 1697122389020]"
865,865,746,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391060,1697122393972,120,,,[109],[1697122391169]
866,866,136,14,[],200,llama-7b,64,1,1097.0,1.0,1,A10,1697122382787,1697122383884,120,31.0,1.0,"[39, 1058]","[1697122382826, 1697122383884]"
867,867,647,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389022,1697122391053,120,,,"[34, 983]","[1697122389056, 1697122390039]"
868,868,699,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373012,1697122374081,120,,,[15],[1697122373027]
869,869,813,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383887,1697122389101,120,,,"[15, 843, 924, 1238, 1059]","[1697122383902, 1697122384745, 1697122385669, 1697122386907, 1697122387966]"
870,870,361,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374087,1697122376091,120,,,"[73, 1778]","[1697122374160, 1697122375938]"
871,871,400,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393976,1697122396184,120,,,[75],[1697122394051]
872,872,132,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376096,1697122378082,120,,,"[49, 1787]","[1697122376145, 1697122377932]"
873,873,418,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391059,1697122392786,120,,,[81],[1697122391140]
874,874,78,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392789,1697122393971,120,,,[31],[1697122392820]
875,875,259,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122413902,1697122416372,120,,,[33],[1697122413935]
876,876,776,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393974,1697122395177,120,,,[32],[1697122394006]
877,877,714,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378087,1697122380021,120,,,"[19, 1829]","[1697122378106, 1697122379935]"
878,878,842,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416377,1697122418472,120,,,"[31, 1908]","[1697122416408, 1697122418316]"
879,879,503,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380025,1697122381805,120,,,[13],[1697122380038]
880,880,100,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354315,1697122356967,120,,,[16],[1697122354331]
881,881,165,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381809,1697122382784,120,,,[37],[1697122381846]
882,882,436,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395180,1697122396184,120,,,[31],[1697122395211]
883,883,861,18,[],200,llama-7b,64,1,1957.0,1.0,1,A10,1697122382788,1697122384745,120,10.0,1.0,"[66, 1891]","[1697122382854, 1697122384745]"
884,884,915,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424977,1697122426577,120,,,[26],[1697122425003]
885,885,522,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122384746,1697122386860,120,,,[7],[1697122384753]
886,886,802,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356974,1697122359213,120,,,[75],[1697122357049]
887,887,683,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426581,1697122427731,120,,,[25],[1697122426606]
888,888,288,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386863,1697122387918,120,,,[22],[1697122386885]
889,889,201,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396198,1697122398322,120,,,[139],[1697122396337]
890,890,343,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122427739,1697122429746,120,,,"[42, 1946]","[1697122427781, 1697122429727]"
891,891,248,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355813,1697122357988,120,,,[56],[1697122355869]
892,892,872,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387921,1697122391053,120,,,"[55, 2063]","[1697122387976, 1697122390039]"
893,893,113,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429752,1697122431565,120,,,[190],[1697122429942]
894,894,791,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398326,1697122399547,120,,,[29],[1697122398355]
895,895,463,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359218,1697122361068,120,,,[24],[1697122359242]
896,896,231,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361077,1697122363189,120,,,[79],[1697122361156]
897,897,702,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431566,1697122432498,120,,,"[19, 832]","[1697122431585, 1697122432417]"
898,898,821,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363194,1697122365125,120,,,[13],[1697122363207]
899,899,312,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362064,1697122364143,120,,,[94],[1697122362158]
900,900,471,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432506,1697122435152,120,,,[38],[1697122432544]
901,901,590,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365129,1697122366981,120,,,[20],[1697122365149]
902,902,562,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399553,1697122402610,120,,,"[56, 2044, 112]","[1697122399609, 1697122401653, 1697122401765]"
903,903,304,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122382789,1697122389100,120,,,"[70, 1886, 925, 1236, 1060]","[1697122382859, 1697122384745, 1697122385670, 1697122386906, 1697122387966]"
904,904,89,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122364149,1697122371105,120,,,"[87, 1804, 993, 984, 1074, 1063]","[1697122364236, 1697122366040, 1697122367033, 1697122368017, 1697122369091, 1697122370154]"
905,905,246,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366987,1697122369038,120,,,[68],[1697122367055]
906,906,22,11,[],200,llama-7b,64,1,1926.0,1.0,1,A10,1697122369045,1697122370971,120,16.0,1.0,"[54, 1871]","[1697122369099, 1697122370970]"
907,907,25,6,[],200,llama-7b,64,1,2167.0,1.0,1,A10,1697122357992,1697122360159,120,12.0,1.0,"[54, 2113]","[1697122358046, 1697122360159]"
908,908,601,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370974,1697122376091,120,,,"[24, 1025, 1041, 1068, 1005]","[1697122370998, 1697122372023, 1697122373064, 1697122374132, 1697122375137]"
909,909,216,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402618,1697122405696,120,,,[146],[1697122402764]
910,910,52,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389104,1697122391054,120,,,"[30, 1834]","[1697122389134, 1697122390968]"
911,911,349,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376094,1697122378079,120,,,"[12, 1826]","[1697122376106, 1697122377932]"
912,912,611,7,[],200,llama-7b,64,1,1740.0,1.0,1,A10,1697122360163,1697122361903,120,14.0,1.0,"[24, 1716]","[1697122360187, 1697122361903]"
913,913,444,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385621,1697122386861,120,,,[6],[1697122385627]
914,914,386,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361906,1697122363189,120,,,[19],[1697122361925]
915,915,661,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402614,1697122404422,120,,,[39],[1697122402653]
916,916,1,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378095,1697122380020,120,,,"[75, 1766]","[1697122378170, 1697122379936]"
917,917,707,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380031,1697122381807,120,,,[129],[1697122380160]
918,918,39,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363194,1697122365124,120,,,[11],[1697122363205]
919,919,216,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386864,1697122389101,120,,,"[85, 2069]","[1697122386949, 1697122389018]"
920,920,536,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355814,1697122357987,120,,,[52],[1697122355866]
921,921,360,16,[],200,llama-7b,64,1,2071.0,1.0,1,A10,1697122381812,1697122383883,120,16.0,1.0,"[74, 1997]","[1697122381886, 1697122383883]"
922,922,892,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405699,1697122407058,120,,,[37],[1697122405736]
923,923,214,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359216,1697122361068,120,,,[31],[1697122359247]
924,924,464,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393980,1697122396183,120,,,[95],[1697122394075]
925,925,804,7,[],200,llama-7b,64,1,828.0,1.0,1,A10,1697122361075,1697122361903,120,20.0,1.0,"[34, 794]","[1697122361109, 1697122361903]"
926,926,717,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365129,1697122366981,120,,,[15],[1697122365144]
927,927,113,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396198,1697122398323,120,,,[80],[1697122396278]
928,928,372,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366987,1697122369038,120,,,[63],[1697122367050]
929,929,660,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407065,1697122409609,120,,,[81],[1697122407146]
930,930,321,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409611,1697122410669,120,,,"[15, 910]","[1697122409626, 1697122410536]"
931,931,56,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370107,1697122376092,120,,,"[78, 1838, 1041, 1068, 1005]","[1697122370185, 1697122372023, 1697122373064, 1697122374132, 1697122375137]"
932,932,141,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122369043,1697122371104,120,,,"[51, 1876]","[1697122369094, 1697122370970]"
933,933,306,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122357990,1697122362055,120,,,"[17, 3122]","[1697122358007, 1697122361129]"
934,934,132,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383886,1697122389101,120,,,"[11, 848, 924, 1237, 1060]","[1697122383897, 1697122384745, 1697122385669, 1697122386906, 1697122387966]"
935,935,522,3,[],200,llama-7b,64,1,2330.0,1.0,1,A10,1697122350741,1697122353071,120,20.0,1.0,"[52, 2278]","[1697122350793, 1697122353071]"
936,936,816,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407101,1697122409609,120,,,[131],[1697122407232]
937,937,891,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362060,1697122364142,120,,,[16],[1697122362076]
938,938,292,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353074,1697122354307,120,,,[18],[1697122353092]
939,939,729,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371109,1697122373011,120,,,[37],[1697122371146]
940,940,877,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354312,1697122356967,120,,,[15],[1697122354327]
941,941,663,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122364145,1697122371104,120,,,"[21, 2867, 984, 1073, 1064]","[1697122364166, 1697122367033, 1697122368017, 1697122369090, 1697122370154]"
942,942,494,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354319,1697122356969,120,,,[52],[1697122354371]
943,943,471,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409612,1697122411707,120,,,[45],[1697122409657]
944,944,241,33,[],200,llama-7b,64,1,2184.0,1.0,1,A10,1697122411715,1697122413899,120,19.0,1.0,"[123, 2061]","[1697122411838, 1697122413899]"
945,945,831,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122413901,1697122416373,120,,,[6],[1697122413907]
946,946,271,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356975,1697122359215,120,,,[94],[1697122357069]
947,947,855,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359221,1697122361069,120,,,[122],[1697122359343]
948,948,624,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361079,1697122363191,120,,,[92],[1697122361171]
949,949,80,17,[],200,llama-7b,64,1,2155.0,1.0,1,A10,1697122386864,1697122389019,120,13.0,1.0,"[85, 2070]","[1697122386949, 1697122389019]"
950,950,599,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416378,1697122418474,120,,,"[87, 1851]","[1697122416465, 1697122418316]"
951,951,474,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363194,1697122365125,120,,,[28],[1697122363222]
952,952,649,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356974,1697122359214,120,,,[33],[1697122357007]
953,953,202,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385621,1697122386860,120,,,[21],[1697122385642]
954,954,251,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365133,1697122366982,120,,,[117],[1697122365250]
955,955,303,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359217,1697122361068,120,,,[20],[1697122359237]
956,956,846,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122364145,1697122371104,120,,,"[15, 1879, 993, 985, 1073, 1064]","[1697122364160, 1697122366039, 1697122367032, 1697122368017, 1697122369090, 1697122370154]"
957,957,688,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396195,1697122398324,120,,,[53],[1697122396248]
958,958,900,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386863,1697122387919,120,,,[37],[1697122386900]
959,959,135,6,[],200,llama-7b,64,1,3140.0,1.0,1,A10,1697122357990,1697122361130,120,52.0,2.0,"[22, 2146, 971]","[1697122358012, 1697122360158, 1697122361129]"
960,960,778,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389022,1697122391052,120,,,"[25, 992]","[1697122389047, 1697122390039]"
961,961,323,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398327,1697122400951,120,,,[118],[1697122398445]
962,962,438,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391058,1697122392787,120,,,[35],[1697122391093]
963,963,95,25,[],200,llama-7b,64,1,1617.0,1.0,1,A10,1697122400960,1697122402577,120,12.0,1.0,"[177, 1440]","[1697122401137, 1697122402577]"
964,964,206,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354318,1697122356969,120,,,[44],[1697122354362]
965,965,654,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352107,1697122353149,120,,,"[28, 935]","[1697122352135, 1697122353070]"
966,966,715,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361132,1697122363191,120,,,[50],[1697122361182]
967,967,619,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371112,1697122373012,120,,,[47],[1697122371159]
968,968,431,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353153,1697122355809,120,,,[48],[1697122353201]
969,969,86,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355813,1697122357987,120,,,[51],[1697122355864]
970,970,311,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371109,1697122373011,120,,,[24],[1697122371133]
971,971,274,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376096,1697122378079,120,,,"[11, 1824]","[1697122376107, 1697122377931]"
972,972,788,6,[],200,llama-7b,64,1,2166.0,1.0,1,A10,1697122357993,1697122360159,120,31.0,1.0,"[58, 2108]","[1697122358051, 1697122360159]"
973,973,450,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398326,1697122400950,120,,,[109],[1697122398435]
974,974,893,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373013,1697122375086,120,,,[24],[1697122373037]
975,975,99,26,[],200,llama-7b,64,1,1619.0,1.0,1,A10,1697122400958,1697122402577,120,10.0,1.0,"[83, 1536]","[1697122401041, 1697122402577]"
976,976,493,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363195,1697122365125,120,,,[62],[1697122363257]
977,977,669,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375089,1697122376092,120,,,"[17, 831]","[1697122375106, 1697122375937]"
978,978,44,13,[],200,llama-7b,64,1,1841.0,1.0,1,A10,1697122378096,1697122379937,120,12.0,1.0,"[64, 1777]","[1697122378160, 1697122379937]"
979,979,273,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373015,1697122375086,120,,,[56],[1697122373071]
980,980,449,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122360162,1697122362056,120,,,"[23, 1717]","[1697122360185, 1697122361902]"
981,981,618,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418484,1697122421735,120,,,[166],[1697122418650]
982,982,44,13,[],200,llama-7b,64,1,2092.0,1.0,1,A10,1697122375092,1697122377184,120,12.0,1.0,"[70, 2022]","[1697122375162, 1697122377184]"
983,983,806,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402579,1697122410669,120,,,"[20, 514, 1352, 1274, 1359, 1072, 1482]","[1697122402599, 1697122403113, 1697122404465, 1697122405739, 1697122407098, 1697122408170, 1697122409652]"
984,984,721,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122379940,1697122383904,120,,,"[20, 973, 925, 974]","[1697122379960, 1697122380933, 1697122381858, 1697122382832]"
985,985,457,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410673,1697122412984,120,,,[28],[1697122410701]
986,986,233,29,[],200,llama-7b,64,1,1873.0,1.0,1,A10,1697122412990,1697122414863,120,6.0,1.0,"[30, 1843]","[1697122413020, 1697122414863]"
987,987,816,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122414866,1697122416373,120,,,[20],[1697122414886]
988,988,605,14,[],200,llama-7b,64,1,1731.0,1.0,1,A10,1697122377189,1697122378920,120,8.0,1.0,"[25, 1706]","[1697122377214, 1697122378920]"
989,989,587,31,[],200,llama-7b,64,1,2581.0,1.0,1,A10,1697122416382,1697122418963,120,13.0,1.0,"[155, 2426]","[1697122416537, 1697122418963]"
990,990,336,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418966,1697122421735,120,,,[10],[1697122418976]
991,991,272,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421738,1697122424990,120,,,"[52, 2322, 88]","[1697122421790, 1697122424112, 1697122424200]"
992,992,635,18,[],200,llama-7b,64,1,1842.0,1.0,1,A10,1697122378095,1697122379937,120,23.0,1.0,"[60, 1782]","[1697122378155, 1697122379937]"
993,993,219,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362061,1697122364144,120,,,[74],[1697122362135]
994,994,52,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375091,1697122378085,120,,,"[65, 2028]","[1697122375156, 1697122377184]"
995,995,218,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435157,1697122438625,120,,,[78],[1697122435235]
996,996,921,33,[],200,llama-7b,64,1,2373.0,1.0,1,A10,1697122421740,1697122424113,120,31.0,1.0,"[113, 2259]","[1697122421853, 1697122424112]"
997,997,890,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352109,1697122354309,120,,,[58],[1697122352167]
998,998,50,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424993,1697122426577,120,,,[67],[1697122425060]
999,999,347,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381861,1697122383905,120,,,[74],[1697122381935]
1000,1000,663,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354322,1697122356968,120,,,[59],[1697122354381]
1001,1001,633,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426582,1697122429746,120,,,"[89, 2158, 59]","[1697122426671, 1697122428829, 1697122428888]"
1002,1002,410,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122379940,1697122383904,120,,,"[28, 965, 925, 974]","[1697122379968, 1697122380933, 1697122381858, 1697122382832]"
1003,1003,679,17,[],200,llama-7b,64,1,1840.0,1.0,1,A10,1697122378096,1697122379936,120,15.0,1.0,"[79, 1761]","[1697122378175, 1697122379936]"
1004,1004,317,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356974,1697122359214,120,,,[34],[1697122357008]
1005,1005,448,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122379939,1697122383904,120,,,"[19, 975, 925, 974]","[1697122379958, 1697122380933, 1697122381858, 1697122382832]"
1006,1006,88,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359220,1697122361069,120,,,[52],[1697122359272]
1007,1007,116,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383914,1697122385619,120,,,[135],[1697122384049]
1008,1008,678,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361075,1697122363189,120,,,[71],[1697122361146]
1009,1009,322,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404427,1697122407057,120,,,[43],[1697122404470]
1010,1010,90,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407061,1697122408127,120,,,[33],[1697122407094]
1011,1011,447,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363195,1697122365125,120,,,[59],[1697122363254]
1012,1012,104,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383909,1697122385618,120,,,[37],[1697122383946]
1013,1013,700,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385622,1697122386860,120,,,[25],[1697122385647]
1014,1014,819,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398327,1697122400950,120,,,[51],[1697122398378]
1015,1015,444,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386863,1697122387918,120,,,[27],[1697122386890]
1016,1016,471,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400955,1697122402608,120,,,"[121, 1501]","[1697122401076, 1697122402577]"
1017,1017,584,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383887,1697122385619,120,,,[39],[1697122383926]
1018,1018,63,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383916,1697122385619,120,,,[52],[1697122383968]
1019,1019,780,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385621,1697122386861,120,,,[41],[1697122385662]
1020,1020,247,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402620,1697122405697,120,,,[162],[1697122402782]
1021,1021,241,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385621,1697122386860,120,,,[24],[1697122385645]
1022,1022,830,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405700,1697122408126,120,,,[45],[1697122405745]
1023,1023,855,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380025,1697122381805,120,,,[23],[1697122380048]
1024,1024,214,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387923,1697122391051,120,,,"[118, 1998]","[1697122388041, 1697122390039]"
1025,1025,601,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408128,1697122409609,120,,,[15],[1697122408143]
1026,1026,568,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361907,1697122363190,120,,,[30],[1697122361937]
1027,1027,263,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409613,1697122411707,120,,,[43],[1697122409656]
1028,1028,515,17,[],200,llama-7b,64,1,2071.0,1.0,1,A10,1697122381812,1697122383883,120,11.0,1.0,"[64, 2007]","[1697122381876, 1697122383883]"
1029,1029,35,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122411711,1697122415031,120,,,"[27, 2160]","[1697122411738, 1697122413898]"
1030,1030,550,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386864,1697122389100,120,,,"[66, 2088]","[1697122386930, 1697122389018]"
1031,1031,895,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385628,1697122387919,120,,,[121],[1697122385749]
1032,1032,595,33,[],200,llama-7b,64,1,2313.0,1.0,1,A10,1697122415036,1697122417349,120,8.0,1.0,"[29, 2284]","[1697122415065, 1697122417349]"
1033,1033,316,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363196,1697122365126,120,,,[81],[1697122363277]
1034,1034,214,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389104,1697122391054,120,,,"[36, 1828]","[1697122389140, 1697122390968]"
1035,1035,364,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122417352,1697122424990,120,,,"[14, 1598, 1456, 1353, 1424, 1003]","[1697122417366, 1697122418964, 1697122420420, 1697122421773, 1697122423197, 1697122424200]"
1036,1036,899,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365131,1697122366982,120,,,[101],[1697122365232]
1037,1037,670,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366985,1697122367968,120,,,[40],[1697122367025]
1038,1038,331,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367974,1697122370101,120,,,[74],[1697122368048]
1039,1039,912,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391060,1697122393972,120,,,[119],[1697122391179]
1040,1040,100,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370105,1697122371105,120,,,"[25, 840]","[1697122370130, 1697122370970]"
1041,1041,572,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393976,1697122396183,120,,,[69],[1697122394045]
1042,1042,673,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387922,1697122391051,120,,,"[114, 2004]","[1697122388036, 1697122390040]"
1043,1043,646,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.87 GiB is allocated by PyTorch, and 5.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122354317,1697122356968,120,,,[35],[1697122354352]
1044,1044,832,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366986,1697122369038,120,,,[49],[1697122367035]
1045,1045,690,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371112,1697122374080,120,,,[119],[1697122371231]
1046,1046,433,10,[],200,llama-7b,64,1,2884.0,1.0,1,A10,1697122364149,1697122367033,120,109.0,2.0,"[37, 2847]","[1697122364186, 1697122367033]"
1047,1047,461,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374083,1697122375087,120,,,[12],[1697122374095]
1048,1048,576,12,[],200,llama-7b,64,1,1926.0,1.0,1,A10,1697122369045,1697122370971,120,14.0,1.0,"[60, 1866]","[1697122369105, 1697122370971]"
1049,1049,122,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375090,1697122376091,120,,,"[37, 811]","[1697122375127, 1697122375938]"
1050,1050,346,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370973,1697122376091,120,,,"[20, 1030, 1041, 1068, 1005]","[1697122370993, 1697122372023, 1697122373064, 1697122374132, 1697122375137]"
1051,1051,820,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376095,1697122378079,120,,,"[6, 1830]","[1697122376101, 1697122377931]"
1052,1052,475,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378095,1697122380019,120,,,"[28, 1813]","[1697122378123, 1697122379936]"
1053,1053,224,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380026,1697122381807,120,,,[51],[1697122380077]
1054,1054,24,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424994,1697122426577,120,,,[71],[1697122425065]
1055,1055,1,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376096,1697122378083,120,,,"[48, 1788]","[1697122376144, 1697122377932]"
1056,1056,341,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396195,1697122397244,120,,,[29],[1697122396224]
1057,1057,707,15,[],200,llama-7b,64,1,1841.0,1.0,1,A10,1697122378096,1697122379937,120,8.0,1.0,"[140, 1700]","[1697122378236, 1697122379936]"
1058,1058,926,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397247,1697122399547,120,,,[51],[1697122397298]
1059,1059,405,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375089,1697122376090,120,,,"[22, 826]","[1697122375111, 1697122375937]"
1060,1060,360,16,[],200,llama-7b,64,1,994.0,1.0,1,A10,1697122379940,1697122380934,120,16.0,1.0,"[33, 961]","[1697122379973, 1697122380934]"
1061,1061,136,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380937,1697122382783,120,,,[15],[1697122380952]
1062,1062,175,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376096,1697122378085,120,,,[28],[1697122376124]
1063,1063,718,18,[],200,llama-7b,64,1,1958.0,1.0,1,A10,1697122382787,1697122384745,120,13.0,1.0,"[53, 1905]","[1697122382840, 1697122384745]"
1064,1064,912,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356974,1697122359214,120,,,[39],[1697122357013]
1065,1065,498,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122384749,1697122386861,120,,,[9],[1697122384758]
1066,1066,565,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359218,1697122361068,120,,,[34],[1697122359252]
1067,1067,421,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122360162,1697122362056,120,,,"[20, 1720]","[1697122360182, 1697122361902]"
1068,1068,154,20,[],200,llama-7b,64,1,2153.0,1.0,1,A10,1697122386866,1697122389019,120,13.0,1.0,"[102, 2051]","[1697122386968, 1697122389019]"
1069,1069,492,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122364149,1697122371105,120,,,"[84, 1807, 993, 985, 1073, 1063]","[1697122364233, 1697122366040, 1697122367033, 1697122368018, 1697122369091, 1697122370154]"
1070,1070,336,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361071,1697122362056,120,,,"[18, 814]","[1697122361089, 1697122361903]"
1071,1071,852,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389021,1697122391051,120,,,"[15, 1004]","[1697122389036, 1697122390040]"
1072,1072,374,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378923,1697122383905,120,,,"[20, 1990, 925, 974]","[1697122378943, 1697122380933, 1697122381858, 1697122382832]"
1073,1073,376,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383909,1697122385618,120,,,[22],[1697122383931]
1074,1074,33,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383916,1697122385619,120,,,[59],[1697122383975]
1075,1075,146,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385621,1697122386861,120,,,[16],[1697122385637]
1076,1076,169,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362060,1697122364142,120,,,[26],[1697122362086]
1077,1077,735,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386865,1697122389101,120,,,"[88, 2065]","[1697122386953, 1697122389018]"
1078,1078,868,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122364148,1697122371105,120,,,"[37, 1854, 994, 985, 1072, 1064]","[1697122364185, 1697122366039, 1697122367033, 1697122368018, 1697122369090, 1697122370154]"
1079,1079,146,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365129,1697122366981,120,,,[26],[1697122365155]
1080,1080,732,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385621,1697122386861,120,,,[39],[1697122385660]
1081,1081,752,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391060,1697122393972,120,,,[115],[1697122391175]
1082,1082,405,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393975,1697122396183,120,,,[56],[1697122394031]
1083,1083,508,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389108,1697122391052,120,,,"[69, 1792]","[1697122389177, 1697122390969]"
1084,1084,847,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366987,1697122369038,120,,,[63],[1697122367050]
1085,1085,183,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396194,1697122397244,120,,,[25],[1697122396219]
1086,1086,168,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391063,1697122393971,120,,,[169],[1697122391232]
1087,1087,763,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397249,1697122399547,120,,,[82],[1697122397331]
1088,1088,866,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393974,1697122396182,120,,,[39],[1697122394013]
1089,1089,503,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122369043,1697122371106,120,,,"[42, 1885]","[1697122369085, 1697122370970]"
1090,1090,611,16,[],200,llama-7b,64,1,1841.0,1.0,1,A10,1697122378096,1697122379937,120,14.0,1.0,"[54, 1786]","[1697122378150, 1697122379936]"
1091,1091,410,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429749,1697122431564,120,,,[105],[1697122429854]
1092,1092,273,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371112,1697122373011,120,,,[121],[1697122371233]
1093,1093,66,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431569,1697122433672,120,,,[87],[1697122431656]
1094,1094,377,17,[],200,llama-7b,64,1,993.0,1.0,1,A10,1697122379941,1697122380934,120,13.0,1.0,"[37, 956]","[1697122379978, 1697122380934]"
1095,1095,540,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399550,1697122400950,120,,,[25],[1697122399575]
1096,1096,38,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380937,1697122382784,120,,,[19],[1697122380956]
1097,1097,738,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122382789,1697122389100,120,,,"[66, 2815, 1236, 1060]","[1697122382855, 1697122385670, 1697122386906, 1697122387966]"
1098,1098,751,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378096,1697122380020,120,,,[69],[1697122378165]
1099,1099,659,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389115,1697122391052,120,,,"[127, 1727]","[1697122389242, 1697122390969]"
1100,1100,8,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356973,1697122359213,120,,,[21],[1697122356994]
1101,1101,197,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400954,1697122402609,120,,,"[50, 1572]","[1697122401004, 1697122402576]"
1102,1102,523,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380030,1697122381806,120,,,[119],[1697122380149]
1103,1103,899,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371107,1697122373011,120,,,[12],[1697122371119]
1104,1104,898,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402619,1697122405697,120,,,[159],[1697122402778]
1105,1105,391,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389104,1697122391053,120,,,[17],[1697122389121]
1106,1106,558,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405700,1697122408126,120,,,[46],[1697122405746]
1107,1107,572,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359218,1697122361068,120,,,[29],[1697122359247]
1108,1108,169,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391060,1697122392787,120,,,[90],[1697122391150]
1109,1109,327,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408129,1697122409609,120,,,[24],[1697122408153]
1110,1110,284,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383886,1697122385619,120,,,[23],[1697122383909]
1111,1111,844,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385624,1697122387919,120,,,[116],[1697122385740]
1112,1112,286,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363199,1697122365127,120,,,[135],[1697122363334]
1113,1113,614,20,[],200,llama-7b,64,1,2117.0,1.0,1,A10,1697122387922,1697122390039,120,15.0,1.0,"[110, 2007]","[1697122388032, 1697122390039]"
1114,1114,751,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392792,1697122395178,120,,,[72],[1697122392864]
1115,1115,415,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356979,1697122359213,120,,,[161],[1697122357140]
1116,1116,55,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365133,1697122366982,120,,,[109],[1697122365242]
1117,1117,328,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391058,1697122392787,120,,,[30],[1697122391088]
1118,1118,561,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387923,1697122391051,120,,,"[114, 2003]","[1697122388037, 1697122390040]"
1119,1119,346,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418481,1697122420380,120,,,[78],[1697122418559]
1120,1120,332,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391056,1697122392786,120,,,[7],[1697122391063]
1121,1121,272,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122390043,1697122402607,120,,,"[11, 1600, 1179, 1185, 1213, 999, 1062, 1079, 1222, 1400, 772]","[1697122390054, 1697122391654, 1697122392833, 1697122394018, 1697122395231, 1697122396230, 1697122397292, 1697122398371, 1697122399593, 1697122400993, 1697122401765]"
1122,1122,646,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366989,1697122369039,120,,,[80],[1697122367069]
1123,1123,526,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395180,1697122396184,120,,,[44],[1697122395224]
1124,1124,725,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426582,1697122429746,120,,,"[94, 2152, 60]","[1697122426676, 1697122428828, 1697122428888]"
1125,1125,925,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420385,1697122423158,120,,,[65],[1697122420450]
1126,1126,50,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402613,1697122404422,120,,,[13],[1697122402626]
1127,1127,183,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396198,1697122398323,120,,,[86],[1697122396284]
1128,1128,416,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122369042,1697122370102,120,,,[38],[1697122369080]
1129,1129,378,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429751,1697122431564,120,,,[123],[1697122429874]
1130,1130,915,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392790,1697122393971,120,,,[34],[1697122392824]
1131,1131,48,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370108,1697122376090,120,,,"[131, 2825, 1068, 1005]","[1697122370239, 1697122373064, 1697122374132, 1697122375137]"
1132,1132,171,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396198,1697122398323,120,,,[134],[1697122396332]
1133,1133,760,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378097,1697122383905,120,,,"[134, 2701, 926, 973]","[1697122378231, 1697122380932, 1697122381858, 1697122382831]"
1134,1134,691,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393975,1697122395177,120,,,[33],[1697122394008]
1135,1135,259,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383913,1697122386860,120,,,[141],[1697122384054]
1136,1136,456,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.94 GiB is allocated by PyTorch, and 5.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122352107,1697122353149,120,,,"[38, 926]","[1697122352145, 1697122353071]"
1137,1137,753,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398326,1697122399548,120,,,[44],[1697122398370]
1138,1138,587,16,[],200,llama-7b,64,1,1865.0,1.0,1,A10,1697122389104,1697122390969,120,13.0,1.0,"[36, 1829]","[1697122389140, 1697122390969]"
1139,1139,156,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431567,1697122432498,120,,,"[32, 817]","[1697122431599, 1697122432416]"
1140,1140,841,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386863,1697122387918,120,,,[17],[1697122386880]
1141,1141,532,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383910,1697122385618,120,,,[43],[1697122383953]
1142,1142,702,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399549,1697122400950,120,,,[16],[1697122399565]
1143,1143,241,17,[],200,llama-7b,64,1,682.0,1.0,1,A10,1697122390972,1697122391654,120,19.0,1.0,"[26, 656]","[1697122390998, 1697122391654]"
1144,1144,18,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391658,1697122393972,120,,,[26],[1697122391684]
1145,1145,599,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393976,1697122396183,120,,,[72],[1697122394048]
1146,1146,396,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386864,1697122389101,120,,,"[80, 2074]","[1697122386944, 1697122389018]"
1147,1147,589,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387921,1697122389100,120,,,"[35, 1063]","[1697122387956, 1697122389019]"
1148,1148,186,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385621,1697122386861,120,,,[44],[1697122385665]
1149,1149,116,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122353150,1697122355807,120,,,[7],[1697122353157]
1150,1150,244,19,[],200,llama-7b,64,1,1865.0,1.0,1,A10,1697122389104,1697122390969,120,9.0,1.0,"[43, 1822]","[1697122389147, 1697122390969]"
1151,1151,356,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400954,1697122402609,120,,,"[81, 1541]","[1697122401035, 1697122402576]"
1152,1152,811,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 6.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122355813,1697122357988,120,,,[58],[1697122355871]
1153,1153,168,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389116,1697122391053,120,,,"[134, 1719]","[1697122389250, 1697122390969]"
1154,1154,14,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122390972,1697122402608,120,,,"[6, 676, 1179, 1185, 1213, 999, 1062, 1079, 1223, 1399, 772]","[1697122390978, 1697122391654, 1697122392833, 1697122394018, 1697122395231, 1697122396230, 1697122397292, 1697122398371, 1697122399594, 1697122400993, 1697122401765]"
1155,1155,807,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122364150,1697122371103,120,,,"[105, 1785, 993, 985, 1073, 1063]","[1697122364255, 1697122366040, 1697122367033, 1697122368018, 1697122369091, 1697122370154]"
1156,1156,98,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402618,1697122405696,120,,,[145],[1697122402763]
1157,1157,681,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405702,1697122408127,120,,,[79],[1697122405781]
1158,1158,375,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396187,1697122397244,120,,,[18],[1697122396205]
1159,1159,733,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432510,1697122435152,120,,,[121],[1697122432631]
1160,1160,527,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371109,1697122373011,120,,,[35],[1697122371144]
1161,1161,30,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397245,1697122398321,120,,,[8],[1697122397253]
1162,1162,510,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435157,1697122438625,120,,,[73],[1697122435230]
1163,1163,531,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399553,1697122402609,120,,,"[80, 2020, 112]","[1697122399633, 1697122401653, 1697122401765]"
1164,1164,603,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402614,1697122404422,120,,,[37],[1697122402651]
1165,1165,162,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438632,1697122442469,120,,,"[133, 2638]","[1697122438765, 1697122441403]"
1166,1166,374,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404427,1697122407058,120,,,[58],[1697122404485]
1167,1167,186,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402614,1697122404422,120,,,[52],[1697122402666]
1168,1168,885,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404425,1697122405696,120,,,[15],[1697122404440]
1169,1169,576,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371108,1697122373011,120,,,[10],[1697122371118]
1170,1170,363,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383915,1697122385619,120,,,[58],[1697122383973]
1171,1171,632,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405698,1697122407058,120,,,[22],[1697122405720]
1172,1172,324,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373014,1697122374081,120,,,[28],[1697122373042]
1173,1173,284,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407062,1697122408127,120,,,[34],[1697122407096]
1174,1174,908,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374088,1697122376092,120,,,"[86, 1764]","[1697122374174, 1697122375938]"
1175,1175,296,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373015,1697122375086,120,,,[51],[1697122373066]
1176,1176,35,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407063,1697122409609,120,,,[51],[1697122407114]
1177,1177,25,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385623,1697122387917,120,,,[50],[1697122385673]
1178,1178,64,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408130,1697122410670,120,,,"[44, 2362]","[1697122408174, 1697122410536]"
1179,1179,764,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433681,1697122436783,120,,,[167],[1697122433848]
1180,1180,723,20,[],200,llama-7b,64,1,1098.0,1.0,1,A10,1697122387921,1697122389019,120,14.0,1.0,"[40, 1058]","[1697122387961, 1697122389019]"
1181,1181,734,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409612,1697122410669,120,,,"[30, 895]","[1697122409642, 1697122410537]"
1182,1182,647,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410675,1697122412984,120,,,[92],[1697122410767]
1183,1183,419,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412989,1697122415032,120,,,"[18, 1856]","[1697122413007, 1697122414863]"
1184,1184,679,13,[],200,llama-7b,64,1,2821.0,1.0,1,A10,1697122376098,1697122378919,120,15.0,1.0,"[157, 2664]","[1697122376255, 1697122378919]"
1185,1185,335,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378923,1697122383905,120,,,"[25, 1985, 925, 974]","[1697122378948, 1697122380933, 1697122381858, 1697122382832]"
1186,1186,680,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408129,1697122410669,120,,,"[29, 2378]","[1697122408158, 1697122410536]"
1187,1187,512,36,[],200,llama-7b,64,1,1817.0,1.0,1,A10,1697122436790,1697122438607,120,11.0,1.0,"[75, 1742]","[1697122436865, 1697122438607]"
1188,1188,390,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410674,1697122412985,120,,,[73],[1697122410747]
1189,1189,166,26,[],200,llama-7b,64,1,1870.0,1.0,1,A10,1697122412993,1697122414863,120,14.0,1.0,"[58, 1812]","[1697122413051, 1697122414863]"
1190,1190,570,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380026,1697122381806,120,,,[37],[1697122380063]
1191,1191,798,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389104,1697122391053,120,,,[29],[1697122389133]
1192,1192,79,33,[],200,llama-7b,64,1,2313.0,1.0,1,A10,1697122415036,1697122417349,120,12.0,1.0,"[25, 2288]","[1697122415061, 1697122417349]"
1193,1193,769,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385622,1697122387918,120,,,[108],[1697122385730]
1194,1194,102,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383912,1697122386860,120,,,[127],[1697122384039]
1195,1195,163,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438610,1697122440576,120,,,"[11, 770]","[1697122438621, 1697122439391]"
1196,1196,693,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386865,1697122389101,120,,,"[98, 2056]","[1697122386963, 1697122389019]"
1197,1197,12,18,[],200,llama-7b,64,1,2154.0,1.0,1,A10,1697122386864,1697122389018,120,11.0,1.0,"[46, 2108]","[1697122386910, 1697122389018]"
1198,1198,575,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391057,1697122392787,120,,,[41],[1697122391098]
1199,1199,342,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361071,1697122362057,120,,,"[28, 803]","[1697122361099, 1697122361902]"
1200,1200,462,17,[],200,llama-7b,64,1,1862.0,1.0,1,A10,1697122389108,1697122390970,120,52.0,1.0,"[63, 1799]","[1697122389171, 1697122390970]"
1201,1201,865,38,[],200,llama-7b,64,1,1786.0,1.0,1,A10,1697122440588,1697122442374,120,9.0,1.0,"[86, 1700]","[1697122440674, 1697122442374]"
1202,1202,425,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387920,1697122389101,120,,,"[16, 1084]","[1697122387936, 1697122389020]"
1203,1203,519,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442376,1697122443688,120,,,[15],[1697122442391]
1204,1204,197,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389104,1697122391051,120,,,"[48, 1817]","[1697122389152, 1697122390969]"
1205,1205,602,19,[],200,llama-7b,64,1,1018.0,1.0,1,A10,1697122389021,1697122390039,120,15.0,1.0,"[31, 987]","[1697122389052, 1697122390039]"
1206,1206,118,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122390973,1697122402609,120,,,"[30, 651, 1179, 1186, 1212, 999, 1062, 1079, 1223, 1399, 772]","[1697122391003, 1697122391654, 1697122392833, 1697122394019, 1697122395231, 1697122396230, 1697122397292, 1697122398371, 1697122399594, 1697122400993, 1697122401765]"
1207,1207,290,40,[],200,llama-7b,64,1,2392.0,1.0,1,A10,1697122443694,1697122446086,120,14.0,1.0,"[69, 2323]","[1697122443763, 1697122446086]"
1208,1208,802,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391061,1697122393972,120,,,[109],[1697122391170]
1209,1209,787,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391058,1697122392786,120,,,[25],[1697122391083]
1210,1210,371,20,[],200,llama-7b,64,1,1608.0,1.0,1,A10,1697122390046,1697122391654,120,13.0,1.0,"[27, 1581]","[1697122390073, 1697122391654]"
1211,1211,572,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393975,1697122396183,120,,,[54],[1697122394029]
1212,1212,555,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392790,1697122393971,120,,,[35],[1697122392825]
1213,1213,232,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396193,1697122397244,120,,,[17],[1697122396210]
1214,1214,302,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393974,1697122396183,120,,,[41],[1697122394015]
1215,1215,4,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397246,1697122398322,120,,,[10],[1697122397256]
1216,1216,43,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365131,1697122366982,120,,,[48],[1697122365179]
1217,1217,33,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391656,1697122393972,120,,,[17],[1697122391673]
1218,1218,172,20,[],200,llama-7b,64,1,2071.0,1.0,1,A10,1697122381812,1697122383883,120,19.0,1.0,"[75, 1996]","[1697122381887, 1697122383883]"
1219,1219,586,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398326,1697122400949,120,,,[57],[1697122398383]
1220,1220,742,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366985,1697122367969,120,,,[45],[1697122367030]
1221,1221,412,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409613,1697122411708,120,,,[117],[1697122409730]
1222,1222,886,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396194,1697122397244,120,,,[33],[1697122396227]
1223,1223,823,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402614,1697122404423,120,,,[119],[1697122402733]
1224,1224,656,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397248,1697122399547,120,,,[50],[1697122397298]
1225,1225,179,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367035,1697122369039,120,,,[39],[1697122367074]
1226,1226,477,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404430,1697122407057,120,,,[129],[1697122404559]
1227,1227,254,12,[],200,llama-7b,64,1,2822.0,1.0,1,A10,1697122376098,1697122378920,120,58.0,1.0,"[139, 2682]","[1697122376237, 1697122378919]"
1228,1228,159,26,[],200,llama-7b,64,1,2185.0,1.0,1,A10,1697122411714,1697122413899,120,31.0,1.0,"[63, 2121]","[1697122411777, 1697122413898]"
1229,1229,366,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400954,1697122402609,120,,,"[92, 1531]","[1697122401046, 1697122402577]"
1230,1230,836,13,[],200,llama-7b,64,1,2010.0,1.0,1,A10,1697122378923,1697122380933,120,11.0,1.0,"[16, 1994]","[1697122378939, 1697122380933]"
1231,1231,860,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398326,1697122399547,120,,,[34],[1697122398360]
1232,1232,19,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402618,1697122405696,120,,,[155],[1697122402773]
1233,1233,631,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399551,1697122402609,120,,,"[48, 2166]","[1697122399599, 1697122401765]"
1234,1234,316,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371108,1697122373010,120,,,[6],[1697122371114]
1235,1235,608,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380936,1697122382783,120,,,[6],[1697122380942]
1236,1236,285,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402615,1697122405695,120,,,[134],[1697122402749]
1237,1237,356,15,[],200,llama-7b,64,1,2882.0,1.0,1,A10,1697122382787,1697122385669,120,874.0,2.0,"[42, 1915, 925]","[1697122382829, 1697122384744, 1697122385669]"
1238,1238,62,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405698,1697122407058,120,,,[18],[1697122405716]
1239,1239,75,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359220,1697122361069,120,,,[129],[1697122359349]
1240,1240,642,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407065,1697122409610,120,,,[91],[1697122407156]
1241,1241,620,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391057,1697122392786,120,,,[21],[1697122391078]
1242,1242,92,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373013,1697122374081,120,,,[29],[1697122373042]
1243,1243,152,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371109,1697122373012,120,,,[47],[1697122371156]
1244,1244,851,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373016,1697122375087,120,,,[70],[1697122373086]
1245,1245,892,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386865,1697122389101,120,,,"[93, 2061]","[1697122386958, 1697122389019]"
1246,1246,729,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398324,1697122399547,120,,,[16],[1697122398340]
1247,1247,801,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438629,1697122440577,120,,,"[34, 1779]","[1697122438663, 1697122440442]"
1248,1248,697,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424114,1697122424992,120,,,"[16, 844]","[1697122424130, 1697122424974]"
1249,1249,458,31,[],200,llama-7b,64,1,2403.0,1.0,1,A10,1697122408134,1697122410537,120,11.0,1.0,"[114, 2288]","[1697122408248, 1697122410536]"
1250,1250,419,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409613,1697122411707,120,,,[58],[1697122409671]
1251,1251,391,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399550,1697122402609,120,,,"[34, 2182]","[1697122399584, 1697122401766]"
1252,1252,576,46,[],200,llama-7b,64,1,1786.0,1.0,1,A10,1697122440588,1697122442374,120,14.0,1.0,"[61, 1725]","[1697122440649, 1697122442374]"
1253,1253,273,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392793,1697122395178,120,,,[75],[1697122392868]
1254,1254,156,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402618,1697122405695,120,,,[141],[1697122402759]
1255,1255,19,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373015,1697122375086,120,,,[62],[1697122373077]
1256,1256,434,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacty of 21.99 GiB of which 285.00 MiB is free. Process 430828 has 21.70 GiB memory in use. Of the allocated memory 15.60 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122356975,1697122359214,120,,,[89],[1697122357064]
1257,1257,886,9,[],200,llama-7b,64,1,848.0,1.0,1,A10,1697122375090,1697122375938,120,17.0,1.0,"[46, 802]","[1697122375136, 1697122375938]"
1258,1258,87,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.61 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.58 GiB is free. Process 430828 has 20.39 GiB memory in use. Of the allocated memory 16.48 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122359221,1697122361069,120,,,[56],[1697122359277]
1259,1259,236,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442379,1697122443688,120,,,[27],[1697122442406]
1260,1260,794,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361077,1697122363189,120,,,[64],[1697122361141]
1261,1261,6,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122443691,1697122451944,120,,,"[42, 3167, 975, 970, 987, 931]","[1697122443733, 1697122446900, 1697122447875, 1697122448845, 1697122449832, 1697122450763]"
1262,1262,601,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375089,1697122376091,120,,,"[33, 816]","[1697122375122, 1697122375938]"
1263,1263,449,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363194,1697122365126,120,,,[53],[1697122363247]
1264,1264,51,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395183,1697122397244,120,,,[76],[1697122395259]
1265,1265,113,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410541,1697122411708,120,,,[28],[1697122410569]
1266,1266,139,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365131,1697122366982,120,,,[44],[1697122365175]
1267,1267,631,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397249,1697122399547,120,,,[54],[1697122397303]
1268,1268,723,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366985,1697122367968,120,,,[30],[1697122367015]
1269,1269,660,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375941,1697122378082,120,,,"[30, 1213]","[1697122375971, 1697122377184]"
1270,1270,492,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367970,1697122370100,120,,,[16],[1697122367986]
1271,1271,812,33,[],200,llama-7b,64,1,2184.0,1.0,1,A10,1697122411715,1697122413899,120,16.0,1.0,"[115, 2069]","[1697122411830, 1697122413899]"
1272,1272,378,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376097,1697122380019,120,,,[67],[1697122376164]
1273,1273,218,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365130,1697122366982,120,,,[35],[1697122365165]
1274,1274,408,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399550,1697122400951,120,,,[39],[1697122399589]
1275,1275,343,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381810,1697122382784,120,,,[31],[1697122381841]
1276,1276,182,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383919,1697122386860,120,,,[145],[1697122384064]
1277,1277,472,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122413901,1697122416373,120,,,[15],[1697122413916]
1278,1278,154,13,[],200,llama-7b,64,1,1917.0,1.0,1,A10,1697122370105,1697122372022,120,13.0,1.0,"[55, 1862]","[1697122370160, 1697122372022]"
1279,1279,808,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366989,1697122369039,120,,,[81],[1697122367070]
1280,1280,850,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122372031,1697122374082,120,,,[23],[1697122372054]
1281,1281,886,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386863,1697122387918,120,,,[32],[1697122386895]
1282,1282,314,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391058,1697122392787,120,,,[30],[1697122391088]
1283,1283,4,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122382786,1697122383904,120,,,"[28, 1069]","[1697122382814, 1697122383883]"
1284,1284,880,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446092,1697122447823,120,,,[12],[1697122446104]
1285,1285,926,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362065,1697122364143,120,,,[103],[1697122362168]
1286,1286,704,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383913,1697122385619,120,,,[52],[1697122383965]
1287,1287,649,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447829,1697122449781,120,,,[121],[1697122447950]
1288,1288,581,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122369041,1697122370102,120,,,[24],[1697122369065]
1289,1289,639,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376097,1697122380019,120,,,"[153, 2670]","[1697122376250, 1697122378920]"
1290,1290,308,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449784,1697122451943,120,,,"[40, 1927]","[1697122449824, 1697122451751]"
1291,1291,79,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451948,1697122453810,120,,,[31],[1697122451979]
1292,1292,514,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374085,1697122376092,120,,,"[40, 1812]","[1697122374125, 1697122375937]"
1293,1293,84,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392795,1697122395178,120,,,[74],[1697122392869]
1294,1294,642,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453813,1697122455926,120,,,[25],[1697122453838]
1295,1295,703,11,[],200,llama-7b,64,1,1889.0,1.0,1,A10,1697122364151,1697122366040,120,12.0,1.0,"[107, 1782]","[1697122364258, 1697122366040]"
1296,1296,760,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395182,1697122397244,120,,,[68],[1697122395250]
1297,1297,325,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122357992,1697122362057,120,,,"[67, 2100, 971]","[1697122358059, 1697122360159, 1697122361130]"
1298,1298,211,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370109,1697122376090,120,,,"[129, 1784, 1042, 1068, 1005]","[1697122370238, 1697122372022, 1697122373064, 1697122374132, 1697122375137]"
1299,1299,356,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366042,1697122367967,120,,,[27],[1697122366069]
1300,1300,284,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376097,1697122380018,120,,,[73],[1697122376170]
1301,1301,507,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373014,1697122375086,120,,,[38],[1697122373052]
1302,1302,414,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455929,1697122456993,120,,,[33],[1697122455962]
1303,1303,868,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380025,1697122381806,120,,,[28],[1697122380053]
1304,1304,103,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362060,1697122364142,120,,,[21],[1697122362081]
1305,1305,25,28,[],200,llama-7b,64,1,1618.0,1.0,1,A10,1697122400959,1697122402577,120,12.0,1.0,"[102, 1516]","[1697122401061, 1697122402577]"
1306,1306,394,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398330,1697122400950,120,,,[142],[1697122398472]
1307,1307,167,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400958,1697122402609,120,,,"[51, 1567]","[1697122401009, 1697122402576]"
1308,1308,762,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122369042,1697122370102,120,,,[38],[1697122369080]
1309,1309,752,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402612,1697122404422,120,,,[9],[1697122402621]
1310,1310,806,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381812,1697122383905,120,,,"[60, 2010]","[1697122381872, 1697122383882]"
1311,1311,227,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407060,1697122408127,120,,,[21],[1697122407081]
1312,1312,499,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404428,1697122407057,120,,,[121],[1697122404549]
1313,1313,153,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407060,1697122408126,120,,,[12],[1697122407072]
1314,1314,857,32,[],200,llama-7b,64,1,2405.0,1.0,1,A10,1697122408132,1697122410537,120,18.0,1.0,"[100, 2305]","[1697122408232, 1697122410537]"
1315,1315,510,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410540,1697122411708,120,,,[24],[1697122410564]
1316,1316,697,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423163,1697122424991,120,,,"[51, 1759]","[1697122423214, 1697122424973]"
1317,1317,287,34,[],200,llama-7b,64,1,2185.0,1.0,1,A10,1697122411714,1697122413899,120,10.0,1.0,"[59, 2125]","[1697122411773, 1697122413898]"
1318,1318,582,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383916,1697122385619,120,,,[64],[1697122383980]
1319,1319,868,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122413902,1697122416374,120,,,[24],[1697122413926]
1320,1320,231,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385621,1697122386860,120,,,[29],[1697122385650]
1321,1321,80,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361078,1697122363190,120,,,[88],[1697122361166]
1322,1322,660,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363194,1697122365125,120,,,[38],[1697122363232]
1323,1323,357,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424994,1697122426578,120,,,[81],[1697122425075]
1324,1324,638,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416378,1697122418474,120,,,"[92, 1847]","[1697122416470, 1697122418317]"
1325,1325,8,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386863,1697122387918,120,,,[27],[1697122386890]
1326,1326,677,26,[],200,llama-7b,64,1,534.0,1.0,1,A10,1697122402579,1697122403113,120,9.0,1.0,"[13, 521]","[1697122402592, 1697122403113]"
1327,1327,408,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365130,1697122366982,120,,,[40],[1697122365170]
1328,1328,177,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366988,1697122369039,120,,,[77],[1697122367065]
1329,1329,127,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426582,1697122429745,120,,,"[84, 2163, 59]","[1697122426666, 1697122428829, 1697122428888]"
1330,1330,592,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387921,1697122391053,120,,,"[45, 2073]","[1697122387966, 1697122390039]"
1331,1331,715,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429750,1697122431564,120,,,[35],[1697122429785]
1332,1332,762,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122369042,1697122370102,120,,,[33],[1697122369075]
1333,1333,298,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418482,1697122420381,120,,,[91],[1697122418573]
1334,1334,863,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442476,1697122445116,120,,,[54],[1697122442530]
1335,1335,485,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431569,1697122433673,120,,,[105],[1697122431674]
1336,1336,467,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122357992,1697122362057,120,,,"[50, 2117, 971]","[1697122358042, 1697122360159, 1697122361130]"
1337,1337,543,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370112,1697122376090,120,,,"[132, 1778, 1042, 1068, 1005]","[1697122370244, 1697122372022, 1697122373064, 1697122374132, 1697122375137]"
1338,1338,145,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433677,1697122436783,120,,,[54],[1697122433731]
1339,1339,611,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445121,1697122446847,120,,,[35],[1697122445156]
1340,1340,362,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391061,1697122392787,120,,,[104],[1697122391165]
1341,1341,264,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446848,1697122447824,120,,,[15],[1697122446863]
1342,1342,196,14,[],200,llama-7b,64,1,1837.0,1.0,1,A10,1697122376095,1697122377932,120,13.0,1.0,"[18, 1819]","[1697122376113, 1697122377932]"
1343,1343,41,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447827,1697122449781,120,,,[43],[1697122447870]
1344,1344,23,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392791,1697122395177,120,,,[57],[1697122392848]
1345,1345,243,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362061,1697122364143,120,,,[40],[1697122362101]
1346,1346,625,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449785,1697122451944,120,,,"[64, 1903]","[1697122449849, 1697122451752]"
1347,1347,719,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395180,1697122396184,120,,,[30],[1697122395210]
1348,1348,900,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122377935,1697122380020,120,,,"[6, 979]","[1697122377941, 1697122378920]"
1349,1349,467,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396194,1697122397244,120,,,[28],[1697122396222]
1350,1350,826,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122364149,1697122371105,120,,,"[96, 1794, 994, 985, 1073, 1063]","[1697122364245, 1697122366039, 1697122367033, 1697122368018, 1697122369091, 1697122370154]"
1351,1351,124,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397247,1697122398322,120,,,[21],[1697122397268]
1352,1352,403,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451949,1697122453810,120,,,[34],[1697122451983]
1353,1353,68,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420387,1697122423159,120,,,[88],[1697122420475]
1354,1354,825,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398326,1697122400950,120,,,[49],[1697122398375]
1355,1355,743,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423162,1697122424992,120,,,"[27, 924, 87]","[1697122423189, 1697122424113, 1697122424200]"
1356,1356,553,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380024,1697122381805,120,,,[9],[1697122380033]
1357,1357,56,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453813,1697122455926,120,,,[35],[1697122453848]
1358,1358,396,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424994,1697122426575,120,,,[91],[1697122425085]
1359,1359,345,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395180,1697122396184,120,,,[35],[1697122395215]
1360,1360,846,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436787,1697122438625,120,,,"[27, 1792]","[1697122436814, 1697122438606]"
1361,1361,173,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426581,1697122429745,120,,,"[45, 2202, 60]","[1697122426626, 1697122428828, 1697122428888]"
1362,1362,503,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438629,1697122440577,120,,,"[12, 1800]","[1697122438641, 1697122440441]"
1363,1363,331,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381810,1697122382784,120,,,[38],[1697122381848]
1364,1364,761,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429750,1697122431564,120,,,[27],[1697122429777]
1365,1365,914,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122382789,1697122389101,120,,,"[75, 1881, 924, 1237, 1060]","[1697122382864, 1697122384745, 1697122385669, 1697122386906, 1697122387966]"
1366,1366,250,46,[],200,llama-7b,64,1,1789.0,1.0,1,A10,1697122440584,1697122442373,120,31.0,1.0,"[35, 1754]","[1697122440619, 1697122442373]"
1367,1367,69,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122411710,1697122415031,120,,,"[23, 2164]","[1697122411733, 1697122413897]"
1368,1368,485,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400954,1697122402609,120,,,"[87, 1536]","[1697122401041, 1697122402577]"
1369,1369,833,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442375,1697122443687,120,,,[17],[1697122442392]
1370,1370,95,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396198,1697122398323,120,,,[134],[1697122396332]
1371,1371,608,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122443691,1697122451943,120,,,"[22, 2372, 815, 975, 970, 987, 930]","[1697122443713, 1697122446085, 1697122446900, 1697122447875, 1697122448845, 1697122449832, 1697122450762]"
1372,1372,381,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389022,1697122391052,120,,,"[20, 997]","[1697122389042, 1697122390039]"
1373,1373,255,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402615,1697122404423,120,,,[128],[1697122402743]
1374,1374,594,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451952,1697122454906,120,,,[116],[1697122452068]
1375,1375,106,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365129,1697122366982,120,,,[31],[1697122365160]
1376,1376,677,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371112,1697122373011,120,,,[58],[1697122371170]
1377,1377,446,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373015,1697122375087,120,,,[67],[1697122373082]
1378,1378,684,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389104,1697122391051,120,,,"[53, 1812]","[1697122389157, 1697122390969]"
1379,1379,364,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454917,1697122456991,120,,,[71],[1697122454988]
1380,1380,107,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375089,1697122376092,120,,,[43],[1697122375132]
1381,1381,312,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391062,1697122393972,120,,,[175],[1697122391237]
1382,1382,449,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410673,1697122412984,120,,,[32],[1697122410705]
1383,1383,806,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376097,1697122378083,120,,,"[63, 1772]","[1697122376160, 1697122377932]"
1384,1384,24,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122456994,1697122458094,120,,,[35],[1697122457029]
1385,1385,552,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378095,1697122380020,120,,,"[65, 1776]","[1697122378160, 1697122379936]"
1386,1386,205,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380031,1697122382783,120,,,[128],[1697122380159]
1387,1387,749,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122414866,1697122416372,120,,,[11],[1697122414877]
1388,1388,725,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458103,1697122461247,120,,,[142],[1697122458245]
1389,1389,911,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122382788,1697122389102,120,,,"[51, 1905, 925, 1237, 1059]","[1697122382839, 1697122384744, 1697122385669, 1697122386906, 1697122387965]"
1390,1390,374,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461250,1697122463976,120,,,[44],[1697122461294]
1391,1391,540,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387921,1697122389100,120,,,"[40, 1058]","[1697122387961, 1697122389019]"
1392,1392,131,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367971,1697122369039,120,,,[30],[1697122368001]
1393,1393,562,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389107,1697122391051,120,,,"[50, 1812]","[1697122389157, 1697122390969]"
1394,1394,690,5,[],200,llama-7b,64,1,1887.0,1.0,1,A10,1697122364153,1697122366040,120,39.0,1.0,"[110, 1777]","[1697122364263, 1697122366040]"
1395,1395,729,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393975,1697122395177,120,,,[28],[1697122394003]
1396,1396,160,8,[],200,llama-7b,64,1,2094.0,1.0,1,A10,1697122375090,1697122377184,120,13.0,1.0,"[52, 2041]","[1697122375142, 1697122377183]"
1397,1397,419,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380026,1697122381807,120,,,[47],[1697122380073]
1398,1398,71,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381811,1697122383904,120,,,"[45, 2027]","[1697122381856, 1697122383883]"
1399,1399,390,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395181,1697122397243,120,,,[63],[1697122395244]
1400,1400,860,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122377187,1697122380019,120,,,"[17, 1716]","[1697122377204, 1697122378920]"
1401,1401,748,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383910,1697122385619,120,,,[60],[1697122383970]
1402,1402,318,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399550,1697122400951,120,,,[30],[1697122399580]
1403,1403,517,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380031,1697122381807,120,,,[119],[1697122380150]
1404,1404,156,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397246,1697122398322,120,,,[23],[1697122397269]
1405,1405,517,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385624,1697122387918,120,,,[111],[1697122385735]
1406,1406,123,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463980,1697122466343,120,,,[70],[1697122464050]
1407,1407,740,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398325,1697122399547,120,,,[20],[1697122398345]
1408,1408,809,22,[],200,llama-7b,64,1,2405.0,1.0,1,A10,1697122408132,1697122410537,120,16.0,1.0,"[105, 2300]","[1697122408237, 1697122410537]"
1409,1409,173,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387920,1697122389102,120,,,"[31, 1068]","[1697122387951, 1697122389019]"
1410,1410,488,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399549,1697122400950,120,,,[11],[1697122399560]
1411,1411,586,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410540,1697122411708,120,,,[14],[1697122410554]
1412,1412,695,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405699,1697122407058,120,,,[17],[1697122405716]
1413,1413,878,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389108,1697122391052,120,,,"[68, 1793]","[1697122389176, 1697122390969]"
1414,1414,487,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380026,1697122381805,120,,,[56],[1697122380082]
1415,1415,287,11,[],200,llama-7b,64,1,2070.0,1.0,1,A10,1697122381814,1697122383884,120,10.0,1.0,"[116, 1953]","[1697122381930, 1697122383883]"
1416,1416,141,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381809,1697122382783,120,,,[27],[1697122381836]
1417,1417,816,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122382786,1697122383904,120,,,"[25, 1072]","[1697122382811, 1697122383883]"
1418,1418,875,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383887,1697122385619,120,,,[34],[1697122383921]
1419,1419,532,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391058,1697122392787,120,,,[40],[1697122391098]
1420,1420,632,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404426,1697122407057,120,,,[39],[1697122404465]
1421,1421,484,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391057,1697122392786,120,,,[21],[1697122391078]
1422,1422,305,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392791,1697122395177,120,,,[58],[1697122392849]
1423,1423,349,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407062,1697122409608,120,,,[40],[1697122407102]
1424,1424,886,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395182,1697122397244,120,,,[57],[1697122395239]
1425,1425,757,49,[],200,llama-7b,64,1,2080.0,1.0,1,A10,1697122455932,1697122458012,120,20.0,1.0,"[98, 1982]","[1697122456030, 1697122458012]"
1426,1426,253,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392789,1697122393972,120,,,[41],[1697122392830]
1427,1427,417,50,[],200,llama-7b,64,1,738.0,1.0,1,A10,1697122458018,1697122458756,120,17.0,1.0,"[32, 706]","[1697122458050, 1697122458756]"
1428,1428,842,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393974,1697122395177,120,,,[22],[1697122393996]
1429,1429,611,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395180,1697122396183,120,,,[20],[1697122395200]
1430,1430,407,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407061,1697122408127,120,,,[18],[1697122407079]
1431,1431,120,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409614,1697122411708,120,,,[116],[1697122409730]
1432,1432,527,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396188,1697122397245,120,,,[18],[1697122396206]
1433,1433,710,28,[],200,llama-7b,64,1,2187.0,1.0,1,A10,1697122411711,1697122413898,120,14.0,1.0,"[27, 2160]","[1697122411738, 1697122413898]"
1434,1434,298,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397251,1697122399547,120,,,[85],[1697122397336]
1435,1435,61,25,[],200,llama-7b,64,1,2407.0,1.0,1,A10,1697122408130,1697122410537,120,9.0,1.0,"[47, 2360]","[1697122408177, 1697122410537]"
1436,1436,881,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399550,1697122402609,120,,,"[35, 2068, 113]","[1697122399585, 1697122401653, 1697122401766]"
1437,1437,573,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371109,1697122374081,120,,,[40],[1697122371149]
1438,1438,663,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397246,1697122398323,120,,,[37],[1697122397283]
1439,1439,766,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410538,1697122411708,120,,,[6],[1697122410544]
1440,1440,268,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396195,1697122398322,120,,,[147],[1697122396342]
1441,1441,422,27,[],200,llama-7b,64,1,2184.0,1.0,1,A10,1697122411714,1697122413898,120,26.0,1.0,"[54, 2130]","[1697122411768, 1697122413898]"
1442,1442,342,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374084,1697122375086,120,,,[26],[1697122374110]
1443,1443,40,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398324,1697122399547,120,,,[14],[1697122398338]
1444,1444,187,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122413901,1697122416373,120,,,[16],[1697122413917]
1445,1445,2,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375089,1697122378079,120,,,"[52, 2042]","[1697122375141, 1697122377183]"
1446,1446,628,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402618,1697122405696,120,,,[155],[1697122402773]
1447,1447,622,28,[],200,llama-7b,64,1,2099.0,1.0,1,A10,1697122399554,1697122401653,120,20.0,1.0,"[84, 2015]","[1697122399638, 1697122401653]"
1448,1448,865,29,[],200,llama-7b,64,1,2581.0,1.0,1,A10,1697122416382,1697122418963,120,9.0,1.0,"[159, 2422]","[1697122416541, 1697122418963]"
1449,1449,701,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378087,1697122380021,120,,,"[21, 1828]","[1697122378108, 1697122379936]"
1450,1450,276,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405701,1697122408126,120,,,[70],[1697122405771]
1451,1451,359,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380031,1697122381807,120,,,[124],[1697122380155]
1452,1452,518,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418969,1697122421735,120,,,[42],[1697122419011]
1453,1453,316,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398326,1697122399548,120,,,[22],[1697122398348]
1454,1454,88,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399549,1697122400951,120,,,[21],[1697122399570]
1455,1455,136,15,[],200,llama-7b,64,1,2071.0,1.0,1,A10,1697122381812,1697122383883,120,31.0,1.0,"[65, 2006]","[1697122381877, 1697122383883]"
1456,1456,480,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122413903,1697122416372,120,,,[42],[1697122413945]
1457,1457,136,30,[],200,llama-7b,64,1,2581.0,1.0,1,A10,1697122416382,1697122418963,120,31.0,1.0,"[150, 2431]","[1697122416532, 1697122418963]"
1458,1458,648,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400960,1697122402608,120,,,"[173, 1444]","[1697122401133, 1697122402577]"
1459,1459,53,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408130,1697122410670,120,,,"[49, 2358]","[1697122408179, 1697122410537]"
1460,1460,399,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122401656,1697122410669,120,,,"[23, 1434, 1352, 1274, 1359, 1071, 1483]","[1697122401679, 1697122403113, 1697122404465, 1697122405739, 1697122407098, 1697122408169, 1697122409652]"
1461,1461,636,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410679,1697122412985,120,,,[155],[1697122410834]
1462,1462,719,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383886,1697122385619,120,,,[30],[1697122383916]
1463,1463,407,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412996,1697122416371,120,,,[71],[1697122413067]
1464,1464,293,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421739,1697122424991,120,,,"[92, 2282, 87]","[1697122421831, 1697122424113, 1697122424200]"
1465,1465,833,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418966,1697122421735,120,,,[20],[1697122418986]
1466,1466,493,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385622,1697122387917,120,,,[63],[1697122385685]
1467,1467,68,29,[],200,llama-7b,64,1,1940.0,1.0,1,A10,1697122416376,1697122418316,120,12.0,1.0,"[14, 1926]","[1697122416390, 1697122418316]"
1468,1468,494,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421738,1697122424990,120,,,"[44, 2330, 88]","[1697122421782, 1697122424112, 1697122424200]"
1469,1469,418,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402613,1697122404422,120,,,[23],[1697122402636]
1470,1470,80,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404428,1697122407057,120,,,[52],[1697122404480]
1471,1471,779,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407065,1697122409610,120,,,[98],[1697122407163]
1472,1472,875,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424995,1697122426576,120,,,[156],[1697122425151]
1473,1473,50,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410673,1697122412984,120,,,[99],[1697122410772]
1474,1474,727,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412989,1697122415031,120,,,"[23, 1851]","[1697122413012, 1697122414863]"
1475,1475,264,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424993,1697122426577,120,,,[77],[1697122425070]
1476,1476,497,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415034,1697122418475,120,,,"[11, 2303]","[1697122415045, 1697122417348]"
1477,1477,440,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409613,1697122411707,120,,,[58],[1697122409671]
1478,1478,652,33,[],200,llama-7b,64,1,2247.0,1.0,1,A10,1697122426582,1697122428829,120,14.0,1.0,"[49, 2197]","[1697122426631, 1697122428828]"
1479,1479,715,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405699,1697122407057,120,,,[32],[1697122405731]
1480,1480,147,18,[],200,llama-7b,64,1,1101.0,1.0,1,A10,1697122387919,1697122389020,120,182.0,1.0,"[7, 1094]","[1697122387926, 1697122389020]"
1481,1481,153,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418481,1697122420382,120,,,[67],[1697122418548]
1482,1482,848,34,[],200,llama-7b,64,1,2247.0,1.0,1,A10,1697122426582,1697122428829,120,47.0,1.0,"[54, 2193]","[1697122426636, 1697122428829]"
1483,1483,596,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122428832,1697122432498,120,,,"[42, 1467, 1271]","[1697122428874, 1697122430341, 1697122431612]"
1484,1484,485,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407061,1697122408127,120,,,[26],[1697122407087]
1485,1485,805,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366987,1697122369038,120,,,[73],[1697122367060]
1486,1486,315,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378086,1697122380019,120,,,"[27, 1823]","[1697122378113, 1697122379936]"
1487,1487,262,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451949,1697122453810,120,,,[85],[1697122452034]
1488,1488,145,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408131,1697122410670,120,,,"[53, 2353]","[1697122408184, 1697122410537]"
1489,1489,556,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122369042,1697122370102,120,,,[33],[1697122369075]
1490,1490,212,13,[],200,llama-7b,64,1,1917.0,1.0,1,A10,1697122370106,1697122372023,120,31.0,1.0,"[69, 1848]","[1697122370175, 1697122372023]"
1491,1491,824,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389022,1697122391053,120,,,"[25, 992]","[1697122389047, 1697122390039]"
1492,1492,211,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122411716,1697122415032,120,,,"[124, 2059]","[1697122411840, 1697122413899]"
1493,1493,910,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122372032,1697122374081,120,,,[34],[1697122372066]
1494,1494,480,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391062,1697122393973,120,,,[122],[1697122391184]
1495,1495,846,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410675,1697122412983,120,,,[88],[1697122410763]
1496,1496,365,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432511,1697122435152,120,,,[123],[1697122432634]
1497,1497,245,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393976,1697122396183,120,,,[62],[1697122394038]
1498,1498,794,30,[],200,llama-7b,64,1,2311.0,1.0,1,A10,1697122415039,1697122417350,120,11.0,1.0,"[106, 2204]","[1697122415145, 1697122417349]"
1499,1499,499,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412996,1697122416372,120,,,[76],[1697122413072]
1500,1500,570,15,[],200,llama-7b,64,1,1853.0,1.0,1,A10,1697122374085,1697122375938,120,18.0,1.0,"[65, 1788]","[1697122374150, 1697122375938]"
1501,1501,277,30,[],200,llama-7b,64,1,1940.0,1.0,1,A10,1697122416378,1697122418318,120,18.0,1.0,"[82, 1857]","[1697122416460, 1697122418317]"
1502,1502,27,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435162,1697122438626,120,,,"[102, 2602]","[1697122435264, 1697122437866]"
1503,1503,862,31,[],200,llama-7b,64,1,2101.0,1.0,1,A10,1697122418320,1697122420421,120,216.0,2.0,"[9, 2092]","[1697122418329, 1697122420421]"
1504,1504,91,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380031,1697122381806,120,,,[114],[1697122380145]
1505,1505,339,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375941,1697122378082,120,,,"[20, 1223]","[1697122375961, 1697122377184]"
1506,1506,637,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420422,1697122423160,120,,,[115],[1697122420537]
1507,1507,928,17,[],200,llama-7b,64,1,1849.0,1.0,1,A10,1697122378087,1697122379936,120,20.0,1.0,"[11, 1838]","[1697122378098, 1697122379936]"
1508,1508,570,31,[],200,llama-7b,64,1,1611.0,1.0,1,A10,1697122417353,1697122418964,120,18.0,1.0,"[23, 1588]","[1697122417376, 1697122418964]"
1509,1509,698,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122379938,1697122383905,120,,,"[7, 988, 925, 974]","[1697122379945, 1697122380933, 1697122381858, 1697122382832]"
1510,1510,223,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418967,1697122421735,120,,,[29],[1697122418996]
1511,1511,291,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423163,1697122424991,120,,,[67],[1697122423230]
1512,1512,105,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412997,1697122416372,120,,,[140],[1697122413137]
1513,1513,38,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424993,1697122426577,120,,,[68],[1697122425061]
1514,1514,65,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400954,1697122402608,120,,,"[34, 665, 112]","[1697122400988, 1697122401653, 1697122401765]"
1515,1515,739,35,[],200,llama-7b,64,1,1070.0,1.0,1,A10,1697122426581,1697122427651,120,216.0,1.0,"[13, 1057]","[1697122426594, 1697122427651]"
1516,1516,392,36,[],200,llama-7b,64,1,1172.0,1.0,1,A10,1697122427656,1697122428828,120,20.0,1.0,"[23, 1149]","[1697122427679, 1697122428828]"
1517,1517,726,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438631,1697122440576,120,,,"[104, 1706]","[1697122438735, 1697122440441]"
1518,1518,170,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122428831,1697122432497,120,,,"[34, 1476, 1271]","[1697122428865, 1697122430341, 1697122431612]"
1519,1519,672,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381810,1697122382784,120,,,[15],[1697122381825]
1520,1520,895,33,[],200,llama-7b,64,1,2374.0,1.0,1,A10,1697122421739,1697122424113,120,15.0,1.0,"[58, 2316]","[1697122421797, 1697122424113]"
1521,1521,387,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440589,1697122442470,120,,,"[75, 1709]","[1697122440664, 1697122442373]"
1522,1522,665,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424115,1697122424992,120,,,"[20, 839]","[1697122424135, 1697122424974]"
1523,1523,419,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122382788,1697122389101,120,,,"[61, 1896, 924, 1237, 1059]","[1697122382849, 1697122384745, 1697122385669, 1697122386906, 1697122387965]"
1524,1524,746,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432502,1697122435151,120,,,[18],[1697122432520]
1525,1525,320,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424996,1697122427731,120,,,[189],[1697122425185]
1526,1526,228,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392790,1697122395176,120,,,[44],[1697122392834]
1527,1527,523,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435160,1697122438626,120,,,"[90, 2615]","[1697122435250, 1697122437865]"
1528,1528,807,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416377,1697122418473,120,,,"[41, 1899]","[1697122416418, 1697122418317]"
1529,1529,4,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395179,1697122396183,120,,,[21],[1697122395200]
1530,1530,159,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442482,1697122445119,120,,,[96],[1697122442578]
1531,1531,460,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418481,1697122420381,120,,,[88],[1697122418569]
1532,1532,586,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396195,1697122398323,120,,,[48],[1697122396243]
1533,1533,97,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122427737,1697122429746,120,,,"[16, 1974]","[1697122427753, 1697122429727]"
1534,1534,73,15,[],200,llama-7b,64,1,1865.0,1.0,1,A10,1697122389104,1697122390969,120,9.0,1.0,"[18, 1846]","[1697122389122, 1697122390968]"
1535,1535,366,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398326,1697122399547,120,,,[37],[1697122398363]
1536,1536,889,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409612,1697122410669,120,,,"[29, 896]","[1697122409641, 1697122410537]"
1537,1537,206,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420386,1697122423158,120,,,[68],[1697122420454]
1538,1538,358,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385621,1697122386861,120,,,[34],[1697122385655]
1539,1539,656,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410676,1697122412984,120,,,[157],[1697122410833]
1540,1540,680,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429750,1697122431564,120,,,[89],[1697122429839]
1541,1541,135,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386863,1697122389100,120,,,"[67, 2088]","[1697122386930, 1697122389018]"
1542,1542,616,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381815,1697122383905,120,,,"[122, 1947]","[1697122381937, 1697122383884]"
1543,1543,774,16,[],200,llama-7b,64,1,681.0,1.0,1,A10,1697122390973,1697122391654,120,8.0,1.0,"[35, 646]","[1697122391008, 1697122391654]"
1544,1544,22,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399549,1697122400950,120,,,[6],[1697122399555]
1545,1545,715,23,[],200,llama-7b,64,1,1864.0,1.0,1,A10,1697122389104,1697122390968,120,20.0,1.0,"[6, 1858]","[1697122389110, 1697122390968]"
1546,1546,463,24,[],200,llama-7b,64,1,682.0,1.0,1,A10,1697122390972,1697122391654,120,39.0,1.0,"[21, 661]","[1697122390993, 1697122391654]"
1547,1547,177,40,[],200,llama-7b,64,1,2770.0,1.0,1,A10,1697122438634,1697122441404,120,14.0,1.0,"[145, 2625]","[1697122438779, 1697122441404]"
1548,1548,113,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391658,1697122393971,120,,,[34],[1697122391692]
1549,1549,430,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391657,1697122393972,120,,,[20],[1697122391677]
1550,1550,877,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122441408,1697122443687,120,,,[31],[1697122441439]
1551,1551,788,39,[],200,llama-7b,64,1,1809.0,1.0,1,A10,1697122423165,1697122424974,120,31.0,1.0,"[110, 1699]","[1697122423275, 1697122424974]"
1552,1552,456,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431565,1697122432497,120,,,"[11, 841]","[1697122431576, 1697122432417]"
1553,1553,566,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424977,1697122426577,120,,,[18],[1697122424995]
1554,1554,538,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122443692,1697122451944,120,,,"[46, 2348, 814, 976, 969, 986, 931]","[1697122443738, 1697122446086, 1697122446900, 1697122447876, 1697122448845, 1697122449831, 1697122450762]"
1555,1555,200,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393975,1697122395178,120,,,[43],[1697122394018]
1556,1556,385,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383913,1697122386860,120,,,[131],[1697122384044]
1557,1557,221,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426581,1697122429745,120,,,"[65, 2182, 60]","[1697122426646, 1697122428828, 1697122428888]"
1558,1558,814,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393975,1697122396183,120,,,[54],[1697122394029]
1559,1559,45,20,[],200,llama-7b,64,1,2154.0,1.0,1,A10,1697122386866,1697122389020,120,19.0,1.0,"[103, 2051]","[1697122386969, 1697122389020]"
1560,1560,743,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389024,1697122391053,120,,,"[42, 974]","[1697122389066, 1697122390040]"
1561,1561,920,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429749,1697122431564,120,,,[18],[1697122429767]
1562,1562,404,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391060,1697122393971,120,,,[172],[1697122391232]
1563,1563,287,18,[],200,llama-7b,64,1,1863.0,1.0,1,A10,1697122389107,1697122390970,120,10.0,1.0,"[59, 1804]","[1697122389166, 1697122390970]"
1564,1564,788,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395181,1697122397243,120,,,[54],[1697122395235]
1565,1565,59,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122390973,1697122402608,120,,,"[14, 667, 1179, 1185, 1213, 999, 1062, 1079, 1223, 1399, 772]","[1697122390987, 1697122391654, 1697122392833, 1697122394018, 1697122395231, 1697122396230, 1697122397292, 1697122398371, 1697122399594, 1697122400993, 1697122401765]"
1566,1566,307,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451951,1697122453811,120,,,[97],[1697122452048]
1567,1567,866,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453816,1697122455927,120,,,[62],[1697122453878]
1568,1568,583,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431567,1697122432498,120,,,"[28, 821]","[1697122431595, 1697122432416]"
1569,1569,639,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455930,1697122456992,120,,,[27],[1697122455957]
1570,1570,108,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432504,1697122435152,120,,,[30],[1697122432534]
1571,1571,333,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391058,1697122392787,120,,,[35],[1697122391093]
1572,1572,817,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435160,1697122438626,120,,,"[92, 2613]","[1697122435252, 1697122437865]"
1573,1573,460,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366042,1697122367968,120,,,[17],[1697122366059]
1574,1574,351,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432503,1697122435151,120,,,[15],[1697122432518]
1575,1575,121,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367972,1697122370101,120,,,[69],[1697122368041]
1576,1576,172,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393979,1697122396183,120,,,[94],[1697122394073]
1577,1577,472,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438629,1697122440577,120,,,"[29, 1784]","[1697122438658, 1697122440442]"
1578,1578,12,45,[],200,llama-7b,64,1,2705.0,1.0,1,A10,1697122435161,1697122437866,120,11.0,1.0,"[108, 2597]","[1697122435269, 1697122437866]"
1579,1579,710,46,[],200,llama-7b,64,1,1522.0,1.0,1,A10,1697122437870,1697122439392,120,14.0,1.0,"[24, 1497]","[1697122437894, 1697122439391]"
1580,1580,642,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402613,1697122404422,120,,,[18],[1697122402631]
1581,1581,922,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392788,1697122393971,120,,,[16],[1697122392804]
1582,1582,690,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393976,1697122396183,120,,,[61],[1697122394037]
1583,1583,366,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122439394,1697122442470,120,,,"[14, 1995]","[1697122439408, 1697122441403]"
1584,1584,414,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404426,1697122405696,120,,,[24],[1697122404450]
1585,1585,350,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396194,1697122397244,120,,,[23],[1697122396217]
1586,1586,242,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440587,1697122442469,120,,,"[37, 1749]","[1697122440624, 1697122442373]"
1587,1587,754,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396194,1697122397244,120,,,[21],[1697122396215]
1588,1588,68,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405700,1697122408127,120,,,[56],[1697122405756]
1589,1589,114,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442477,1697122445118,120,,,[53],[1697122442530]
1590,1590,531,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397246,1697122398322,120,,,[32],[1697122397278]
1591,1591,813,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445124,1697122447824,120,,,[142],[1697122445266]
1592,1592,120,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397246,1697122398323,120,,,[33],[1697122397279]
1593,1593,818,8,[],200,llama-7b,64,1,866.0,1.0,1,A10,1697122370105,1697122370971,120,13.0,1.0,"[30, 835]","[1697122370135, 1697122370970]"
1594,1594,469,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447828,1697122449780,120,,,[103],[1697122447931]
1595,1595,772,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408130,1697122410669,120,,,"[37, 2370]","[1697122408167, 1697122410537]"
1596,1596,804,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442474,1697122445116,120,,,[9],[1697122442483]
1597,1597,479,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370972,1697122376090,120,,,"[16, 1035, 1041, 1068, 1005]","[1697122370988, 1697122372023, 1697122373064, 1697122374132, 1697122375137]"
1598,1598,238,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449783,1697122450712,120,,,[12],[1697122449795]
1599,1599,573,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445121,1697122446847,120,,,[20],[1697122445141]
1600,1600,426,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410674,1697122412984,120,,,[78],[1697122410752]
1601,1601,184,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398325,1697122399548,120,,,[18],[1697122398343]
1602,1602,202,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412993,1697122415033,120,,,"[63, 1807]","[1697122413056, 1697122414863]"
1603,1603,827,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122450715,1697122458093,120,,,"[49, 2075, 1025, 1096, 1021, 1064]","[1697122450764, 1697122452839, 1697122453864, 1697122454960, 1697122455981, 1697122457045]"
1604,1604,897,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362064,1697122364143,120,,,[91],[1697122362155]
1605,1605,670,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122364151,1697122371104,120,,,"[109, 1780, 993, 985, 1073, 1063]","[1697122364260, 1697122366040, 1697122367033, 1697122368018, 1697122369091, 1697122370154]"
1606,1606,787,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415037,1697122418474,120,,,"[48, 2264]","[1697122415085, 1697122417349]"
1607,1607,860,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399551,1697122402609,120,,,"[43, 2059, 112]","[1697122399594, 1697122401653, 1697122401765]"
1608,1608,454,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122403118,1697122405697,120,,,[13],[1697122403131]
1609,1609,248,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376096,1697122378079,120,,,"[24, 1812]","[1697122376120, 1697122377932]"
1610,1610,106,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405700,1697122408126,120,,,[50],[1697122405750]
1611,1611,833,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378089,1697122380020,120,,,"[61, 1786]","[1697122378150, 1697122379936]"
1612,1612,777,7,[],200,llama-7b,64,1,827.0,1.0,1,A10,1697122361076,1697122361903,120,9.0,1.0,"[43, 784]","[1697122361119, 1697122361903]"
1613,1613,513,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402612,1697122404422,120,,,[11],[1697122402623]
1614,1614,318,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376096,1697122378083,120,,,"[38, 1798]","[1697122376134, 1697122377932]"
1615,1615,331,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371111,1697122373011,120,,,[53],[1697122371164]
1616,1616,674,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374083,1697122375087,120,,,[7],[1697122374090]
1617,1617,511,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375091,1697122378083,120,,,"[70, 2023]","[1697122375161, 1697122377184]"
1618,1618,186,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458759,1697122461247,120,,,[22],[1697122458781]
1619,1619,469,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383911,1697122385618,120,,,[40],[1697122383951]
1620,1620,531,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431567,1697122432498,120,,,"[43, 807]","[1697122431610, 1697122432417]"
1621,1621,246,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385624,1697122387918,120,,,[69],[1697122385693]
1622,1622,191,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432504,1697122435151,120,,,[25],[1697122432529]
1623,1623,746,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461249,1697122463975,120,,,[25],[1697122461274]
1624,1624,576,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380030,1697122381806,120,,,[114],[1697122380144]
1625,1625,511,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463979,1697122466343,120,,,[46],[1697122464025]
1626,1626,830,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387921,1697122391053,120,,,"[45, 2072]","[1697122387966, 1697122390038]"
1627,1627,451,9,[],200,llama-7b,64,1,850.0,1.0,1,A10,1697122375088,1697122375938,120,286.0,1.0,"[19, 830]","[1697122375107, 1697122375937]"
1628,1628,151,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391060,1697122392787,120,,,[85],[1697122391145]
1629,1629,767,30,[],200,llama-7b,64,1,646.0,1.0,1,A10,1697122418318,1697122418964,120,11.0,1.0,"[6, 639]","[1697122418324, 1697122418963]"
1630,1630,747,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122357992,1697122362057,120,,,"[57, 2110, 971]","[1697122358049, 1697122360159, 1697122361130]"
1631,1631,230,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381812,1697122383905,120,,,"[69, 2002]","[1697122381881, 1697122383883]"
1632,1632,107,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375940,1697122378083,120,,,[16],[1697122375956]
1633,1633,425,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418968,1697122421735,120,,,[38],[1697122419006]
1634,1634,7,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383910,1697122385618,120,,,[31],[1697122383941]
1635,1635,195,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421737,1697122423158,120,,,[20],[1697122421757]
1636,1636,588,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385623,1697122387918,120,,,[65],[1697122385688]
1637,1637,401,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 5.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122362063,1697122364142,120,,,[90],[1697122362153]
1638,1638,875,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423162,1697122424992,120,,,"[32, 919, 86]","[1697122423194, 1697122424113, 1697122424199]"
1639,1639,172,5,[],200,llama-7b,64,1,1890.0,1.0,1,A10,1697122364150,1697122366040,120,19.0,1.0,"[103, 1786]","[1697122364253, 1697122366039]"
1640,1640,364,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387927,1697122391051,120,,,"[114, 1999]","[1697122388041, 1697122390040]"
1641,1641,80,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393977,1697122396184,120,,,[84],[1697122394061]
1642,1642,806,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378096,1697122383905,120,,,"[79, 2757, 926, 973]","[1697122378175, 1697122380932, 1697122381858, 1697122382831]"
1643,1643,670,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396195,1697122398323,120,,,[43],[1697122396238]
1644,1644,17,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391057,1697122392786,120,,,[16],[1697122391073]
1645,1645,494,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416377,1697122418473,120,,,"[60, 1880]","[1697122416437, 1697122418317]"
1646,1646,440,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383921,1697122386860,120,,,[146],[1697122384067]
1647,1647,440,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398326,1697122399547,120,,,[27],[1697122398353]
1648,1648,33,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380025,1697122381805,120,,,[18],[1697122380043]
1649,1649,718,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392791,1697122395177,120,,,[48],[1697122392839]
1650,1650,732,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366042,1697122367967,120,,,[19],[1697122366061]
1651,1651,382,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395182,1697122397243,120,,,[63],[1697122395245]
1652,1652,503,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.62 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367970,1697122369039,120,,,[6],[1697122367976]
1653,1653,152,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397246,1697122398323,120,,,[28],[1697122397274]
1654,1654,161,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122369043,1697122371104,120,,,[57],[1697122369100]
1655,1655,531,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424996,1697122427730,120,,,"[169, 2486]","[1697122425165, 1697122427651]"
1656,1656,95,24,[],200,llama-7b,64,1,2099.0,1.0,1,A10,1697122399554,1697122401653,120,12.0,1.0,"[93, 2006]","[1697122399647, 1697122401653]"
1657,1657,721,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389104,1697122391054,120,,,"[48, 1817]","[1697122389152, 1697122390969]"
1658,1658,300,35,[],200,llama-7b,64,1,1989.0,1.0,1,A10,1697122427738,1697122429727,120,9.0,1.0,"[23, 1965]","[1697122427761, 1697122429726]"
1659,1659,260,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418477,1697122420380,120,,,[20],[1697122418497]
1660,1660,414,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397245,1697122398322,120,,,[18],[1697122397263]
1661,1661,850,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420384,1697122421735,120,,,[14],[1697122420398]
1662,1662,621,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421739,1697122424991,120,,,"[99, 2275, 86]","[1697122421838, 1697122424113, 1697122424199]"
1663,1663,860,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371108,1697122373011,120,,,[46],[1697122371154]
1664,1664,186,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398327,1697122400951,120,,,[122],[1697122398449]
1665,1665,275,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424994,1697122426575,120,,,[96],[1697122425090]
1666,1666,517,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373014,1697122374082,120,,,[43],[1697122373057]
1667,1667,52,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426581,1697122429745,120,,,"[39, 2208, 60]","[1697122426620, 1697122428828, 1697122428888]"
1668,1668,788,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366985,1697122367969,120,,,[25],[1697122367010]
1669,1669,317,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412990,1697122415031,120,,,"[25, 1848]","[1697122413015, 1697122414863]"
1670,1670,827,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398328,1697122400952,120,,,[125],[1697122398453]
1671,1671,289,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374084,1697122376092,120,,,"[46, 1807]","[1697122374130, 1697122375937]"
1672,1672,83,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415036,1697122418474,120,,,"[40, 2273]","[1697122415076, 1697122417349]"
1673,1673,668,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418480,1697122420381,120,,,[32],[1697122418512]
1674,1674,481,22,[],200,llama-7b,64,1,1619.0,1.0,1,A10,1697122400958,1697122402577,120,10.0,1.0,"[45, 1573]","[1697122401003, 1697122402576]"
1675,1675,890,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429730,1697122431563,120,,,[20],[1697122429750]
1676,1676,258,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402580,1697122404421,120,,,[29],[1697122402609]
1677,1677,871,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376096,1697122378084,120,,,"[39, 1797]","[1697122376135, 1697122377932]"
1678,1678,436,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367971,1697122370101,120,,,[35],[1697122368006]
1679,1679,660,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431567,1697122432498,120,,,"[23, 827]","[1697122431590, 1697122432417]"
1680,1680,648,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378091,1697122383905,120,,,"[140, 2701, 926, 973]","[1697122378231, 1697122380932, 1697122381858, 1697122382831]"
1681,1681,318,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432503,1697122435151,120,,,[21],[1697122432524]
1682,1682,444,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420385,1697122423158,120,,,[70],[1697122420455]
1683,1683,184,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacty of 21.99 GiB of which 737.00 MiB is free. Process 430828 has 21.26 GiB memory in use. Of the allocated memory 16.02 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370104,1697122371104,120,,,"[20, 846]","[1697122370124, 1697122370970]"
1684,1684,724,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402580,1697122404422,120,,,[34],[1697122402614]
1685,1685,301,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383913,1697122385618,120,,,[119],[1697122384032]
1686,1686,356,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404428,1697122407058,120,,,[102],[1697122404530]
1687,1687,842,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404425,1697122405697,120,,,[35],[1697122404460]
1688,1688,393,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367973,1697122370102,120,,,[75],[1697122368048]
1689,1689,300,46,[],200,llama-7b,64,1,1760.0,1.0,1,A10,1697122456996,1697122458756,120,9.0,1.0,"[58, 1701]","[1697122457054, 1697122458755]"
1690,1690,72,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458757,1697122461248,120,,,[13],[1697122458770]
1691,1691,171,14,[],200,llama-7b,64,1,1916.0,1.0,1,A10,1697122370108,1697122372024,120,6.0,1.0,"[82, 1834]","[1697122370190, 1697122372024]"
1692,1692,124,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407062,1697122409608,120,,,[37],[1697122407099]
1693,1693,47,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385621,1697122386861,120,,,[36],[1697122385657]
1694,1694,231,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446854,1697122448793,120,,,[50],[1697122446904]
1695,1695,704,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398329,1697122400951,120,,,[135],[1697122398464]
1696,1696,748,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376096,1697122378082,120,,,[44],[1697122376140]
1697,1697,753,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122372030,1697122374081,120,,,[31],[1697122372061]
1698,1698,654,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461250,1697122463976,120,,,[49],[1697122461299]
1699,1699,401,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378087,1697122380019,120,,,"[24, 1825]","[1697122378111, 1697122379936]"
1700,1700,746,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386864,1697122389100,120,,,"[46, 2108]","[1697122386910, 1697122389018]"
1701,1701,179,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380025,1697122381806,120,,,[33],[1697122380058]
1702,1702,714,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409612,1697122410670,120,,,"[34, 891]","[1697122409646, 1697122410537]"
1703,1703,759,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381811,1697122383904,120,,,"[51, 2020]","[1697122381862, 1697122383882]"
1704,1704,536,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383909,1697122385619,120,,,[13],[1697122383922]
1705,1705,241,24,[],200,llama-7b,64,1,2186.0,1.0,1,A10,1697122411713,1697122413899,120,19.0,1.0,"[50, 2136]","[1697122411763, 1697122413899]"
1706,1706,410,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389104,1697122391053,120,,,"[7, 1857]","[1697122389111, 1697122390968]"
1707,1707,11,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122413903,1697122416372,120,,,[38],[1697122413941]
1708,1708,483,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410676,1697122412985,120,,,[162],[1697122410838]
1709,1709,186,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385624,1697122387918,120,,,[74],[1697122385698]
1710,1710,556,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418477,1697122420381,120,,,[40],[1697122418517]
1711,1711,886,20,[],200,llama-7b,64,1,2117.0,1.0,1,A10,1697122387922,1697122390039,120,17.0,1.0,"[68, 2049]","[1697122387990, 1697122390039]"
1712,1712,139,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412991,1697122415032,120,,,"[41, 1831]","[1697122413032, 1697122414863]"
1713,1713,750,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391059,1697122392786,120,,,[71],[1697122391130]
1714,1714,547,21,[],200,llama-7b,64,1,1610.0,1.0,1,A10,1697122390044,1697122391654,120,12.0,1.0,"[29, 1581]","[1697122390073, 1697122391654]"
1715,1715,257,27,[],200,llama-7b,64,1,1619.0,1.0,1,A10,1697122400959,1697122402578,120,14.0,1.0,"[112, 1506]","[1697122401071, 1697122402577]"
1716,1716,191,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420384,1697122421736,120,,,[36],[1697122420420]
1717,1717,527,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392792,1697122395177,120,,,[61],[1697122392853]
1718,1718,596,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458098,1697122459962,120,,,[52],[1697122458150]
1719,1719,889,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421739,1697122424991,120,,,"[109, 2264, 87]","[1697122421848, 1697122424112, 1697122424199]"
1720,1720,252,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459966,1697122462680,120,,,[49],[1697122460015]
1721,1721,29,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462684,1697122464904,120,,,[60],[1697122462744]
1722,1722,182,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391056,1697122392786,120,,,[12],[1697122391068]
1723,1723,770,32,[],200,llama-7b,64,1,2313.0,1.0,1,A10,1697122415036,1697122417349,120,13.0,1.0,"[97, 2216]","[1697122415133, 1697122417349]"
1724,1724,848,35,[],200,llama-7b,64,1,2310.0,1.0,1,A10,1697122415040,1697122417350,120,47.0,1.0,"[113, 2196]","[1697122415153, 1697122417349]"
1725,1725,280,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378087,1697122380019,120,,,"[30, 1819]","[1697122378117, 1697122379936]"
1726,1726,549,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424994,1697122426575,120,,,[137],[1697122425131]
1727,1727,764,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392792,1697122395178,120,,,[67],[1697122392859]
1728,1728,600,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391057,1697122392786,120,,,[11],[1697122391068]
1729,1729,319,31,[],200,llama-7b,64,1,2247.0,1.0,1,A10,1697122426582,1697122428829,120,31.0,1.0,"[59, 2187]","[1697122426641, 1697122428828]"
1730,1730,903,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122428830,1697122429746,120,,,"[12, 885]","[1697122428842, 1697122429727]"
1731,1731,264,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392790,1697122395177,120,,,[48],[1697122392838]
1732,1732,27,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380025,1697122381806,120,,,[33],[1697122380058]
1733,1733,680,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429751,1697122431564,120,,,[118],[1697122429869]
1734,1734,33,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395181,1697122397243,120,,,[59],[1697122395240]
1735,1735,541,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395181,1697122397243,120,,,[53],[1697122395234]
1736,1736,333,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431569,1697122433671,120,,,[85],[1697122431654]
1737,1737,622,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397247,1697122398323,120,,,[41],[1697122397288]
1738,1738,610,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381812,1697122383904,120,,,"[59, 2011]","[1697122381871, 1697122383882]"
1739,1739,392,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398330,1697122400950,120,,,[144],[1697122398474]
1740,1740,105,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433681,1697122436783,120,,,[95],[1697122433776]
1741,1741,47,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400954,1697122402608,120,,,"[29, 670, 112]","[1697122400983, 1697122401653, 1697122401765]"
1742,1742,687,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436787,1697122438625,120,,,"[27, 1792]","[1697122436814, 1697122438606]"
1743,1743,193,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397245,1697122398322,120,,,[19],[1697122397264]
1744,1744,38,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453813,1697122455926,120,,,[30],[1697122453843]
1745,1745,377,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383911,1697122385618,120,,,[47],[1697122383958]
1746,1746,898,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398326,1697122399548,120,,,[39],[1697122398365]
1747,1747,38,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385622,1697122387917,120,,,[46],[1697122385668]
1748,1748,623,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455929,1697122456992,120,,,[18],[1697122455947]
1749,1749,552,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399552,1697122402609,120,,,"[48, 2053, 112]","[1697122399600, 1697122401653, 1697122401765]"
1750,1750,389,52,[],200,llama-7b,64,1,1017.0,1.0,1,A10,1697122456995,1697122458012,120,8.0,1.0,"[32, 985]","[1697122457027, 1697122458012]"
1751,1751,732,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381809,1697122382784,120,,,[34],[1697122381843]
1752,1752,49,53,[],200,llama-7b,64,1,3277.0,1.0,1,A10,1697122458014,1697122461291,120,109.0,3.0,"[32, 710, 1250, 1285]","[1697122458046, 1697122458756, 1697122460006, 1697122461291]"
1753,1753,746,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461294,1697122463977,120,,,[67],[1697122461361]
1754,1754,396,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122382787,1697122383906,120,,,"[19, 1076]","[1697122382806, 1697122383882]"
1755,1755,910,14,[],200,llama-7b,64,1,1836.0,1.0,1,A10,1697122376096,1697122377932,120,8.0,1.0,"[34, 1802]","[1697122376130, 1697122377932]"
1756,1756,494,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463979,1697122466343,120,,,[73],[1697122464052]
1757,1757,737,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387920,1697122389101,120,,,"[16, 1082]","[1697122387936, 1697122389018]"
1758,1758,395,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389108,1697122391052,120,,,"[125, 1736]","[1697122389233, 1697122390969]"
1759,1759,435,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438629,1697122440577,120,,,"[12, 1800]","[1697122438641, 1697122440441]"
1760,1760,165,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391060,1697122392787,120,,,[95],[1697122391155]
1761,1761,207,38,[],200,llama-7b,64,1,1786.0,1.0,1,A10,1697122440587,1697122442373,120,10.0,1.0,"[13, 1773]","[1697122440600, 1697122442373]"
1762,1762,166,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383916,1697122386860,120,,,[141],[1697122384057]
1763,1763,789,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442375,1697122443688,120,,,[7],[1697122442382]
1764,1764,320,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402618,1697122405695,120,,,[140],[1697122402758]
1765,1765,566,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122443693,1697122451945,120,,,"[60, 2332, 815, 976, 969, 987, 931]","[1697122443753, 1697122446085, 1697122446900, 1697122447876, 1697122448845, 1697122449832, 1697122450763]"
1766,1766,67,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122457005,1697122466987,120,,,"[67, 1684, 1250, 1285, 1433, 1295, 928, 1438]","[1697122457072, 1697122458756, 1697122460006, 1697122461291, 1697122462724, 1697122464019, 1697122464947, 1697122466385]"
1767,1767,880,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405698,1697122407058,120,,,[23],[1697122405721]
1768,1768,650,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407064,1697122409609,120,,,[85],[1697122407149]
1769,1769,309,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409612,1697122411707,120,,,[55],[1697122409667]
1770,1770,755,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392792,1697122395177,120,,,[62],[1697122392854]
1771,1771,78,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122411711,1697122415031,120,,,"[32, 2155]","[1697122411743, 1697122413898]"
1772,1772,527,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395180,1697122396184,120,,,[35],[1697122395215]
1773,1773,754,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386863,1697122387918,120,,,[22],[1697122386885]
1774,1774,768,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400955,1697122402608,120,,,"[29, 669, 112]","[1697122400984, 1697122401653, 1697122401765]"
1775,1775,800,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122401654,1697122410668,120,,,"[12, 2798, 1275, 1359, 1071, 1483]","[1697122401666, 1697122404464, 1697122405739, 1697122407098, 1697122408169, 1697122409652]"
1776,1776,668,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415037,1697122418474,120,,,"[101, 2211]","[1697122415138, 1697122417349]"
1777,1777,183,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396195,1697122398323,120,,,[38],[1697122396233]
1778,1778,635,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429750,1697122431564,120,,,[109],[1697122429859]
1779,1779,440,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418477,1697122420380,120,,,[20],[1697122418497]
1780,1780,491,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391059,1697122392787,120,,,[71],[1697122391130]
1781,1781,860,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398326,1697122399548,120,,,[42],[1697122398368]
1782,1782,474,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396198,1697122398322,120,,,[65],[1697122396263]
1783,1783,153,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392789,1697122393971,120,,,[21],[1697122392810]
1784,1784,409,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431569,1697122433671,120,,,[163],[1697122431732]
1785,1785,512,26,[],200,llama-7b,64,1,2102.0,1.0,1,A10,1697122399551,1697122401653,120,11.0,1.0,"[44, 2058]","[1697122399595, 1697122401653]"
1786,1786,63,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433681,1697122436783,120,,,[156],[1697122433837]
1787,1787,288,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122401656,1697122410668,120,,,"[18, 1439, 1351, 1275, 1359, 1071, 1482]","[1697122401674, 1697122403113, 1697122404464, 1697122405739, 1697122407098, 1697122408169, 1697122409651]"
1788,1788,545,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402614,1697122404422,120,,,[27],[1697122402641]
1789,1789,743,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436787,1697122438626,120,,,"[52, 1767]","[1697122436839, 1697122438606]"
1790,1790,96,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420384,1697122423160,120,,,[53],[1697122420437]
1791,1791,243,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398326,1697122400949,120,,,[59],[1697122398385]
1792,1792,88,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435158,1697122438625,120,,,"[87, 2620]","[1697122435245, 1697122437865]"
1793,1793,200,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404426,1697122407057,120,,,[39],[1697122404465]
1794,1794,398,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438631,1697122442468,120,,,"[119, 2652]","[1697122438750, 1697122441402]"
1795,1795,832,29,[],200,llama-7b,64,1,699.0,1.0,1,A10,1697122400954,1697122401653,120,15.0,1.0,"[24, 675]","[1697122400978, 1697122401653]"
1796,1796,714,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122369042,1697122370102,120,,,[28],[1697122369070]
1797,1797,899,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407062,1697122409608,120,,,[42],[1697122407104]
1798,1798,487,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122370107,1697122376091,120,,,"[72, 2885, 1068, 1005]","[1697122370179, 1697122373064, 1697122374132, 1697122375137]"
1799,1799,872,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410673,1697122412984,120,,,[27],[1697122410700]
1800,1800,98,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392790,1697122393971,120,,,[29],[1697122392819]
1801,1801,559,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409610,1697122410669,120,,,"[14, 912]","[1697122409624, 1697122410536]"
1802,1802,601,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122401656,1697122410669,120,,,"[20, 1437, 1352, 1274, 1359, 1071, 1483]","[1697122401676, 1697122403113, 1697122404465, 1697122405739, 1697122407098, 1697122408169, 1697122409652]"
1803,1803,674,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438634,1697122442470,120,,,"[145, 2625]","[1697122438779, 1697122441404]"
1804,1804,643,29,[],200,llama-7b,64,1,1870.0,1.0,1,A10,1697122412993,1697122414863,120,18.0,1.0,"[53, 1817]","[1697122413046, 1697122414863]"
1805,1805,327,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410672,1697122412985,120,,,[18],[1697122410690]
1806,1806,860,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122413901,1697122416373,120,,,[20],[1697122413921]
1807,1807,687,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393974,1697122395177,120,,,[18],[1697122393992]
1808,1808,304,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122414864,1697122416372,120,,,[7],[1697122414871]
1809,1809,98,33,[],200,llama-7b,64,1,1812.0,1.0,1,A10,1697122423162,1697122424974,120,14.0,1.0,"[83, 1729]","[1697122423245, 1697122424974]"
1810,1810,542,13,[],200,llama-7b,64,1,1916.0,1.0,1,A10,1697122370108,1697122372024,120,11.0,1.0,"[76, 1839]","[1697122370184, 1697122372023]"
1811,1811,451,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395179,1697122396184,120,,,[26],[1697122395205]
1812,1812,611,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405701,1697122408127,120,,,[69],[1697122405770]
1813,1813,83,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396195,1697122398324,120,,,[49],[1697122396244]
1814,1814,268,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408130,1697122409610,120,,,[32],[1697122408162]
1815,1815,446,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442482,1697122445116,120,,,[153],[1697122442635]
1816,1816,36,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409613,1697122411707,120,,,[63],[1697122409676]
1817,1817,99,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445124,1697122446847,120,,,[57],[1697122445181]
1818,1818,626,28,[],200,llama-7b,64,1,2187.0,1.0,1,A10,1697122411712,1697122413899,120,10.0,1.0,"[45, 2142]","[1697122411757, 1697122413899]"
1819,1819,781,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398326,1697122400950,120,,,[47],[1697122398373]
1820,1820,437,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400955,1697122402609,120,,,"[96, 1526]","[1697122401051, 1697122402577]"
1821,1821,776,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446852,1697122448793,120,,,[47],[1697122446899]
1822,1822,802,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424978,1697122426578,120,,,[36],[1697122425014]
1823,1823,600,26,[],200,llama-7b,64,1,1939.0,1.0,1,A10,1697122416378,1697122418317,120,23.0,1.0,"[77, 1862]","[1697122416455, 1697122418317]"
1824,1824,1,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448796,1697122449780,120,,,[41],[1697122448837]
1825,1825,587,47,[],200,llama-7b,64,1,1967.0,1.0,1,A10,1697122449785,1697122451752,120,13.0,1.0,"[79, 1888]","[1697122449864, 1697122451752]"
1826,1826,370,27,[],200,llama-7b,64,1,644.0,1.0,1,A10,1697122418320,1697122418964,120,31.0,1.0,"[9, 634]","[1697122418329, 1697122418963]"
1827,1827,455,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426584,1697122429746,120,,,"[92, 2153, 59]","[1697122426676, 1697122428829, 1697122428888]"
1828,1828,25,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418969,1697122421735,120,,,[47],[1697122419016]
1829,1829,359,48,[],200,llama-7b,64,1,1084.0,1.0,1,A10,1697122451757,1697122452841,120,10.0,1.0,"[40, 1044]","[1697122451797, 1697122452841]"
1830,1830,428,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448796,1697122449780,120,,,[31],[1697122448827]
1831,1831,12,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122452846,1697122454905,120,,,[24],[1697122452870]
1832,1832,724,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421737,1697122423159,120,,,[33],[1697122421770]
1833,1833,472,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423162,1697122424992,120,,,"[23, 928, 87]","[1697122423185, 1697122424113, 1697122424200]"
1834,1834,203,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429749,1697122431565,120,,,[90],[1697122429839]
1835,1835,214,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402614,1697122404422,120,,,[54],[1697122402668]
1836,1836,907,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431568,1697122433672,120,,,[96],[1697122431664]
1837,1837,797,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404430,1697122407057,120,,,[130],[1697122404560]
1838,1838,204,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449783,1697122450712,120,,,[21],[1697122449804]
1839,1839,561,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433678,1697122436783,120,,,[71],[1697122433749]
1840,1840,573,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407061,1697122408126,120,,,[15],[1697122407076]
1841,1841,337,39,[],200,llama-7b,64,1,1818.0,1.0,1,A10,1697122436789,1697122438607,120,12.0,1.0,"[80, 1738]","[1697122436869, 1697122438607]"
1842,1842,228,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408128,1697122409609,120,,,[16],[1697122408144]
1843,1843,787,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122450714,1697122458092,120,,,"[37, 2088, 1025, 1096, 1020, 1065]","[1697122450751, 1697122452839, 1697122453864, 1697122454960, 1697122455980, 1697122457045]"
1844,1844,918,40,[],200,llama-7b,64,1,1829.0,1.0,1,A10,1697122438612,1697122440441,120,23.0,1.0,"[14, 1815]","[1697122438626, 1697122440441]"
1845,1845,6,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409611,1697122410669,120,,,[20],[1697122409631]
1846,1846,502,36,[],200,llama-7b,64,1,1611.0,1.0,1,A10,1697122417353,1697122418964,120,19.0,1.0,"[20, 1591]","[1697122417373, 1697122418964]"
1847,1847,544,21,[],200,llama-7b,64,1,1859.0,1.0,1,A10,1697122389110,1697122390969,120,26.0,1.0,"[135, 1724]","[1697122389245, 1697122390969]"
1848,1848,94,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378097,1697122383905,120,,,"[149, 2686, 926, 973]","[1697122378246, 1697122380932, 1697122381858, 1697122382831]"
1849,1849,291,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122390972,1697122402608,120,,,"[11, 1850, 1185, 1213, 999, 1062, 1079, 1222, 1400, 772]","[1697122390983, 1697122392833, 1697122394018, 1697122395231, 1697122396230, 1697122397292, 1697122398371, 1697122399593, 1697122400993, 1697122401765]"
1850,1850,94,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410674,1697122412985,120,,,[68],[1697122410742]
1851,1851,210,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386862,1697122387918,120,,,[10],[1697122386872]
1852,1852,278,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418966,1697122421735,120,,,[20],[1697122418986]
1853,1853,778,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122417352,1697122424991,120,,,"[19, 1593, 1456, 1353, 1424, 1003]","[1697122417371, 1697122418964, 1697122420420, 1697122421773, 1697122423197, 1697122424200]"
1854,1854,798,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387921,1697122391053,120,,,[60],[1697122387981]
1855,1855,859,38,[],200,llama-7b,64,1,2374.0,1.0,1,A10,1697122421738,1697122424112,120,23.0,1.0,"[49, 2325]","[1697122421787, 1697122424112]"
1856,1856,874,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402614,1697122404422,120,,,[57],[1697122402671]
1857,1857,524,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387921,1697122389100,120,,,"[35, 1063]","[1697122387956, 1697122389019]"
1858,1858,679,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412997,1697122416371,120,,,[65],[1697122413062]
1859,1859,155,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389104,1697122391053,120,,,"[15, 1850]","[1697122389119, 1697122390969]"
1860,1860,455,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416377,1697122418473,120,,,"[21, 1918]","[1697122416398, 1697122418316]"
1861,1861,720,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400954,1697122402610,120,,,"[20, 679, 112]","[1697122400974, 1697122401653, 1697122401765]"
1862,1862,454,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410671,1697122412985,120,,,[12],[1697122410683]
1863,1863,468,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402615,1697122404423,120,,,[124],[1697122402739]
1864,1864,119,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404430,1697122407058,120,,,[134],[1697122404564]
1865,1865,855,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391059,1697122392786,120,,,[76],[1697122391135]
1866,1866,509,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392789,1697122393971,120,,,[25],[1697122392814]
1867,1867,645,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404425,1697122405696,120,,,[20],[1697122404445]
1868,1868,282,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393976,1697122396184,120,,,[82],[1697122394058]
1869,1869,309,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405699,1697122408127,120,,,[42],[1697122405741]
1870,1870,234,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412996,1697122416373,120,,,[146],[1697122413142]
1871,1871,80,26,[],200,llama-7b,64,1,2405.0,1.0,1,A10,1697122408132,1697122410537,120,13.0,1.0,"[106, 2299]","[1697122408238, 1697122410537]"
1872,1872,109,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418481,1697122420380,120,,,[83],[1697122418564]
1873,1873,863,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396198,1697122398322,120,,,[55],[1697122396253]
1874,1874,803,32,[],200,llama-7b,64,1,1811.0,1.0,1,A10,1697122423164,1697122424975,120,20.0,1.0,"[96, 1714]","[1697122423260, 1697122424974]"
1875,1875,456,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424979,1697122426576,120,,,[66],[1697122425045]
1876,1876,143,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376096,1697122378084,120,,,"[29, 1807]","[1697122376125, 1697122377932]"
1877,1877,640,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398329,1697122400951,120,,,[129],[1697122398458]
1878,1878,813,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420384,1697122423159,120,,,[48],[1697122420432]
1879,1879,83,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400960,1697122410669,120,,,"[172, 1981, 1351, 1275, 1359, 1071, 1482]","[1697122401132, 1697122403113, 1697122404464, 1697122405739, 1697122407098, 1697122408169, 1697122409651]"
1880,1880,202,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426585,1697122429747,120,,,"[162, 2081, 60]","[1697122426747, 1697122428828, 1697122428888]"
1881,1881,294,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400959,1697122402609,120,,,[97],[1697122401056]
1882,1882,65,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402614,1697122404423,120,,,[34],[1697122402648]
1883,1883,667,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410538,1697122411708,120,,,[16],[1697122410554]
1884,1884,467,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423163,1697122424991,120,,,"[75, 1736]","[1697122423238, 1697122424974]"
1885,1885,437,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122411711,1697122415032,120,,,"[51, 2137]","[1697122411762, 1697122413899]"
1886,1886,654,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404426,1697122405696,120,,,[29],[1697122404455]
1887,1887,97,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415034,1697122418475,120,,,"[7, 2307]","[1697122415041, 1697122417348]"
1888,1888,672,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410676,1697122412984,120,,,[92],[1697122410768]
1889,1889,456,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400954,1697122402610,120,,,"[14, 685, 112]","[1697122400968, 1697122401653, 1697122401765]"
1890,1890,215,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424994,1697122426575,120,,,[86],[1697122425080]
1891,1891,798,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418482,1697122420381,120,,,[91],[1697122418573]
1892,1892,529,16,[],200,llama-7b,64,1,1853.0,1.0,1,A10,1697122374085,1697122375938,120,10.0,1.0,"[60, 1792]","[1697122374145, 1697122375937]"
1893,1893,795,41,[],200,llama-7b,64,1,2247.0,1.0,1,A10,1697122426582,1697122428829,120,12.0,1.0,"[74, 2172]","[1697122426656, 1697122428828]"
1894,1894,451,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420385,1697122423158,120,,,[74],[1697122420459]
1895,1895,441,32,[],200,llama-7b,64,1,1872.0,1.0,1,A10,1697122412992,1697122414864,120,6.0,1.0,"[51, 1821]","[1697122413043, 1697122414864]"
1896,1896,182,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375941,1697122378082,120,,,"[24, 1219]","[1697122375965, 1697122377184]"
1897,1897,199,32,[],200,llama-7b,64,1,1809.0,1.0,1,A10,1697122423165,1697122424974,120,13.0,1.0,"[105, 1704]","[1697122423270, 1697122424974]"
1898,1898,101,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122414867,1697122416373,120,,,[14],[1697122414881]
1899,1899,178,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395182,1697122397244,120,,,[73],[1697122395255]
1900,1900,802,34,[],200,llama-7b,64,1,2581.0,1.0,1,A10,1697122416382,1697122418963,120,9.0,1.0,"[154, 2427]","[1697122416536, 1697122418963]"
1901,1901,455,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418966,1697122421735,120,,,[25],[1697122418991]
1902,1902,204,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421737,1697122423160,120,,,[15],[1697122421752]
1903,1903,290,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404427,1697122407058,120,,,[58],[1697122404485]
1904,1904,856,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397251,1697122399547,120,,,[80],[1697122397331]
1905,1905,789,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423164,1697122424991,120,,,"[95, 1715]","[1697122423259, 1697122424974]"
1906,1906,878,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407066,1697122409609,120,,,[102],[1697122407168]
1907,1907,611,56,[],200,llama-7b,64,1,2062.0,1.0,1,A10,1697122464908,1697122466970,120,14.0,1.0,"[43, 2019]","[1697122464951, 1697122466970]"
1908,1908,647,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409614,1697122411708,120,,,[121],[1697122409735]
1909,1909,308,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122411710,1697122415031,120,,,"[18, 2170]","[1697122411728, 1697122413898]"
1910,1910,888,45,[],200,llama-7b,64,1,2709.0,1.0,1,A10,1697122435157,1697122437866,120,19.0,1.0,"[43, 2665]","[1697122435200, 1697122437865]"
1911,1911,549,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122437869,1697122440577,120,,,"[15, 1507]","[1697122437884, 1697122439391]"
1912,1912,565,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424993,1697122426577,120,,,[73],[1697122425066]
1913,1913,430,33,[],200,llama-7b,64,1,1611.0,1.0,1,A10,1697122417353,1697122418964,120,15.0,1.0,"[15, 1596]","[1697122417368, 1697122418964]"
1914,1914,319,47,[],200,llama-7b,64,1,1786.0,1.0,1,A10,1697122440587,1697122442373,120,31.0,1.0,"[67, 1719]","[1697122440654, 1697122442373]"
1915,1915,625,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399549,1697122400951,120,,,[21],[1697122399570]
1916,1916,218,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426581,1697122429745,120,,,"[44, 2263]","[1697122426625, 1697122428888]"
1917,1917,903,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442376,1697122443688,120,,,[11],[1697122442387]
1918,1918,647,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122443693,1697122451945,120,,,"[64, 2329, 814, 976, 969, 987, 931]","[1697122443757, 1697122446086, 1697122446900, 1697122447876, 1697122448845, 1697122449832, 1697122450763]"
1919,1919,75,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415035,1697122418473,120,,,"[25, 2289]","[1697122415060, 1697122417349]"
1920,1920,666,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418481,1697122420382,120,,,[63],[1697122418544]
1921,1921,923,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429749,1697122431565,120,,,[95],[1697122429844]
1922,1922,579,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431569,1697122433673,120,,,[107],[1697122431676]
1923,1923,348,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433681,1697122436783,120,,,[152],[1697122433833]
1924,1924,10,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436792,1697122440577,120,,,"[148, 2451]","[1697122436940, 1697122439391]"
1925,1925,435,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420386,1697122423158,120,,,[78],[1697122420464]
1926,1926,679,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383913,1697122385618,120,,,[124],[1697122384037]
1927,1927,91,36,[],200,llama-7b,64,1,1811.0,1.0,1,A10,1697122423163,1697122424974,120,23.0,1.0,"[41, 1769]","[1697122423204, 1697122424973]"
1928,1928,240,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416378,1697122418473,120,,,"[72, 1867]","[1697122416450, 1697122418317]"
1929,1929,764,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424978,1697122426575,120,,,[51],[1697122425029]
1930,1930,534,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426582,1697122429747,120,,,"[160, 2086, 60]","[1697122426742, 1697122428828, 1697122428888]"
1931,1931,833,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418481,1697122421735,120,,,[149],[1697122418630]
1932,1932,603,37,[],200,llama-7b,64,1,2374.0,1.0,1,A10,1697122421739,1697122424113,120,9.0,1.0,"[104, 2270]","[1697122421843, 1697122424113]"
1933,1933,258,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424119,1697122424992,120,,,"[25, 830]","[1697122424144, 1697122424974]"
1934,1934,702,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440591,1697122442471,120,,,"[14, 1767]","[1697122440605, 1697122442372]"
1935,1935,448,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385621,1697122387917,120,,,[49],[1697122385670]
1936,1936,350,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383913,1697122385618,120,,,[50],[1697122383963]
1937,1937,192,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429751,1697122431564,120,,,[113],[1697122429864]
1938,1938,451,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442478,1697122445118,120,,,[90],[1697122442568]
1939,1939,81,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387920,1697122389101,120,,,"[21, 1078]","[1697122387941, 1697122389019]"
1940,1940,559,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373013,1697122374081,120,,,[19],[1697122373032]
1941,1941,104,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445124,1697122447822,120,,,[109],[1697122445233]
1942,1942,127,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385621,1697122387918,120,,,[59],[1697122385680]
1943,1943,328,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374084,1697122375087,120,,,[31],[1697122374115]
1944,1944,709,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387927,1697122391051,120,,,"[118, 1995]","[1697122388045, 1697122390040]"
1945,1945,917,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375089,1697122376092,120,,,"[13, 835]","[1697122375102, 1697122375937]"
1946,1946,777,20,[],200,llama-7b,64,1,1865.0,1.0,1,A10,1697122389104,1697122390969,120,9.0,1.0,"[43, 1822]","[1697122389147, 1697122390969]"
1947,1947,571,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122377935,1697122380020,120,,,"[17, 968]","[1697122377952, 1697122378920]"
1948,1948,457,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391057,1697122392786,120,,,[16],[1697122391073]
1949,1949,687,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376097,1697122380019,120,,,"[145, 2677]","[1697122376242, 1697122378919]"
1950,1950,438,21,[],200,llama-7b,64,1,683.0,1.0,1,A10,1697122390971,1697122391654,120,9.0,1.0,"[17, 666]","[1697122390988, 1697122391654]"
1951,1951,607,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424114,1697122424991,120,,,"[16, 844]","[1697122424130, 1697122424974]"
1952,1952,891,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412996,1697122416372,120,,,[136],[1697122413132]
1953,1953,108,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392789,1697122393971,120,,,[16],[1697122392805]
1954,1954,841,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378095,1697122380020,120,,,[50],[1697122378145]
1955,1955,211,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391665,1697122393972,120,,,[23],[1697122391688]
1956,1956,661,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416378,1697122418474,120,,,"[97, 1842]","[1697122416475, 1697122418317]"
1957,1957,814,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393974,1697122395177,120,,,[17],[1697122393991]
1958,1958,376,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424993,1697122426577,120,,,[63],[1697122425056]
1959,1959,468,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395180,1697122396184,120,,,[25],[1697122395205]
1960,1960,431,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463980,1697122466343,120,,,[50],[1697122464030]
1961,1961,32,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426585,1697122429747,120,,,"[177, 2067, 59]","[1697122426762, 1697122428829, 1697122428888]"
1962,1962,316,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418482,1697122420382,120,,,[67],[1697122418549]
1963,1963,849,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383888,1697122385619,120,,,[29],[1697122383917]
1964,1964,109,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402614,1697122404423,120,,,[120],[1697122402734]
1965,1965,617,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385622,1697122387917,120,,,[56],[1697122385678]
1966,1966,432,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.42 GiB is allocated by PyTorch, and 5.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122361910,1697122363190,120,,,[34],[1697122361944]
1967,1967,180,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 653.00 MiB is free. Process 430828 has 21.34 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122363194,1697122365126,120,,,[50],[1697122363244]
1968,1968,93,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420385,1697122423160,120,,,[55],[1697122420440]
1969,1969,763,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 3.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122365131,1697122366982,120,,,[119],[1697122365250]
1970,1970,676,33,[],200,llama-7b,64,1,1810.0,1.0,1,A10,1697122423164,1697122424974,120,19.0,1.0,"[91, 1718]","[1697122423255, 1697122424973]"
1971,1971,846,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402580,1697122404422,120,,,[31],[1697122402611]
1972,1972,242,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396198,1697122398322,120,,,[66],[1697122396264]
1973,1973,734,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429749,1697122431564,120,,,[21],[1697122429770]
1974,1974,388,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431567,1697122432498,120,,,"[21, 829]","[1697122431588, 1697122432417]"
1975,1975,277,23,[],200,llama-7b,64,1,2117.0,1.0,1,A10,1697122387922,1697122390039,120,18.0,1.0,"[49, 2068]","[1697122387971, 1697122390039]"
1976,1976,813,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404427,1697122407057,120,,,[43],[1697122404470]
1977,1977,47,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122390042,1697122402608,120,,,"[16, 1595, 1180, 1185, 1213, 999, 1062, 1079, 1222, 1400, 772]","[1697122390058, 1697122391653, 1697122392833, 1697122394018, 1697122395231, 1697122396230, 1697122397292, 1697122398371, 1697122399593, 1697122400993, 1697122401765]"
1978,1978,162,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432507,1697122435153,120,,,[46],[1697122432553]
1979,1979,537,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.51 GiB is free. Process 430828 has 20.46 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122366985,1697122367968,120,,,[15],[1697122367000]
1980,1980,833,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398326,1697122400951,120,,,[114],[1697122398440]
1981,1981,99,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373019,1697122375087,120,,,[68],[1697122373087]
1982,1982,191,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.39 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122367971,1697122370101,120,,,[35],[1697122368006]
1983,1983,695,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440444,1697122442471,120,,,"[16, 943]","[1697122440460, 1697122441403]"
1984,1984,689,12,[],200,llama-7b,64,1,2094.0,1.0,1,A10,1697122375090,1697122377184,120,15.0,1.0,"[56, 2037]","[1697122375146, 1697122377183]"
1985,1985,602,28,[],200,llama-7b,64,1,1623.0,1.0,1,A10,1697122400954,1697122402577,120,15.0,1.0,"[107, 1516]","[1697122401061, 1697122402577]"
1986,1986,348,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442478,1697122445118,120,,,[85],[1697122442563]
1987,1987,828,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392790,1697122395177,120,,,[39],[1697122392829]
1988,1988,200,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418966,1697122421735,120,,,[25],[1697122418991]
1989,1989,458,13,[],200,llama-7b,64,1,1732.0,1.0,1,A10,1697122377188,1697122378920,120,11.0,1.0,"[11, 1720]","[1697122377199, 1697122378919]"
1990,1990,114,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378922,1697122383905,120,,,"[14, 1997, 925, 973]","[1697122378936, 1697122380933, 1697122381858, 1697122382831]"
1991,1991,277,25,[],200,llama-7b,64,1,1619.0,1.0,1,A10,1697122400958,1697122402577,120,18.0,1.0,"[73, 1545]","[1697122401031, 1697122402576]"
1992,1992,835,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396198,1697122398323,120,,,[75],[1697122396273]
1993,1993,484,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395182,1697122397244,120,,,[72],[1697122395254]
1994,1994,256,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397247,1697122399547,120,,,[46],[1697122397293]
1995,1995,820,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383910,1697122385618,120,,,[46],[1697122383956]
1996,1996,847,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399549,1697122400950,120,,,[16],[1697122399565]
1997,1997,54,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402579,1697122410669,120,,,"[15, 519, 1352, 1274, 1359, 1072, 1482]","[1697122402594, 1697122403113, 1697122404465, 1697122405739, 1697122407098, 1697122408170, 1697122409652]"
1998,1998,616,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400962,1697122410669,120,,,"[176, 1975, 1351, 1275, 1359, 1071, 1483]","[1697122401138, 1697122403113, 1697122404464, 1697122405739, 1697122407098, 1697122408169, 1697122409652]"
1999,1999,275,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410673,1697122412985,120,,,[23],[1697122410696]
2000,2000,469,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385624,1697122387919,120,,,[121],[1697122385745]
2001,2001,45,29,[],200,llama-7b,64,1,1873.0,1.0,1,A10,1697122412991,1697122414864,120,19.0,1.0,"[50, 1823]","[1697122413041, 1697122414864]"
2002,2002,215,17,[],200,llama-7b,64,1,2117.0,1.0,1,A10,1697122387922,1697122390039,120,12.0,1.0,"[69, 2048]","[1697122387991, 1697122390039]"
2003,2003,634,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122414868,1697122416373,120,,,[28],[1697122414896]
2004,2004,913,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122390042,1697122402607,120,,,"[7, 1604, 1180, 1185, 1213, 999, 1062, 1079, 1222, 1400, 772]","[1697122390049, 1697122391653, 1697122392833, 1697122394018, 1697122395231, 1697122396230, 1697122397292, 1697122398371, 1697122399593, 1697122400993, 1697122401765]"
2005,2005,603,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398327,1697122400952,120,,,[127],[1697122398454]
2006,2006,263,24,[],200,llama-7b,64,1,1619.0,1.0,1,A10,1697122400958,1697122402577,120,15.0,1.0,"[88, 1531]","[1697122401046, 1697122402577]"
2007,2007,33,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402580,1697122410669,120,,,"[26, 507, 1352, 1274, 1359, 1072, 1482]","[1697122402606, 1697122403113, 1697122404465, 1697122405739, 1697122407098, 1697122408170, 1697122409652]"
2008,2008,731,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371109,1697122373011,120,,,[22],[1697122371131]
2009,2009,308,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122428833,1697122432498,120,,,"[51, 1457, 1271]","[1697122428884, 1697122430341, 1697122431612]"
2010,2010,890,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431567,1697122432498,120,,,"[37, 813]","[1697122431604, 1697122432417]"
2011,2011,567,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391060,1697122393972,120,,,[95],[1697122391155]
2012,2012,617,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410674,1697122412985,120,,,[58],[1697122410732]
2013,2013,395,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412996,1697122416372,120,,,[80],[1697122413076]
2014,2014,51,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416377,1697122418472,120,,,"[20, 1919]","[1697122416397, 1697122418316]"
2015,2015,728,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418477,1697122420380,120,,,[17],[1697122418494]
2016,2016,495,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373014,1697122375086,120,,,[47],[1697122373061]
2017,2017,81,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432505,1697122435153,120,,,[44],[1697122432549]
2018,2018,156,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375088,1697122376092,120,,,"[14, 836]","[1697122375102, 1697122375938]"
2019,2019,671,36,[],200,llama-7b,64,1,2705.0,1.0,1,A10,1697122435161,1697122437866,120,12.0,1.0,"[98, 2607]","[1697122435259, 1697122437866]"
2020,2020,438,37,[],200,llama-7b,64,1,1521.0,1.0,1,A10,1697122437870,1697122439391,120,9.0,1.0,"[28, 1493]","[1697122437898, 1697122439391]"
2021,2021,854,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122376097,1697122380019,120,,,"[81, 2741]","[1697122376178, 1697122378919]"
2022,2022,229,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393976,1697122396184,120,,,[77],[1697122394053]
2023,2023,70,38,[],200,llama-7b,64,1,2007.0,1.0,1,A10,1697122439396,1697122441403,120,39.0,1.0,"[6, 2001]","[1697122439402, 1697122441403]"
2024,2024,928,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396198,1697122398323,120,,,[76],[1697122396274]
2025,2025,768,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122441407,1697122443687,120,,,[11],[1697122441418]
2026,2026,582,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398328,1697122400951,120,,,[131],[1697122398459]
2027,2027,496,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420384,1697122421736,120,,,[24],[1697122420408]
2028,2028,424,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122443690,1697122451944,120,,,"[53, 2342, 815, 975, 970, 987, 930]","[1697122443743, 1697122446085, 1697122446900, 1697122447875, 1697122448845, 1697122449832, 1697122450762]"
2029,2029,558,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397246,1697122398322,120,,,[27],[1697122397273]
2030,2030,510,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380025,1697122381805,120,,,[18],[1697122380043]
2031,2031,218,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398325,1697122399548,120,,,[25],[1697122398350]
2032,2032,219,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451949,1697122454906,120,,,[95],[1697122452044]
2033,2033,169,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442476,1697122445117,120,,,[18],[1697122442494]
2034,2034,201,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451952,1697122454906,120,,,[102],[1697122452054]
2035,2035,758,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445124,1697122447823,120,,,[129],[1697122445253]
2036,2036,156,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421737,1697122423160,120,,,[18],[1697122421755]
2037,2037,526,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447826,1697122448793,120,,,[20],[1697122447846]
2038,2038,856,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423165,1697122424991,120,,,"[114, 1695]","[1697122423279, 1697122424974]"
2039,2039,919,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399551,1697122400951,120,,,[39],[1697122399590]
2040,2040,852,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393974,1697122395177,120,,,[24],[1697122393998]
2041,2041,510,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424994,1697122426575,120,,,[92],[1697122425086]
2042,2042,924,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454910,1697122456992,120,,,[64],[1697122454974]
2043,2043,572,23,[],200,llama-7b,64,1,1619.0,1.0,1,A10,1697122400959,1697122402578,120,16.0,1.0,"[116, 1502]","[1697122401075, 1697122402577]"
2044,2044,779,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454911,1697122456992,120,,,[72],[1697122454983]
2045,2045,555,43,[],200,llama-7b,64,1,1761.0,1.0,1,A10,1697122456995,1697122458756,120,11.0,1.0,"[52, 1709]","[1697122457047, 1697122458756]"
2046,2046,186,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448797,1697122450711,120,,,[47],[1697122448844]
2047,2047,396,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122413902,1697122416372,120,,,[28],[1697122413930]
2048,2048,208,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458759,1697122461247,120,,,[18],[1697122458777]
2049,2049,581,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122456995,1697122458094,120,,,"[49, 968]","[1697122457044, 1697122458012]"
2050,2050,914,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461251,1697122463976,120,,,[86],[1697122461337]
2051,2051,569,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463980,1697122466343,120,,,[65],[1697122464045]
2052,2052,288,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426581,1697122429745,120,,,"[70, 2178, 59]","[1697122426651, 1697122428829, 1697122428888]"
2053,2053,51,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416378,1697122418474,120,,,"[87, 1852]","[1697122416465, 1697122418317]"
2054,2054,885,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122450715,1697122458092,120,,,"[39, 2085, 1025, 1096, 1020, 1065]","[1697122450754, 1697122452839, 1697122453864, 1697122454960, 1697122455980, 1697122457045]"
2055,2055,357,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458099,1697122459963,120,,,[73],[1697122458172]
2056,2056,728,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418482,1697122420382,120,,,[167],[1697122418649]
2057,2057,866,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429750,1697122431563,120,,,[99],[1697122429849]
2058,2058,381,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420387,1697122423159,120,,,[92],[1697122420479]
2059,2059,13,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459967,1697122462681,120,,,[95],[1697122460062]
2060,2060,161,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423162,1697122424991,120,,,[38],[1697122423200]
2061,2061,901,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429752,1697122431565,120,,,[185],[1697122429937]
2062,2062,642,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431566,1697122432498,120,,,"[16, 835]","[1697122431582, 1697122432417]"
2063,2063,513,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416377,1697122418473,120,,,"[36, 1904]","[1697122416413, 1697122418317]"
2064,2064,711,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462683,1697122463975,120,,,[25],[1697122462708]
2065,2065,562,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431570,1697122433670,120,,,[114],[1697122431684]
2066,2066,295,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432503,1697122435151,120,,,[22],[1697122432525]
2067,2067,333,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433676,1697122436782,120,,,[25],[1697122433701]
2068,2068,42,38,[],200,llama-7b,64,1,2709.0,1.0,1,A10,1697122435156,1697122437865,120,10.0,1.0,"[30, 2679]","[1697122435186, 1697122437865]"
2069,2069,911,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436787,1697122438625,120,,,"[22, 1797]","[1697122436809, 1697122438606]"
2070,2070,812,29,[],200,llama-7b,64,1,2406.0,1.0,1,A10,1697122408131,1697122410537,120,16.0,1.0,"[56, 2350]","[1697122408187, 1697122410537]"
2071,2071,424,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405700,1697122408127,120,,,[61],[1697122405761]
2072,2072,293,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418477,1697122420380,120,,,[25],[1697122418502]
2073,2073,465,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410539,1697122411708,120,,,[20],[1697122410559]
2074,2074,237,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122411712,1697122415031,120,,,"[40, 2146]","[1697122411752, 1697122413898]"
2075,2075,689,39,[],200,llama-7b,64,1,2768.0,1.0,1,A10,1697122438634,1697122441402,120,15.0,1.0,"[150, 2618]","[1697122438784, 1697122441402]"
2076,2076,627,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122437868,1697122440577,120,,,"[15, 1508]","[1697122437883, 1697122439391]"
2077,2077,822,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415034,1697122418475,120,,,"[16, 2298]","[1697122415050, 1697122417348]"
2078,2078,718,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454909,1697122455928,120,,,[40],[1697122454949]
2079,2079,592,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418482,1697122420382,120,,,[157],[1697122418639]
2080,2080,370,51,[],200,llama-7b,64,1,2081.0,1.0,1,A10,1697122455932,1697122458013,120,31.0,1.0,"[106, 1974]","[1697122456038, 1697122458012]"
2081,2081,118,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458015,1697122466987,120,,,"[20, 721, 1250, 1285, 1433, 1295, 929, 1437]","[1697122458035, 1697122458756, 1697122460006, 1697122461291, 1697122462724, 1697122464019, 1697122464948, 1697122466385]"
2082,2082,396,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440592,1697122442469,120,,,"[23, 1758]","[1697122440615, 1697122442373]"
2083,2083,887,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122378089,1697122380020,120,,,"[49, 1798]","[1697122378138, 1697122379936]"
2084,2084,57,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442477,1697122445116,120,,,[66],[1697122442543]
2085,2085,793,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398327,1697122400950,120,,,[61],[1697122398388]
2086,2086,340,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420387,1697122423158,120,,,[83],[1697122420470]
2087,2087,758,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445124,1697122447823,120,,,[127],[1697122445251]
2088,2088,587,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410676,1697122412984,120,,,[97],[1697122410773]
2089,2089,921,35,[],200,llama-7b,64,1,1810.0,1.0,1,A10,1697122423164,1697122424974,120,31.0,1.0,"[110, 1700]","[1697122423274, 1697122424974]"
2090,2090,862,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420384,1697122421736,120,,,[21],[1697122420405]
2091,2091,454,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400959,1697122402610,120,,,"[112, 1506]","[1697122401071, 1697122402577]"
2092,2092,300,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451949,1697122453810,120,,,[49],[1697122451998]
2093,2093,698,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424975,1697122427731,120,,,"[12, 165, 1462]","[1697122424987, 1697122425152, 1697122426614]"
2094,2094,225,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402615,1697122404423,120,,,[129],[1697122402744]
2095,2095,351,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122427737,1697122429746,120,,,"[26, 1964]","[1697122427763, 1697122429727]"
2096,2096,123,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429752,1697122431564,120,,,[117],[1697122429869]
2097,2097,419,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447826,1697122448793,120,,,[25],[1697122447851]
2098,2098,188,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448798,1697122450712,120,,,[61],[1697122448859]
2099,2099,716,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431567,1697122433670,120,,,[79],[1697122431646]
2100,2100,759,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421738,1697122424991,120,,,"[57, 2317, 88]","[1697122421795, 1697122424112, 1697122424200]"
2101,2101,723,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402614,1697122404423,120,,,[62],[1697122402676]
2102,2102,808,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404429,1697122407058,120,,,[111],[1697122404540]
2103,2103,584,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407063,1697122409608,120,,,[46],[1697122407109]
2104,2104,515,35,[],200,llama-7b,64,1,2373.0,1.0,1,A10,1697122421739,1697122424112,120,11.0,1.0,"[112, 2261]","[1697122421851, 1697122424112]"
2105,2105,406,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416378,1697122418473,120,,,"[57, 1882]","[1697122416435, 1697122418317]"
2106,2106,773,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122450714,1697122458092,120,,,"[32, 2093, 1025, 1096, 1020, 1065]","[1697122450746, 1697122452839, 1697122453864, 1697122454960, 1697122455980, 1697122457045]"
2107,2107,741,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445124,1697122447823,120,,,[134],[1697122445258]
2108,2108,805,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447829,1697122449781,120,,,[117],[1697122447946]
2109,2109,290,36,[],200,llama-7b,64,1,856.0,1.0,1,A10,1697122424118,1697122424974,120,14.0,1.0,"[27, 829]","[1697122424145, 1697122424974]"
2110,2110,493,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404428,1697122407057,120,,,[111],[1697122404539]
2111,2111,236,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409614,1697122411708,120,,,[121],[1697122409735]
2112,2112,465,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449784,1697122451944,120,,,"[53, 1914]","[1697122449837, 1697122451751]"
2113,2113,872,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424978,1697122426578,120,,,[35],[1697122425013]
2114,2114,518,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447828,1697122449781,120,,,[103],[1697122447931]
2115,2115,148,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407060,1697122408126,120,,,[14],[1697122407074]
2116,2116,9,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122411712,1697122415032,120,,,"[41, 2145]","[1697122411753, 1697122413898]"
2117,2117,650,38,[],200,llama-7b,64,1,2244.0,1.0,1,A10,1697122426584,1697122428828,120,13.0,1.0,"[163, 2081]","[1697122426747, 1697122428828]"
2118,2118,305,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122428831,1697122432499,120,,,"[24, 1486, 1270]","[1697122428855, 1697122430341, 1697122431611]"
2119,2119,766,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402613,1697122404422,120,,,[15],[1697122402628]
2120,2120,169,43,[],200,llama-7b,64,1,1968.0,1.0,1,A10,1697122449784,1697122451752,120,10.0,1.0,"[55, 1912]","[1697122449839, 1697122451751]"
2121,2121,426,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404429,1697122407057,120,,,[125],[1697122404554]
2122,2122,847,44,[],200,llama-7b,64,1,1085.0,1.0,1,A10,1697122451755,1697122452840,120,10.0,1.0,"[27, 1058]","[1697122451782, 1697122452840]"
2123,2123,496,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122452845,1697122454905,120,,,[14],[1697122452859]
2124,2124,196,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407061,1697122408127,120,,,[30],[1697122407091]
2125,2125,592,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415036,1697122418474,120,,,"[34, 2279]","[1697122415070, 1697122417349]"
2126,2126,355,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400957,1697122402608,120,,,"[42, 1578]","[1697122400999, 1697122402577]"
2127,2127,342,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380030,1697122381806,120,,,[110],[1697122380140]
2128,2128,815,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416379,1697122418474,120,,,"[91, 1847]","[1697122416470, 1697122418317]"
2129,2129,7,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402614,1697122404423,120,,,[64],[1697122402678]
2130,2130,924,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381811,1697122382784,120,,,[47],[1697122381858]
2131,2131,363,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418482,1697122420382,120,,,[72],[1697122418554]
2132,2132,684,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404429,1697122407057,120,,,[125],[1697122404554]
2133,2133,924,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420388,1697122423159,120,,,[145],[1697122420533]
2134,2134,847,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408130,1697122409610,120,,,[39],[1697122408169]
2135,2135,563,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418481,1697122420380,120,,,[77],[1697122418558]
2136,2136,701,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122382788,1697122389102,120,,,"[63, 1894, 924, 1237, 1060]","[1697122382851, 1697122384745, 1697122385669, 1697122386906, 1697122387966]"
2137,2137,333,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420384,1697122423159,120,,,[40],[1697122420424]
2138,2138,871,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408129,1697122410669,120,,,"[25, 2382]","[1697122408154, 1697122410536]"
2139,2139,453,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407062,1697122409608,120,,,[45],[1697122407107]
2140,2140,508,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409613,1697122411708,120,,,[68],[1697122409681]
2141,2141,524,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410674,1697122412985,120,,,[73],[1697122410747]
2142,2142,280,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122411712,1697122415031,120,,,"[31, 2155]","[1697122411743, 1697122413898]"
2143,2143,302,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412996,1697122416372,120,,,[143],[1697122413139]
2144,2144,795,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393976,1697122396183,120,,,[57],[1697122394033]
2145,2145,882,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416377,1697122418473,120,,,"[36, 1904]","[1697122416413, 1697122418317]"
2146,2146,862,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415035,1697122418475,120,,,[11],[1697122415046]
2147,2147,742,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424994,1697122426576,120,,,[152],[1697122425146]
2148,2148,9,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385672,1697122387917,120,,,[83],[1697122385755]
2149,2149,537,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458097,1697122459961,120,,,[31],[1697122458128]
2150,2150,715,17,[],200,llama-7b,64,1,1098.0,1.0,1,A10,1697122387921,1697122389019,120,20.0,1.0,"[30, 1068]","[1697122387951, 1697122389019]"
2151,2151,316,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391657,1697122393972,120,,,[25],[1697122391682]
2152,2152,652,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418482,1697122420382,120,,,[163],[1697122418645]
2153,2153,312,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420388,1697122423159,120,,,[91],[1697122420479]
2154,2154,450,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424977,1697122426577,120,,,[23],[1697122425000]
2155,2155,572,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396195,1697122398324,120,,,[54],[1697122396249]
2156,2156,225,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398329,1697122400952,120,,,[134],[1697122398463]
2157,2157,638,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418482,1697122420381,120,,,[158],[1697122418640]
2158,2158,1,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400958,1697122402608,120,,,"[35, 1584]","[1697122400993, 1697122402577]"
2159,2159,292,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420384,1697122421736,120,,,[35],[1697122420419]
2160,2160,104,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426582,1697122427730,120,,,"[29, 1041]","[1697122426611, 1697122427652]"
2161,2161,583,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402614,1697122404422,120,,,[49],[1697122402663]
2162,2162,331,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404428,1697122407058,120,,,[116],[1697122404544]
2163,2163,806,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122427734,1697122429745,120,,,"[14, 1979]","[1697122427748, 1697122429727]"
2164,2164,99,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407066,1697122409609,120,,,[107],[1697122407173]
2165,2165,462,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429749,1697122431564,120,,,[23],[1697122429772]
2166,2166,41,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421739,1697122424991,120,,,"[102, 2272, 86]","[1697122421841, 1697122424113, 1697122424199]"
2167,2167,467,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407063,1697122409609,120,,,[70],[1697122407133]
2168,2168,63,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393977,1697122396184,120,,,[86],[1697122394063]
2169,2169,173,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408128,1697122409609,120,,,[20],[1697122408148]
2170,2170,231,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431572,1697122433671,120,,,[170],[1697122431742]
2171,2171,893,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424976,1697122426577,120,,,[22],[1697122424998]
2172,2172,756,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409612,1697122411707,120,,,[55],[1697122409667]
2173,2173,897,13,[],200,llama-7b,64,1,1918.0,1.0,1,A10,1697122370105,1697122372023,120,9.0,1.0,"[65, 1853]","[1697122370170, 1697122372023]"
2174,2174,340,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122441407,1697122443687,120,,,[6],[1697122441413]
2175,2175,624,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424996,1697122427730,120,,,"[164, 2491]","[1697122425160, 1697122427651]"
2176,2176,645,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396195,1697122398324,120,,,[44],[1697122396239]
2177,2177,401,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122427736,1697122429745,120,,,"[22, 1968]","[1697122427758, 1697122429726]"
2178,2178,117,41,[],200,llama-7b,64,1,3210.0,1.0,1,A10,1697122443690,1697122446900,120,364.0,2.0,"[18, 2377, 815]","[1697122443708, 1697122446085, 1697122446900]"
2179,2179,528,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424996,1697122427731,120,,,"[185, 2470]","[1697122425181, 1697122427651]"
2180,2180,422,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398329,1697122400950,120,,,[140],[1697122398469]
2181,2181,548,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122372026,1697122374081,120,,,[14],[1697122372040]
2182,2182,189,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122427737,1697122429746,120,,,"[19, 1971]","[1697122427756, 1697122429727]"
2183,2183,533,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122411711,1697122415031,120,,,[17],[1697122411728]
2184,2184,261,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402580,1697122404422,120,,,[36],[1697122402616]
2185,2185,318,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122374083,1697122375086,120,,,[22],[1697122374105]
2186,2186,30,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404426,1697122405697,120,,,[25],[1697122404451]
2187,2187,908,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.35 GiB. GPU 0 has a total capacty of 21.99 GiB of which 865.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 15.88 GiB is allocated by PyTorch, and 4.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122375090,1697122376091,120,,,"[26, 821]","[1697122375116, 1697122375937]"
2188,2188,893,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429750,1697122431564,120,,,[84],[1697122429834]
2189,2189,189,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415034,1697122418475,120,,,"[6, 2308]","[1697122415040, 1697122417348]"
2190,2190,553,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426581,1697122429745,120,,,"[52, 2195, 60]","[1697122426633, 1697122428828, 1697122428888]"
2191,2191,57,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429751,1697122431565,120,,,[127],[1697122429878]
2192,2192,56,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418477,1697122420380,120,,,[9],[1697122418486]
2193,2193,755,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431570,1697122433670,120,,,[109],[1697122431679]
2194,2194,887,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418480,1697122420381,120,,,[32],[1697122418512]
2195,2195,547,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431568,1697122433672,120,,,[91],[1697122431659]
2196,2196,416,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433676,1697122436784,120,,,[21],[1697122433697]
2197,2197,7,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424995,1697122427730,120,,,"[161, 2495]","[1697122425156, 1697122427651]"
2198,2198,548,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420384,1697122421736,120,,,[26],[1697122420410]
2199,2199,317,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421739,1697122424991,120,,,"[107, 2267, 86]","[1697122421846, 1697122424113, 1697122424199]"
2200,2200,733,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420384,1697122421736,120,,,[31],[1697122420415]
2201,2201,323,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433677,1697122436782,120,,,[52],[1697122433729]
2202,2202,323,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429749,1697122431564,120,,,[13],[1697122429762]
2203,2203,384,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421738,1697122424991,120,,,"[39, 2335, 88]","[1697122421777, 1697122424112, 1697122424200]"
2204,2204,907,36,[],200,llama-7b,64,1,850.0,1.0,1,A10,1697122431567,1697122432417,120,10.0,1.0,"[33, 816]","[1697122431600, 1697122432416]"
2205,2205,234,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451952,1697122454906,120,,,[107],[1697122452059]
2206,2206,684,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432420,1697122433672,120,,,[15],[1697122432435]
2207,2207,823,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454911,1697122456992,120,,,[67],[1697122454978]
2208,2208,906,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436787,1697122438625,120,,,"[45, 1774]","[1697122436832, 1697122438606]"
2209,2209,681,42,[],200,llama-7b,64,1,2772.0,1.0,1,A10,1697122438631,1697122441403,120,23.0,1.0,"[124, 2648]","[1697122438755, 1697122441403]"
2210,2210,595,51,[],200,llama-7b,64,1,1761.0,1.0,1,A10,1697122456995,1697122458756,120,8.0,1.0,"[54, 1707]","[1697122457049, 1697122458756]"
2211,2211,161,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424995,1697122426575,120,,,[141],[1697122425136]
2212,2212,337,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433681,1697122436784,120,,,[90],[1697122433771]
2213,2213,184,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436788,1697122438626,120,,,"[67, 1752]","[1697122436855, 1697122438607]"
2214,2214,257,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458759,1697122461248,120,,,[23],[1697122458782]
2215,2215,743,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426581,1697122427730,120,,,"[20, 1050]","[1697122426601, 1697122427651]"
2216,2216,769,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438631,1697122442469,120,,,"[128, 2644]","[1697122438759, 1697122441403]"
2217,2217,826,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407066,1697122409609,120,,,[110],[1697122407176]
2218,2218,705,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122427737,1697122429746,120,,,[29],[1697122427766]
2219,2219,198,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122372030,1697122374081,120,,,[19],[1697122372049]
2220,2220,365,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429750,1697122431564,120,,,[109],[1697122429859]
2221,2221,896,15,[],200,llama-7b,64,1,1851.0,1.0,1,A10,1697122374086,1697122375937,120,15.0,1.0,"[49, 1802]","[1697122374135, 1697122375937]"
2222,2222,267,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454910,1697122456992,120,,,[58],[1697122454968]
2223,2223,575,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402614,1697122404422,120,,,[44],[1697122402658]
2224,2224,134,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431569,1697122433670,120,,,[112],[1697122431681]
2225,2225,345,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380025,1697122381806,120,,,[28],[1697122380053]
2226,2226,539,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442476,1697122445118,120,,,[37],[1697122442513]
2227,2227,346,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404426,1697122405697,120,,,[30],[1697122404456]
2228,2228,589,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380031,1697122382783,120,,,[134],[1697122380165]
2229,2229,69,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416378,1697122418473,120,,,"[72, 1867]","[1697122416450, 1697122418317]"
2230,2230,916,31,[],200,llama-7b,64,1,1811.0,1.0,1,A10,1697122423163,1697122424974,120,8.0,1.0,"[101, 1710]","[1697122423264, 1697122424974]"
2231,2231,123,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381809,1697122382784,120,,,[7],[1697122381816]
2232,2232,858,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122456997,1697122466987,120,,,"[65, 2944, 1284, 1434, 1295, 928, 1438]","[1697122457062, 1697122460006, 1697122461290, 1697122462724, 1697122464019, 1697122464947, 1697122466385]"
2233,2233,694,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424978,1697122426576,120,,,[60],[1697122425038]
2234,2234,240,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122382786,1697122383904,120,,,"[30, 1067]","[1697122382816, 1697122383883]"
2235,2235,347,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426582,1697122429746,120,,,"[155, 2151]","[1697122426737, 1697122428888]"
2236,2236,17,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.85 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383910,1697122385618,120,,,[37],[1697122383947]
2237,2237,118,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429750,1697122431564,120,,,[32],[1697122429782]
2238,2238,323,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402579,1697122410669,120,,,"[25, 509, 1352, 1274, 1359, 1072, 1482]","[1697122402604, 1697122403113, 1697122404465, 1697122405739, 1697122407098, 1697122408170, 1697122409652]"
2239,2239,719,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433677,1697122436783,120,,,[75],[1697122433752]
2240,2240,701,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431566,1697122432498,120,,,"[39, 811]","[1697122431605, 1697122432416]"
2241,2241,489,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436792,1697122440577,120,,,[82],[1697122436874]
2242,2242,659,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418488,1697122421735,120,,,[167],[1697122418655]
2243,2243,144,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440589,1697122442470,120,,,"[80, 1704]","[1697122440669, 1697122442373]"
2244,2244,427,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421737,1697122423160,120,,,[12],[1697122421749]
2245,2245,194,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445123,1697122446847,120,,,[53],[1697122445176]
2246,2246,871,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446850,1697122448792,120,,,[24],[1697122446874]
2247,2247,127,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424996,1697122427730,120,,,"[160, 2495]","[1697122425156, 1697122427651]"
2248,2248,313,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459967,1697122462680,120,,,[84],[1697122460051]
2249,2249,851,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442482,1697122445116,120,,,[154],[1697122442636]
2250,2250,504,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445121,1697122446846,120,,,[8],[1697122445129]
2251,2251,94,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410674,1697122412985,120,,,[57],[1697122410731]
2252,2252,250,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446851,1697122448793,120,,,[32],[1697122446883]
2253,2253,896,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462684,1697122464904,120,,,[44],[1697122462728]
2254,2254,615,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404425,1697122407057,120,,,[50],[1697122404475]
2255,2255,832,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448796,1697122449780,120,,,[38],[1697122448834]
2256,2256,642,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464909,1697122466987,120,,,"[52, 2009]","[1697122464961, 1697122466970]"
2257,2257,276,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407064,1697122409609,120,,,[74],[1697122407138]
2258,2258,612,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449783,1697122450712,120,,,[26],[1697122449809]
2259,2259,519,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426581,1697122427731,120,,,"[29, 1041]","[1697122426610, 1697122427651]"
2260,2260,268,51,[],200,llama-7b,64,1,2122.0,1.0,1,A10,1697122450718,1697122452840,120,19.0,1.0,"[51, 2070]","[1697122450769, 1697122452839]"
2261,2261,80,37,[],200,llama-7b,64,1,952.0,1.0,1,A10,1697122423161,1697122424113,120,13.0,1.0,"[18, 934]","[1697122423179, 1697122424113]"
2262,2262,670,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424117,1697122424992,120,,,"[17, 840]","[1697122424134, 1697122424974]"
2263,2263,173,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122427739,1697122429746,120,,,"[92, 1896]","[1697122427831, 1697122429727]"
2264,2264,51,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409613,1697122411708,120,,,[127],[1697122409740]
2265,2265,439,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424995,1697122426575,120,,,[136],[1697122425131]
2266,2266,37,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122452848,1697122454905,120,,,[16],[1697122452864]
2267,2267,634,32,[],200,llama-7b,64,1,2183.0,1.0,1,A10,1697122411716,1697122413899,120,13.0,1.0,"[127, 2056]","[1697122411843, 1697122413899]"
2268,2268,744,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435160,1697122438626,120,,,"[94, 2611]","[1697122435254, 1697122437865]"
2269,2269,95,40,[],200,llama-7b,64,1,1070.0,1.0,1,A10,1697122426581,1697122427651,120,12.0,1.0,"[19, 1051]","[1697122426600, 1697122427651]"
2270,2270,681,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412996,1697122416372,120,,,[70],[1697122413066]
2271,2271,627,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454909,1697122456991,120,,,[54],[1697122454963]
2272,2272,775,41,[],200,llama-7b,64,1,1174.0,1.0,1,A10,1697122427654,1697122428828,120,17.0,1.0,"[18, 1156]","[1697122427672, 1697122428828]"
2273,2273,395,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122456996,1697122466987,120,,,"[61, 1699, 1250, 1284, 1434, 1295, 928, 1438]","[1697122457057, 1697122458756, 1697122460006, 1697122461290, 1697122462724, 1697122464019, 1697122464947, 1697122466385]"
2274,2274,410,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122413903,1697122416374,120,,,[23],[1697122413926]
2275,2275,359,30,[],200,llama-7b,64,1,1869.0,1.0,1,A10,1697122412994,1697122414863,120,10.0,1.0,"[58, 1811]","[1697122413052, 1697122414863]"
2276,2276,451,27,[],200,llama-7b,64,1,1939.0,1.0,1,A10,1697122416377,1697122418316,120,286.0,1.0,"[25, 1914]","[1697122416402, 1697122418316]"
2277,2277,522,46,[],200,llama-7b,64,1,2770.0,1.0,1,A10,1697122438634,1697122441404,120,20.0,1.0,"[141, 2629]","[1697122438775, 1697122441404]"
2278,2278,429,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122428830,1697122429747,120,,,"[20, 877]","[1697122428850, 1697122429727]"
2279,2279,81,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400954,1697122402609,120,,,"[97, 1526]","[1697122401051, 1697122402577]"
2280,2280,111,28,[],200,llama-7b,64,1,5882.0,1.0,1,A10,1697122418318,1697122424200,120,79.0,5.0,"[6, 2096, 1353, 1424, 1002]","[1697122418324, 1697122420420, 1697122421773, 1697122423197, 1697122424199]"
2281,2281,779,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402618,1697122405696,120,,,[150],[1697122402768]
2282,2282,205,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429751,1697122432497,120,,,"[132, 2533]","[1697122429883, 1697122432416]"
2283,2283,440,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405698,1697122407058,120,,,[28],[1697122405726]
2284,2284,75,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453813,1697122455927,120,,,[40],[1697122453853]
2285,2285,209,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407066,1697122409610,120,,,[100],[1697122407166]
2286,2286,798,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409612,1697122411707,120,,,[39],[1697122409651]
2287,2287,658,52,[],200,llama-7b,64,1,2081.0,1.0,1,A10,1697122455932,1697122458013,120,11.0,1.0,"[106, 1974]","[1697122456038, 1697122458012]"
2288,2288,434,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458016,1697122466987,120,,,"[29, 711, 1250, 1285, 1433, 1295, 929, 1437]","[1697122458045, 1697122458756, 1697122460006, 1697122461291, 1697122462724, 1697122464019, 1697122464948, 1697122466385]"
2289,2289,107,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122414866,1697122416372,120,,,[10],[1697122414876]
2290,2290,812,29,[],200,llama-7b,64,1,948.0,1.0,1,A10,1697122424204,1697122425152,120,16.0,1.0,"[8, 940]","[1697122424212, 1697122425152]"
2291,2291,465,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122425154,1697122427731,120,,,"[76, 2422]","[1697122425230, 1697122427652]"
2292,2292,176,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122441408,1697122443687,120,,,[20],[1697122441428]
2293,2293,876,48,[],200,llama-7b,64,1,2396.0,1.0,1,A10,1697122443690,1697122446086,120,11.0,1.0,"[28, 2367]","[1697122443718, 1697122446085]"
2294,2294,511,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446092,1697122447823,120,,,[21],[1697122446113]
2295,2295,690,32,[],200,llama-7b,64,1,1939.0,1.0,1,A10,1697122416378,1697122418317,120,39.0,1.0,"[82, 1857]","[1697122416460, 1697122418317]"
2296,2296,279,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447826,1697122448794,120,,,[30],[1697122447856]
2297,2297,676,17,[],200,llama-7b,64,1,1835.0,1.0,1,A10,1697122376097,1697122377932,120,19.0,1.0,"[68, 1767]","[1697122376165, 1697122377932]"
2298,2298,238,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122427740,1697122429746,120,,,"[46, 1941]","[1697122427786, 1697122429727]"
2299,2299,335,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122441408,1697122443687,120,,,[26],[1697122441434]
2300,2300,868,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448796,1697122449780,120,,,[43],[1697122448839]
2301,2301,549,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458098,1697122459961,120,,,[35],[1697122458133]
2302,2302,82,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122443693,1697122451945,120,,,"[59, 2333, 815, 976, 969, 987, 931]","[1697122443752, 1697122446085, 1697122446900, 1697122447876, 1697122448845, 1697122449832, 1697122450763]"
2303,2303,287,18,[],200,llama-7b,64,1,2072.0,1.0,1,A10,1697122381811,1697122383883,120,10.0,1.0,"[50, 2021]","[1697122381861, 1697122383882]"
2304,2304,869,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383885,1697122389101,120,,,"[18, 842, 924, 1238, 1059]","[1697122383903, 1697122384745, 1697122385669, 1697122386907, 1697122387966]"
2305,2305,202,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459966,1697122462680,120,,,[54],[1697122460020]
2306,2306,820,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429752,1697122432497,120,,,"[180, 2484]","[1697122429932, 1697122432416]"
2307,2307,114,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436790,1697122440577,120,,,"[80, 2521]","[1697122436870, 1697122439391]"
2308,2308,464,33,[],200,llama-7b,64,1,643.0,1.0,1,A10,1697122418321,1697122418964,120,12.0,1.0,"[18, 625]","[1697122418339, 1697122418964]"
2309,2309,600,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395183,1697122397245,120,,,[77],[1697122395260]
2310,2310,879,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462685,1697122464905,120,,,[69],[1697122462754]
2311,2311,617,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389108,1697122391053,120,,,"[130, 1731]","[1697122389238, 1697122390969]"
2312,2312,118,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418968,1697122421735,120,,,[38],[1697122419006]
2313,2313,699,40,[],200,llama-7b,64,1,1787.0,1.0,1,A10,1697122440587,1697122442374,120,39.0,1.0,"[47, 1740]","[1697122440634, 1697122442374]"
2314,2314,693,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423165,1697122424992,120,,,"[167, 1642]","[1697122423332, 1697122424974]"
2315,2315,820,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421737,1697122424990,120,,,"[38, 2337, 87]","[1697122421775, 1697122424112, 1697122424199]"
2316,2316,352,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424996,1697122427730,120,,,"[165, 2490]","[1697122425161, 1697122427651]"
2317,2317,255,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397251,1697122399547,120,,,[85],[1697122397336]
2318,2318,644,49,[],200,llama-7b,64,1,2061.0,1.0,1,A10,1697122464909,1697122466970,120,19.0,1.0,"[57, 2004]","[1697122464966, 1697122466970]"
2319,2319,122,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122427734,1697122429746,120,,,"[13, 1980]","[1697122427747, 1697122429727]"
2320,2320,475,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424994,1697122426576,120,,,[151],[1697122425145]
2321,2321,447,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442378,1697122443688,120,,,[34],[1697122442412]
2322,2322,245,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426582,1697122429745,120,,,"[79, 2168, 59]","[1697122426661, 1697122428829, 1697122428888]"
2323,2323,715,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429750,1697122431564,120,,,[40],[1697122429790]
2324,2324,100,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122443691,1697122451944,120,,,"[56, 2338, 815, 975, 970, 987, 931]","[1697122443747, 1697122446085, 1697122446900, 1697122447875, 1697122448845, 1697122449832, 1697122450763]"
2325,2325,25,24,[],200,llama-7b,64,1,2102.0,1.0,1,A10,1697122399551,1697122401653,120,12.0,1.0,"[53, 2049]","[1697122399604, 1697122401653]"
2326,2326,487,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431568,1697122433670,120,,,[46],[1697122431614]
2327,2327,779,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451952,1697122454906,120,,,[112],[1697122452064]
2328,2328,140,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433678,1697122436784,120,,,[89],[1697122433767]
2329,2329,800,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451952,1697122454905,120,,,[97],[1697122452049]
2330,2330,433,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454908,1697122455927,120,,,[21],[1697122454929]
2331,2331,175,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423163,1697122424991,120,,,[81],[1697122423244]
2332,2332,343,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463978,1697122464905,120,,,[35],[1697122464013]
2333,2333,209,47,[],200,llama-7b,64,1,2081.0,1.0,1,A10,1697122455931,1697122458012,120,20.0,1.0,"[56, 2025]","[1697122455987, 1697122458012]"
2334,2334,363,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389022,1697122391053,120,,,"[29, 988]","[1697122389051, 1697122390039]"
2335,2335,110,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464908,1697122466987,120,,,"[33, 2028]","[1697122464941, 1697122466969]"
2336,2336,826,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122427734,1697122429747,120,,,"[9, 1984]","[1697122427743, 1697122429727]"
2337,2337,682,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409612,1697122411707,120,,,[50],[1697122409662]
2338,2338,846,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436788,1697122438626,120,,,"[55, 1763]","[1697122436843, 1697122438606]"
2339,2339,486,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429750,1697122431564,120,,,[104],[1697122429854]
2340,2340,757,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424993,1697122426576,120,,,[58],[1697122425051]
2341,2341,644,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385628,1697122387918,120,,,[107],[1697122385735]
2342,2342,500,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438631,1697122442468,120,,,"[114, 2657]","[1697122438745, 1697122441402]"
2343,2343,790,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458015,1697122466987,120,,,"[14, 727, 1250, 1284, 1434, 1295, 928, 1438]","[1697122458029, 1697122458756, 1697122460006, 1697122461290, 1697122462724, 1697122464019, 1697122464947, 1697122466385]"
2344,2344,254,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431568,1697122433671,120,,,[81],[1697122431649]
2345,2345,276,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387920,1697122389101,120,,,[21],[1697122387941]
2346,2346,541,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380031,1697122381806,120,,,[104],[1697122380135]
2347,2347,243,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409612,1697122410669,120,,,"[34, 891]","[1697122409646, 1697122410537]"
2348,2348,847,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433677,1697122436782,120,,,[40],[1697122433717]
2349,2349,47,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389108,1697122391052,120,,,"[130, 1731]","[1697122389238, 1697122390969]"
2350,2350,245,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442476,1697122445116,120,,,[13],[1697122442489]
2351,2351,315,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381813,1697122383905,120,,,"[119, 1951]","[1697122381932, 1697122383883]"
2352,2352,617,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436787,1697122438625,120,,,"[32, 1787]","[1697122436819, 1697122438606]"
2353,2353,458,31,[],200,llama-7b,64,1,2186.0,1.0,1,A10,1697122411713,1697122413899,120,11.0,1.0,"[54, 2132]","[1697122411767, 1697122413899]"
2354,2354,828,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410673,1697122412985,120,,,[10],[1697122410683]
2355,2355,16,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445124,1697122447823,120,,,[119],[1697122445243]
2356,2356,64,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122383917,1697122386860,120,,,[142],[1697122384059]
2357,2357,597,26,[],200,llama-7b,64,1,1873.0,1.0,1,A10,1697122412991,1697122414864,120,39.0,1.0,"[43, 1829]","[1697122413034, 1697122414863]"
2358,2358,646,22,[],200,llama-7b,64,1,2154.0,1.0,1,A10,1697122386865,1697122389019,120,14.0,1.0,"[89, 2065]","[1697122386954, 1697122389019]"
2359,2359,254,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122414868,1697122416373,120,,,[18],[1697122414886]
2360,2360,630,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391060,1697122392787,120,,,[80],[1697122391140]
2361,2361,24,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416378,1697122418473,120,,,[66],[1697122416444]
2362,2362,410,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392789,1697122393971,120,,,[26],[1697122392815]
2363,2363,111,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122413902,1697122416372,120,,,[38],[1697122413940]
2364,2364,421,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389021,1697122391052,120,,,"[16, 1002]","[1697122389037, 1697122390039]"
2365,2365,63,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393977,1697122396184,120,,,[79],[1697122394056]
2366,2366,816,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416378,1697122418474,120,,,"[77, 1862]","[1697122416455, 1697122418317]"
2367,2367,601,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447826,1697122449781,120,,,[39],[1697122447865]
2368,2368,631,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402613,1697122404422,120,,,[20],[1697122402633]
2369,2369,768,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396195,1697122397244,120,,,[34],[1697122396229]
2370,2370,469,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418482,1697122420380,120,,,[81],[1697122418563]
2371,2371,421,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397247,1697122398323,120,,,[41],[1697122397288]
2372,2372,75,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391060,1697122393972,120,,,[114],[1697122391174]
2373,2373,193,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398326,1697122400950,120,,,[67],[1697122398393]
2374,2374,409,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404426,1697122407058,120,,,[109],[1697122404535]
2375,2375,62,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416377,1697122418472,120,,,"[31, 1908]","[1697122416408, 1697122418316]"
2376,2376,782,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400954,1697122402610,120,,,"[14, 685, 112]","[1697122400968, 1697122401653, 1697122401765]"
2377,2377,65,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407066,1697122409609,120,,,[105],[1697122407171]
2378,2378,769,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409611,1697122410669,120,,,"[25, 900]","[1697122409636, 1697122410536]"
2379,2379,552,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402615,1697122405695,120,,,[138],[1697122402753]
2380,2380,739,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418477,1697122420380,120,,,[17],[1697122418494]
2381,2381,699,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446903,1697122448793,120,,,[29],[1697122446932]
2382,2382,392,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420384,1697122423160,120,,,[51],[1697122420435]
2383,2383,471,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448796,1697122449780,120,,,[26],[1697122448822]
2384,2384,423,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410676,1697122412984,120,,,[102],[1697122410778]
2385,2385,164,37,[],200,llama-7b,64,1,1807.0,1.0,1,A10,1697122423167,1697122424974,120,15.0,1.0,"[170, 1637]","[1697122423337, 1697122424974]"
2386,2386,102,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449783,1697122450712,120,,,[31],[1697122449814]
2387,2387,707,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405701,1697122408126,120,,,[75],[1697122405776]
2388,2388,170,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412991,1697122415032,120,,,"[34, 1838]","[1697122413025, 1697122414863]"
2389,2389,567,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122411711,1697122415031,120,,,"[22, 2165]","[1697122411733, 1697122413898]"
2390,2390,363,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408129,1697122410669,120,,,"[35, 2372]","[1697122408164, 1697122410536]"
2391,2391,28,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461251,1697122463976,120,,,[81],[1697122461332]
2392,2392,486,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433676,1697122436782,120,,,[26],[1697122433702]
2393,2393,750,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424977,1697122426577,120,,,[27],[1697122425004]
2394,2394,611,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463980,1697122466343,120,,,[62],[1697122464042]
2395,2395,128,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410674,1697122412984,120,,,[88],[1697122410762]
2396,2396,520,39,[],200,llama-7b,64,1,2244.0,1.0,1,A10,1697122426585,1697122428829,120,11.0,1.0,"[172, 2072]","[1697122426757, 1697122428829]"
2397,2397,551,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432507,1697122435153,120,,,[51],[1697122432558]
2398,2398,180,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122428831,1697122432499,120,,,"[28, 1482, 1271]","[1697122428859, 1697122430341, 1697122431612]"
2399,2399,144,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436786,1697122438625,120,,,"[18, 1802]","[1697122436804, 1697122438606]"
2400,2400,323,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435156,1697122438625,120,,,"[40, 2669]","[1697122435196, 1697122437865]"
2401,2401,199,32,[],200,llama-7b,64,1,2314.0,1.0,1,A10,1697122415035,1697122417349,120,13.0,1.0,"[20, 2294]","[1697122415055, 1697122417349]"
2402,2402,896,33,[],200,llama-7b,64,1,1611.0,1.0,1,A10,1697122417352,1697122418963,120,15.0,1.0,"[6, 1605]","[1697122417358, 1697122418963]"
2403,2403,842,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438631,1697122440578,120,,,"[42, 1769]","[1697122438673, 1697122440442]"
2404,2404,550,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418966,1697122421735,120,,,[35],[1697122419001]
2405,2405,75,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432506,1697122435152,120,,,[37],[1697122432543]
2406,2406,326,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421737,1697122423158,120,,,[23],[1697122421760]
2407,2407,906,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423162,1697122424990,120,,,"[42, 1769]","[1697122423204, 1697122424973]"
2408,2408,636,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410676,1697122412984,120,,,[101],[1697122410777]
2409,2409,475,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440588,1697122442470,120,,,"[66, 1719]","[1697122440654, 1697122442373]"
2410,2410,246,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442476,1697122445117,120,,,[23],[1697122442499]
2411,2411,423,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122377935,1697122380020,120,,,"[11, 974]","[1697122377946, 1697122378920]"
2412,2412,906,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438631,1697122440578,120,,,"[47, 1764]","[1697122438678, 1697122440442]"
2413,2413,438,35,[],200,llama-7b,64,1,2656.0,1.0,1,A10,1697122424996,1697122427652,120,9.0,1.0,"[184, 2471]","[1697122425180, 1697122427651]"
2414,2414,413,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412995,1697122415033,120,,,"[66, 1802]","[1697122413061, 1697122414863]"
2415,2415,77,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380026,1697122381806,120,,,[42],[1697122380068]
2416,2416,638,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449783,1697122451945,120,,,"[36, 1932]","[1697122449819, 1697122451751]"
2417,2417,207,36,[],200,llama-7b,64,1,1174.0,1.0,1,A10,1697122427655,1697122428829,120,10.0,1.0,"[22, 1152]","[1697122427677, 1697122428829]"
2418,2418,632,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435158,1697122438626,120,,,"[85, 2622]","[1697122435243, 1697122437865]"
2419,2419,686,44,[],200,llama-7b,64,1,1786.0,1.0,1,A10,1697122440587,1697122442373,120,31.0,1.0,"[18, 1768]","[1697122440605, 1697122442373]"
2420,2420,777,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381810,1697122382783,120,,,[28],[1697122381838]
2421,2421,401,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438631,1697122442469,120,,,"[124, 2648]","[1697122438755, 1697122441403]"
2422,2422,829,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445124,1697122447822,120,,,[114],[1697122445238]
2423,2423,438,21,[],200,llama-7b,64,1,1958.0,1.0,1,A10,1697122382787,1697122384745,120,9.0,1.0,"[58, 1900]","[1697122382845, 1697122384745]"
2424,2424,763,37,[],200,llama-7b,64,1,896.0,1.0,1,A10,1697122428831,1697122429727,120,20.0,1.0,"[39, 857]","[1697122428870, 1697122429727]"
2425,2425,60,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442478,1697122445118,120,,,[95],[1697122442573]
2426,2426,601,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447827,1697122449782,120,,,[49],[1697122447876]
2427,2427,212,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122384746,1697122386860,120,,,[8],[1697122384754]
2428,2428,340,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442377,1697122443687,120,,,[19],[1697122442396]
2429,2429,64,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415038,1697122418474,120,,,"[97, 2214]","[1697122415135, 1697122417349]"
2430,2430,758,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445122,1697122446847,120,,,[44],[1697122445166]
2431,2431,293,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451952,1697122454905,120,,,[101],[1697122452053]
2432,2432,70,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454910,1697122455928,120,,,[44],[1697122454954]
2433,2433,254,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449784,1697122450712,120,,,[33],[1697122449817]
2434,2434,30,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122450715,1697122458092,120,,,"[34, 2090, 1025, 1096, 1020, 1065]","[1697122450749, 1697122452839, 1697122453864, 1697122454960, 1697122455980, 1697122457045]"
2435,2435,419,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446850,1697122447824,120,,,[28],[1697122446878]
2436,2436,533,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429730,1697122431564,120,,,[25],[1697122429755]
2437,2437,191,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447828,1697122449782,120,,,[57],[1697122447885]
2438,2438,85,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122443694,1697122451945,120,,,"[68, 2324, 814, 976, 969, 987, 931]","[1697122443762, 1697122446086, 1697122446900, 1697122447876, 1697122448845, 1697122449832, 1697122450763]"
2439,2439,188,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431568,1697122433670,120,,,[72],[1697122431640]
2440,2440,801,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386863,1697122387919,120,,,[37],[1697122386900]
2441,2441,894,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433678,1697122436783,120,,,[77],[1697122433755]
2442,2442,569,24,[],200,llama-7b,64,1,2117.0,1.0,1,A10,1697122387922,1697122390039,120,16.0,1.0,"[109, 2008]","[1697122388031, 1697122390039]"
2443,2443,230,25,[],200,llama-7b,64,1,6187.0,1.0,1,A10,1697122390043,1697122396230,120,86.0,5.0,"[20, 1591, 1179, 1185, 1213, 999]","[1697122390063, 1697122391654, 1697122392833, 1697122394018, 1697122395231, 1697122396230]"
2444,2444,600,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122385622,1697122386860,120,,,[30],[1697122385652]
2445,2445,612,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458098,1697122459961,120,,,[40],[1697122458138]
2446,2446,774,47,[],200,llama-7b,64,1,1965.0,1.0,1,A10,1697122449787,1697122451752,120,8.0,1.0,"[75, 1890]","[1697122449862, 1697122451752]"
2447,2447,384,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459967,1697122462680,120,,,[76],[1697122460043]
2448,2448,375,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.81 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.46 GiB is allocated by PyTorch, and 5.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386863,1697122387919,120,,,[42],[1697122386905]
2449,2449,44,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462685,1697122464905,120,,,[69],[1697122462754]
2450,2450,653,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455930,1697122458094,120,,,"[42, 2039]","[1697122455972, 1697122458011]"
2451,2451,36,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122387922,1697122391053,120,,,"[54, 2063]","[1697122387976, 1697122390039]"
2452,2452,554,48,[],200,llama-7b,64,1,1084.0,1.0,1,A10,1697122451756,1697122452840,120,26.0,1.0,"[31, 1053]","[1697122451787, 1697122452840]"
2453,2453,734,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391061,1697122393971,120,,,[99],[1697122391160]
2454,2454,744,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464907,1697122466344,120,,,[20],[1697122464927]
2455,2455,206,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122452853,1697122454905,120,,,[27],[1697122452880]
2456,2456,207,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392793,1697122395178,120,,,[70],[1697122392863]
2457,2457,425,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458103,1697122461247,120,,,[129],[1697122458232]
2458,2458,78,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461250,1697122463976,120,,,[39],[1697122461289]
2459,2459,754,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463980,1697122466343,120,,,[67],[1697122464047]
2460,2460,395,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393973,1697122395177,120,,,[13],[1697122393986]
2461,2461,882,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454907,1697122455927,120,,,[17],[1697122454924]
2462,2462,162,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395179,1697122396184,120,,,[41],[1697122395220]
2463,2463,705,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122382788,1697122389101,120,,,"[72, 2810, 1236, 1060]","[1697122382860, 1697122385670, 1697122386906, 1697122387966]"
2464,2464,724,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396195,1697122398323,120,,,[39],[1697122396234]
2465,2465,652,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455930,1697122456992,120,,,[27],[1697122455957]
2466,2466,493,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398327,1697122400952,120,,,[121],[1697122398448]
2467,2467,307,52,[],200,llama-7b,64,1,1759.0,1.0,1,A10,1697122456997,1697122458756,120,26.0,1.0,"[62, 1697]","[1697122457059, 1697122458756]"
2468,2468,144,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400958,1697122402610,120,,,"[98, 1521]","[1697122401056, 1697122402577]"
2469,2469,84,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458760,1697122461248,120,,,[32],[1697122458792]
2470,2470,851,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402619,1697122405696,120,,,[159],[1697122402778]
2471,2471,668,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451952,1697122454906,120,,,[111],[1697122452063]
2472,2472,667,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461251,1697122463976,120,,,[53],[1697122461304]
2473,2473,438,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463980,1697122466343,120,,,[60],[1697122464040]
2474,2474,388,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.05 GiB is allocated by PyTorch, and 4.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391061,1697122393972,120,,,[99],[1697122391160]
2475,2475,350,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424995,1697122426576,120,,,[155],[1697122425150]
2476,2476,445,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454908,1697122456991,120,,,[30],[1697122454938]
2477,2477,100,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122456994,1697122458093,120,,,"[18, 1000]","[1697122457012, 1697122458012]"
2478,2478,49,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393976,1697122396183,120,,,[67],[1697122394043]
2479,2479,349,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 5.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122389109,1697122391052,120,,,"[73, 1787]","[1697122389182, 1697122390969]"
2480,2480,835,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429749,1697122431564,120,,,[26],[1697122429775]
2481,2481,748,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396195,1697122398322,120,,,[73],[1697122396268]
2482,2482,799,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458096,1697122459962,120,,,[8],[1697122458104]
2483,2483,603,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431570,1697122433671,120,,,[163],[1697122431733]
2484,2484,126,36,[],200,llama-7b,64,1,2248.0,1.0,1,A10,1697122426581,1697122428829,120,19.0,1.0,"[58, 2189]","[1697122426639, 1697122428828]"
2485,2485,711,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122428831,1697122432498,120,,,"[29, 1481, 1271]","[1697122428860, 1697122430341, 1697122431612]"
2486,2486,234,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433679,1697122436783,120,,,[98],[1697122433777]
2487,2487,480,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432504,1697122435152,120,,,[35],[1697122432539]
2488,2488,451,18,[],200,llama-7b,64,1,1865.0,1.0,1,A10,1697122389104,1697122390969,120,286.0,1.0,"[15, 1850]","[1697122389119, 1697122390969]"
2489,2489,455,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459965,1697122461247,120,,,[40],[1697122460005]
2490,2490,221,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122390974,1697122402609,120,,,"[39, 641, 1179, 1186, 1212, 999, 1062, 1079, 1223, 1399, 772]","[1697122391013, 1697122391654, 1697122392833, 1697122394019, 1697122395231, 1697122396230, 1697122397292, 1697122398371, 1697122399594, 1697122400993, 1697122401765]"
2491,2491,461,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454908,1697122455928,120,,,[26],[1697122454934]
2492,2492,126,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391060,1697122392787,120,,,[85],[1697122391145]
2493,2493,4,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436790,1697122440577,120,,,"[141, 2460]","[1697122436931, 1697122439391]"
2494,2494,230,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455930,1697122458094,120,,,"[47, 2034]","[1697122455977, 1697122458011]"
2495,2495,142,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435156,1697122438624,120,,,"[22, 2687]","[1697122435178, 1697122437865]"
2496,2496,708,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392792,1697122395178,120,,,[66],[1697122392858]
2497,2497,592,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440589,1697122442470,120,,,"[60, 1725]","[1697122440649, 1697122442374]"
2498,2498,819,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458098,1697122459962,120,,,[45],[1697122458143]
2499,2499,224,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461251,1697122463975,120,,,[91],[1697122461342]
2500,2500,584,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459968,1697122462680,120,,,[103],[1697122460071]
2501,2501,836,40,[],200,llama-7b,64,1,1812.0,1.0,1,A10,1697122438630,1697122440442,120,11.0,1.0,"[33, 1779]","[1697122438663, 1697122440442]"
2502,2502,467,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440446,1697122442471,120,,,"[24, 933]","[1697122440470, 1697122441403]"
2503,2503,614,25,[],200,llama-7b,64,1,1457.0,1.0,1,A10,1697122401656,1697122403113,120,15.0,1.0,"[25, 1432]","[1697122401681, 1697122403113]"
2504,2504,875,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420384,1697122421736,120,,,[19],[1697122420403]
2505,2505,565,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122428832,1697122432498,120,,,"[48, 1461, 1271]","[1697122428880, 1697122430341, 1697122431612]"
2506,2506,810,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402618,1697122405696,120,,,[150],[1697122402768]
2507,2507,651,31,[],200,llama-7b,64,1,2460.0,1.0,1,A10,1697122421740,1697122424200,120,457.0,2.0,"[116, 2256, 87]","[1697122421856, 1697122424112, 1697122424199]"
2508,2508,528,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426582,1697122429746,120,,,"[150, 2096, 60]","[1697122426732, 1697122428828, 1697122428888]"
2509,2509,562,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458096,1697122459962,120,,,[16],[1697122458112]
2510,2510,813,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463979,1697122464905,120,,,[27],[1697122464006]
2511,2511,190,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429750,1697122431564,120,,,[84],[1697122429834]
2512,2512,583,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464908,1697122466987,120,,,"[38, 2023]","[1697122464946, 1697122466969]"
2513,2513,305,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424201,1697122427731,120,,,"[6, 945, 1462]","[1697122424207, 1697122425152, 1697122426614]"
2514,2514,891,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431567,1697122432498,120,,,"[27, 822]","[1697122431594, 1697122432416]"
2515,2515,845,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404428,1697122407058,120,,,[106],[1697122404534]
2516,2516,551,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432506,1697122435151,120,,,[53],[1697122432559]
2517,2517,225,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432503,1697122435152,120,,,[36],[1697122432539]
2518,2518,582,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405701,1697122408127,120,,,[64],[1697122405765]
2519,2519,612,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407063,1697122409609,120,,,[81],[1697122407144]
2520,2520,699,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418484,1697122421735,120,,,[170],[1697122418654]
2521,2521,223,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459966,1697122461247,120,,,[19],[1697122459985]
2522,2522,924,44,[],200,llama-7b,64,1,2705.0,1.0,1,A10,1697122435161,1697122437866,120,9.0,1.0,"[111, 2594]","[1697122435272, 1697122437866]"
2523,2523,583,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122437869,1697122440578,120,,,"[20, 1502]","[1697122437889, 1697122439391]"
2524,2524,76,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122427740,1697122429746,120,,,"[96, 1891]","[1697122427836, 1697122429727]"
2525,2525,353,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440590,1697122442470,120,,,"[54, 1730]","[1697122440644, 1697122442374]"
2526,2526,666,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429749,1697122431564,120,,,[16],[1697122429765]
2527,2527,231,22,[],200,llama-7b,64,1,2404.0,1.0,1,A10,1697122408133,1697122410537,120,13.0,1.0,"[109, 2294]","[1697122408242, 1697122410536]"
2528,2528,353,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421737,1697122423159,120,,,[30],[1697122421767]
2529,2529,129,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423171,1697122424991,120,,,"[171, 1632]","[1697122423342, 1697122424974]"
2530,2530,435,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431569,1697122433670,120,,,[75],[1697122431644]
2531,2531,714,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424994,1697122426575,120,,,[87],[1697122425081]
2532,2532,67,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433682,1697122436783,120,,,[160],[1697122433842]
2533,2533,13,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442477,1697122445116,120,,,[71],[1697122442548]
2534,2534,483,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426581,1697122429746,120,,,"[90, 2157, 60]","[1697122426671, 1697122428828, 1697122428888]"
2535,2535,717,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445121,1697122446846,120,,,[30],[1697122445151]
2536,2536,760,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436788,1697122440577,120,,,"[77, 2525]","[1697122436865, 1697122439390]"
2537,2537,780,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122393974,1697122395178,120,,,[37],[1697122394011]
2538,2538,373,47,[],200,llama-7b,64,1,1966.0,1.0,1,A10,1697122449786,1697122451752,120,15.0,1.0,"[71, 1895]","[1697122449857, 1697122451752]"
2539,2539,371,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446851,1697122448792,120,,,[38],[1697122446889]
2540,2540,421,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440592,1697122442469,120,,,"[33, 1748]","[1697122440625, 1697122442373]"
2541,2541,436,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395180,1697122396183,120,,,[12],[1697122395192]
2542,2542,901,39,[],200,llama-7b,64,1,2655.0,1.0,1,A10,1697122424996,1697122427651,120,17.0,1.0,"[170, 2485]","[1697122425166, 1697122427651]"
2543,2543,755,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415036,1697122418474,120,,,"[44, 2268]","[1697122415080, 1697122417348]"
2544,2544,118,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448797,1697122450711,120,,,[50],[1697122448847]
2545,2545,26,48,[],200,llama-7b,64,1,1084.0,1.0,1,A10,1697122451756,1697122452840,120,18.0,1.0,"[30, 1054]","[1697122451786, 1697122452840]"
2546,2546,9,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410539,1697122411708,120,,,[10],[1697122410549]
2547,2547,201,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396195,1697122398322,120,,,[59],[1697122396254]
2548,2548,815,51,[],200,llama-7b,64,1,5266.0,1.0,1,A10,1697122450714,1697122455980,120,52.0,4.0,"[22, 2103, 1025, 1095, 1021]","[1697122450736, 1697122452839, 1697122453864, 1697122454959, 1697122455980]"
2549,2549,877,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432509,1697122435151,120,,,[59],[1697122432568]
2550,2550,476,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455983,1697122458093,120,,,"[60, 1970]","[1697122456043, 1697122458013]"
2551,2551,671,40,[],200,llama-7b,64,1,1176.0,1.0,1,A10,1697122427653,1697122428829,120,12.0,1.0,"[14, 1162]","[1697122427667, 1697122428829]"
2552,2552,791,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398326,1697122400949,120,,,[54],[1697122398380]
2553,2553,591,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122411715,1697122415032,120,,,"[120, 2064]","[1697122411835, 1697122413899]"
2554,2554,732,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122452849,1697122454905,120,,,[25],[1697122452874]
2555,2555,515,37,[],200,llama-7b,64,1,1989.0,1.0,1,A10,1697122427738,1697122429727,120,11.0,1.0,"[35, 1954]","[1697122427773, 1697122429727]"
2556,2556,246,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458101,1697122459963,120,,,[61],[1697122458162]
2557,2557,567,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432502,1697122435151,120,,,[9],[1697122432511]
2558,2558,303,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122428834,1697122432498,120,,,"[50, 1457, 1271]","[1697122428884, 1697122430341, 1697122431612]"
2559,2559,684,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424994,1697122426578,120,,,[77],[1697122425071]
2560,2560,559,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400954,1697122402608,120,,,"[44, 1579]","[1697122400998, 1697122402577]"
2561,2561,830,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459966,1697122462680,120,,,[44],[1697122460010]
2562,2562,176,38,[],200,llama-7b,64,1,1882.0,1.0,1,A10,1697122429730,1697122431612,120,216.0,2.0,"[10, 1872]","[1697122429740, 1697122431612]"
2563,2563,221,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435156,1697122438624,120,,,"[20, 2689]","[1697122435176, 1697122437865]"
2564,2564,607,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462682,1697122463977,120,,,[7],[1697122462689]
2565,2565,191,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402614,1697122404422,120,,,[47],[1697122402661]
2566,2566,640,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448796,1697122449780,120,,,[33],[1697122448829]
2567,2567,403,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398326,1697122400950,120,,,[104],[1697122398430]
2568,2568,921,35,[],200,llama-7b,64,1,1813.0,1.0,1,A10,1697122438629,1697122440442,120,31.0,1.0,"[24, 1788]","[1697122438653, 1697122440441]"
2569,2569,300,48,[],200,llama-7b,64,1,1967.0,1.0,1,A10,1697122449785,1697122451752,120,9.0,1.0,"[57, 1909]","[1697122449842, 1697122451751]"
2570,2570,504,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405699,1697122408127,120,,,[42],[1697122405741]
2571,2571,180,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400954,1697122402610,120,,,"[19, 680, 112]","[1697122400973, 1697122401653, 1697122401765]"
2572,2572,478,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432510,1697122435152,120,,,[126],[1697122432636]
2573,2573,69,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451755,1697122458094,120,,,"[17, 1067, 1025, 1096, 1020, 1065]","[1697122451772, 1697122452839, 1697122453864, 1697122454960, 1697122455980, 1697122457045]"
2574,2574,480,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395182,1697122397244,120,,,[67],[1697122395249]
2575,2575,763,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402615,1697122405695,120,,,[133],[1697122402748]
2576,2576,228,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122397248,1697122399547,120,,,[45],[1697122397293]
2577,2577,256,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463980,1697122466343,120,,,[75],[1697122464055]
2578,2578,889,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404426,1697122407057,120,,,[49],[1697122404475]
2579,2579,246,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462686,1697122464905,120,,,[73],[1697122462759]
2580,2580,662,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458097,1697122459961,120,,,[33],[1697122458130]
2581,2581,434,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459965,1697122461247,120,,,[30],[1697122459995]
2582,2582,582,36,[],200,llama-7b,64,1,954.0,1.0,1,A10,1697122440450,1697122441404,120,19.0,1.0,"[30, 924]","[1697122440480, 1697122441404]"
2583,2583,87,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461252,1697122463976,120,,,[100],[1697122461352]
2584,2584,17,49,[],200,llama-7b,64,1,2062.0,1.0,1,A10,1697122464908,1697122466970,120,23.0,1.0,"[44, 2018]","[1697122464952, 1697122466970]"
2585,2585,134,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435160,1697122438625,120,,,"[87, 2618]","[1697122435247, 1697122437865]"
2586,2586,831,38,[],200,llama-7b,64,1,1811.0,1.0,1,A10,1697122438631,1697122440442,120,11.0,1.0,"[109, 1702]","[1697122438740, 1697122440442]"
2587,2587,794,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463981,1697122466344,120,,,[91],[1697122464072]
2588,2588,464,39,[],200,llama-7b,64,1,957.0,1.0,1,A10,1697122440447,1697122441404,120,12.0,1.0,"[28, 929]","[1697122440475, 1697122441404]"
2589,2589,231,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122441410,1697122443688,120,,,[33],[1697122441443]
2590,2590,824,41,[],200,llama-7b,64,1,5154.0,1.0,1,A10,1697122443691,1697122448845,120,58.0,4.0,"[37, 2357, 815, 975, 970]","[1697122443728, 1697122446085, 1697122446900, 1697122447875, 1697122448845]"
2591,2591,524,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418481,1697122420381,120,,,[87],[1697122418568]
2592,2592,786,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432503,1697122435151,120,,,[27],[1697122432530]
2593,2593,186,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420384,1697122421736,120,,,[16],[1697122420400]
2594,2594,719,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412989,1697122415032,120,,,[15],[1697122413004]
2595,2595,557,16,[],200,llama-7b,64,1,1243.0,1.0,1,A10,1697122375941,1697122377184,120,31.0,1.0,"[34, 1209]","[1697122375975, 1697122377184]"
2596,2596,880,34,[],200,llama-7b,64,1,2461.0,1.0,1,A10,1697122421739,1697122424200,120,84.0,2.0,"[94, 2280, 86]","[1697122421833, 1697122424113, 1697122424199]"
2597,2597,538,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435158,1697122438625,120,,,"[80, 2627]","[1697122435238, 1697122437865]"
2598,2598,563,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435161,1697122438626,120,,,"[96, 2608]","[1697122435257, 1697122437865]"
2599,2599,0,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396232,1697122398322,120,,,[115],[1697122396347]
2600,2600,796,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395181,1697122396184,120,,,[49],[1697122395230]
2601,2601,801,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122450715,1697122458093,120,,,"[44, 2080, 1025, 1096, 1021, 1064]","[1697122450759, 1697122452839, 1697122453864, 1697122454960, 1697122455981, 1697122457045]"
2602,2602,486,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415035,1697122418473,120,,,"[21, 2293]","[1697122415056, 1697122417349]"
2603,2603,147,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418477,1697122420380,120,,,[30],[1697122418507]
2604,2604,216,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438629,1697122440576,120,,,"[6, 1806]","[1697122438635, 1697122440441]"
2605,2605,845,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420385,1697122423158,120,,,[60],[1697122420445]
2606,2606,326,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122377189,1697122380020,120,,,"[30, 1701]","[1697122377219, 1697122378920]"
2607,2607,566,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396198,1697122398323,120,,,[85],[1697122396283]
2608,2608,501,38,[],200,llama-7b,64,1,1812.0,1.0,1,A10,1697122423162,1697122424974,120,19.0,1.0,"[47, 1764]","[1697122423209, 1697122424973]"
2609,2609,583,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398327,1697122400950,120,,,[106],[1697122398433]
2610,2610,217,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398326,1697122399548,120,,,[32],[1697122398358]
2611,2611,877,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431613,1697122433671,120,,,[136],[1697122431749]
2612,2612,537,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433677,1697122436783,120,,,[64],[1697122433741]
2613,2613,917,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440589,1697122442470,120,,,"[55, 1730]","[1697122440644, 1697122442374]"
2614,2614,914,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380026,1697122381806,120,,,[108],[1697122380134]
2615,2615,924,24,[],200,llama-7b,64,1,2100.0,1.0,1,A10,1697122399553,1697122401653,120,9.0,1.0,"[87, 2013]","[1697122399640, 1697122401653]"
2616,2616,577,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122401655,1697122410668,120,,,"[14, 1444, 1352, 1274, 1359, 1071, 1483]","[1697122401669, 1697122403113, 1697122404465, 1697122405739, 1697122407098, 1697122408169, 1697122409652]"
2617,2617,574,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442476,1697122445118,120,,,[38],[1697122442514]
2618,2618,332,28,[],200,llama-7b,64,1,1619.0,1.0,1,A10,1697122400958,1697122402577,120,39.0,1.0,"[78, 1541]","[1697122401036, 1697122402577]"
2619,2619,684,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122381809,1697122382784,120,,,[11],[1697122381820]
2620,2620,272,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438631,1697122442468,120,,,"[114, 2657]","[1697122438745, 1697122441402]"
2621,2621,910,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402580,1697122404422,120,,,[39],[1697122402619]
2622,2622,428,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122382787,1697122389101,120,,,"[49, 1908, 925, 1237, 1059]","[1697122382836, 1697122384744, 1697122385669, 1697122386906, 1697122387965]"
2623,2623,344,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445127,1697122447824,120,,,[141],[1697122445268]
2624,2624,873,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429752,1697122431565,120,,,[177],[1697122429929]
2625,2625,49,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442476,1697122445116,120,,,[12],[1697122442488]
2626,2626,534,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431567,1697122432499,120,,,"[42, 807]","[1697122431609, 1697122432416]"
2627,2627,246,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420385,1697122423158,120,,,[64],[1697122420449]
2628,2628,303,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432506,1697122435152,120,,,[42],[1697122432548]
2629,2629,685,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404425,1697122405696,120,,,[14],[1697122404439]
2630,2630,50,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435157,1697122438625,120,,,"[76, 2632]","[1697122435233, 1697122437865]"
2631,2631,339,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405700,1697122408127,120,,,[55],[1697122405755]
2632,2632,115,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408130,1697122409610,120,,,[29],[1697122408159]
2633,2633,834,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423162,1697122424992,120,,,"[22, 929, 86]","[1697122423184, 1697122424113, 1697122424199]"
2634,2634,700,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409613,1697122411708,120,,,[63],[1697122409676]
2635,2635,469,34,[],200,llama-7b,64,1,2184.0,1.0,1,A10,1697122411715,1697122413899,120,17.0,1.0,"[62, 2121]","[1697122411777, 1697122413898]"
2636,2636,921,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461253,1697122463977,120,,,[104],[1697122461357]
2637,2637,84,21,[],200,llama-7b,64,1,1862.0,1.0,1,A10,1697122389108,1697122390970,120,26.0,1.0,"[64, 1798]","[1697122389172, 1697122390970]"
2638,2638,604,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424996,1697122427731,120,,,"[180, 2475]","[1697122425176, 1697122427651]"
2639,2639,782,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122390973,1697122402608,120,,,"[20, 661, 1179, 1186, 1212, 999, 1062, 1079, 1223, 1399, 772]","[1697122390993, 1697122391654, 1697122392833, 1697122394019, 1697122395231, 1697122396230, 1697122397292, 1697122398371, 1697122399594, 1697122400993, 1697122401765]"
2640,2640,628,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438631,1697122440576,120,,,[104],[1697122438735]
2641,2641,235,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122427740,1697122429746,120,,,[43],[1697122427783]
2642,2642,3,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429749,1697122431565,120,,,[95],[1697122429844]
2643,2643,593,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431567,1697122433670,120,,,[63],[1697122431630]
2644,2644,362,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433677,1697122436783,120,,,[70],[1697122433747]
2645,2645,580,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463979,1697122466342,120,,,[41],[1697122464020]
2646,2646,405,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440592,1697122442471,120,,,"[17, 1764]","[1697122440609, 1697122442373]"
2647,2647,594,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448848,1697122450712,120,,,[21],[1697122448869]
2648,2648,351,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122441407,1697122443687,120,,,[16],[1697122441423]
2649,2649,250,43,[],200,llama-7b,64,1,2121.0,1.0,1,A10,1697122450719,1697122452840,120,31.0,1.0,"[62, 2059]","[1697122450781, 1697122452840]"
2650,2650,18,42,[],200,llama-7b,64,1,1819.0,1.0,1,A10,1697122436788,1697122438607,120,15.0,1.0,"[67, 1752]","[1697122436855, 1697122438607]"
2651,2651,766,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.93 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122371112,1697122373011,120,,,[53],[1697122371165]
2652,2652,191,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442476,1697122445117,120,,,[22],[1697122442498]
2653,2653,775,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445124,1697122447823,120,,,[123],[1697122445247]
2654,2654,537,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.40 GiB is free. Process 430828 has 20.58 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122373013,1697122374082,120,,,[34],[1697122373047]
2655,2655,771,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418481,1697122420382,120,,,[72],[1697122418553]
2656,2656,279,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408132,1697122410669,120,,,"[111, 2293]","[1697122408243, 1697122410536]"
2657,2657,109,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409611,1697122410669,120,,,"[21, 905]","[1697122409632, 1697122410537]"
2658,2658,720,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438609,1697122440578,120,,,"[11, 771]","[1697122438620, 1697122439391]"
2659,2659,199,16,[],200,llama-7b,64,1,1851.0,1.0,1,A10,1697122374087,1697122375938,120,13.0,1.0,"[72, 1779]","[1697122374159, 1697122375938]"
2660,2660,27,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122452847,1697122454905,120,,,[22],[1697122452869]
2661,2661,814,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410674,1697122412985,120,,,[66],[1697122410740]
2662,2662,307,43,[],200,llama-7b,64,1,2770.0,1.0,1,A10,1697122438633,1697122441403,120,26.0,1.0,"[131, 2639]","[1697122438764, 1697122441403]"
2663,2663,609,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454908,1697122455927,120,,,[20],[1697122454928]
2664,2664,468,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412996,1697122416371,120,,,[75],[1697122413071]
2665,2665,552,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447828,1697122449781,120,,,[113],[1697122447941]
2666,2666,247,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416382,1697122424990,120,,,"[160, 2421, 1457, 1353, 1424, 1002]","[1697122416542, 1697122418963, 1697122420420, 1697122421773, 1697122423197, 1697122424199]"
2667,2667,891,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122441407,1697122443687,120,,,[22],[1697122441429]
2668,2668,643,45,[],200,llama-7b,64,1,2395.0,1.0,1,A10,1697122443691,1697122446086,120,18.0,1.0,"[42, 2353]","[1697122443733, 1697122446086]"
2669,2669,413,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446094,1697122447823,120,,,[24],[1697122446118]
2670,2670,829,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424995,1697122426575,120,,,[96],[1697122425091]
2671,2671,71,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447825,1697122448794,120,,,[11],[1697122447836]
2672,2672,386,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455930,1697122458093,120,,,"[37, 2044]","[1697122455967, 1697122458011]"
2673,2673,770,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448797,1697122450711,120,,,[60],[1697122448857]
2674,2674,606,28,[],200,llama-7b,64,1,2248.0,1.0,1,A10,1697122426581,1697122428829,120,9.0,1.0,"[34, 2213]","[1697122426615, 1697122428828]"
2675,2675,424,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420386,1697122423158,120,,,[74],[1697122420460]
2676,2676,431,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122450714,1697122458092,120,,,"[30, 2095, 1025, 1095, 1021, 1065]","[1697122450744, 1697122452839, 1697122453864, 1697122454959, 1697122455980, 1697122457045]"
2677,2677,368,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442482,1697122445118,120,,,[93],[1697122442575]
2678,2678,537,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405698,1697122407058,120,,,[28],[1697122405726]
2679,2679,262,29,[],200,llama-7b,64,1,1507.0,1.0,1,A10,1697122428835,1697122430342,120,39.0,1.0,"[55, 1451]","[1697122428890, 1697122430341]"
2680,2680,120,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445125,1697122447823,120,,,[138],[1697122445263]
2681,2681,31,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122430344,1697122432497,120,,,"[16, 2057]","[1697122430360, 1697122432417]"
2682,2682,37,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458104,1697122461246,120,,,[138],[1697122458242]
2683,2683,710,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461249,1697122462681,120,,,[30],[1697122461279]
2684,2684,187,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407061,1697122408127,120,,,[28],[1697122407089]
2685,2685,706,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447827,1697122449782,120,,,[59],[1697122447886]
2686,2686,480,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462688,1697122464905,120,,,[76],[1697122462764]
2687,2687,135,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464909,1697122466987,120,,,"[53, 2008]","[1697122464962, 1697122466970]"
2688,2688,476,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449786,1697122451945,120,,,"[88, 1877]","[1697122449874, 1697122451751]"
2689,2689,89,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447827,1697122449782,120,,,[53],[1697122447880]
2690,2690,107,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451948,1697122453810,120,,,[15],[1697122451963]
2691,2691,864,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408132,1697122410669,120,,,"[101, 2304]","[1697122408233, 1697122410537]"
2692,2692,908,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433677,1697122436784,120,,,[80],[1697122433757]
2693,2693,479,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409612,1697122411707,120,,,[39],[1697122409651]
2694,2694,804,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453814,1697122455928,120,,,[54],[1697122453868]
2695,2695,247,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122411719,1697122415033,120,,,"[129, 2051]","[1697122411848, 1697122413899]"
2696,2696,519,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410674,1697122412984,120,,,[32],[1697122410706]
2697,2697,464,48,[],200,llama-7b,64,1,2080.0,1.0,1,A10,1697122455932,1697122458012,120,12.0,1.0,"[101, 1979]","[1697122456033, 1697122458012]"
2698,2698,561,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436788,1697122438626,120,,,"[72, 1747]","[1697122436860, 1697122438607]"
2699,2699,289,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412990,1697122415031,120,,,"[20, 1853]","[1697122413010, 1697122414863]"
2700,2700,235,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458016,1697122466987,120,,,"[35, 1955, 1285, 1433, 1295, 929, 1437]","[1697122458051, 1697122460006, 1697122461291, 1697122462724, 1697122464019, 1697122464948, 1697122466385]"
2701,2701,878,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415036,1697122418473,120,,,"[30, 2283]","[1697122415066, 1697122417349]"
2702,2702,647,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418481,1697122420381,120,,,[62],[1697122418543]
2703,2703,320,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435156,1697122438625,120,,,[32],[1697122435188]
2704,2704,837,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415039,1697122418474,120,,,"[101, 2209]","[1697122415140, 1697122417349]"
2705,2705,296,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405701,1697122408127,120,,,[59],[1697122405760]
2706,2706,910,41,[],200,llama-7b,64,1,1812.0,1.0,1,A10,1697122438630,1697122440442,120,8.0,1.0,"[28, 1784]","[1697122438658, 1697122440442]"
2707,2707,606,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418482,1697122420381,120,,,[153],[1697122418635]
2708,2708,877,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408130,1697122410670,120,,,"[42, 2365]","[1697122408172, 1697122410537]"
2709,2709,265,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420385,1697122423160,120,,,[59],[1697122420444]
2710,2710,681,42,[],200,llama-7b,64,1,957.0,1.0,1,A10,1697122440447,1697122441404,120,23.0,1.0,"[28, 929]","[1697122440475, 1697122441404]"
2711,2711,654,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410674,1697122412985,120,,,[78],[1697122410752]
2712,2712,334,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122441410,1697122443688,120,,,[39],[1697122441449]
2713,2713,34,34,[],200,llama-7b,64,1,1809.0,1.0,1,A10,1697122423165,1697122424974,120,12.0,1.0,"[104, 1705]","[1697122423269, 1697122424974]"
2714,2714,82,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122443693,1697122451945,120,,,"[65, 2328, 814, 976, 969, 987, 931]","[1697122443758, 1697122446086, 1697122446900, 1697122447876, 1697122448845, 1697122449832, 1697122450763]"
2715,2715,540,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424202,1697122427731,120,,,"[6, 944, 1462]","[1697122424208, 1697122425152, 1697122426614]"
2716,2716,205,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449784,1697122450711,120,,,[23],[1697122449807]
2717,2717,861,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410675,1697122412984,120,,,[83],[1697122410758]
2718,2718,910,43,[],200,llama-7b,64,1,1039.0,1.0,1,A10,1697122450713,1697122451752,120,8.0,1.0,"[18, 1021]","[1697122450731, 1697122451752]"
2719,2719,384,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454908,1697122455928,120,,,[35],[1697122454943]
2720,2720,566,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451755,1697122458094,120,,,"[21, 1063, 1025, 1096, 1020, 1065]","[1697122451776, 1697122452839, 1697122453864, 1697122454960, 1697122455980, 1697122457045]"
2721,2721,160,51,[],200,llama-7b,64,1,2080.0,1.0,1,A10,1697122455932,1697122458012,120,13.0,1.0,"[98, 1982]","[1697122456030, 1697122458012]"
2722,2722,198,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423163,1697122424991,120,,,"[87, 1724]","[1697122423250, 1697122424974]"
2723,2723,659,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451954,1697122454906,120,,,[115],[1697122452069]
2724,2724,639,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412989,1697122415031,120,,,"[28, 1846]","[1697122413017, 1697122414863]"
2725,2725,236,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442482,1697122445116,120,,,[163],[1697122442645]
2726,2726,591,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432509,1697122435152,120,,,[70],[1697122432579]
2727,2727,306,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436787,1697122438626,120,,,[58],[1697122436845]
2728,2728,140,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.10 GiB is allocated by PyTorch, and 4.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122391060,1697122392787,120,,,[90],[1697122391150]
2729,2729,293,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415036,1697122418474,120,,,"[39, 2274]","[1697122415075, 1697122417349]"
2730,2730,722,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.99 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 17.06 GiB is allocated by PyTorch, and 4.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122392791,1697122395177,120,,,[52],[1697122392843]
2731,2731,66,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418481,1697122421735,120,,,[164],[1697122418645]
2732,2732,826,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445121,1697122446847,120,,,[45],[1697122445166]
2733,2733,672,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449786,1697122451945,120,,,"[83, 1883]","[1697122449869, 1697122451752]"
2734,2734,54,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438632,1697122442469,120,,,"[137, 2634]","[1697122438769, 1697122441403]"
2735,2735,597,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446848,1697122447824,120,,,[16],[1697122446864]
2736,2736,744,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421737,1697122423158,120,,,[25],[1697122421762]
2737,2737,449,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451951,1697122454906,120,,,[88],[1697122452039]
2738,2738,395,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423161,1697122424991,120,,,"[48, 1764]","[1697122423209, 1697122424973]"
2739,2739,130,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122413903,1697122416372,120,,,[33],[1697122413936]
2740,2740,104,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454910,1697122456991,120,,,[48],[1697122454958]
2741,2741,172,39,[],200,llama-7b,64,1,2655.0,1.0,1,A10,1697122424996,1697122427651,120,19.0,1.0,"[238, 2417]","[1697122425234, 1697122427651]"
2742,2742,61,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442477,1697122445116,120,,,[68],[1697122442545]
2743,2743,250,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447828,1697122449781,120,,,[112],[1697122447940]
2744,2744,760,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424996,1697122427730,120,,,"[175, 2480]","[1697122425171, 1697122427651]"
2745,2745,145,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429749,1697122431564,120,,,[31],[1697122429780]
2746,2746,336,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438631,1697122442468,120,,,"[119, 2652]","[1697122438750, 1697122441402]"
2747,2747,759,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445121,1697122446846,120,,,[30],[1697122445151]
2748,2748,845,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431570,1697122433671,120,,,[167],[1697122431737]
2749,2749,74,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432506,1697122435153,120,,,[48],[1697122432554]
2750,2750,420,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446851,1697122448793,120,,,[47],[1697122446898]
2751,2751,187,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448795,1697122449780,120,,,[23],[1697122448818]
2752,2752,548,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436787,1697122438625,120,,,"[50, 1769]","[1697122436837, 1697122438606]"
2753,2753,777,47,[],200,llama-7b,64,1,1967.0,1.0,1,A10,1697122449785,1697122451752,120,9.0,1.0,"[67, 1900]","[1697122449852, 1697122451752]"
2754,2754,322,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438631,1697122440578,120,,,"[42, 1769]","[1697122438673, 1697122440442]"
2755,2755,550,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451755,1697122458094,120,,,"[16, 1068, 1025, 1096, 1020, 1065]","[1697122451771, 1697122452839, 1697122453864, 1697122454960, 1697122455980, 1697122457045]"
2756,2756,803,54,[],200,llama-7b,64,1,1017.0,1.0,1,A10,1697122456995,1697122458012,120,20.0,1.0,"[42, 975]","[1697122457037, 1697122458012]"
2757,2757,919,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442475,1697122445116,120,,,[9],[1697122442484]
2758,2758,505,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433678,1697122436784,120,,,[84],[1697122433762]
2759,2759,467,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458015,1697122466987,120,,,"[25, 716, 1250, 1285, 1433, 1296, 927, 1438]","[1697122458040, 1697122458756, 1697122460006, 1697122461291, 1697122462724, 1697122464020, 1697122464947, 1697122466385]"
2760,2760,657,43,[],200,llama-7b,64,1,2705.0,1.0,1,A10,1697122435161,1697122437866,120,10.0,1.0,"[106, 2599]","[1697122435267, 1697122437866]"
2761,2761,699,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445123,1697122446847,120,,,[48],[1697122445171]
2762,2762,275,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436788,1697122438626,120,,,"[62, 1756]","[1697122436850, 1697122438606]"
2763,2763,337,38,[],200,llama-7b,64,1,2243.0,1.0,1,A10,1697122426585,1697122428828,120,12.0,1.0,"[167, 2076]","[1697122426752, 1697122428828]"
2764,2764,308,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412994,1697122415032,120,,,"[53, 1816]","[1697122413047, 1697122414863]"
2765,2765,79,28,[],200,llama-7b,64,1,2310.0,1.0,1,A10,1697122415039,1697122417349,120,12.0,1.0,"[104, 2206]","[1697122415143, 1697122417349]"
2766,2766,355,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446852,1697122448792,120,,,[41],[1697122446893]
2767,2767,206,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458102,1697122459962,120,,,[78],[1697122458180]
2768,2768,859,38,[],200,llama-7b,64,1,2769.0,1.0,1,A10,1697122438634,1697122441403,120,23.0,1.0,"[155, 2614]","[1697122438789, 1697122441403]"
2769,2769,278,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424979,1697122426575,120,,,[52],[1697122425031]
2770,2770,323,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410674,1697122412984,120,,,[37],[1697122410711]
2771,2771,383,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122403117,1697122405697,120,,,[18],[1697122403135]
2772,2772,607,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122441407,1697122443687,120,,,[17],[1697122441424]
2773,2773,92,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412993,1697122415032,120,,,"[45, 1826]","[1697122413038, 1697122414864]"
2774,2774,863,40,[],200,llama-7b,64,1,2246.0,1.0,1,A10,1697122426582,1697122428828,120,10.0,1.0,"[150, 2096]","[1697122426732, 1697122428828]"
2775,2775,883,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459967,1697122461247,120,,,[38],[1697122460005]
2776,2776,544,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407064,1697122409609,120,,,[89],[1697122407153]
2777,2777,682,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415037,1697122418474,120,,,"[48, 2264]","[1697122415085, 1697122417349]"
2778,2778,612,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122428831,1697122432499,120,,,"[23, 1487, 1270]","[1697122428854, 1697122430341, 1697122431611]"
2779,2779,202,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458098,1697122459962,120,,,[54],[1697122458152]
2780,2780,361,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435156,1697122438625,120,,,"[41, 2668]","[1697122435197, 1697122437865]"
2781,2781,322,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409612,1697122411707,120,,,[49],[1697122409661]
2782,2782,536,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461249,1697122462681,120,,,[30],[1697122461279]
2783,2783,314,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458100,1697122459962,120,,,[55],[1697122458155]
2784,2784,86,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459964,1697122461247,120,,,[16],[1697122459980]
2785,2785,454,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418482,1697122421735,120,,,[153],[1697122418635]
2786,2786,632,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445121,1697122446846,120,,,[25],[1697122445146]
2787,2787,313,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462685,1697122464904,120,,,[49],[1697122462734]
2788,2788,110,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421737,1697122424990,120,,,"[43, 2332, 88]","[1697122421780, 1697122424112, 1697122424200]"
2789,2789,785,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459968,1697122462680,120,,,[88],[1697122460056]
2790,2790,378,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446850,1697122448793,120,,,[29],[1697122446879]
2791,2791,558,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462685,1697122464904,120,,,[59],[1697122462744]
2792,2792,907,34,[],200,llama-7b,64,1,2187.0,1.0,1,A10,1697122411711,1697122413898,120,10.0,1.0,"[10, 2177]","[1697122411721, 1697122413898]"
2793,2793,893,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464906,1697122466343,120,,,[15],[1697122464921]
2794,2794,32,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448797,1697122450711,120,,,[55],[1697122448852]
2795,2795,443,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402614,1697122404421,120,,,[42],[1697122402656]
2796,2796,733,42,[],200,llama-7b,64,1,1037.0,1.0,1,A10,1697122450715,1697122451752,120,31.0,1.0,"[46, 991]","[1697122450761, 1697122451752]"
2797,2797,28,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449783,1697122450712,120,,,[7],[1697122449790]
2798,2798,366,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415037,1697122418474,120,,,"[44, 2267]","[1697122415081, 1697122417348]"
2799,2799,668,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461249,1697122462681,120,,,[35],[1697122461284]
2800,2800,445,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462683,1697122463975,120,,,[20],[1697122462703]
2801,2801,210,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404425,1697122405696,120,,,[20],[1697122404445]
2802,2802,800,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405699,1697122407058,120,,,[36],[1697122405735]
2803,2803,570,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407065,1697122409610,120,,,[93],[1697122407158]
2804,2804,96,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463980,1697122466343,120,,,[77],[1697122464057]
2805,2805,905,43,[],200,llama-7b,64,1,1790.0,1.0,1,A10,1697122440584,1697122442374,120,11.0,1.0,"[55, 1735]","[1697122440639, 1697122442374]"
2806,2806,685,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122413901,1697122416373,120,,,[11],[1697122413912]
2807,2807,229,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409616,1697122411708,120,,,[133],[1697122409749]
2808,2808,685,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442377,1697122443687,120,,,[25],[1697122442402]
2809,2809,529,34,[],200,llama-7b,64,1,1990.0,1.0,1,A10,1697122427737,1697122429727,120,10.0,1.0,"[34, 1956]","[1697122427771, 1697122429727]"
2810,2810,19,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418477,1697122420380,120,,,[25],[1697122418502]
2811,2811,464,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458103,1697122461247,120,,,[151],[1697122458254]
2812,2812,696,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420384,1697122421736,120,,,[30],[1697122420414]
2813,2813,260,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122443690,1697122451943,120,,,"[23, 2372, 815, 975, 970, 987, 930]","[1697122443713, 1697122446085, 1697122446900, 1697122447875, 1697122448845, 1697122449832, 1697122450762]"
2814,2814,668,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122417352,1697122424991,120,,,"[11, 1600, 1457, 1353, 1424, 1002]","[1697122417363, 1697122418963, 1697122420420, 1697122421773, 1697122423197, 1697122424199]"
2815,2815,109,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122428831,1697122432498,120,,,"[38, 1472, 1271]","[1697122428869, 1697122430341, 1697122431612]"
2816,2816,810,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122399550,1697122400951,120,,,[30],[1697122399580]
2817,2817,351,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421737,1697122423159,120,,,[28],[1697122421765]
2818,2818,16,33,[],200,llama-7b,64,1,1809.0,1.0,1,A10,1697122438633,1697122440442,120,9.0,1.0,"[137, 1672]","[1697122438770, 1697122440442]"
2819,2819,39,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405701,1697122408127,120,,,[65],[1697122405766]
2820,2820,715,34,[],200,llama-7b,64,1,958.0,1.0,1,A10,1697122440446,1697122441404,120,20.0,1.0,"[24, 933]","[1697122440470, 1697122441403]"
2821,2821,125,29,[],200,llama-7b,64,1,1810.0,1.0,1,A10,1697122423164,1697122424974,120,13.0,1.0,"[101, 1708]","[1697122423265, 1697122424973]"
2822,2822,715,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424977,1697122426578,120,,,[31],[1697122425008]
2823,2823,737,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408130,1697122410670,120,,,"[52, 2355]","[1697122408182, 1697122410537]"
2824,2824,702,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432507,1697122435151,120,,,[56],[1697122432563]
2825,2825,817,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424994,1697122426575,120,,,[82],[1697122425076]
2826,2826,472,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435158,1697122438625,120,,,"[82, 2625]","[1697122435240, 1697122437865]"
2827,2827,393,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410673,1697122412985,120,,,[16],[1697122410689]
2828,2828,831,36,[],200,llama-7b,64,1,1940.0,1.0,1,A10,1697122416377,1697122418317,120,11.0,1.0,"[53, 1887]","[1697122416430, 1697122418317]"
2829,2829,273,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409614,1697122411707,120,,,[130],[1697122409744]
2830,2830,468,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426581,1697122429746,120,,,"[80, 2168, 59]","[1697122426661, 1697122428829, 1697122428888]"
2831,2831,11,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122443690,1697122451944,120,,,"[38, 2357, 815, 976, 969, 987, 931]","[1697122443728, 1697122446085, 1697122446900, 1697122447876, 1697122448845, 1697122449832, 1697122450763]"
2832,2832,170,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412990,1697122415032,120,,,"[32, 1841]","[1697122413022, 1697122414863]"
2833,2833,579,37,[],200,llama-7b,64,1,642.0,1.0,1,A10,1697122418322,1697122418964,120,19.0,1.0,"[17, 624]","[1697122418339, 1697122418963]"
2834,2834,245,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429749,1697122431564,120,,,[8],[1697122429757]
2835,2835,753,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415035,1697122418473,120,,,"[16, 2298]","[1697122415051, 1697122417349]"
2836,2836,217,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438632,1697122442470,120,,,"[142, 2629]","[1697122438774, 1697122441403]"
2837,2837,827,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431569,1697122433672,120,,,[100],[1697122431669]
2838,2838,232,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418966,1697122421735,120,,,[11],[1697122418977]
2839,2839,307,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420388,1697122423159,120,,,[96],[1697122420484]
2840,2840,599,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433679,1697122436784,120,,,[87],[1697122433766]
2841,2841,39,36,[],200,llama-7b,64,1,2187.0,1.0,1,A10,1697122411712,1697122413899,120,8.0,1.0,"[46, 2141]","[1697122411758, 1697122413899]"
2842,2842,500,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418477,1697122420380,120,,,[30],[1697122418507]
2843,2843,712,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451946,1697122453809,120,,,[7],[1697122451953]
2844,2844,336,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416377,1697122418473,120,,,"[68, 1872]","[1697122416445, 1697122418317]"
2845,2845,373,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453816,1697122455928,120,,,[57],[1697122453873]
2846,2846,80,35,[],200,llama-7b,64,1,1807.0,1.0,1,A10,1697122423167,1697122424974,120,13.0,1.0,"[170, 1637]","[1697122423337, 1697122424974]"
2847,2847,188,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429730,1697122432498,120,,,"[11, 600, 1271]","[1697122429741, 1697122430341, 1697122431612]"
2848,2848,3,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421738,1697122424991,120,,,"[54, 2320, 88]","[1697122421792, 1697122424112, 1697122424200]"
2849,2849,743,52,[],200,llama-7b,64,1,6934.0,1.0,1,A10,1697122458014,1697122464948,120,123.0,6.0,"[17, 725, 1250, 1285, 1433, 1295, 929]","[1697122458031, 1697122458756, 1697122460006, 1697122461291, 1697122462724, 1697122464019, 1697122464948]"
2850,2850,262,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410674,1697122412984,120,,,[83],[1697122410757]
2851,2851,231,36,[],200,llama-7b,64,1,1815.0,1.0,1,A10,1697122436792,1697122438607,120,13.0,1.0,"[144, 1670]","[1697122436936, 1697122438606]"
2852,2852,925,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438609,1697122440578,120,,,"[7, 775]","[1697122438616, 1697122439391]"
2853,2853,145,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455930,1697122458092,120,,,"[52, 2029]","[1697122455982, 1697122458011]"
2854,2854,586,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440588,1697122442469,120,,,"[27, 1758]","[1697122440615, 1697122442373]"
2855,2855,665,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424975,1697122426577,120,,,[18],[1697122424993]
2856,2856,518,53,[],200,llama-7b,64,1,2020.0,1.0,1,A10,1697122464950,1697122466970,120,23.0,1.0,"[32, 1988]","[1697122464982, 1697122466970]"
2857,2857,37,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412997,1697122416372,120,,,[80],[1697122413077]
2858,2858,152,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420384,1697122423159,120,,,[41],[1697122420425]
2859,2859,620,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122416377,1697122418472,120,,,"[13, 1926]","[1697122416390, 1697122418316]"
2860,2860,727,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458097,1697122459961,120,,,[28],[1697122458125]
2861,2861,6,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122411711,1697122415032,120,,,[37],[1697122411748]
2862,2862,367,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418477,1697122420381,120,,,[58],[1697122418535]
2863,2863,354,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442475,1697122445117,120,,,[33],[1697122442508]
2864,2864,588,29,[],200,llama-7b,64,1,2311.0,1.0,1,A10,1697122415039,1697122417350,120,11.0,1.0,"[109, 2202]","[1697122415148, 1697122417350]"
2865,2865,137,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420384,1697122423159,120,,,[46],[1697122420430]
2866,2866,593,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424995,1697122426575,120,,,[141],[1697122425136]
2867,2867,886,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432507,1697122435151,120,,,[57],[1697122432564]
2868,2868,475,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459965,1697122461247,120,,,[35],[1697122460000]
2869,2869,362,41,[],200,llama-7b,64,1,2248.0,1.0,1,A10,1697122426581,1697122428829,120,14.0,1.0,"[85, 2162]","[1697122426666, 1697122428828]"
2870,2870,15,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445123,1697122446847,120,,,[48],[1697122445171]
2871,2871,244,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461252,1697122463977,120,,,[104],[1697122461356]
2872,2872,713,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446851,1697122448793,120,,,[43],[1697122446894]
2873,2873,725,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423163,1697122424991,120,,,"[86, 1724]","[1697122423249, 1697122424973]"
2874,2874,369,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448795,1697122449780,120,,,[18],[1697122448813]
2875,2875,548,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435156,1697122438625,120,,,"[36, 2673]","[1697122435192, 1697122437865]"
2876,2876,494,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424995,1697122426576,120,,,[146],[1697122425141]
2877,2877,334,30,[],200,llama-7b,64,1,1608.0,1.0,1,A10,1697122417356,1697122418964,120,15.0,1.0,"[25, 1583]","[1697122417381, 1697122418964]"
2878,2878,833,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463979,1697122466343,120,,,[48],[1697122464027]
2879,2879,24,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122428833,1697122432498,120,,,"[46, 2733]","[1697122428879, 1697122431612]"
2880,2880,155,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426581,1697122427730,120,,,"[24, 1046]","[1697122426605, 1697122427651]"
2881,2881,437,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454910,1697122456992,120,,,[63],[1697122454973]
2882,2882,917,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418967,1697122421735,120,,,[34],[1697122419001]
2883,2883,124,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448795,1697122449780,120,,,[11],[1697122448806]
2884,2884,210,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464907,1697122466344,120,,,[15],[1697122464922]
2885,2885,611,47,[],200,llama-7b,64,1,1039.0,1.0,1,A10,1697122450713,1697122451752,120,14.0,1.0,"[6, 1033]","[1697122450719, 1697122451752]"
2886,2886,434,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122437869,1697122440578,120,,,"[19, 1503]","[1697122437888, 1697122439391]"
2887,2887,714,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449784,1697122450712,120,,,[28],[1697122449812]
2888,2888,442,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426585,1697122429746,120,,,"[152, 2091, 60]","[1697122426737, 1697122428828, 1697122428888]"
2889,2889,0,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405701,1697122408127,120,,,[74],[1697122405775]
2890,2890,861,34,[],200,llama-7b,64,1,1811.0,1.0,1,A10,1697122423163,1697122424974,120,10.0,1.0,"[91, 1720]","[1697122423254, 1697122424974]"
2891,2891,22,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445124,1697122447824,120,,,[147],[1697122445271]
2892,2892,85,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440589,1697122442470,120,,,"[50, 1735]","[1697122440639, 1697122442374]"
2893,2893,585,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400957,1697122402608,120,,,"[22, 674, 112]","[1697122400979, 1697122401653, 1697122401765]"
2894,2894,341,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122443690,1697122451943,120,,,"[18, 2377, 815, 975, 969, 988, 930]","[1697122443708, 1697122446085, 1697122446900, 1697122447875, 1697122448844, 1697122449832, 1697122450762]"
2895,2895,95,38,[],200,llama-7b,64,1,2665.0,1.0,1,A10,1697122429752,1697122432417,120,12.0,1.0,"[195, 2470]","[1697122429947, 1697122432417]"
2896,2896,309,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122427737,1697122429746,120,,,"[31, 1958]","[1697122427768, 1697122429726]"
2897,2897,242,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402613,1697122404422,120,,,[33],[1697122402646]
2898,2898,19,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404427,1697122407057,120,,,[53],[1697122404480]
2899,2899,898,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429749,1697122431564,120,,,[100],[1697122429849]
2900,2900,603,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407066,1697122409609,120,,,[163],[1697122407229]
2901,2901,110,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451948,1697122453809,120,,,[20],[1697122451968]
2902,2902,374,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409611,1697122410669,120,,,"[25, 900]","[1697122409636, 1697122410536]"
2903,2903,34,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410673,1697122412985,120,,,[22],[1697122410695]
2904,2904,787,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453812,1697122455926,120,,,[14],[1697122453826]
2905,2905,638,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442476,1697122445118,120,,,[33],[1697122442509]
2906,2906,694,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122421738,1697122423159,120,,,[34],[1697122421772]
2907,2907,90,47,[],200,llama-7b,64,1,1758.0,1.0,1,A10,1697122456998,1697122458756,120,19.0,1.0,"[71, 1687]","[1697122457069, 1697122458756]"
2908,2908,439,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455929,1697122456992,120,,,[23],[1697122455952]
2909,2909,349,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423162,1697122424992,120,,,"[37, 1774]","[1697122423199, 1697122424973]"
2910,2910,376,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122441408,1697122443687,120,,,[25],[1697122441433]
2911,2911,147,36,[],200,llama-7b,64,1,2396.0,1.0,1,A10,1697122443690,1697122446086,120,182.0,1.0,"[33, 2362]","[1697122443723, 1697122446085]"
2912,2912,36,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451948,1697122453810,120,,,[25],[1697122451973]
2913,2913,215,49,[],200,llama-7b,64,1,1017.0,1.0,1,A10,1697122456995,1697122458012,120,12.0,1.0,"[47, 970]","[1697122457042, 1697122458012]"
2914,2914,614,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453815,1697122454906,120,,,[48],[1697122453863]
2915,2915,798,50,[],200,llama-7b,64,1,6933.0,1.0,1,A10,1697122458015,1697122464948,120,79.0,6.0,"[26, 1965, 1285, 1433, 1296, 928]","[1697122458041, 1697122460006, 1697122461291, 1697122462724, 1697122464020, 1697122464948]"
2916,2916,730,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446092,1697122447823,120,,,[17],[1697122446109]
2917,2917,146,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449784,1697122451944,120,,,"[45, 1922]","[1697122449829, 1697122451751]"
2918,2918,391,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454909,1697122456991,120,,,[44],[1697122454953]
2919,2919,566,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464951,1697122466986,120,,,"[34, 1985]","[1697122464985, 1697122466970]"
2920,2920,506,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447828,1697122449780,120,,,[62],[1697122447890]
2921,2921,47,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122456994,1697122458093,120,,,"[20, 997]","[1697122457014, 1697122458011]"
2922,2922,800,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442478,1697122445117,120,,,[72],[1697122442550]
2923,2923,731,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451952,1697122454907,120,,,[92],[1697122452044]
2924,2924,158,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449783,1697122450711,120,,,[18],[1697122449801]
2925,2925,838,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122450714,1697122458092,120,,,"[20, 2105, 1025, 1095, 1021, 1064]","[1697122450734, 1697122452839, 1697122453864, 1697122454959, 1697122455980, 1697122457044]"
2926,2926,852,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122427736,1697122429745,120,,,"[15, 1976]","[1697122427751, 1697122429727]"
2927,2927,506,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429751,1697122431564,120,,,[113],[1697122429864]
2928,2928,745,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458102,1697122459962,120,,,[138],[1697122458240]
2929,2929,608,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458099,1697122459962,120,,,[71],[1697122458170]
2930,2930,577,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445121,1697122446846,120,,,[25],[1697122445146]
2931,2931,263,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459965,1697122461247,120,,,[25],[1697122459990]
2932,2932,705,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 847.00 MiB is free. Process 430828 has 21.15 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408129,1697122409609,120,,,[20],[1697122408149]
2933,2933,357,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.86 GiB is allocated by PyTorch, and 4.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122409613,1697122411708,120,,,[69],[1697122409682]
2934,2934,478,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454911,1697122456993,120,,,[68],[1697122454979]
2935,2935,232,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446849,1697122447824,120,,,[19],[1697122446868]
2936,2936,138,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122411712,1697122415032,120,,,"[36, 2150]","[1697122411748, 1697122413898]"
2937,2937,719,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415036,1697122418473,120,,,[35],[1697122415071]
2938,2938,247,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122457005,1697122466987,120,,,"[69, 1682, 1250, 1285, 1433, 1295, 928, 1438]","[1697122457074, 1697122458756, 1697122460006, 1697122461291, 1697122462724, 1697122464019, 1697122464947, 1697122466385]"
2939,2939,282,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431569,1697122433672,120,,,[102],[1697122431671]
2940,2940,492,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418477,1697122420380,120,,,[9],[1697122418486]
2941,2941,863,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433676,1697122436783,120,,,[30],[1697122433706]
2942,2942,791,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442477,1697122445117,120,,,[76],[1697122442553]
2943,2943,2,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447826,1697122448794,120,,,[34],[1697122447860]
2944,2944,611,43,[],200,llama-7b,64,1,1815.0,1.0,1,A10,1697122436792,1697122438607,120,14.0,1.0,"[154, 1660]","[1697122436946, 1697122438606]"
2945,2945,113,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418482,1697122420381,120,,,[148],[1697122418630]
2946,2946,587,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448798,1697122450712,120,,,[66],[1697122448864]
2947,2947,123,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420388,1697122423159,120,,,[144],[1697122420532]
2948,2948,448,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445121,1697122446847,120,,,[35],[1697122445156]
2949,2949,220,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446849,1697122447824,120,,,[24],[1697122446873]
2950,2950,357,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122450714,1697122451945,120,,,"[10, 1028]","[1697122450724, 1697122451752]"
2951,2951,822,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423163,1697122424992,120,,,"[31, 919, 87]","[1697122423194, 1697122424113, 1697122424200]"
2952,2952,263,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432510,1697122435152,120,,,[63],[1697122432573]
2953,2953,482,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426585,1697122429747,120,,,"[167, 2076, 60]","[1697122426752, 1697122428828, 1697122428888]"
2954,2954,494,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.68 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122395181,1697122396184,120,,,[48],[1697122395229]
2955,2955,695,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420386,1697122423159,120,,,[88],[1697122420474]
2956,2956,155,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122396198,1697122398323,120,,,[81],[1697122396279]
2957,2957,466,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423162,1697122424992,120,,,"[17, 934, 87]","[1697122423179, 1697122424113, 1697122424200]"
2958,2958,408,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445124,1697122447823,120,,,[124],[1697122445248]
2959,2959,733,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412996,1697122416372,120,,,[138],[1697122413134]
2960,2960,215,40,[],200,llama-7b,64,1,2656.0,1.0,1,A10,1697122424996,1697122427652,120,12.0,1.0,"[190, 2466]","[1697122425186, 1697122427652]"
2961,2961,114,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424996,1697122427731,120,,,"[243, 2412]","[1697122425239, 1697122427651]"
2962,2962,754,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122427654,1697122429747,120,,,"[9, 1225]","[1697122427663, 1697122428888]"
2963,2963,793,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122427655,1697122429747,120,,,"[19, 1215]","[1697122427674, 1697122428889]"
2964,2964,16,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451952,1697122453810,120,,,[177],[1697122452129]
2965,2965,362,32,[],200,llama-7b,64,1,2581.0,1.0,1,A10,1697122416382,1697122418963,120,14.0,1.0,"[163, 2418]","[1697122416545, 1697122418963]"
2966,2966,40,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435161,1697122438626,120,,,"[101, 2603]","[1697122435262, 1697122437865]"
2967,2967,622,44,[],200,llama-7b,64,1,1813.0,1.0,1,A10,1697122438629,1697122440442,120,20.0,1.0,"[6, 1806]","[1697122438635, 1697122440441]"
2968,2968,527,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429752,1697122432497,120,,,[189],[1697122429941]
2969,2969,394,45,[],200,llama-7b,64,1,956.0,1.0,1,A10,1697122440449,1697122441405,120,11.0,1.0,"[31, 924]","[1697122440480, 1697122441404]"
2970,2970,187,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432503,1697122435152,120,,,[31],[1697122432534]
2971,2971,55,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122441411,1697122443688,120,,,[43],[1697122441454]
2972,2972,886,43,[],200,llama-7b,64,1,2709.0,1.0,1,A10,1697122435156,1697122437865,120,17.0,1.0,"[27, 2682]","[1697122435183, 1697122437865]"
2973,2973,542,44,[],200,llama-7b,64,1,1521.0,1.0,1,A10,1697122437870,1697122439391,120,11.0,1.0,"[23, 1498]","[1697122437893, 1697122439391]"
2974,2974,310,45,[],200,llama-7b,64,1,2007.0,1.0,1,A10,1697122439396,1697122441403,120,26.0,1.0,"[19, 1988]","[1697122439415, 1697122441403]"
2975,2975,389,43,[],200,llama-7b,64,1,1084.0,1.0,1,A10,1697122451756,1697122452840,120,8.0,1.0,"[25, 1059]","[1697122451781, 1697122452840]"
2976,2976,319,38,[],200,llama-7b,64,1,1811.0,1.0,1,A10,1697122438631,1697122440442,120,31.0,1.0,"[99, 1712]","[1697122438730, 1697122440442]"
2977,2977,158,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122452845,1697122454905,120,,,[13],[1697122452858]
2978,2978,389,48,[],200,llama-7b,64,1,1085.0,1.0,1,A10,1697122451755,1697122452840,120,8.0,1.0,"[22, 1062]","[1697122451777, 1697122452839]"
2979,2979,871,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122441407,1697122443687,120,,,[31],[1697122441438]
2980,2980,515,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424981,1697122426576,120,,,[65],[1697122425046]
2981,2981,715,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453814,1697122455928,120,,,[49],[1697122453863]
2982,2982,286,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426582,1697122429745,120,,,"[64, 2242]","[1697122426646, 1697122428888]"
2983,2983,902,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440445,1697122442471,120,,,"[20, 938]","[1697122440465, 1697122441403]"
2984,2984,876,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429751,1697122431564,120,,,[122],[1697122429873]
2985,2985,347,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455933,1697122458093,120,,,[110],[1697122456043]
2986,2986,646,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431571,1697122433671,120,,,[173],[1697122431744]
2987,2987,675,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442478,1697122445117,120,,,[77],[1697122442555]
2988,2988,42,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122452845,1697122454905,120,,,[20],[1697122452865]
2989,2989,748,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454907,1697122455926,120,,,[16],[1697122454923]
2990,2990,743,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454909,1697122456991,120,,,[35],[1697122454944]
2991,2991,771,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432420,1697122433672,120,,,[20],[1697122432440]
2992,2992,304,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433677,1697122436782,120,,,[30],[1697122433707]
2993,2993,518,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455930,1697122456993,120,,,[47],[1697122455977]
2994,2994,326,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445121,1697122446847,120,,,[40],[1697122445161]
2995,2995,74,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436787,1697122438625,120,,,"[22, 1797]","[1697122436809, 1697122438606]"
2996,2996,640,47,[],200,llama-7b,64,1,2391.0,1.0,1,A10,1697122443695,1697122446086,120,15.0,1.0,"[72, 2319]","[1697122443767, 1697122446086]"
2997,2997,728,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447829,1697122449781,120,,,[126],[1697122447955]
2998,2998,296,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446094,1697122447823,120,,,[20],[1697122446114]
2999,2999,540,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433681,1697122436783,120,,,[157],[1697122433838]
3000,3000,380,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449785,1697122451945,120,,,[74],[1697122449859]
3001,3001,200,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436791,1697122438626,120,,,"[140, 1676]","[1697122436931, 1697122438607]"
3002,3002,156,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451949,1697122454906,120,,,[90],[1697122452039]
3003,3003,899,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438631,1697122440578,120,,,"[47, 1764]","[1697122438678, 1697122440442]"
3004,3004,73,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447827,1697122449782,120,,,[48],[1697122447875]
3005,3005,739,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454908,1697122455927,120,,,[25],[1697122454933]
3006,3006,74,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446851,1697122448792,120,,,[33],[1697122446884]
3007,3007,655,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449786,1697122451945,120,,,"[81, 1885]","[1697122449867, 1697122451752]"
3008,3008,747,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438630,1697122440578,120,,,"[38, 1774]","[1697122438668, 1697122440442]"
3009,3009,176,47,[],200,llama-7b,64,1,3009.0,1.0,1,A10,1697122456997,1697122460006,120,216.0,2.0,"[67, 2942]","[1697122457064, 1697122460006]"
3010,3010,403,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440588,1697122443687,120,,,[71],[1697122440659]
3011,3011,897,17,[],200,llama-7b,64,1,1242.0,1.0,1,A10,1697122375942,1697122377184,120,9.0,1.0,"[34, 1208]","[1697122375976, 1697122377184]"
3012,3012,507,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455930,1697122458094,120,,,"[52, 2029]","[1697122455982, 1697122458011]"
3013,3013,875,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122460008,1697122462680,120,,,[68],[1697122460076]
3014,3014,172,43,[],200,llama-7b,64,1,2394.0,1.0,1,A10,1697122443692,1697122446086,120,19.0,1.0,"[56, 2337]","[1697122443748, 1697122446085]"
3015,3015,482,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424996,1697122427730,120,,,"[174, 2481]","[1697122425170, 1697122427651]"
3016,3016,255,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458103,1697122461247,120,,,[147],[1697122458250]
3017,3017,762,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446091,1697122447823,120,,,[12],[1697122446103]
3018,3018,233,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461248,1697122462680,120,,,[16],[1697122461264]
3019,3019,490,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122456994,1697122458093,120,,,"[25, 992]","[1697122457019, 1697122458011]"
3020,3020,626,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462684,1697122463975,120,,,[24],[1697122462708]
3021,3021,823,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462682,1697122463977,120,,,[7],[1697122462689]
3022,3022,282,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463977,1697122464904,120,,,[11],[1697122463988]
3023,3023,594,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463982,1697122466344,120,,,[88],[1697122464070]
3024,3024,623,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122413901,1697122416374,120,,,[20],[1697122413921]
3025,3025,51,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464907,1697122466986,120,,,"[30, 2033]","[1697122464937, 1697122466970]"
3026,3026,371,38,[],200,llama-7b,64,1,1935.0,1.0,1,A10,1697122416382,1697122418317,120,13.0,1.0,"[93, 1842]","[1697122416475, 1697122418317]"
3027,3027,837,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461252,1697122463976,120,,,[95],[1697122461347]
3028,3028,69,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447826,1697122448794,120,,,[15],[1697122447841]
3029,3029,25,39,[],200,llama-7b,64,1,644.0,1.0,1,A10,1697122418320,1697122418964,120,12.0,1.0,"[14, 629]","[1697122418334, 1697122418963]"
3030,3030,717,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432509,1697122435152,120,,,[69],[1697122432578]
3031,3031,482,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122450715,1697122458093,120,,,"[51, 2073, 1025, 1096, 1021, 1064]","[1697122450766, 1697122452839, 1697122453864, 1697122454960, 1697122455981, 1697122457045]"
3032,3032,791,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458760,1697122461248,120,,,[26],[1697122458786]
3033,3033,763,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448797,1697122450711,120,,,[52],[1697122448849]
3034,3034,423,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122450714,1697122458092,120,,,"[25, 2100, 1025, 1095, 1021, 1065]","[1697122450739, 1697122452839, 1697122453864, 1697122454959, 1697122455980, 1697122457045]"
3035,3035,612,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463979,1697122466343,120,,,[43],[1697122464022]
3036,3036,705,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122427737,1697122429746,120,,,[39],[1697122427776]
3037,3037,41,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461249,1697122462680,120,,,[20],[1697122461269]
3038,3038,434,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451949,1697122453810,120,,,[39],[1697122451988]
3039,3039,623,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462682,1697122463975,120,,,[21],[1697122462703]
3040,3040,192,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458098,1697122459962,120,,,[50],[1697122458148]
3041,3041,729,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418967,1697122421735,120,,,[29],[1697122418996]
3042,3042,474,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429751,1697122431565,120,,,[128],[1697122429879]
3043,3043,398,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463977,1697122464904,120,,,[13],[1697122463990]
3044,3044,782,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459967,1697122462680,120,,,[79],[1697122460046]
3045,3045,133,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431569,1697122433672,120,,,[97],[1697122431666]
3046,3046,383,41,[],200,llama-7b,64,1,2374.0,1.0,1,A10,1697122421738,1697122424112,120,15.0,1.0,"[47, 2327]","[1697122421785, 1697122424112]"
3047,3047,670,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431569,1697122433671,120,,,[92],[1697122431661]
3048,3048,323,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433679,1697122436783,120,,,[93],[1697122433772]
3049,3049,71,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436787,1697122438625,120,,,"[32, 1787]","[1697122436819, 1697122438606]"
3050,3050,553,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462683,1697122463975,120,,,[10],[1697122462693]
3051,3051,51,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464906,1697122466343,120,,,[7],[1697122464913]
3052,3052,771,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438631,1697122440578,120,,,"[99, 1711]","[1697122438730, 1697122440441]"
3053,3053,144,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458098,1697122459962,120,,,[59],[1697122458157]
3054,3054,556,18,[],200,llama-7b,64,1,1732.0,1.0,1,A10,1697122377188,1697122378920,120,9.0,1.0,"[7, 1724]","[1697122377195, 1697122378919]"
3055,3055,754,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122443695,1697122451945,120,,,"[73, 3133, 975, 969, 987, 931]","[1697122443768, 1697122446901, 1697122447876, 1697122448845, 1697122449832, 1697122450763]"
3056,3056,853,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 4.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122398327,1697122400951,120,,,[116],[1697122398443]
3057,3057,432,42,[],200,llama-7b,64,1,1788.0,1.0,1,A10,1697122440586,1697122442374,120,13.0,1.0,"[48, 1740]","[1697122440634, 1697122442374]"
3058,3058,207,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463979,1697122464905,120,,,[32],[1697122464011]
3059,3059,848,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459967,1697122462680,120,,,[64],[1697122460031]
3060,3060,373,44,[],200,llama-7b,64,1,1781.0,1.0,1,A10,1697122440592,1697122442373,120,15.0,1.0,"[28, 1753]","[1697122440620, 1697122442373]"
3061,3061,378,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435155,1697122438624,120,,,[12],[1697122435167]
3062,3062,884,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464908,1697122466987,120,,,"[48, 2014]","[1697122464956, 1697122466970]"
3063,3063,406,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459966,1697122462680,120,,,[67],[1697122460033]
3064,3064,497,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462684,1697122464905,120,,,[39],[1697122462723]
3065,3065,202,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442377,1697122443688,120,,,[30],[1697122442407]
3066,3066,786,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122443691,1697122451944,120,,,"[47, 2348, 814, 975, 970, 987, 931]","[1697122443738, 1697122446086, 1697122446900, 1697122447875, 1697122448845, 1697122449832, 1697122450763]"
3067,3067,809,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447828,1697122449781,120,,,[38],[1697122447866]
3068,3068,148,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442376,1697122443687,120,,,[21],[1697122442397]
3069,3069,579,50,[],200,llama-7b,64,1,1965.0,1.0,1,A10,1697122449787,1697122451752,120,19.0,1.0,"[85, 1879]","[1697122449872, 1697122451751]"
3070,3070,731,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122443691,1697122451943,120,,,"[27, 2367, 815, 976, 969, 987, 931]","[1697122443718, 1697122446085, 1697122446900, 1697122447876, 1697122448845, 1697122449832, 1697122450763]"
3071,3071,264,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438609,1697122440578,120,,,"[7, 775]","[1697122438616, 1697122439391]"
3072,3072,275,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464908,1697122466987,120,,,"[34, 2027]","[1697122464942, 1697122466969]"
3073,3073,36,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440588,1697122442468,120,,,"[22, 1763]","[1697122440610, 1697122442373]"
3074,3074,175,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462683,1697122464905,120,,,[35],[1697122462718]
3075,3075,629,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442482,1697122445116,120,,,[158],[1697122442640]
3076,3076,851,48,[],200,llama-7b,64,1,2060.0,1.0,1,A10,1697122464910,1697122466970,120,23.0,1.0,"[70, 1990]","[1697122464980, 1697122466970]"
3077,3077,409,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451951,1697122454905,120,,,[107],[1697122452058]
3078,3078,325,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451755,1697122458094,120,,,"[11, 1073, 1025, 1096, 1020, 1065]","[1697122451766, 1697122452839, 1697122453864, 1697122454960, 1697122455980, 1697122457045]"
3079,3079,398,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445121,1697122446846,120,,,[20],[1697122445141]
3080,3080,251,30,[],200,llama-7b,64,1,1993.0,1.0,1,A10,1697122427734,1697122429727,120,31.0,1.0,"[8, 1985]","[1697122427742, 1697122429727]"
3081,3081,113,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458102,1697122459963,120,,,[65],[1697122458167]
3082,3082,178,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454912,1697122456993,120,,,[72],[1697122454984]
3083,3083,812,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459969,1697122462680,120,,,[103],[1697122460072]
3084,3084,563,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451949,1697122453811,120,,,[34],[1697122451983]
3085,3085,159,42,[],200,llama-7b,64,1,857.0,1.0,1,A10,1697122424118,1697122424975,120,31.0,1.0,"[21, 835]","[1697122424139, 1697122424974]"
3086,3086,568,42,[],200,llama-7b,64,1,2664.0,1.0,1,A10,1697122429753,1697122432417,120,11.0,1.0,"[193, 2471]","[1697122429946, 1697122432417]"
3087,3087,128,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418968,1697122421735,120,,,[43],[1697122419011]
3088,3088,216,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453815,1697122455928,120,,,[58],[1697122453873]
3089,3089,718,34,[],200,llama-7b,64,1,2374.0,1.0,1,A10,1697122421739,1697122424113,120,13.0,1.0,"[97, 2277]","[1697122421836, 1697122424113]"
3090,3090,464,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462687,1697122464905,120,,,[72],[1697122462759]
3091,3091,836,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429730,1697122431563,120,,,[22],[1697122429752]
3092,3092,747,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424980,1697122426576,120,,,[61],[1697122425041]
3093,3093,329,19,[],200,llama-7b,64,1,2007.0,1.0,1,A10,1697122378927,1697122380934,120,15.0,1.0,"[22, 1984]","[1697122378949, 1697122380933]"
3094,3094,489,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424118,1697122424992,120,,,[22],[1697122424140]
3095,3095,855,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122456996,1697122466987,120,,,"[56, 1704, 1250, 1284, 1434, 1295, 928, 1438]","[1697122457052, 1697122458756, 1697122460006, 1697122461290, 1697122462724, 1697122464019, 1697122464947, 1697122466385]"
3096,3096,517,44,[],200,llama-7b,64,1,2246.0,1.0,1,A10,1697122426582,1697122428828,120,15.0,1.0,"[39, 2207]","[1697122426621, 1697122428828]"
3097,3097,177,45,[],200,llama-7b,64,1,897.0,1.0,1,A10,1697122428830,1697122429727,120,14.0,1.0,"[12, 885]","[1697122428842, 1697122429727]"
3098,3098,57,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446851,1697122447824,120,,,[37],[1697122446888]
3099,3099,241,51,[],200,llama-7b,64,1,2062.0,1.0,1,A10,1697122464908,1697122466970,120,19.0,1.0,"[49, 2013]","[1697122464957, 1697122466970]"
3100,3100,756,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447825,1697122448794,120,,,[6],[1697122447831]
3101,3101,831,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433681,1697122436783,120,,,[151],[1697122433832]
3102,3102,874,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429731,1697122431564,120,,,[29],[1697122429760]
3103,3103,417,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448797,1697122450711,120,,,[57],[1697122448854]
3104,3104,530,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447828,1697122449781,120,,,[108],[1697122447936]
3105,3105,189,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122450714,1697122451945,120,,,"[15, 1023]","[1697122450729, 1697122451752]"
3106,3106,771,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451948,1697122453809,120,,,[10],[1697122451958]
3107,3107,579,39,[],200,llama-7b,64,1,1817.0,1.0,1,A10,1697122436790,1697122438607,120,19.0,1.0,"[85, 1732]","[1697122436875, 1697122438607]"
3108,3108,514,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453812,1697122455926,120,,,[21],[1697122453833]
3109,3109,190,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449784,1697122451945,120,,,"[38, 1929]","[1697122449822, 1697122451751]"
3110,3110,284,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455929,1697122456992,120,,,[33],[1697122455962]
3111,3111,234,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438610,1697122440576,120,,,"[16, 1815]","[1697122438626, 1697122440441]"
3112,3112,889,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451952,1697122454905,120,,,[121],[1697122452073]
3113,3113,921,47,[],200,llama-7b,64,1,2081.0,1.0,1,A10,1697122455932,1697122458013,120,31.0,1.0,"[101, 1979]","[1697122456033, 1697122458012]"
3114,3114,872,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122456995,1697122458094,120,,,"[39, 978]","[1697122457034, 1697122458012]"
3115,3115,548,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454910,1697122456991,120,,,[49],[1697122454959]
3116,3116,642,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458102,1697122461246,120,,,[133],[1697122458235]
3117,3117,325,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122456994,1697122458094,120,,,"[30, 988]","[1697122457024, 1697122458012]"
3118,3118,5,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440587,1697122442469,120,,,"[42, 1744]","[1697122440629, 1697122442373]"
3119,3119,570,48,[],200,llama-7b,64,1,738.0,1.0,1,A10,1697122458018,1697122458756,120,18.0,1.0,"[38, 700]","[1697122458056, 1697122458756]"
3120,3120,598,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442476,1697122445117,120,,,[17],[1697122442493]
3121,3121,222,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432420,1697122433672,120,,,[15],[1697122432435]
3122,3122,318,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458758,1697122461247,120,,,[11],[1697122458769]
3123,3123,551,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440589,1697122442470,120,,,"[75, 1709]","[1697122440664, 1697122442373]"
3124,3124,903,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461250,1697122463976,120,,,[54],[1697122461304]
3125,3125,327,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442476,1697122445117,120,,,[27],[1697122442503]
3126,3126,302,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461248,1697122462680,120,,,[16],[1697122461264]
3127,3127,605,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431568,1697122433671,120,,,[83],[1697122431651]
3128,3128,910,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445127,1697122447824,120,,,[154],[1697122445281]
3129,3129,261,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433676,1697122436784,120,,,[12],[1697122433688]
3130,3130,451,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461250,1697122463976,120,,,[44],[1697122461294]
3131,3131,143,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424995,1697122427731,120,,,"[180, 2476]","[1697122425175, 1697122427651]"
3132,3132,928,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433681,1697122436783,120,,,[162],[1697122433843]
3133,3133,849,37,[],200,llama-7b,64,1,1990.0,1.0,1,A10,1697122427737,1697122429727,120,10.0,1.0,"[41, 1949]","[1697122427778, 1697122429727]"
3134,3134,221,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463980,1697122466344,120,,,[80],[1697122464060]
3135,3135,501,38,[],200,llama-7b,64,1,611.0,1.0,1,A10,1697122429730,1697122430341,120,19.0,1.0,"[6, 605]","[1697122429736, 1697122430341]"
3136,3136,74,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462683,1697122463977,120,,,[10],[1697122462693]
3137,3137,118,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458096,1697122459962,120,,,[20],[1697122458116]
3138,3138,701,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459968,1697122462681,120,,,[98],[1697122460066]
3139,3139,656,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463983,1697122466343,120,,,[94],[1697122464077]
3140,3140,481,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462682,1697122463975,120,,,[16],[1697122462698]
3141,3141,583,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436791,1697122440577,120,,,"[145, 2455]","[1697122436936, 1697122439391]"
3142,3142,133,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463979,1697122464905,120,,,[22],[1697122464001]
3143,3143,838,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464907,1697122466343,120,,,[9],[1697122464916]
3144,3144,353,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440590,1697122442471,120,,,"[10, 1773]","[1697122440600, 1697122442373]"
3145,3145,907,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458101,1697122459963,120,,,[59],[1697122458160]
3146,3146,479,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451946,1697122453809,120,,,[17],[1697122451963]
3147,3147,685,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459966,1697122461247,120,,,[34],[1697122460000]
3148,3148,250,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453813,1697122454906,120,,,[35],[1697122453848]
3149,3149,336,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461252,1697122463976,120,,,[95],[1697122461347]
3150,3150,833,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454908,1697122456991,120,,,[31],[1697122454939]
3151,3151,365,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445123,1697122447822,120,,,[53],[1697122445176]
3152,3152,147,45,[],200,llama-7b,64,1,1813.0,1.0,1,A10,1697122438629,1697122440442,120,182.0,1.0,"[18, 1794]","[1697122438647, 1697122440441]"
3153,3153,13,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442482,1697122445118,120,,,[88],[1697122442570]
3154,3154,613,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122456994,1697122458093,120,,,"[28, 989]","[1697122457022, 1697122458011]"
3155,3155,277,39,[],200,llama-7b,64,1,2072.0,1.0,1,A10,1697122430345,1697122432417,120,18.0,1.0,"[8, 2064]","[1697122430353, 1697122432417]"
3156,3156,622,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431567,1697122433670,120,,,[47],[1697122431614]
3157,3157,907,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458103,1697122459962,120,,,[134],[1697122458237]
3158,3158,673,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463979,1697122466342,120,,,[56],[1697122464035]
3159,3159,655,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459965,1697122461247,120,,,[10],[1697122459975]
3160,3160,860,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432420,1697122433672,120,,,[10],[1697122432430]
3161,3161,276,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433677,1697122436782,120,,,[35],[1697122433712]
3162,3162,307,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461248,1697122462680,120,,,[21],[1697122461269]
3163,3163,731,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440445,1697122442471,120,,,"[15, 943]","[1697122440460, 1697122441403]"
3164,3164,83,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462683,1697122463975,120,,,[15],[1697122462698]
3165,3165,714,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445120,1697122446847,120,,,[16],[1697122445136]
3166,3166,479,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442482,1697122445118,120,,,[148],[1697122442630]
3167,3167,346,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446849,1697122447824,120,,,[20],[1697122446869]
3168,3168,132,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445124,1697122447823,120,,,[137],[1697122445261]
3169,3169,439,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424993,1697122426576,120,,,[62],[1697122425055]
3170,3170,101,31,[],200,llama-7b,64,1,2248.0,1.0,1,A10,1697122426581,1697122428829,120,13.0,1.0,"[75, 2172]","[1697122426656, 1697122428828]"
3171,3171,635,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433676,1697122436784,120,,,[20],[1697122433696]
3172,3172,115,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447828,1697122449781,120,,,[117],[1697122447945]
3173,3173,799,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122428832,1697122432498,120,,,"[32, 1477, 1270]","[1697122428864, 1697122430341, 1697122431611]"
3174,3174,47,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436786,1697122438624,120,,,"[18, 1802]","[1697122436804, 1697122438606]"
3175,3175,685,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447825,1697122448794,120,,,[10],[1697122447835]
3176,3176,836,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447827,1697122449780,120,,,[63],[1697122447890]
3177,3177,382,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436789,1697122438626,120,,,"[71, 1747]","[1697122436860, 1697122438607]"
3178,3178,700,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449785,1697122451945,120,,,[69],[1697122449854]
3179,3179,105,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463979,1697122466342,120,,,[58],[1697122464037]
3180,3180,772,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448795,1697122449780,120,,,[17],[1697122448812]
3181,3181,595,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424980,1697122426576,120,,,[70],[1697122425050]
3182,3182,476,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451949,1697122453810,120,,,[85],[1697122452034]
3183,3183,339,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448796,1697122449780,120,,,[36],[1697122448832]
3184,3184,267,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458099,1697122459962,120,,,[76],[1697122458175]
3185,3185,86,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449784,1697122451944,120,,,"[48, 1919]","[1697122449832, 1697122451751]"
3186,3186,428,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449783,1697122450711,120,,,[14],[1697122449797]
3187,3187,493,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449784,1697122451943,120,,,"[43, 1924]","[1697122449827, 1697122451751]"
3188,3188,205,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122450714,1697122458093,120,,,"[42, 2083, 1025, 1095, 1021, 1065]","[1697122450756, 1697122452839, 1697122453864, 1697122454959, 1697122455980, 1697122457045]"
3189,3189,633,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438629,1697122440577,120,,,"[18, 1794]","[1697122438647, 1697122440441]"
3190,3190,367,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.94 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122426582,1697122429745,120,,,"[34, 2212, 60]","[1697122426616, 1697122428828, 1697122428888]"
3191,3191,130,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453814,1697122455928,120,,,[54],[1697122453868]
3192,3192,271,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451948,1697122453810,120,,,[30],[1697122451978]
3193,3193,403,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440587,1697122442469,120,,,"[42, 1744]","[1697122440629, 1697122442373]"
3194,3194,919,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122380937,1697122382784,120,,,[24],[1697122380961]
3195,3195,21,37,[],200,llama-7b,64,1,2665.0,1.0,1,A10,1697122429751,1697122432416,120,15.0,1.0,"[186, 2479]","[1697122429937, 1697122432416]"
3196,3196,671,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451949,1697122453810,120,,,[44],[1697122451993]
3197,3197,730,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432419,1697122433671,120,,,[7],[1697122432426]
3198,3198,63,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442478,1697122445117,120,,,[82],[1697122442560]
3199,3199,444,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453813,1697122455926,120,,,[19],[1697122453832]
3200,3200,835,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455931,1697122458093,120,,,"[56, 2025]","[1697122455987, 1697122458012]"
3201,3201,690,21,[],200,llama-7b,64,1,1956.0,1.0,1,A10,1697122382789,1697122384745,120,39.0,1.0,"[76, 1880]","[1697122382865, 1697122384745]"
3202,3202,344,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 16.72 GiB is allocated by PyTorch, and 4.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122384749,1697122386861,120,,,[20],[1697122384769]
3203,3203,854,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453813,1697122455927,120,,,[40],[1697122453853]
3204,3204,383,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433677,1697122436783,120,,,[61],[1697122433738]
3205,3205,104,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455929,1697122456992,120,,,[18],[1697122455947]
3206,3206,92,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacty of 21.99 GiB of which 205.00 MiB is free. Process 430828 has 21.78 GiB memory in use. Of the allocated memory 15.92 GiB is allocated by PyTorch, and 5.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122386864,1697122389101,120,,,"[80, 2074]","[1697122386944, 1697122389018]"
3207,3207,483,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458098,1697122459962,120,,,[47],[1697122458145]
3208,3208,788,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458096,1697122459961,120,,,[24],[1697122458120]
3209,3209,158,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436787,1697122438625,120,,,"[37, 1782]","[1697122436824, 1697122438606]"
3210,3210,261,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459967,1697122462680,120,,,[43],[1697122460010]
3211,3211,788,24,[],200,llama-7b,64,1,1863.0,1.0,1,A10,1697122389107,1697122390970,120,31.0,1.0,"[55, 1808]","[1697122389162, 1697122390970]"
3212,3212,568,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459965,1697122461247,120,,,[15],[1697122459980]
3213,3213,625,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455930,1697122458093,120,,,"[37, 2044]","[1697122455967, 1697122458011]"
3214,3214,449,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122390974,1697122402608,120,,,"[24, 656, 1179, 1185, 1213, 999, 1062, 1079, 1223, 1399, 772]","[1697122390998, 1697122391654, 1697122392833, 1697122394018, 1697122395231, 1697122396230, 1697122397292, 1697122398371, 1697122399594, 1697122400993, 1697122401765]"
3215,3215,843,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462684,1697122464904,120,,,[55],[1697122462739]
3216,3216,615,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464907,1697122466986,120,,,"[29, 2034]","[1697122464936, 1697122466970]"
3217,3217,801,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122456994,1697122458093,120,,,"[23, 994]","[1697122457017, 1697122458011]"
3218,3218,41,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459968,1697122462681,120,,,[93],[1697122460061]
3219,3219,285,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458096,1697122459962,120,,,[16],[1697122458112]
3220,3220,219,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461250,1697122463976,120,,,[39],[1697122461289]
3221,3221,925,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463978,1697122464905,120,,,[30],[1697122464008]
3222,3222,666,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463978,1697122464905,120,,,[25],[1697122464003]
3223,3223,483,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.65 GiB is free. Process 430828 has 20.33 GiB memory in use. Of the allocated memory 16.49 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122400958,1697122402610,120,,,"[108, 1511]","[1697122401066, 1697122402577]"
3224,3224,760,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445124,1697122447823,120,,,[132],[1697122445256]
3225,3225,578,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464907,1697122466343,120,,,[10],[1697122464917]
3226,3226,421,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447826,1697122448794,120,,,[30],[1697122447856]
3227,3227,36,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438634,1697122442470,120,,,"[198, 2571]","[1697122438832, 1697122441403]"
3228,3228,191,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448796,1697122449780,120,,,[28],[1697122448824]
3229,3229,774,56,[],200,llama-7b,64,1,1968.0,1.0,1,A10,1697122449784,1697122451752,120,8.0,1.0,"[60, 1908]","[1697122449844, 1697122451752]"
3230,3230,256,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402614,1697122404423,120,,,[59],[1697122402673]
3231,3231,87,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453813,1697122455926,120,,,[30],[1697122453843]
3232,3232,793,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455930,1697122458093,120,,,[42],[1697122455972]
3233,3233,431,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432509,1697122435152,120,,,[65],[1697122432574]
3234,3234,26,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447827,1697122448793,120,,,[24],[1697122447851]
3235,3235,523,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451754,1697122458093,120,,,"[7, 1079, 1024, 1096, 1021, 1064]","[1697122451761, 1697122452840, 1697122453864, 1697122454960, 1697122455981, 1697122457045]"
3236,3236,725,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448796,1697122449781,120,,,[46],[1697122448842]
3237,3237,203,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435156,1697122438625,120,,,"[35, 2674]","[1697122435191, 1697122437865]"
3238,3238,462,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458103,1697122461247,120,,,[144],[1697122458247]
3239,3239,380,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449785,1697122451944,120,,,[62],[1697122449847]
3240,3240,740,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442477,1697122445116,120,,,[62],[1697122442539]
3241,3241,785,35,[],200,llama-7b,64,1,1811.0,1.0,1,A10,1697122438631,1697122440442,120,10.0,1.0,"[109, 1702]","[1697122438740, 1697122440442]"
3242,3242,448,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458096,1697122459962,120,,,[9],[1697122458105]
3243,3243,143,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429751,1697122431565,120,,,[181],[1697122429932]
3244,3244,218,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459968,1697122462681,120,,,[89],[1697122460057]
3245,3245,561,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440445,1697122442471,120,,,"[20, 938]","[1697122440465, 1697122441403]"
3246,3246,895,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462685,1697122464905,120,,,[64],[1697122462749]
3247,3247,547,57,[],200,llama-7b,64,1,2060.0,1.0,1,A10,1697122464910,1697122466970,120,12.0,1.0,"[66, 1994]","[1697122464976, 1697122466970]"
3248,3248,841,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431568,1697122433670,120,,,[63],[1697122431631]
3249,3249,214,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442476,1697122445118,120,,,[42],[1697122442518]
3250,3250,915,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445124,1697122447824,120,,,[152],[1697122445276]
3251,3251,569,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447828,1697122449781,120,,,[108],[1697122447936]
3252,3252,496,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433678,1697122436784,120,,,[83],[1697122433761]
3253,3253,180,58,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458102,1697122459962,120,,,[128],[1697122458230]
3254,3254,624,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462685,1697122464905,120,,,[64],[1697122462749]
3255,3255,883,59,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459965,1697122461247,120,,,[30],[1697122459995]
3256,3256,394,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445124,1697122447823,120,,,[116],[1697122445240]
3257,3257,274,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436791,1697122440577,120,,,"[150, 2450]","[1697122436941, 1697122439391]"
3258,3258,401,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464910,1697122466987,120,,,"[67, 1993]","[1697122464977, 1697122466970]"
3259,3259,232,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461249,1697122462681,120,,,[35],[1697122461284]
3260,3260,170,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447826,1697122448794,120,,,[35],[1697122447861]
3261,3261,537,60,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461250,1697122463976,120,,,[49],[1697122461299]
3262,3262,340,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449784,1697122451944,120,,,"[50, 1917]","[1697122449834, 1697122451751]"
3263,3263,434,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464908,1697122466987,120,,,"[24, 2037]","[1697122464932, 1697122466969]"
3264,3264,755,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448798,1697122450712,120,,,[69],[1697122448867]
3265,3265,816,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462683,1697122463975,120,,,[30],[1697122462713]
3266,3266,156,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451949,1697122453810,120,,,[39],[1697122451988]
3267,3267,53,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459968,1697122462681,120,,,[99],[1697122460067]
3268,3268,739,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453813,1697122455926,120,,,[25],[1697122453838]
3269,3269,38,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436788,1697122438626,120,,,"[62, 1756]","[1697122436850, 1697122438606]"
3270,3270,521,48,[],200,llama-7b,64,1,2124.0,1.0,1,A10,1697122450716,1697122452840,120,18.0,1.0,"[60, 2064]","[1697122450776, 1697122452840]"
3271,3271,482,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455929,1697122456992,120,,,[23],[1697122455952]
3272,3272,621,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438631,1697122442469,120,,,"[129, 2643]","[1697122438760, 1697122441403]"
3273,3273,730,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462684,1697122464904,120,,,[48],[1697122462732]
3274,3274,846,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404426,1697122405697,120,,,[34],[1697122404460]
3275,3275,852,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440587,1697122442471,120,,,"[82, 1704]","[1697122440669, 1697122442373]"
3276,3276,366,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442476,1697122445117,120,,,[28],[1697122442504]
3277,3277,135,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122456994,1697122458094,120,,,"[38, 980]","[1697122457032, 1697122458012]"
3278,3278,181,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122452841,1697122454905,120,,,[19],[1697122452860]
3279,3279,136,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445127,1697122447824,120,,,[146],[1697122445273]
3280,3280,729,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447828,1697122449782,120,,,[53],[1697122447881]
3281,3281,599,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442478,1697122445118,120,,,[87],[1697122442565]
3282,3282,368,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445123,1697122447823,120,,,[58],[1697122445181]
3283,3283,501,39,[],200,llama-7b,64,1,1965.0,1.0,1,A10,1697122449787,1697122451752,120,19.0,1.0,"[97, 1868]","[1697122449884, 1697122451752]"
3284,3284,617,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122405700,1697122408127,120,,,[51],[1697122405751]
3285,3285,29,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447825,1697122448793,120,,,[21],[1697122447846]
3286,3286,741,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438630,1697122440578,120,,,"[38, 1774]","[1697122438668, 1697122440442]"
3287,3287,841,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458102,1697122459962,120,,,[63],[1697122458165]
3288,3288,271,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408131,1697122410668,120,,,"[61, 2345]","[1697122408192, 1697122410537]"
3289,3289,496,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459966,1697122462680,120,,,[75],[1697122460041]
3290,3290,154,40,[],200,llama-7b,64,1,1085.0,1.0,1,A10,1697122451756,1697122452841,120,13.0,1.0,"[36, 1049]","[1697122451792, 1697122452841]"
3291,3291,518,42,[],200,llama-7b,64,1,1789.0,1.0,1,A10,1697122440584,1697122442373,120,23.0,1.0,"[75, 1714]","[1697122440659, 1697122442373]"
3292,3292,860,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122452847,1697122454905,120,,,[28],[1697122452875]
3293,3293,729,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448795,1697122450711,120,,,[22],[1697122448817]
3294,3294,382,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122450714,1697122458092,120,,,"[27, 2098, 1025, 1095, 1021, 1065]","[1697122450741, 1697122452839, 1697122453864, 1697122454959, 1697122455980, 1697122457045]"
3295,3295,512,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454911,1697122456992,120,,,[58],[1697122454969]
3296,3296,266,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462684,1697122463975,120,,,[29],[1697122462713]
3297,3297,288,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122456995,1697122458094,120,,,"[44, 973]","[1697122457039, 1697122458012]"
3298,3298,871,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458100,1697122459962,120,,,[77],[1697122458177]
3299,3299,172,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442378,1697122443687,120,,,[23],[1697122442401]
3300,3300,379,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464907,1697122466344,120,,,[19],[1697122464926]
3301,3301,855,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463979,1697122464905,120,,,[37],[1697122464016]
3302,3302,872,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122443691,1697122451944,120,,,"[32, 2362, 815, 976, 969, 987, 931]","[1697122443723, 1697122446085, 1697122446900, 1697122447876, 1697122448845, 1697122449832, 1697122450763]"
3303,3303,1,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451949,1697122453810,120,,,[44],[1697122451993]
3304,3304,48,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410671,1697122412985,120,,,[7],[1697122410678]
3305,3305,880,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454909,1697122456991,120,,,[39],[1697122454948]
3306,3306,160,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458096,1697122459961,120,,,[21],[1697122458117]
3307,3307,593,56,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463978,1697122464905,120,,,[19],[1697122463997]
3308,3308,628,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.86 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122412996,1697122415032,120,,,[61],[1697122413057]
3309,3309,242,57,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464909,1697122466987,120,,,"[58, 2003]","[1697122464967, 1697122466970]"
3310,3310,405,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacty of 21.99 GiB of which 597.00 MiB is free. Process 430828 has 21.39 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122415037,1697122418474,120,,,"[93, 2219]","[1697122415130, 1697122417349]"
3311,3311,699,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453814,1697122455927,120,,,[44],[1697122453858]
3312,3312,625,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464908,1697122466987,120,,,"[39, 2022]","[1697122464947, 1697122466969]"
3313,3313,215,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122402614,1697122404423,120,,,[29],[1697122402643]
3314,3314,639,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459967,1697122462680,120,,,[80],[1697122460047]
3315,3315,510,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122456993,1697122458093,120,,,[11],[1697122457004]
3316,3316,314,61,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463979,1697122464905,120,,,[38],[1697122464017]
3317,3317,55,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122418482,1697122420381,120,,,[96],[1697122418578]
3318,3318,745,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459964,1697122461248,120,,,[6],[1697122459970]
3319,3319,271,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462685,1697122464904,120,,,[53],[1697122462738]
3320,3320,756,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420385,1697122423159,120,,,[84],[1697122420469]
3321,3321,280,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458096,1697122459961,120,,,[27],[1697122458123]
3322,3322,448,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122455931,1697122458093,120,,,"[61, 2020]","[1697122455992, 1697122458012]"
3323,3323,615,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451949,1697122453810,120,,,[24],[1697122451973]
3324,3324,267,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.98 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453814,1697122455927,120,,,[44],[1697122453858]
3325,3325,869,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459966,1697122461247,120,,,[24],[1697122459990]
3326,3326,503,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.70 GiB is free. Process 430828 has 20.28 GiB memory in use. Of the allocated memory 16.32 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122423162,1697122424992,120,,,"[28, 923, 87]","[1697122423190, 1697122424113, 1697122424200]"
3327,3327,157,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424994,1697122426576,120,,,[147],[1697122425141]
3328,3328,641,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461252,1697122463976,120,,,[90],[1697122461342]
3329,3329,40,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464909,1697122466987,120,,,"[63, 1998]","[1697122464972, 1697122466970]"
3330,3330,521,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461252,1697122463976,120,,,[100],[1697122461352]
3331,3331,899,62,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464906,1697122466343,120,,,[5],[1697122464911]
3332,3332,174,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463980,1697122466344,120,,,[82],[1697122464062]
3333,3333,863,36,[],200,llama-7b,64,1,2247.0,1.0,1,A10,1697122426582,1697122428829,120,10.0,1.0,"[69, 2177]","[1697122426651, 1697122428828]"
3334,3334,298,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463981,1697122466344,120,,,[84],[1697122464065]
3335,3335,515,37,[],200,llama-7b,64,1,896.0,1.0,1,A10,1697122428831,1697122429727,120,11.0,1.0,"[18, 878]","[1697122428849, 1697122429727]"
3336,3336,291,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 17.40 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122429730,1697122431565,120,,,[17],[1697122429747]
3337,3337,100,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458098,1697122459962,120,,,[42],[1697122458140]
3338,3338,44,47,[],200,llama-7b,64,1,2080.0,1.0,1,A10,1697122455932,1697122458012,120,12.0,1.0,"[60, 2020]","[1697122455992, 1697122458012]"
3339,3339,626,48,[],200,llama-7b,64,1,741.0,1.0,1,A10,1697122458015,1697122458756,120,10.0,1.0,"[21, 720]","[1697122458036, 1697122458756]"
3340,3340,877,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.36 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122431570,1697122433671,120,,,[168],[1697122431738]
3341,3341,398,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458759,1697122461248,120,,,[28],[1697122458787]
3342,3342,800,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.91 GiB is allocated by PyTorch, and 3.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122404429,1697122407057,120,,,[115],[1697122404544]
3343,3343,59,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461251,1697122463976,120,,,[86],[1697122461337]
3344,3344,649,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122433677,1697122436782,120,,,[34],[1697122433711]
3345,3345,576,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 879.00 MiB is free. Process 430828 has 21.12 GiB memory in use. Of the allocated memory 16.37 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122407060,1697122408127,120,,,[24],[1697122407084]
3346,3346,758,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463978,1697122464905,120,,,[18],[1697122463996]
3347,3347,309,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122436787,1697122438626,120,,,"[45, 1774]","[1697122436832, 1697122438606]"
3348,3348,808,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459967,1697122462681,120,,,[85],[1697122460052]
3349,3349,79,42,[],200,llama-7b,64,1,2769.0,1.0,1,A10,1697122438635,1697122441404,120,12.0,1.0,"[149, 2620]","[1697122438784, 1697122441404]"
3350,3350,462,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462684,1697122463975,120,,,[34],[1697122462718]
3351,3351,233,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463980,1697122466344,120,,,[87],[1697122464067]
3352,3352,420,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 15.22 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464909,1697122466987,120,,,"[62, 1999]","[1697122464971, 1697122466970]"
3353,3353,230,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.23 GiB is free. Process 430828 has 20.75 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122408131,1697122410669,120,,,"[58, 2348]","[1697122408189, 1697122410537]"
3354,3354,7,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.11 GiB is free. Process 430828 has 20.86 GiB memory in use. Of the allocated memory 16.15 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122410673,1697122412984,120,,,[37],[1697122410710]
3355,3355,638,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.54 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122441408,1697122443688,120,,,[36],[1697122441444]
3356,3356,587,31,[],200,llama-7b,64,1,1873.0,1.0,1,A10,1697122412991,1697122414864,120,13.0,1.0,"[36, 1836]","[1697122413027, 1697122414863]"
3357,3357,408,44,[],200,llama-7b,64,1,2393.0,1.0,1,A10,1697122443692,1697122446085,120,16.0,1.0,"[51, 2342]","[1697122443743, 1697122446085]"
3358,3358,335,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.28 GiB. GPU 0 has a total capacty of 21.99 GiB of which 239.00 MiB is free. Process 430828 has 21.74 GiB memory in use. Of the allocated memory 16.45 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122414867,1697122416373,120,,,[24],[1697122414891]
3359,3359,68,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446091,1697122447823,120,,,[17],[1697122446108]
3360,3360,921,33,[],200,llama-7b,64,1,1936.0,1.0,1,A10,1697122416381,1697122418317,120,31.0,1.0,"[150, 1786]","[1697122416531, 1697122418317]"
3361,3361,769,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122447826,1697122449781,120,,,[45],[1697122447871]
3362,3362,693,34,[],200,llama-7b,64,1,2100.0,1.0,1,A10,1697122418321,1697122420421,120,67.0,2.0,"[13, 629, 1458]","[1697122418334, 1697122418963, 1697122420421]"
3363,3363,419,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacty of 21.99 GiB of which 461.00 MiB is free. Process 430828 has 21.53 GiB memory in use. Of the allocated memory 16.69 GiB is allocated by PyTorch, and 4.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122449786,1697122451945,120,,,"[93, 1872]","[1697122449879, 1697122451751]"
3364,3364,353,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacty of 21.99 GiB of which 863.00 MiB is free. Process 430828 has 21.13 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 3.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122420423,1697122423160,120,,,[114],[1697122420537]
3365,3365,195,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.36 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 2.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122451948,1697122453809,120,,,[20],[1697122451968]
3366,3366,123,36,[],200,llama-7b,64,1,1809.0,1.0,1,A10,1697122423165,1697122424974,120,14.0,1.0,"[119, 1690]","[1697122423284, 1697122424974]"
3367,3367,776,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122453812,1697122454906,120,,,[16],[1697122453828]
3368,3368,711,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.75 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122424977,1697122426578,120,,,[32],[1697122425009]
3369,3369,553,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122454909,1697122456992,120,,,[55],[1697122454964]
3370,3370,480,38,[],200,llama-7b,64,1,2244.0,1.0,1,A10,1697122426585,1697122428829,120,26.0,1.0,"[157, 2086]","[1697122426742, 1697122428828]"
3371,3371,141,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.06 GiB is free. Process 430828 has 20.91 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122428832,1697122432498,120,,,"[43, 1466, 1270]","[1697122428875, 1697122430341, 1697122431611]"
3372,3372,207,51,[],200,llama-7b,64,1,1759.0,1.0,1,A10,1697122456997,1697122458756,120,10.0,1.0,"[70, 1689]","[1697122457067, 1697122458756]"
3373,3373,838,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacty of 21.99 GiB of which 903.00 MiB is free. Process 430828 has 21.09 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122432507,1697122435151,120,,,[62],[1697122432569]
3374,3374,492,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacty of 21.99 GiB of which 709.00 MiB is free. Process 430828 has 21.28 GiB memory in use. Of the allocated memory 16.90 GiB is allocated by PyTorch, and 4.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122435156,1697122438624,120,,,"[25, 2684]","[1697122435181, 1697122437865]"
3375,3375,907,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458759,1697122461247,120,,,[16],[1697122458775]
3376,3376,239,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.85 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.99 GiB is allocated by PyTorch, and 4.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122438629,1697122440577,120,,,"[24, 1788]","[1697122438653, 1697122440441]"
3377,3377,655,53,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461249,1697122462681,120,,,[25],[1697122461274]
3378,3378,7,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.97 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122440588,1697122442471,120,,,"[86, 1700]","[1697122440674, 1697122442374]"
3379,3379,311,54,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 15.95 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122462684,1697122464904,120,,,[39],[1697122462723]
3380,3380,597,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122442477,1697122445117,120,,,[81],[1697122442558]
3381,3381,88,55,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122464907,1697122466344,120,,,[24],[1697122464931]
3382,3382,367,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.11 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122445121,1697122446847,120,,,[40],[1697122445161]
3383,3383,22,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 17.12 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122446853,1697122448793,120,,,[50],[1697122446903]
3384,3384,731,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacty of 21.99 GiB of which 541.00 MiB is free. Process 430828 has 21.45 GiB memory in use. Of the allocated memory 16.94 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122448798,1697122450712,120,,,[64],[1697122448862]
3385,3385,385,48,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.61 GiB is free. Process 430828 has 20.37 GiB memory in use. Of the allocated memory 16.71 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122450715,1697122458093,120,,,"[56, 2069, 1024, 1096, 1021, 1064]","[1697122450771, 1697122452840, 1697122453864, 1697122454960, 1697122455981, 1697122457045]"
3386,3386,161,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 17.15 GiB is allocated by PyTorch, and 3.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122458098,1697122459961,120,,,[37],[1697122458135]
3387,3387,742,50,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.24 GiB is free. Process 430828 has 20.74 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122459965,1697122461247,120,,,[20],[1697122459985]
3388,3388,490,51,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.09 GiB is free. Process 430828 has 20.88 GiB memory in use. Of the allocated memory 16.76 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122461251,1697122463976,120,,,[81],[1697122461332]
3389,3389,144,52,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacty of 21.99 GiB of which 1.02 GiB is free. Process 430828 has 20.96 GiB memory in use. Of the allocated memory 16.78 GiB is allocated by PyTorch, and 3.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,llama-7b,64,1,,,1,A10,1697122463979,1697122466342,120,,,[53],[1697122464032]
