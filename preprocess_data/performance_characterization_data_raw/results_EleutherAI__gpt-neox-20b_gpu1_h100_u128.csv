,smpnum,reqnum,errors,status,model,num_users,requests,latency_ms,records,n_gpus,gpu_type,start_timestamp,end_timestamp,experiment_duration_s,n_input_tokens,n_output_tokens,latency_ms_per_token,timestamps_per_token
0,664,0,[],200,EleutherAI/gpt-neox-20b,128,1,3594.0,1.0,1,H100,1697105154527,1697105158121.0,120,364.0,9.0,"[281, 2274, 307, 84, 61, 81, 78, 358, 70]","[1697105154808, 1697105157082, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121]"
1,591,0,[],200,EleutherAI/gpt-neox-20b,128,1,9167.0,1.0,1,H100,1697105154516,1697105163683.0,120,874.0,47.0,"[49, 1436, 76, 292, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86, 610, 92, 87, 85, 84, 78, 444, 93, 87, 86, 84, 436, 92, 93, 86, 240, 89, 68, 67, 548, 84, 79, 362, 91, 88, 79, 251]","[1697105154565, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160136, 1697105160580, 1697105160673, 1697105160760, 1697105160846, 1697105160930, 1697105161366, 1697105161458, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162101, 1697105162649, 1697105162733, 1697105162812, 1697105163174, 1697105163265, 1697105163353, 1697105163432, 1697105163683]"
2,882,0,[],200,EleutherAI/gpt-neox-20b,128,1,3099.0,1.0,1,H100,1697105154516,1697105157615.0,120,345.0,11.0,"[86, 1399, 77, 291, 66, 84, 562, 308, 84, 61, 81]","[1697105154602, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615]"
3,474,0,[],200,EleutherAI/gpt-neox-20b,128,1,6850.0,1.0,1,H100,1697105154516,1697105161366.0,120,109.0,33.0,"[28, 225, 1232, 76, 292, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 85, 611, 92, 87, 85, 84, 78, 444, 93, 87, 86, 84, 436]","[1697105154544, 1697105154769, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159099, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160136, 1697105160580, 1697105160673, 1697105160760, 1697105160846, 1697105160930, 1697105161366]"
4,145,0,[],200,EleutherAI/gpt-neox-20b,128,1,2873.0,1.0,1,H100,1697105154516,1697105157389.0,120,161.0,9.0,"[20, 233, 1232, 76, 292, 66, 84, 562, 308]","[1697105154536, 1697105154769, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389]"
5,563,0,[],200,EleutherAI/gpt-neox-20b,128,1,4410.0,1.0,1,H100,1697105154518,1697105158928.0,120,874.0,18.0,"[101, 1382, 76, 292, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 94]","[1697105154619, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928]"
6,802,0,[],200,EleutherAI/gpt-neox-20b,128,1,191.0,1.0,1,H100,1697105154516,1697105154707.0,120,9.0,1.0,"[24, 167]","[1697105154540, 1697105154707]"
7,258,0,[],200,EleutherAI/gpt-neox-20b,128,1,10314.0,1.0,1,H100,1697105154559,1697105164873.0,120,244.0,50.0,"[330, 2193, 307, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86, 610, 92, 87, 85, 84, 78, 445, 92, 87, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 84, 79, 362, 92, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88]","[1697105154889, 1697105157082, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160136, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162733, 1697105162812, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873]"
8,225,0,[],200,EleutherAI/gpt-neox-20b,128,1,1723.0,1.0,1,H100,1697105154559,1697105156282.0,120,23.0,1.0,"[322, 1401]","[1697105154881, 1697105156282]"
9,39,0,[],200,EleutherAI/gpt-neox-20b,128,1,1389.0,1.0,1,H100,1697105154518,1697105155907.0,120,8.0,1.0,"[97, 1292]","[1697105154615, 1697105155907]"
10,861,0,[],200,EleutherAI/gpt-neox-20b,128,1,1381.0,1.0,1,H100,1697105154527,1697105155908.0,120,10.0,1.0,"[198, 1183]","[1697105154725, 1697105155908]"
11,284,0,[],200,EleutherAI/gpt-neox-20b,128,1,6414.0,1.0,1,H100,1697105154516,1697105160930.0,120,90.0,31.0,"[45, 1440, 76, 292, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86, 610, 92, 87, 85, 84, 78, 444, 93, 87, 86, 84]","[1697105154561, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160136, 1697105160580, 1697105160673, 1697105160760, 1697105160846, 1697105160930]"
12,836,0,[],200,EleutherAI/gpt-neox-20b,128,1,1391.0,1.0,1,H100,1697105154516,1697105155907.0,120,11.0,1.0,"[58, 1333]","[1697105154574, 1697105155907]"
13,698,0,[],200,EleutherAI/gpt-neox-20b,128,1,2002.0,1.0,1,H100,1697105154517,1697105156519.0,120,182.0,6.0,"[73, 1411, 77, 291, 66, 84]","[1697105154590, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519]"
14,886,0,[],200,EleutherAI/gpt-neox-20b,128,1,191.0,1.0,1,H100,1697105154516,1697105154707.0,120,17.0,1.0,"[30, 161]","[1697105154546, 1697105154707]"
15,95,0,[],200,EleutherAI/gpt-neox-20b,128,1,1391.0,1.0,1,H100,1697105154516,1697105155907.0,120,12.0,1.0,"[38, 1353]","[1697105154554, 1697105155907]"
16,89,0,[],200,EleutherAI/gpt-neox-20b,128,1,5275.0,1.0,1,H100,1697105154527,1697105159802.0,120,52.0,20.0,"[253, 1589, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 94, 88, 85, 609, 92]","[1697105154780, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159016, 1697105159101, 1697105159710, 1697105159802]"
17,61,0,[],200,EleutherAI/gpt-neox-20b,128,1,1759.0,1.0,1,H100,1697105154523,1697105156282.0,120,9.0,1.0,"[281, 1478]","[1697105154804, 1697105156282]"
18,921,0,[],200,EleutherAI/gpt-neox-20b,128,1,1723.0,1.0,1,H100,1697105154559,1697105156282.0,120,31.0,1.0,"[309, 1414]","[1697105154868, 1697105156282]"
19,802,0,[],200,EleutherAI/gpt-neox-20b,128,1,2323.0,1.0,1,H100,1697105154559,1697105156882.0,120,9.0,1.0,"[325, 1998]","[1697105154884, 1697105156882]"
20,368,0,[],200,EleutherAI/gpt-neox-20b,128,1,5275.0,1.0,1,H100,1697105154527,1697105159802.0,120,88.0,20.0,"[273, 1569, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 94, 86, 87, 609, 92]","[1697105154800, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159101, 1697105159710, 1697105159802]"
21,93,0,[],200,EleutherAI/gpt-neox-20b,128,1,5275.0,1.0,1,H100,1697105154527,1697105159802.0,120,88.0,20.0,"[281, 1561, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 94, 86, 87, 609, 92]","[1697105154808, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159101, 1697105159710, 1697105159802]"
22,536,0,[],200,EleutherAI/gpt-neox-20b,128,1,4583.0,1.0,1,H100,1697105154517,1697105159100.0,120,83.0,20.0,"[41, 1443, 76, 292, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86]","[1697105154558, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100]"
23,530,0,[],200,EleutherAI/gpt-neox-20b,128,1,192.0,1.0,1,H100,1697105154515,1697105154707.0,120,26.0,1.0,"[11, 181]","[1697105154526, 1697105154707]"
24,858,0,[],200,EleutherAI/gpt-neox-20b,128,1,3177.0,1.0,1,H100,1697105154516,1697105157693.0,120,182.0,12.0,"[54, 1431, 76, 292, 66, 84, 562, 308, 84, 61, 81, 78]","[1697105154570, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693]"
25,639,0,[],200,EleutherAI/gpt-neox-20b,128,1,2863.0,1.0,1,H100,1697105154527,1697105157390.0,120,100.0,6.0,"[245, 1597, 66, 84, 562, 309]","[1697105154772, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157390]"
26,533,0,[],200,EleutherAI/gpt-neox-20b,128,1,253.0,1.0,1,H100,1697105154516,1697105154769.0,120,216.0,2.0,"[26, 227]","[1697105154542, 1697105154769]"
27,119,0,[],200,EleutherAI/gpt-neox-20b,128,1,1755.0,1.0,1,H100,1697105154527,1697105156282.0,120,31.0,1.0,"[253, 1502]","[1697105154780, 1697105156282]"
28,775,0,[],200,EleutherAI/gpt-neox-20b,128,1,1389.0,1.0,1,H100,1697105154518,1697105155907.0,120,17.0,1.0,"[88, 1301]","[1697105154606, 1697105155907]"
29,316,1,[],200,EleutherAI/gpt-neox-20b,128,1,6222.0,1.0,1,H100,1697105154708,1697105160930.0,120,86.0,20.0,"[189, 3155, 69, 86, 466, 161, 93, 87, 86, 610, 92, 87, 85, 84, 78, 445, 92, 87, 87, 83]","[1697105154897, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160136, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930]"
30,69,0,[],200,EleutherAI/gpt-neox-20b,128,1,4582.0,1.0,1,H100,1697105154519,1697105159101.0,120,85.0,20.0,"[160, 1322, 77, 291, 66, 84, 562, 309, 83, 61, 81, 78, 359, 69, 86, 466, 161, 94, 92, 81]","[1697105154679, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157390, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159020, 1697105159101]"
31,427,0,[],200,EleutherAI/gpt-neox-20b,128,1,1918.0,1.0,1,H100,1697105154517,1697105156435.0,120,58.0,5.0,"[69, 1415, 77, 291, 66]","[1697105154586, 1697105156001, 1697105156078, 1697105156369, 1697105156435]"
32,861,1,[],200,EleutherAI/gpt-neox-20b,128,1,3191.0,1.0,1,H100,1697105154770,1697105157961.0,120,10.0,1.0,"[138, 3053]","[1697105154908, 1697105157961]"
33,781,1,[],200,EleutherAI/gpt-neox-20b,128,1,3538.0,1.0,1,H100,1697105156436,1697105159974.0,120,335.0,10.0,"[4, 2233, 161, 94, 92, 81, 609, 92, 87, 85]","[1697105156440, 1697105158673, 1697105158834, 1697105158928, 1697105159020, 1697105159101, 1697105159710, 1697105159802, 1697105159889, 1697105159974]"
34,292,2,[],200,EleutherAI/gpt-neox-20b,128,1,1655.0,1.0,1,H100,1697105157962,1697105159617.0,120,286.0,1.0,"[4, 1650]","[1697105157966, 1697105159616]"
35,207,1,[],200,EleutherAI/gpt-neox-20b,128,1,2053.0,1.0,1,H100,1697105155908,1697105157961.0,120,10.0,1.0,"[5, 2048]","[1697105155913, 1697105157961]"
36,541,2,[],200,EleutherAI/gpt-neox-20b,128,1,4140.0,1.0,1,H100,1697105157962,1697105162102.0,120,90.0,20.0,"[16, 1733, 91, 87, 85, 84, 79, 444, 92, 87, 87, 83, 436, 93, 92, 87, 239, 89, 68, 68]","[1697105157978, 1697105159711, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102]"
37,905,0,[],200,EleutherAI/gpt-neox-20b,128,1,1384.0,1.0,1,H100,1697105154523,1697105155907.0,120,11.0,1.0,"[179, 1205]","[1697105154702, 1697105155907]"
38,649,3,[],200,EleutherAI/gpt-neox-20b,128,1,5765.0,1.0,1,H100,1697105159618,1697105165383.0,120,244.0,20.0,"[12, 3019, 85, 79, 361, 92, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 342, 89]","[1697105159630, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165383]"
39,211,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105159976,1697105170014.0,120,,,"[5, 2668, 85, 79, 361, 92, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 342, 89, 82, 286, 68, 78, 468, 246, 209, 271, 116, 196, 133, 75, 460, 227, 76, 273, 231, 127, 144, 218, 182, 155]","[1697105159981, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005, 1697105169149, 1697105169367, 1697105169549, 1697105169704]"
40,430,1,[],200,EleutherAI/gpt-neox-20b,128,1,2167.0,1.0,1,H100,1697105159103,1697105161270.0,120,15.0,1.0,"[36, 2131]","[1697105159139, 1697105161270]"
41,789,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105161272,1697105170012.0,120,,,"[8, 2403, 87, 84, 306, 77, 370, 89, 89, 88, 79, 342, 88, 83, 286, 68, 78, 468, 247, 208, 271, 116, 196, 133, 75, 460, 227, 76, 273, 231, 127, 144, 218, 182, 155]","[1697105161280, 1697105163683, 1697105163770, 1697105163854, 1697105164160, 1697105164237, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165382, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005, 1697105169149, 1697105169367, 1697105169549, 1697105169704]"
42,337,1,[],200,EleutherAI/gpt-neox-20b,128,1,2052.0,1.0,1,H100,1697105155909,1697105157961.0,120,12.0,1.0,"[32, 2020]","[1697105155941, 1697105157961]"
43,673,0,[],200,EleutherAI/gpt-neox-20b,128,1,4583.0,1.0,1,H100,1697105154517,1697105159100.0,120,93.0,20.0,"[40, 1444, 76, 292, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86]","[1697105154557, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100]"
44,609,0,[],200,EleutherAI/gpt-neox-20b,128,1,4584.0,1.0,1,H100,1697105154516,1697105159100.0,120,88.0,20.0,"[78, 1407, 77, 291, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86]","[1697105154594, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100]"
45,899,3,[],200,EleutherAI/gpt-neox-20b,128,1,5508.0,1.0,1,H100,1697105162103,1697105167611.0,120,100.0,20.0,"[29, 2476, 88, 89, 88, 79, 343, 88, 82, 286, 68, 78, 468, 246, 209, 271, 116, 196, 133, 75]","[1697105162132, 1697105164608, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611]"
46,670,2,[],200,EleutherAI/gpt-neox-20b,128,1,5434.0,1.0,1,H100,1697105160931,1697105166365.0,120,67.0,18.0,"[9, 2743, 86, 85, 306, 76, 371, 89, 89, 88, 79, 343, 88, 82, 286, 68, 78, 468]","[1697105160940, 1697105163683, 1697105163769, 1697105163854, 1697105164160, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365]"
47,149,0,[],200,EleutherAI/gpt-neox-20b,128,1,3679.0,1.0,1,H100,1697105154528,1697105158207.0,120,563.0,10.0,"[296, 2258, 307, 84, 61, 81, 78, 358, 70, 86]","[1697105154824, 1697105157082, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207]"
48,263,0,[],200,EleutherAI/gpt-neox-20b,128,1,1755.0,1.0,1,H100,1697105154527,1697105156282.0,120,15.0,1.0,"[273, 1482]","[1697105154800, 1697105156282]"
49,507,0,[],200,EleutherAI/gpt-neox-20b,128,1,5499.0,1.0,1,H100,1697105154559,1697105160058.0,120,83.0,20.0,"[333, 2190, 307, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86, 610, 92, 87, 85, 84]","[1697105154892, 1697105157082, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058]"
50,618,1,[],200,EleutherAI/gpt-neox-20b,128,1,1677.0,1.0,1,H100,1697105156284,1697105157961.0,120,9.0,1.0,"[28, 1649]","[1697105156312, 1697105157961]"
51,47,2,[],200,EleutherAI/gpt-neox-20b,128,1,5392.0,1.0,1,H100,1697105157962,1697105163354.0,120,90.0,20.0,"[40, 2579, 93, 86, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 85, 79, 361, 92, 88]","[1697105158002, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163354]"
52,365,0,[],200,EleutherAI/gpt-neox-20b,128,1,1389.0,1.0,1,H100,1697105154518,1697105155907.0,120,23.0,1.0,"[88, 1301]","[1697105154606, 1697105155907]"
53,723,1,[],200,EleutherAI/gpt-neox-20b,128,1,2053.0,1.0,1,H100,1697105155908,1697105157961.0,120,14.0,1.0,"[21, 2032]","[1697105155929, 1697105157961]"
54,153,2,[],200,EleutherAI/gpt-neox-20b,128,1,1927.0,1.0,1,H100,1697105157962,1697105159889.0,120,335.0,4.0,"[4, 1744, 92, 87]","[1697105157966, 1697105159710, 1697105159802, 1697105159889]"
55,262,0,[],200,EleutherAI/gpt-neox-20b,128,1,1389.0,1.0,1,H100,1697105154518,1697105155907.0,120,39.0,1.0,"[104, 1285]","[1697105154622, 1697105155907]"
56,38,1,[],200,EleutherAI/gpt-neox-20b,128,1,5057.0,1.0,1,H100,1697105159102,1697105164159.0,120,88.0,20.0,"[21, 2243, 93, 92, 87, 239, 89, 68, 68, 547, 85, 79, 361, 92, 87, 79, 251, 86, 85, 305]","[1697105159123, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159]"
57,396,1,[],200,EleutherAI/gpt-neox-20b,128,1,5022.0,1.0,1,H100,1697105155908,1697105160930.0,120,89.0,20.0,"[25, 2119, 69, 87, 465, 161, 94, 92, 81, 609, 92, 87, 85, 84, 79, 444, 93, 86, 87, 83]","[1697105155933, 1697105158052, 1697105158121, 1697105158208, 1697105158673, 1697105158834, 1697105158928, 1697105159020, 1697105159101, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930]"
58,618,1,[],200,EleutherAI/gpt-neox-20b,128,1,2052.0,1.0,1,H100,1697105155909,1697105157961.0,120,9.0,1.0,"[44, 2008]","[1697105155953, 1697105157961]"
59,510,3,[],200,EleutherAI/gpt-neox-20b,128,1,1987.0,1.0,1,H100,1697105159890,1697105161877.0,120,79.0,2.0,"[4, 1983]","[1697105159894, 1697105161877]"
60,43,2,[],200,EleutherAI/gpt-neox-20b,128,1,2619.0,1.0,1,H100,1697105157962,1697105160581.0,120,732.0,8.0,"[32, 1717, 91, 87, 85, 84, 79, 444]","[1697105157994, 1697105159711, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581]"
61,870,4,[],200,EleutherAI/gpt-neox-20b,128,1,5733.0,1.0,1,H100,1697105161878,1697105167611.0,120,88.0,20.0,"[5, 2725, 88, 89, 88, 79, 343, 88, 82, 286, 68, 77, 470, 246, 208, 271, 116, 196, 133, 75]","[1697105161883, 1697105164608, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165896, 1697105166366, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611]"
62,231,0,[],200,EleutherAI/gpt-neox-20b,128,1,1755.0,1.0,1,H100,1697105154527,1697105156282.0,120,13.0,1.0,"[285, 1470]","[1697105154812, 1697105156282]"
63,690,0,[],200,EleutherAI/gpt-neox-20b,128,1,1388.0,1.0,1,H100,1697105154519,1697105155907.0,120,39.0,1.0,"[181, 1207]","[1697105154700, 1697105155907]"
64,121,1,[],200,EleutherAI/gpt-neox-20b,128,1,2053.0,1.0,1,H100,1697105155908,1697105157961.0,120,13.0,1.0,"[29, 2024]","[1697105155937, 1697105157961]"
65,596,1,[],200,EleutherAI/gpt-neox-20b,128,1,5268.0,1.0,1,H100,1697105156283,1697105161551.0,120,87.0,20.0,"[9, 2381, 161, 94, 92, 81, 609, 92, 87, 85, 84, 78, 445, 93, 86, 87, 83, 436, 93, 92]","[1697105156292, 1697105158673, 1697105158834, 1697105158928, 1697105159020, 1697105159101, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160136, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551]"
66,269,5,[],200,EleutherAI/gpt-neox-20b,128,1,3597.0,1.0,1,H100,1697105167612,1697105171209.0,120,11.0,1.0,"[5, 3592]","[1697105167617, 1697105171209]"
67,280,0,[],200,EleutherAI/gpt-neox-20b,128,1,5275.0,1.0,1,H100,1697105154527,1697105159802.0,120,91.0,20.0,"[249, 1593, 66, 84, 562, 308, 84, 61, 81, 78, 359, 69, 86, 466, 161, 94, 92, 81, 609, 92]","[1697105154776, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159020, 1697105159101, 1697105159710, 1697105159802]"
68,499,1,[],200,EleutherAI/gpt-neox-20b,128,1,4712.0,1.0,1,H100,1697105157390,1697105162102.0,120,88.0,20.0,"[5, 2315, 92, 87, 85, 84, 79, 444, 92, 87, 87, 83, 436, 93, 92, 87, 239, 89, 68, 68]","[1697105157395, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102]"
69,626,6,[],200,EleutherAI/gpt-neox-20b,128,1,1611.0,1.0,1,H100,1697105171210,1697105172821.0,120,10.0,1.0,"[57, 1554]","[1697105171267, 1697105172821]"
70,57,7,[],200,EleutherAI/gpt-neox-20b,128,1,1757.0,1.0,1,H100,1697105172825,1697105174582.0,120,13.0,1.0,"[42, 1715]","[1697105172867, 1697105174582]"
71,65,1,[],200,EleutherAI/gpt-neox-20b,128,1,6751.0,1.0,1,H100,1697105158122,1697105164873.0,120,39.0,30.0,"[4, 2455, 93, 86, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 85, 79, 361, 92, 88, 78, 251, 86, 85, 305, 77, 371, 89, 89, 88]","[1697105158126, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163354, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873]"
72,414,8,[],200,EleutherAI/gpt-neox-20b,128,1,5154.0,1.0,1,H100,1697105174583,1697105179737.0,120,87.0,20.0,"[13, 2427, 82, 80, 63, 674, 95, 90, 88, 67, 87, 468, 90, 67, 87, 81, 356, 88, 85, 65]","[1697105174596, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178262, 1697105178349, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736]"
73,808,0,[],200,EleutherAI/gpt-neox-20b,128,1,1482.0,1.0,1,H100,1697105154519,1697105156001.0,120,286.0,2.0,"[189, 1293]","[1697105154708, 1697105156001]"
74,389,0,[],200,EleutherAI/gpt-neox-20b,128,1,1382.0,1.0,1,H100,1697105154526,1697105155908.0,120,8.0,1.0,"[196, 1185]","[1697105154722, 1697105155907]"
75,208,1,[],200,EleutherAI/gpt-neox-20b,128,1,5549.0,1.0,1,H100,1697105156002,1697105161551.0,120,96.0,20.0,"[9, 2662, 161, 94, 92, 81, 609, 92, 87, 85, 84, 79, 444, 93, 86, 87, 83, 436, 93, 92]","[1697105156011, 1697105158673, 1697105158834, 1697105158928, 1697105159020, 1697105159101, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551]"
76,444,0,[],200,EleutherAI/gpt-neox-20b,128,1,2000.0,1.0,1,H100,1697105154519,1697105156519.0,120,457.0,6.0,"[165, 1317, 77, 291, 66, 84]","[1697105154684, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519]"
77,860,2,[],200,EleutherAI/gpt-neox-20b,128,1,5508.0,1.0,1,H100,1697105162103,1697105167611.0,120,85.0,20.0,"[17, 2488, 88, 89, 88, 79, 343, 88, 82, 286, 68, 78, 468, 246, 209, 271, 116, 196, 133, 75]","[1697105162120, 1697105164608, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611]"
78,718,1,[],200,EleutherAI/gpt-neox-20b,128,1,2052.0,1.0,1,H100,1697105155909,1697105157961.0,120,13.0,1.0,"[40, 2012]","[1697105155949, 1697105157961]"
79,641,0,[],200,EleutherAI/gpt-neox-20b,128,1,10080.0,1.0,1,H100,1697105154527,1697105164607.0,120,16.0,50.0,"[277, 1565, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 94, 86, 87, 609, 92, 87, 85, 84, 78, 445, 92, 87, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 84, 79, 362, 92, 87, 79, 251, 86, 85, 305, 77, 371]","[1697105154804, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159101, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160136, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162733, 1697105162812, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607]"
80,150,2,[],200,EleutherAI/gpt-neox-20b,128,1,1749.0,1.0,1,H100,1697105157962,1697105159711.0,120,216.0,2.0,"[8, 1740]","[1697105157970, 1697105159710]"
81,558,2,[],200,EleutherAI/gpt-neox-20b,128,1,5851.0,1.0,1,H100,1697105161552,1697105167403.0,120,58.0,20.0,"[9, 2599, 77, 370, 89, 89, 88, 79, 342, 89, 82, 286, 68, 78, 468, 246, 209, 271, 116, 196]","[1697105161561, 1697105164160, 1697105164237, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167207, 1697105167403]"
82,693,0,[],200,EleutherAI/gpt-neox-20b,128,1,1484.0,1.0,1,H100,1697105154517,1697105156001.0,120,67.0,2.0,"[61, 1423]","[1697105154578, 1697105156001]"
83,513,3,[],200,EleutherAI/gpt-neox-20b,128,1,5671.0,1.0,1,H100,1697105159712,1697105165383.0,120,83.0,20.0,"[4, 2933, 85, 79, 362, 91, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 342, 89]","[1697105159716, 1697105162649, 1697105162734, 1697105162813, 1697105163175, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165383]"
84,158,0,[],200,EleutherAI/gpt-neox-20b,128,1,4574.0,1.0,1,H100,1697105154527,1697105159101.0,120,85.0,20.0,"[194, 1280, 77, 291, 66, 84, 562, 309, 83, 61, 81, 78, 359, 69, 86, 466, 161, 94, 92, 81]","[1697105154721, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157390, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159020, 1697105159101]"
85,118,1,[],200,EleutherAI/gpt-neox-20b,128,1,5549.0,1.0,1,H100,1697105156002,1697105161551.0,120,85.0,20.0,"[9, 2662, 161, 94, 92, 81, 610, 91, 87, 85, 84, 79, 444, 93, 86, 87, 83, 436, 93, 92]","[1697105156011, 1697105158673, 1697105158834, 1697105158928, 1697105159020, 1697105159101, 1697105159711, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551]"
86,852,0,[],200,EleutherAI/gpt-neox-20b,128,1,4583.0,1.0,1,H100,1697105154518,1697105159101.0,120,100.0,20.0,"[109, 1374, 76, 292, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 94, 86, 86]","[1697105154627, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159100]"
87,871,4,[],200,EleutherAI/gpt-neox-20b,128,1,3985.0,1.0,1,H100,1697105165383,1697105169368.0,120,123.0,6.0,"[5, 3259, 232, 127, 143, 219]","[1697105165388, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368]"
88,553,0,[],200,EleutherAI/gpt-neox-20b,128,1,5499.0,1.0,1,H100,1697105154559,1697105160058.0,120,88.0,20.0,"[321, 2202, 307, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86, 610, 92, 87, 85, 84]","[1697105154880, 1697105157082, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058]"
89,477,0,[],200,EleutherAI/gpt-neox-20b,128,1,10314.0,1.0,1,H100,1697105154559,1697105164873.0,120,244.0,50.0,"[314, 2209, 307, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86, 610, 92, 87, 85, 84, 78, 445, 92, 87, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 84, 79, 362, 92, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88]","[1697105154873, 1697105157082, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160136, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162733, 1697105162812, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873]"
90,515,1,[],200,EleutherAI/gpt-neox-20b,128,1,2168.0,1.0,1,H100,1697105159103,1697105161271.0,120,11.0,1.0,"[40, 2127]","[1697105159143, 1697105161270]"
91,865,2,[],200,EleutherAI/gpt-neox-20b,128,1,2322.0,1.0,1,H100,1697105161272,1697105163594.0,120,9.0,1.0,"[16, 2306]","[1697105161288, 1697105163594]"
92,266,3,[],200,EleutherAI/gpt-neox-20b,128,1,1609.0,1.0,1,H100,1697105163595,1697105165204.0,120,9.0,1.0,"[13, 1596]","[1697105163608, 1697105165204]"
93,554,0,[],200,EleutherAI/gpt-neox-20b,128,1,1755.0,1.0,1,H100,1697105154527,1697105156282.0,120,26.0,1.0,"[257, 1498]","[1697105154784, 1697105156282]"
94,624,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165206,1697105170013.0,120,,,"[16, 3425, 232, 127, 143, 219, 181, 155]","[1697105165222, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
95,56,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170018,1697105172155.0,120,,,"[80, 1665]","[1697105170098, 1697105171763]"
96,388,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105169369,1697105172155.0,120,,,"[4, 2390]","[1697105169373, 1697105171763]"
97,743,6,[],200,EleutherAI/gpt-neox-20b,128,1,2523.0,1.0,1,H100,1697105172158,1697105174681.0,120,123.0,6.0,"[17, 1610, 79, 77, 72, 668]","[1697105172175, 1697105173785, 1697105173864, 1697105173941, 1697105174013, 1697105174681]"
98,419,6,[],200,EleutherAI/gpt-neox-20b,128,1,4107.0,1.0,1,H100,1697105172157,1697105176264.0,120,88.0,20.0,"[7, 1621, 79, 77, 72, 668, 92, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69]","[1697105172164, 1697105173785, 1697105173864, 1697105173941, 1697105174013, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
99,166,7,[],200,EleutherAI/gpt-neox-20b,128,1,2247.0,1.0,1,H100,1697105174682,1697105176929.0,120,14.0,1.0,"[20, 2227]","[1697105174702, 1697105176929]"
100,427,0,[],200,EleutherAI/gpt-neox-20b,128,1,2555.0,1.0,1,H100,1697105154527,1697105157082.0,120,58.0,5.0,"[257, 1585, 66, 84, 562]","[1697105154784, 1697105156369, 1697105156435, 1697105156519, 1697105157081]"
101,743,0,[],200,EleutherAI/gpt-neox-20b,128,1,2000.0,1.0,1,H100,1697105154519,1697105156519.0,120,123.0,6.0,"[175, 1307, 77, 291, 66, 84]","[1697105154694, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519]"
102,777,1,[],200,EleutherAI/gpt-neox-20b,128,1,2533.0,1.0,1,H100,1697105157083,1697105159616.0,120,9.0,1.0,"[4, 2529]","[1697105157087, 1697105159616]"
103,21,1,[],200,EleutherAI/gpt-neox-20b,128,1,1978.0,1.0,1,H100,1697105163684,1697105165662.0,120,15.0,1.0,"[4, 1974]","[1697105163688, 1697105165662]"
104,375,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165663,1697105172155.0,120,,,"[12, 6088]","[1697105165675, 1697105171763]"
105,526,8,[],200,EleutherAI/gpt-neox-20b,128,1,4794.0,1.0,1,H100,1697105176930,1697105181724.0,120,89.0,20.0,"[9, 1878, 90, 67, 87, 81, 356, 88, 85, 66, 365, 85, 66, 280, 79, 75, 488, 81, 80, 388]","[1697105176939, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181724]"
106,202,0,[],200,EleutherAI/gpt-neox-20b,128,1,13780.0,1.0,1,H100,1697105154518,1697105168298.0,120,874.0,72.0,"[100, 1383, 76, 292, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 93, 80, 610, 92, 87, 85, 84, 78, 445, 92, 87, 86, 84, 436, 92, 93, 86, 240, 89, 68, 67, 548, 84, 79, 362, 91, 88, 79, 251, 86, 85, 305, 77, 371, 89, 89, 87, 80, 342, 88, 83, 286, 68, 77, 469, 246, 209, 271, 115, 197, 133, 75, 460, 227]","[1697105154618, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159020, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160136, 1697105160581, 1697105160673, 1697105160760, 1697105160846, 1697105160930, 1697105161366, 1697105161458, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162101, 1697105162649, 1697105162733, 1697105162812, 1697105163174, 1697105163265, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164872, 1697105164952, 1697105165294, 1697105165382, 1697105165465, 1697105165751, 1697105165819, 1697105165896, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167206, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298]"
107,206,2,[],200,EleutherAI/gpt-neox-20b,128,1,1653.0,1.0,1,H100,1697105159618,1697105161271.0,120,16.0,1.0,"[12, 1640]","[1697105159630, 1697105161270]"
108,344,0,[],200,EleutherAI/gpt-neox-20b,128,1,1755.0,1.0,1,H100,1697105154527,1697105156282.0,120,13.0,1.0,"[261, 1494]","[1697105154788, 1697105156282]"
109,565,3,[],200,EleutherAI/gpt-neox-20b,128,1,5549.0,1.0,1,H100,1697105161271,1697105166820.0,120,91.0,20.0,"[9, 2403, 87, 84, 306, 77, 370, 89, 89, 88, 79, 342, 88, 83, 286, 68, 78, 468, 247, 208]","[1697105161280, 1697105163683, 1697105163770, 1697105163854, 1697105164160, 1697105164237, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165382, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166612, 1697105166820]"
110,262,1,[],200,EleutherAI/gpt-neox-20b,128,1,2052.0,1.0,1,H100,1697105155909,1697105157961.0,120,39.0,1.0,"[48, 2004]","[1697105155957, 1697105157961]"
111,699,1,[],200,EleutherAI/gpt-neox-20b,128,1,2279.0,1.0,1,H100,1697105156283,1697105158562.0,120,39.0,1.0,"[17, 2262]","[1697105156300, 1697105158562]"
112,127,2,[],200,EleutherAI/gpt-neox-20b,128,1,2284.0,1.0,1,H100,1697105158563,1697105160847.0,120,100.0,5.0,"[5, 2013, 93, 86, 87]","[1697105158568, 1697105160581, 1697105160674, 1697105160760, 1697105160847]"
113,370,1,[],200,EleutherAI/gpt-neox-20b,128,1,2167.0,1.0,1,H100,1697105159103,1697105161270.0,120,31.0,1.0,"[32, 2135]","[1697105159135, 1697105161270]"
114,705,3,[],200,EleutherAI/gpt-neox-20b,128,1,5947.0,1.0,1,H100,1697105172160,1697105178107.0,120,79.0,27.0,"[145, 1480, 79, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 70, 87, 69, 68, 70, 758, 81, 81, 63, 674, 94, 91]","[1697105172305, 1697105173785, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176265, 1697105177023, 1697105177104, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107]"
115,727,2,[],200,EleutherAI/gpt-neox-20b,128,1,2889.0,1.0,1,H100,1697105161271,1697105164160.0,120,58.0,5.0,"[5, 2407, 86, 85, 306]","[1697105161276, 1697105163683, 1697105163769, 1697105163854, 1697105164160]"
116,365,0,[],200,EleutherAI/gpt-neox-20b,128,1,1388.0,1.0,1,H100,1697105154519,1697105155907.0,120,23.0,1.0,"[107, 1281]","[1697105154626, 1697105155907]"
117,620,2,[],200,EleutherAI/gpt-neox-20b,128,1,3497.0,1.0,1,H100,1697105157962,1697105161459.0,120,100.0,8.0,"[33, 2586, 93, 86, 87, 83, 436, 93]","[1697105157995, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459]"
118,156,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105164161,1697105170013.0,120,,,"[36, 2415, 208, 271, 116, 196, 133, 75, 460, 227, 76, 273, 232, 127, 143, 219, 181, 155]","[1697105164197, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
119,673,0,[],200,EleutherAI/gpt-neox-20b,128,1,4504.0,1.0,1,H100,1697105154516,1697105159020.0,120,93.0,20.0,"[22, 231, 1232, 76, 292, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 465, 162, 93, 87]","[1697105154538, 1697105154769, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158672, 1697105158834, 1697105158927, 1697105159014]"
120,52,3,[],200,EleutherAI/gpt-neox-20b,128,1,3325.0,1.0,1,H100,1697105161460,1697105164785.0,120,58.0,6.0,"[4, 2696, 77, 370, 89, 89]","[1697105161464, 1697105164160, 1697105164237, 1697105164607, 1697105164696, 1697105164785]"
121,98,1,[],200,EleutherAI/gpt-neox-20b,128,1,2042.0,1.0,1,H100,1697105156520,1697105158562.0,120,14.0,1.0,"[13, 2029]","[1697105156533, 1697105158562]"
122,459,2,[],200,EleutherAI/gpt-neox-20b,128,1,2284.0,1.0,1,H100,1697105158563,1697105160847.0,120,58.0,5.0,"[13, 2005, 93, 86, 87]","[1697105158576, 1697105160581, 1697105160674, 1697105160760, 1697105160847]"
123,818,3,[],200,EleutherAI/gpt-neox-20b,128,1,2146.0,1.0,1,H100,1697105160848,1697105162994.0,120,13.0,1.0,"[8, 2138]","[1697105160856, 1697105162994]"
124,645,1,[],200,EleutherAI/gpt-neox-20b,128,1,5889.0,1.0,1,H100,1697105160931,1697105166820.0,120,86.0,20.0,"[5, 2747, 86, 85, 306, 76, 371, 89, 89, 88, 79, 343, 88, 82, 286, 68, 78, 468, 246, 209]","[1697105160936, 1697105163683, 1697105163769, 1697105163854, 1697105164160, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820]"
125,242,4,[],200,EleutherAI/gpt-neox-20b,128,1,3617.0,1.0,1,H100,1697105162995,1697105166612.0,120,345.0,9.0,"[4, 2296, 88, 82, 286, 68, 78, 468, 246]","[1697105162999, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611]"
126,723,0,[],200,EleutherAI/gpt-neox-20b,128,1,1382.0,1.0,1,H100,1697105154526,1697105155908.0,120,14.0,1.0,"[207, 1175]","[1697105154733, 1697105155908]"
127,148,1,[],200,EleutherAI/gpt-neox-20b,128,1,2052.0,1.0,1,H100,1697105155909,1697105157961.0,120,16.0,1.0,"[44, 2008]","[1697105155953, 1697105157961]"
128,507,2,[],200,EleutherAI/gpt-neox-20b,128,1,4140.0,1.0,1,H100,1697105157962,1697105162102.0,120,83.0,20.0,"[24, 1725, 91, 87, 85, 84, 79, 444, 93, 86, 87, 83, 436, 93, 92, 87, 239, 89, 68, 68]","[1697105157986, 1697105159711, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102]"
129,597,5,[],200,EleutherAI/gpt-neox-20b,128,1,2855.0,1.0,1,H100,1697105166613,1697105169468.0,120,39.0,1.0,"[4, 2851]","[1697105166617, 1697105169468]"
130,515,4,[],200,EleutherAI/gpt-neox-20b,128,1,1655.0,1.0,1,H100,1697105170016,1697105171671.0,120,11.0,1.0,"[25, 1630]","[1697105170041, 1697105171671]"
131,719,0,[],200,EleutherAI/gpt-neox-20b,128,1,2003.0,1.0,1,H100,1697105154516,1697105156519.0,120,182.0,6.0,"[50, 1435, 76, 292, 66, 84]","[1697105154566, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519]"
132,870,5,[],200,EleutherAI/gpt-neox-20b,128,1,4592.0,1.0,1,H100,1697105171672,1697105176264.0,120,88.0,20.0,"[13, 2100, 79, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69]","[1697105171685, 1697105173785, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
133,477,0,[],200,EleutherAI/gpt-neox-20b,128,1,9636.0,1.0,1,H100,1697105154523,1697105164159.0,120,244.0,50.0,"[206, 1272, 77, 291, 66, 84, 562, 309, 83, 61, 81, 78, 359, 69, 86, 466, 161, 94, 86, 87, 609, 92, 87, 85, 84, 78, 445, 92, 87, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 84, 79, 362, 91, 88, 79, 251, 86, 85, 305]","[1697105154729, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157390, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159101, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160136, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162733, 1697105162812, 1697105163174, 1697105163265, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159]"
134,927,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105169469,1697105172156.0,120,,,"[4, 2290]","[1697105169473, 1697105171763]"
135,359,7,[],200,EleutherAI/gpt-neox-20b,128,1,1525.0,1.0,1,H100,1697105172159,1697105173684.0,120,10.0,1.0,"[225, 1300]","[1697105172384, 1697105173684]"
136,148,1,[],200,EleutherAI/gpt-neox-20b,128,1,2042.0,1.0,1,H100,1697105156520,1697105158562.0,120,16.0,1.0,"[13, 2029]","[1697105156533, 1697105158562]"
137,721,8,[],200,EleutherAI/gpt-neox-20b,128,1,1245.0,1.0,1,H100,1697105173685,1697105174930.0,120,286.0,5.0,"[33, 963, 92, 89, 68]","[1697105173718, 1697105174681, 1697105174773, 1697105174862, 1697105174930]"
138,778,0,[],200,EleutherAI/gpt-neox-20b,128,1,9640.0,1.0,1,H100,1697105154519,1697105164159.0,120,16.0,50.0,"[111, 1371, 76, 292, 66, 84, 562, 308, 84, 61, 81, 78, 359, 69, 86, 466, 161, 94, 86, 86, 610, 92, 87, 85, 84, 78, 445, 92, 87, 87, 83, 436, 93, 92, 86, 240, 89, 68, 67, 548, 84, 79, 362, 91, 88, 79, 251, 86, 85, 305]","[1697105154630, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160136, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162101, 1697105162649, 1697105162733, 1697105162812, 1697105163174, 1697105163265, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159]"
139,509,2,[],200,EleutherAI/gpt-neox-20b,128,1,2111.0,1.0,1,H100,1697105158563,1697105160674.0,120,286.0,3.0,"[9, 2009, 93]","[1697105158572, 1697105160581, 1697105160674]"
140,865,3,[],200,EleutherAI/gpt-neox-20b,128,1,2412.0,1.0,1,H100,1697105162104,1697105164516.0,120,9.0,1.0,"[32, 2380]","[1697105162136, 1697105164516]"
141,453,1,[],200,EleutherAI/gpt-neox-20b,128,1,2053.0,1.0,1,H100,1697105155908,1697105157961.0,120,26.0,1.0,"[13, 2040]","[1697105155921, 1697105157961]"
142,806,2,[],200,EleutherAI/gpt-neox-20b,128,1,4140.0,1.0,1,H100,1697105157962,1697105162102.0,120,89.0,20.0,"[20, 1729, 91, 87, 85, 84, 79, 444, 93, 86, 87, 83, 436, 93, 92, 87, 239, 89, 68, 68]","[1697105157982, 1697105159711, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102]"
143,264,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105164517,1697105170013.0,120,,,"[8, 3011, 75, 460, 227, 76, 273, 231, 127, 144, 218, 182, 156]","[1697105164525, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005, 1697105169149, 1697105169367, 1697105169549, 1697105169705]"
144,868,3,[],200,EleutherAI/gpt-neox-20b,128,1,5144.0,1.0,1,H100,1697105160675,1697105165819.0,120,85.0,20.0,"[8, 2491, 92, 88, 78, 251, 86, 85, 306, 76, 372, 88, 89, 88, 79, 343, 88, 82, 286, 68]","[1697105160683, 1697105163174, 1697105163266, 1697105163354, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164160, 1697105164236, 1697105164608, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819]"
145,237,3,[],200,EleutherAI/gpt-neox-20b,128,1,5508.0,1.0,1,H100,1697105162103,1697105167611.0,120,87.0,20.0,"[21, 2484, 88, 89, 88, 79, 343, 88, 82, 286, 68, 78, 468, 246, 209, 271, 116, 196, 133, 75]","[1697105162124, 1697105164608, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611]"
146,533,0,[],200,EleutherAI/gpt-neox-20b,128,1,1483.0,1.0,1,H100,1697105154518,1697105156001.0,120,216.0,2.0,"[157, 1326]","[1697105154675, 1697105156001]"
147,864,1,[],200,EleutherAI/gpt-neox-20b,128,1,5549.0,1.0,1,H100,1697105156002,1697105161551.0,120,83.0,20.0,"[5, 2666, 161, 94, 86, 87, 610, 91, 87, 85, 84, 79, 444, 93, 86, 87, 83, 436, 93, 92]","[1697105156007, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159101, 1697105159711, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551]"
148,623,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170017,1697105172155.0,120,,,[88],[1697105170105]
149,831,1,[],200,EleutherAI/gpt-neox-20b,128,1,1501.0,1.0,1,H100,1697105164161,1697105165662.0,120,11.0,1.0,"[16, 1485]","[1697105164177, 1697105165662]"
150,52,6,[],200,EleutherAI/gpt-neox-20b,128,1,2523.0,1.0,1,H100,1697105172158,1697105174681.0,120,58.0,6.0,"[127, 1499, 80, 77, 72, 668]","[1697105172285, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174681]"
151,175,0,[],200,EleutherAI/gpt-neox-20b,128,1,2868.0,1.0,1,H100,1697105154522,1697105157390.0,120,140.0,8.0,"[170, 1309, 77, 291, 66, 84, 562, 309]","[1697105154692, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157390]"
152,346,1,[],200,EleutherAI/gpt-neox-20b,128,1,5268.0,1.0,1,H100,1697105156283,1697105161551.0,120,85.0,20.0,"[13, 2377, 161, 94, 92, 81, 609, 92, 87, 85, 84, 79, 444, 93, 86, 87, 83, 436, 93, 92]","[1697105156296, 1697105158673, 1697105158834, 1697105158928, 1697105159020, 1697105159101, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551]"
153,232,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165663,1697105170013.0,120,,,"[8, 3208, 127, 143, 219, 181, 155]","[1697105165671, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
154,534,1,[],200,EleutherAI/gpt-neox-20b,128,1,4712.0,1.0,1,H100,1697105157390,1697105162102.0,120,96.0,20.0,"[9, 2311, 92, 87, 85, 84, 79, 444, 92, 87, 87, 83, 436, 93, 92, 87, 239, 89, 68, 68]","[1697105157399, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102]"
155,866,2,[],200,EleutherAI/gpt-neox-20b,128,1,5508.0,1.0,1,H100,1697105162103,1697105167611.0,120,93.0,20.0,"[25, 2480, 88, 89, 88, 79, 343, 88, 82, 286, 68, 78, 468, 246, 209, 271, 116, 196, 133, 75]","[1697105162128, 1697105164608, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611]"
156,424,0,[],200,EleutherAI/gpt-neox-20b,128,1,4582.0,1.0,1,H100,1697105154518,1697105159100.0,120,88.0,20.0,"[92, 1391, 76, 292, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86]","[1697105154610, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100]"
157,175,0,[],200,EleutherAI/gpt-neox-20b,128,1,2871.0,1.0,1,H100,1697105154519,1697105157390.0,120,140.0,8.0,"[159, 1323, 77, 291, 66, 84, 562, 309]","[1697105154678, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157390]"
158,586,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170016,1697105172155.0,120,,,[93],[1697105170109]
159,639,0,[],200,EleutherAI/gpt-neox-20b,128,1,1997.0,1.0,1,H100,1697105154522,1697105156519.0,120,100.0,6.0,"[174, 1305, 77, 291, 66, 84]","[1697105154696, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519]"
160,15,4,[],200,EleutherAI/gpt-neox-20b,128,1,4106.0,1.0,1,H100,1697105172158,1697105176264.0,120,100.0,20.0,"[25, 1601, 80, 77, 72, 668, 92, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69]","[1697105172183, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
161,380,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165820,1697105170013.0,120,,,"[16, 3713, 155]","[1697105165836, 1697105169549, 1697105169704]"
162,753,0,[],200,EleutherAI/gpt-neox-20b,128,1,4578.0,1.0,1,H100,1697105154523,1697105159101.0,120,83.0,20.0,"[203, 1275, 77, 291, 66, 84, 562, 309, 83, 61, 81, 78, 359, 69, 86, 466, 161, 94, 92, 81]","[1697105154726, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157390, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159020, 1697105159101]"
163,734,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170017,1697105172155.0,120,,,"[84, 1662]","[1697105170101, 1697105171763]"
164,536,1,[],200,EleutherAI/gpt-neox-20b,128,1,4712.0,1.0,1,H100,1697105157390,1697105162102.0,120,83.0,20.0,"[5, 2315, 92, 87, 85, 84, 79, 444, 92, 87, 87, 83, 436, 93, 92, 87, 239, 89, 68, 68]","[1697105157395, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102]"
165,164,6,[],200,EleutherAI/gpt-neox-20b,128,1,1526.0,1.0,1,H100,1697105172158,1697105173684.0,120,15.0,1.0,"[131, 1395]","[1697105172289, 1697105173684]"
166,208,0,[],200,EleutherAI/gpt-neox-20b,128,1,4581.0,1.0,1,H100,1697105154520,1697105159101.0,120,96.0,20.0,"[184, 1297, 77, 291, 66, 84, 562, 309, 83, 61, 81, 78, 359, 69, 86, 466, 161, 94, 92, 81]","[1697105154704, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157390, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159020, 1697105159101]"
167,371,0,[],200,EleutherAI/gpt-neox-20b,128,1,2323.0,1.0,1,H100,1697105154559,1697105156882.0,120,13.0,1.0,"[329, 1994]","[1697105154888, 1697105156882]"
168,339,0,[],200,EleutherAI/gpt-neox-20b,128,1,4575.0,1.0,1,H100,1697105154526,1697105159101.0,120,87.0,20.0,"[190, 1285, 77, 291, 66, 84, 562, 309, 83, 61, 81, 78, 359, 69, 86, 466, 161, 94, 92, 81]","[1697105154716, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157390, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159020, 1697105159101]"
169,68,1,[],200,EleutherAI/gpt-neox-20b,128,1,2042.0,1.0,1,H100,1697105156520,1697105158562.0,120,12.0,1.0,"[17, 2025]","[1697105156537, 1697105158562]"
170,116,0,[],200,EleutherAI/gpt-neox-20b,128,1,1382.0,1.0,1,H100,1697105154526,1697105155908.0,120,23.0,1.0,"[192, 1189]","[1697105154718, 1697105155907]"
171,396,2,[],200,EleutherAI/gpt-neox-20b,128,1,4791.0,1.0,1,H100,1697105158563,1697105163354.0,120,89.0,20.0,"[9, 2009, 93, 86, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 85, 79, 362, 91, 88]","[1697105158572, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163175, 1697105163266, 1697105163354]"
172,525,7,[],200,EleutherAI/gpt-neox-20b,128,1,10701.0,1.0,1,H100,1697105173686,1697105184387.0,120,216.0,55.0,"[52, 1884, 99, 91, 89, 70, 87, 69, 68, 69, 760, 81, 80, 63, 674, 94, 91, 88, 67, 86, 468, 91, 66, 88, 81, 356, 88, 85, 65, 366, 85, 66, 280, 79, 75, 488, 81, 80, 387, 87, 75, 408, 89, 84, 383, 89, 89, 189, 88, 78, 372, 86, 85, 78, 384]","[1697105173738, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176264, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181885, 1697105182293, 1697105182382, 1697105182466, 1697105182849, 1697105182938, 1697105183027, 1697105183216, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387]"
173,71,1,[],200,EleutherAI/gpt-neox-20b,128,1,3456.0,1.0,1,H100,1697105157391,1697105160847.0,120,364.0,11.0,"[8, 2311, 92, 87, 85, 84, 79, 444, 92, 87, 87]","[1697105157399, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160673, 1697105160760, 1697105160847]"
174,752,0,[],200,EleutherAI/gpt-neox-20b,128,1,1486.0,1.0,1,H100,1697105154515,1697105156001.0,120,39.0,3.0,"[11, 242, 1233]","[1697105154526, 1697105154768, 1697105156001]"
175,805,0,[],200,EleutherAI/gpt-neox-20b,128,1,9641.0,1.0,1,H100,1697105154518,1697105164159.0,120,286.0,50.0,"[113, 1370, 77, 291, 66, 84, 562, 308, 84, 61, 81, 78, 359, 69, 86, 466, 161, 94, 86, 86, 610, 92, 87, 85, 84, 78, 445, 92, 87, 87, 83, 436, 93, 92, 86, 240, 89, 68, 67, 548, 84, 79, 362, 92, 87, 79, 251, 86, 85, 305]","[1697105154631, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160136, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162101, 1697105162649, 1697105162733, 1697105162812, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159]"
176,400,3,[],200,EleutherAI/gpt-neox-20b,128,1,3188.0,1.0,1,H100,1697105160582,1697105163770.0,120,123.0,7.0,"[4, 2588, 92, 88, 78, 251, 86]","[1697105160586, 1697105163174, 1697105163266, 1697105163354, 1697105163432, 1697105163683, 1697105163769]"
177,701,1,[],200,EleutherAI/gpt-neox-20b,128,1,9014.0,1.0,1,H100,1697105156883,1697105165897.0,120,58.0,43.0,"[4, 2823, 92, 87, 85, 84, 79, 444, 92, 87, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 85, 79, 361, 92, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 342, 88, 83, 286, 68, 77]","[1697105156887, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165382, 1697105165465, 1697105165751, 1697105165819, 1697105165896]"
178,828,0,[],200,EleutherAI/gpt-neox-20b,128,1,1920.0,1.0,1,H100,1697105154515,1697105156435.0,120,182.0,6.0,"[15, 238, 1233, 76, 292, 66]","[1697105154530, 1697105154768, 1697105156001, 1697105156077, 1697105156369, 1697105156435]"
179,734,4,[],200,EleutherAI/gpt-neox-20b,128,1,2842.0,1.0,1,H100,1697105163770,1697105166612.0,120,100.0,6.0,"[5, 1976, 68, 78, 468, 247]","[1697105163775, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166612]"
180,392,0,[],200,EleutherAI/gpt-neox-20b,128,1,1755.0,1.0,1,H100,1697105154527,1697105156282.0,120,20.0,1.0,"[249, 1506]","[1697105154776, 1697105156282]"
181,166,5,[],200,EleutherAI/gpt-neox-20b,128,1,3315.0,1.0,1,H100,1697105166613,1697105169928.0,120,14.0,1.0,"[12, 3303]","[1697105166625, 1697105169928]"
182,524,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105169929,1697105172156.0,120,,,"[5, 1829]","[1697105169934, 1697105171763]"
183,883,7,[],200,EleutherAI/gpt-neox-20b,128,1,1525.0,1.0,1,H100,1697105172159,1697105173684.0,120,563.0,1.0,"[53, 1472]","[1697105172212, 1697105173684]"
184,855,0,[],200,EleutherAI/gpt-neox-20b,128,1,4498.0,1.0,1,H100,1697105154516,1697105159014.0,120,83.0,20.0,"[16, 237, 1232, 76, 292, 65, 85, 562, 308, 83, 62, 81, 78, 358, 70, 86, 466, 161, 93, 87]","[1697105154532, 1697105154769, 1697105156001, 1697105156077, 1697105156369, 1697105156434, 1697105156519, 1697105157081, 1697105157389, 1697105157472, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014]"
185,377,3,[],200,EleutherAI/gpt-neox-20b,128,1,3596.0,1.0,1,H100,1697105167613,1697105171209.0,120,13.0,1.0,"[20, 3576]","[1697105167633, 1697105171209]"
186,304,8,[],200,EleutherAI/gpt-neox-20b,128,1,3563.0,1.0,1,H100,1697105173685,1697105177248.0,120,86.0,20.0,"[29, 967, 92, 89, 68, 86, 84, 522, 99, 91, 89, 70, 87, 69, 68, 69, 760, 81, 80, 63]","[1697105173714, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176264, 1697105177024, 1697105177105, 1697105177185, 1697105177248]"
187,477,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105161552,1697105170013.0,120,,,"[17, 2591, 77, 370, 89, 89, 88, 79, 342, 89, 82, 286, 68, 78, 468, 247, 208, 271, 116, 196, 133, 75, 460, 227, 76, 273, 231, 127, 144, 218, 181, 156]","[1697105161569, 1697105164160, 1697105164237, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005, 1697105169149, 1697105169367, 1697105169548, 1697105169704]"
188,283,1,[],200,EleutherAI/gpt-neox-20b,128,1,5138.0,1.0,1,H100,1697105159022,1697105164160.0,120,85.0,20.0,"[8, 2336, 93, 92, 86, 240, 89, 68, 68, 547, 84, 80, 361, 92, 88, 78, 251, 86, 85, 305]","[1697105159030, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162733, 1697105162813, 1697105163174, 1697105163266, 1697105163354, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159]"
189,643,2,[],200,EleutherAI/gpt-neox-20b,128,1,1501.0,1.0,1,H100,1697105164161,1697105165662.0,120,18.0,1.0,"[28, 1473]","[1697105164189, 1697105165662]"
190,75,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165663,1697105170013.0,120,,,"[4, 3212, 127, 143, 219, 181, 155]","[1697105165667, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
191,738,4,[],200,EleutherAI/gpt-neox-20b,128,1,3470.0,1.0,1,H100,1697105171210,1697105174680.0,120,79.0,6.0,"[57, 2517, 80, 77, 72, 667]","[1697105171267, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680]"
192,407,4,[],200,EleutherAI/gpt-neox-20b,128,1,1655.0,1.0,1,H100,1697105170016,1697105171671.0,120,16.0,1.0,"[77, 1578]","[1697105170093, 1697105171671]"
193,767,5,[],200,EleutherAI/gpt-neox-20b,128,1,1148.0,1.0,1,H100,1697105171673,1697105172821.0,120,11.0,1.0,"[40, 1108]","[1697105171713, 1697105172821]"
194,163,5,[],200,EleutherAI/gpt-neox-20b,128,1,3241.0,1.0,1,H100,1697105174681,1697105177922.0,120,67.0,6.0,"[9, 2333, 82, 80, 63, 674]","[1697105174690, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177922]"
195,828,0,[],200,EleutherAI/gpt-neox-20b,128,1,1997.0,1.0,1,H100,1697105154522,1697105156519.0,120,182.0,6.0,"[168, 1311, 77, 291, 66, 84]","[1697105154690, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519]"
196,553,0,[],200,EleutherAI/gpt-neox-20b,128,1,4582.0,1.0,1,H100,1697105154519,1697105159101.0,120,88.0,20.0,"[163, 1319, 77, 291, 66, 84, 562, 309, 83, 61, 81, 78, 359, 69, 86, 466, 161, 94, 86, 87]","[1697105154682, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157390, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159101]"
197,191,6,[],200,EleutherAI/gpt-neox-20b,128,1,4426.0,1.0,1,H100,1697105172822,1697105177248.0,120,85.0,20.0,"[9, 1849, 93, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69, 759, 82, 80, 63]","[1697105172831, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177023, 1697105177105, 1697105177185, 1697105177248]"
198,854,0,[],200,EleutherAI/gpt-neox-20b,128,1,6157.0,1.0,1,H100,1697105154516,1697105160673.0,120,67.0,29.0,"[34, 219, 1232, 76, 292, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86, 610, 92, 87, 85, 84, 78, 444, 93]","[1697105154550, 1697105154769, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160136, 1697105160580, 1697105160673]"
199,554,0,[],200,EleutherAI/gpt-neox-20b,128,1,1755.0,1.0,1,H100,1697105154527,1697105156282.0,120,26.0,1.0,"[269, 1486]","[1697105154796, 1697105156282]"
200,913,1,[],200,EleutherAI/gpt-neox-20b,128,1,5268.0,1.0,1,H100,1697105156283,1697105161551.0,120,88.0,20.0,"[9, 2381, 161, 94, 92, 81, 609, 92, 87, 85, 84, 79, 444, 93, 86, 87, 83, 436, 93, 92]","[1697105156292, 1697105158673, 1697105158834, 1697105158928, 1697105159020, 1697105159101, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551]"
201,253,1,[],200,EleutherAI/gpt-neox-20b,128,1,5582.0,1.0,1,H100,1697105156520,1697105162102.0,120,67.0,20.0,"[5, 3185, 92, 87, 85, 84, 79, 444, 93, 86, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68]","[1697105156525, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102]"
202,96,0,[],200,EleutherAI/gpt-neox-20b,128,1,1385.0,1.0,1,H100,1697105154522,1697105155907.0,120,31.0,1.0,"[190, 1195]","[1697105154712, 1697105155907]"
203,452,1,[],200,EleutherAI/gpt-neox-20b,128,1,2299.0,1.0,1,H100,1697105155909,1697105158208.0,120,216.0,4.0,"[36, 2016, 91, 69, 87]","[1697105155945, 1697105157961, 1697105158052, 1697105158121, 1697105158208]"
204,483,3,[],200,EleutherAI/gpt-neox-20b,128,1,5972.0,1.0,1,H100,1697105160848,1697105166820.0,120,84.0,20.0,"[4, 2831, 86, 85, 306, 76, 372, 88, 89, 88, 79, 343, 88, 82, 286, 68, 77, 469, 246, 209]","[1697105160852, 1697105163683, 1697105163769, 1697105163854, 1697105164160, 1697105164236, 1697105164608, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165896, 1697105166365, 1697105166611, 1697105166820]"
205,98,1,[],200,EleutherAI/gpt-neox-20b,128,1,2240.0,1.0,1,H100,1697105159030,1697105161270.0,120,14.0,1.0,"[5, 2235]","[1697105159035, 1697105161270]"
206,456,2,[],200,EleutherAI/gpt-neox-20b,128,1,5549.0,1.0,1,H100,1697105161271,1697105166820.0,120,90.0,20.0,"[5, 2407, 87, 84, 306, 77, 370, 89, 89, 88, 79, 342, 88, 83, 286, 68, 78, 468, 247, 208]","[1697105161276, 1697105163683, 1697105163770, 1697105163854, 1697105164160, 1697105164237, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165382, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166612, 1697105166820]"
207,225,0,[],200,EleutherAI/gpt-neox-20b,128,1,1755.0,1.0,1,H100,1697105154527,1697105156282.0,120,23.0,1.0,"[285, 1470]","[1697105154812, 1697105156282]"
208,810,2,[],200,EleutherAI/gpt-neox-20b,128,1,5145.0,1.0,1,H100,1697105158209,1697105163354.0,120,91.0,20.0,"[4, 2368, 93, 86, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 85, 79, 361, 92, 88]","[1697105158213, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163354]"
209,556,1,[],200,EleutherAI/gpt-neox-20b,128,1,1678.0,1.0,1,H100,1697105156283,1697105157961.0,120,9.0,1.0,"[21, 1657]","[1697105156304, 1697105157961]"
210,63,0,[],200,EleutherAI/gpt-neox-20b,128,1,1389.0,1.0,1,H100,1697105154518,1697105155907.0,120,39.0,1.0,"[96, 1293]","[1697105154614, 1697105155907]"
211,509,1,[],200,EleutherAI/gpt-neox-20b,128,1,2213.0,1.0,1,H100,1697105155908,1697105158121.0,120,286.0,3.0,"[17, 2127, 69]","[1697105155925, 1697105158052, 1697105158121]"
212,913,2,[],200,EleutherAI/gpt-neox-20b,128,1,5392.0,1.0,1,H100,1697105157962,1697105163354.0,120,88.0,20.0,"[36, 2583, 93, 86, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 85, 79, 361, 92, 88]","[1697105157998, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163354]"
213,63,0,[],200,EleutherAI/gpt-neox-20b,128,1,2670.0,1.0,1,H100,1697105154559,1697105157229.0,120,39.0,1.0,"[334, 2336]","[1697105154893, 1697105157229]"
214,866,2,[],200,EleutherAI/gpt-neox-20b,128,1,5232.0,1.0,1,H100,1697105158122,1697105163354.0,120,93.0,20.0,"[8, 2451, 93, 86, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 85, 79, 361, 92, 88]","[1697105158130, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163354]"
215,393,1,[],200,EleutherAI/gpt-neox-20b,128,1,5504.0,1.0,1,H100,1697105157230,1697105162734.0,120,182.0,22.0,"[4, 2476, 92, 87, 85, 84, 79, 443, 93, 87, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 85]","[1697105157234, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160580, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734]"
216,701,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105162103,1697105170013.0,120,,,"[17, 2488, 88, 89, 88, 79, 343, 88, 82, 286, 68, 77, 469, 246, 209, 271, 116, 196, 133, 75, 460, 227, 76, 273, 231, 127, 144, 218, 182, 155]","[1697105162120, 1697105164608, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165896, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005, 1697105169149, 1697105169367, 1697105169549, 1697105169704]"
217,844,4,[],200,EleutherAI/gpt-neox-20b,128,1,4387.0,1.0,1,H100,1697105166821,1697105171208.0,120,10.0,1.0,"[8, 4379]","[1697105166829, 1697105171208]"
218,243,5,[],200,EleutherAI/gpt-neox-20b,128,1,2731.0,1.0,1,H100,1697105171210,1697105173941.0,120,67.0,4.0,"[21, 2553, 80, 77]","[1697105171231, 1697105173784, 1697105173864, 1697105173941]"
219,811,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105166821,1697105172154.0,120,,,"[20, 4922]","[1697105166841, 1697105171763]"
220,243,4,[],200,EleutherAI/gpt-neox-20b,128,1,1784.0,1.0,1,H100,1697105172157,1697105173941.0,120,67.0,4.0,"[47, 1580, 80, 77]","[1697105172204, 1697105173784, 1697105173864, 1697105173941]"
221,13,0,[],200,EleutherAI/gpt-neox-20b,128,1,4583.0,1.0,1,H100,1697105154517,1697105159100.0,120,90.0,20.0,"[81, 1403, 77, 291, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86]","[1697105154598, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100]"
222,754,2,[],200,EleutherAI/gpt-neox-20b,128,1,3162.0,1.0,1,H100,1697105162735,1697105165897.0,120,88.0,7.0,"[4, 2556, 88, 82, 286, 68, 78]","[1697105162739, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897]"
223,184,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165898,1697105170014.0,120,,,"[8, 3643, 155]","[1697105165906, 1697105169549, 1697105169704]"
224,609,0,[],200,EleutherAI/gpt-neox-20b,128,1,4583.0,1.0,1,H100,1697105154517,1697105159100.0,120,88.0,20.0,"[81, 1403, 77, 291, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86]","[1697105154598, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100]"
225,859,0,[],200,EleutherAI/gpt-neox-20b,128,1,1391.0,1.0,1,H100,1697105154516,1697105155907.0,120,23.0,1.0,"[53, 1338]","[1697105154569, 1697105155907]"
226,42,0,[],200,EleutherAI/gpt-neox-20b,128,1,1381.0,1.0,1,H100,1697105154526,1697105155907.0,120,10.0,1.0,"[184, 1197]","[1697105154710, 1697105155907]"
227,606,6,[],200,EleutherAI/gpt-neox-20b,128,1,1565.0,1.0,1,H100,1697105173942,1697105175507.0,120,9.0,1.0,"[5, 1560]","[1697105173947, 1697105175507]"
228,43,0,[],200,EleutherAI/gpt-neox-20b,128,1,2871.0,1.0,1,H100,1697105154519,1697105157390.0,120,732.0,8.0,"[151, 1331, 77, 291, 65, 85, 562, 308]","[1697105154670, 1697105156001, 1697105156078, 1697105156369, 1697105156434, 1697105156519, 1697105157081, 1697105157389]"
229,887,1,[],200,EleutherAI/gpt-neox-20b,128,1,11111.0,1.0,1,H100,1697105154708,1697105165819.0,120,244.0,50.0,"[196, 3148, 69, 86, 466, 161, 94, 86, 87, 609, 92, 87, 85, 84, 79, 444, 92, 87, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 84, 79, 362, 92, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 342, 88, 83, 286, 68]","[1697105154904, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159101, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162733, 1697105162812, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165382, 1697105165465, 1697105165751, 1697105165819]"
230,396,1,[],200,EleutherAI/gpt-neox-20b,128,1,5022.0,1.0,1,H100,1697105155908,1697105160930.0,120,89.0,20.0,"[25, 2119, 69, 87, 465, 161, 94, 86, 87, 609, 92, 87, 85, 84, 79, 444, 93, 86, 87, 83]","[1697105155933, 1697105158052, 1697105158121, 1697105158208, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159101, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930]"
231,31,7,[],200,EleutherAI/gpt-neox-20b,128,1,4229.0,1.0,1,H100,1697105175508,1697105179737.0,120,84.0,20.0,"[8, 1508, 81, 80, 63, 674, 94, 91, 88, 67, 86, 469, 90, 67, 87, 81, 356, 88, 85, 66]","[1697105175516, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737]"
232,39,0,[],200,EleutherAI/gpt-neox-20b,128,1,191.0,1.0,1,H100,1697105154516,1697105154707.0,120,8.0,1.0,"[12, 179]","[1697105154528, 1697105154707]"
233,400,1,[],200,EleutherAI/gpt-neox-20b,128,1,4220.0,1.0,1,H100,1697105154708,1697105158928.0,120,123.0,7.0,"[192, 3152, 69, 86, 466, 161, 94]","[1697105154900, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928]"
234,533,1,[],200,EleutherAI/gpt-neox-20b,128,1,2846.0,1.0,1,H100,1697105159803,1697105162649.0,120,216.0,2.0,"[5, 2841]","[1697105159808, 1697105162649]"
235,840,2,[],200,EleutherAI/gpt-neox-20b,128,1,1464.0,1.0,1,H100,1697105158929,1697105160393.0,120,17.0,1.0,"[8, 1456]","[1697105158937, 1697105160393]"
236,271,3,[],200,EleutherAI/gpt-neox-20b,128,1,5425.0,1.0,1,H100,1697105160394,1697105165819.0,120,87.0,20.0,"[4, 2776, 92, 88, 78, 251, 86, 85, 306, 76, 371, 89, 89, 88, 79, 343, 88, 82, 286, 68]","[1697105160398, 1697105163174, 1697105163266, 1697105163354, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164160, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819]"
237,672,0,[],200,EleutherAI/gpt-neox-20b,128,1,4498.0,1.0,1,H100,1697105154516,1697105159014.0,120,93.0,20.0,"[6, 246, 1233, 76, 292, 65, 85, 562, 308, 83, 62, 81, 78, 358, 70, 86, 466, 161, 93, 87]","[1697105154522, 1697105154768, 1697105156001, 1697105156077, 1697105156369, 1697105156434, 1697105156519, 1697105157081, 1697105157389, 1697105157472, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014]"
238,889,2,[],200,EleutherAI/gpt-neox-20b,128,1,6229.0,1.0,1,H100,1697105162650,1697105168879.0,120,86.0,20.0,"[5, 2640, 88, 82, 286, 68, 78, 468, 246, 209, 271, 115, 197, 133, 75, 460, 227, 76, 273, 231]","[1697105162655, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167206, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878]"
239,624,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165820,1697105170014.0,120,,,[25],[1697105165845]
240,55,5,[],200,EleutherAI/gpt-neox-20b,128,1,1653.0,1.0,1,H100,1697105170018,1697105171671.0,120,12.0,1.0,"[100, 1553]","[1697105170118, 1697105171671]"
241,231,0,[],200,EleutherAI/gpt-neox-20b,128,1,1381.0,1.0,1,H100,1697105154526,1697105155907.0,120,13.0,1.0,"[180, 1201]","[1697105154706, 1697105155907]"
242,371,0,[],200,EleutherAI/gpt-neox-20b,128,1,1755.0,1.0,1,H100,1697105154527,1697105156282.0,120,13.0,1.0,"[289, 1466]","[1697105154816, 1697105156282]"
243,72,1,[],200,EleutherAI/gpt-neox-20b,128,1,5138.0,1.0,1,H100,1697105159022,1697105164160.0,120,84.0,20.0,"[11, 2333, 93, 92, 87, 239, 89, 68, 68, 547, 84, 80, 361, 92, 88, 78, 251, 86, 85, 305]","[1697105159033, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162733, 1697105162813, 1697105163174, 1697105163266, 1697105163354, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159]"
244,691,0,[],200,EleutherAI/gpt-neox-20b,128,1,1390.0,1.0,1,H100,1697105154517,1697105155907.0,120,47.0,1.0,"[73, 1317]","[1697105154590, 1697105155907]"
245,343,0,[],200,EleutherAI/gpt-neox-20b,128,1,5499.0,1.0,1,H100,1697105154559,1697105160058.0,120,84.0,20.0,"[326, 2197, 307, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86, 610, 92, 87, 85, 84]","[1697105154885, 1697105157082, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058]"
246,592,1,[],200,EleutherAI/gpt-neox-20b,128,1,9910.0,1.0,1,H100,1697105155909,1697105165819.0,120,15.0,50.0,"[32, 2111, 69, 87, 465, 161, 94, 90, 83, 610, 91, 87, 85, 84, 79, 444, 93, 86, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 85, 79, 362, 91, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 342, 88, 83, 286, 68]","[1697105155941, 1697105158052, 1697105158121, 1697105158208, 1697105158673, 1697105158834, 1697105158928, 1697105159018, 1697105159101, 1697105159711, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163175, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165382, 1697105165465, 1697105165751, 1697105165819]"
247,481,1,[],200,EleutherAI/gpt-neox-20b,128,1,2278.0,1.0,1,H100,1697105156284,1697105158562.0,120,10.0,1.0,"[32, 2246]","[1697105156316, 1697105158562]"
248,121,1,[],200,EleutherAI/gpt-neox-20b,128,1,2053.0,1.0,1,H100,1697105155908,1697105157961.0,120,13.0,1.0,"[37, 2016]","[1697105155945, 1697105157961]"
249,479,2,[],200,EleutherAI/gpt-neox-20b,128,1,6911.0,1.0,1,H100,1697105157962,1697105164873.0,120,140.0,36.0,"[29, 1720, 91, 87, 85, 84, 79, 444, 93, 86, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 85, 79, 361, 92, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88]","[1697105157991, 1697105159711, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873]"
250,80,4,[],200,EleutherAI/gpt-neox-20b,128,1,1762.0,1.0,1,H100,1697105165384,1697105167146.0,120,13.0,1.0,"[12, 1750]","[1697105165396, 1697105167146]"
251,408,5,[],200,EleutherAI/gpt-neox-20b,128,1,4061.0,1.0,1,H100,1697105167147,1697105171208.0,120,16.0,1.0,"[5, 4056]","[1697105167152, 1697105171208]"
252,762,6,[],200,EleutherAI/gpt-neox-20b,128,1,5054.0,1.0,1,H100,1697105171210,1697105176264.0,120,92.0,20.0,"[21, 2553, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 98, 92, 89, 69, 88, 68, 69, 69]","[1697105171231, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175720, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
253,755,3,[],200,EleutherAI/gpt-neox-20b,128,1,6349.0,1.0,1,H100,1697105163355,1697105169704.0,120,286.0,25.0,"[8, 1932, 88, 82, 286, 68, 78, 468, 246, 209, 271, 115, 197, 133, 75, 460, 227, 76, 273, 232, 127, 143, 218, 182, 155]","[1697105163363, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167206, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169367, 1697105169549, 1697105169704]"
254,396,2,[],200,EleutherAI/gpt-neox-20b,128,1,4971.0,1.0,1,H100,1697105160848,1697105165819.0,120,89.0,20.0,"[4, 2322, 92, 88, 78, 251, 86, 85, 306, 76, 372, 88, 89, 88, 79, 343, 88, 82, 286, 68]","[1697105160852, 1697105163174, 1697105163266, 1697105163354, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164160, 1697105164236, 1697105164608, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819]"
255,697,1,[],200,EleutherAI/gpt-neox-20b,128,1,3546.0,1.0,1,H100,1697105159103,1697105162649.0,120,123.0,10.0,"[32, 2231, 93, 92, 87, 239, 89, 68, 68, 547]","[1697105159135, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649]"
256,185,1,[],200,EleutherAI/gpt-neox-20b,128,1,5549.0,1.0,1,H100,1697105156002,1697105161551.0,120,93.0,20.0,"[5, 2666, 161, 94, 86, 87, 610, 91, 87, 85, 84, 79, 444, 93, 86, 87, 83, 436, 93, 92]","[1697105156007, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159101, 1697105159711, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551]"
257,101,3,[],200,EleutherAI/gpt-neox-20b,128,1,3101.0,1.0,1,H100,1697105166367,1697105169468.0,120,13.0,1.0,"[6, 3095]","[1697105166373, 1697105169468]"
258,100,2,[],200,EleutherAI/gpt-neox-20b,128,1,4886.0,1.0,1,H100,1697105162650,1697105167536.0,120,732.0,14.0,"[5, 2640, 88, 82, 286, 68, 78, 468, 246, 209, 271, 116, 196, 133]","[1697105162655, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536]"
259,482,2,[],200,EleutherAI/gpt-neox-20b,128,1,4140.0,1.0,1,H100,1697105157962,1697105162102.0,120,91.0,20.0,"[25, 1724, 91, 87, 85, 84, 79, 444, 93, 86, 87, 83, 436, 93, 92, 87, 239, 89, 68, 68]","[1697105157987, 1697105159711, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102]"
260,463,3,[],200,EleutherAI/gpt-neox-20b,128,1,3671.0,1.0,1,H100,1697105167537,1697105171208.0,120,39.0,1.0,"[9, 3662]","[1697105167546, 1697105171208]"
261,821,4,[],200,EleutherAI/gpt-neox-20b,128,1,5054.0,1.0,1,H100,1697105171210,1697105176264.0,120,85.0,20.0,"[33, 2541, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 98, 92, 89, 69, 88, 68, 69, 69]","[1697105171243, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175720, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
262,755,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165820,1697105170013.0,120,,,"[12, 3717, 155]","[1697105165832, 1697105169549, 1697105169704]"
263,842,3,[],200,EleutherAI/gpt-neox-20b,128,1,4988.0,1.0,1,H100,1697105162103,1697105167091.0,120,161.0,16.0,"[25, 2480, 88, 89, 88, 79, 343, 88, 82, 286, 68, 78, 468, 246, 209, 271]","[1697105162128, 1697105164608, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820, 1697105167091]"
264,540,2,[],200,EleutherAI/gpt-neox-20b,128,1,3144.0,1.0,1,H100,1697105161552,1697105164696.0,120,140.0,5.0,"[5, 2603, 77, 370, 89]","[1697105161557, 1697105164160, 1697105164237, 1697105164607, 1697105164696]"
265,869,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105164697,1697105170014.0,120,,,"[5, 3369, 227, 76, 273, 231, 127, 144, 218, 182, 155]","[1697105164702, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005, 1697105169149, 1697105169367, 1697105169549, 1697105169704]"
266,401,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105164161,1697105170013.0,120,,,"[8, 2197, 246, 208, 271, 116, 196, 133, 75, 460, 227, 76, 273, 232, 127, 143, 219, 181, 155]","[1697105164169, 1697105166366, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
267,590,0,[],200,EleutherAI/gpt-neox-20b,128,1,4582.0,1.0,1,H100,1697105154519,1697105159101.0,120,88.0,20.0,"[167, 1315, 77, 291, 66, 84, 562, 309, 83, 61, 81, 78, 359, 69, 86, 466, 161, 94, 92, 81]","[1697105154686, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157390, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159020, 1697105159101]"
268,180,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170016,1697105172155.0,120,,,"[70, 1677]","[1697105170086, 1697105171763]"
269,69,0,[],200,EleutherAI/gpt-neox-20b,128,1,4498.0,1.0,1,H100,1697105154516,1697105159014.0,120,85.0,20.0,"[33, 220, 1232, 76, 292, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87]","[1697105154549, 1697105154769, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014]"
270,541,5,[],200,EleutherAI/gpt-neox-20b,128,1,4107.0,1.0,1,H100,1697105172158,1697105176265.0,120,90.0,20.0,"[61, 1565, 80, 77, 72, 668, 92, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 70]","[1697105172219, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176265]"
271,430,1,[],200,EleutherAI/gpt-neox-20b,128,1,2247.0,1.0,1,H100,1697105159023,1697105161270.0,120,15.0,1.0,"[10, 2237]","[1697105159033, 1697105161270]"
272,900,6,[],200,EleutherAI/gpt-neox-20b,128,1,1992.0,1.0,1,H100,1697105176271,1697105178263.0,120,67.0,6.0,"[41, 1610, 95, 90, 88, 68]","[1697105176312, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178263]"
273,789,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105161271,1697105170012.0,120,,,"[13, 2399, 87, 84, 306, 77, 370, 89, 89, 88, 79, 342, 88, 83, 286, 68, 78, 468, 246, 209, 271, 116, 196, 133, 75, 460, 227, 76, 273, 231, 127, 144, 218, 182, 155]","[1697105161284, 1697105163683, 1697105163770, 1697105163854, 1697105164160, 1697105164237, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165382, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005, 1697105169149, 1697105169367, 1697105169549, 1697105169704]"
274,244,4,[],200,EleutherAI/gpt-neox-20b,128,1,4116.0,1.0,1,H100,1697105167092,1697105171208.0,120,9.0,1.0,"[5, 4111]","[1697105167097, 1697105171208]"
275,281,0,[],200,EleutherAI/gpt-neox-20b,128,1,3402.0,1.0,1,H100,1697105154559,1697105157961.0,120,23.0,1.0,"[337, 3065]","[1697105154896, 1697105157961]"
276,299,4,[],200,EleutherAI/gpt-neox-20b,128,1,1655.0,1.0,1,H100,1697105170016,1697105171671.0,120,14.0,1.0,"[69, 1586]","[1697105170085, 1697105171671]"
277,807,1,[],200,EleutherAI/gpt-neox-20b,128,1,5582.0,1.0,1,H100,1697105156520,1697105162102.0,120,90.0,20.0,"[5, 3185, 92, 87, 85, 84, 79, 444, 93, 86, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68]","[1697105156525, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102]"
278,884,8,[],200,EleutherAI/gpt-neox-20b,128,1,5427.0,1.0,1,H100,1697105184388,1697105189815.0,120,90.0,20.0,"[4, 2197, 88, 79, 77, 60, 280, 83, 83, 83, 376, 89, 561, 94, 164, 81, 376, 86, 85, 481]","[1697105184392, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186893, 1697105187173, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189163, 1697105189249, 1697105189334, 1697105189815]"
279,642,1,[],200,EleutherAI/gpt-neox-20b,128,1,4140.0,1.0,1,H100,1697105157962,1697105162102.0,120,89.0,20.0,"[8, 1741, 91, 87, 85, 84, 79, 444, 92, 87, 87, 83, 436, 93, 92, 87, 239, 89, 68, 68]","[1697105157970, 1697105159711, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102]"
280,656,5,[],200,EleutherAI/gpt-neox-20b,128,1,1148.0,1.0,1,H100,1697105171673,1697105172821.0,120,26.0,1.0,"[36, 1112]","[1697105171709, 1697105172821]"
281,73,2,[],200,EleutherAI/gpt-neox-20b,128,1,1873.0,1.0,1,H100,1697105162103,1697105163976.0,120,9.0,1.0,"[13, 1860]","[1697105162116, 1697105163976]"
282,420,7,[],200,EleutherAI/gpt-neox-20b,128,1,5491.0,1.0,1,H100,1697105178264,1697105183755.0,120,52.0,20.0,"[8, 2261, 79, 75, 488, 81, 80, 387, 87, 76, 408, 88, 84, 384, 89, 88, 190, 87, 78, 372]","[1697105178272, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182382, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754]"
283,288,9,[],200,EleutherAI/gpt-neox-20b,128,1,5340.0,1.0,1,H100,1697105189816,1697105195156.0,120,93.0,20.0,"[8, 2942, 87, 83, 234, 82, 62, 305, 87, 189, 84, 64, 81, 265, 64, 84, 199, 81, 78, 261]","[1697105189824, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193619, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194817, 1697105194895, 1697105195156]"
284,85,6,[],200,EleutherAI/gpt-neox-20b,128,1,4423.0,1.0,1,H100,1697105172825,1697105177248.0,120,88.0,20.0,"[22, 1833, 93, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69, 760, 81, 80, 63]","[1697105172847, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177024, 1697105177105, 1697105177185, 1697105177248]"
285,11,0,[],200,EleutherAI/gpt-neox-20b,128,1,4318.0,1.0,1,H100,1697105154516,1697105158834.0,120,732.0,17.0,"[46, 1439, 76, 292, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161]","[1697105154562, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834]"
286,71,1,[],200,EleutherAI/gpt-neox-20b,128,1,3631.0,1.0,1,H100,1697105159103,1697105162734.0,120,364.0,11.0,"[16, 2247, 93, 92, 87, 239, 89, 68, 68, 547, 85]","[1697105159119, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734]"
287,612,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105164874,1697105170014.0,120,,,"[4, 3193, 227, 76, 273, 232, 126, 144, 218, 182, 155]","[1697105164878, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169005, 1697105169149, 1697105169367, 1697105169549, 1697105169704]"
288,915,1,[],200,EleutherAI/gpt-neox-20b,128,1,2279.0,1.0,1,H100,1697105156283,1697105158562.0,120,182.0,1.0,"[5, 2274]","[1697105156288, 1697105158562]"
289,345,2,[],200,EleutherAI/gpt-neox-20b,128,1,4791.0,1.0,1,H100,1697105158563,1697105163354.0,120,39.0,20.0,"[13, 2005, 93, 86, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 85, 79, 361, 92, 88]","[1697105158576, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163354]"
290,522,6,[],200,EleutherAI/gpt-neox-20b,128,1,2088.0,1.0,1,H100,1697105177923,1697105180011.0,120,20.0,1.0,"[5, 2083]","[1697105177928, 1697105180011]"
291,880,7,[],200,EleutherAI/gpt-neox-20b,128,1,2283.0,1.0,1,H100,1697105180011,1697105182294.0,120,84.0,2.0,"[9, 2274]","[1697105180020, 1697105182294]"
292,450,0,[],200,EleutherAI/gpt-neox-20b,128,1,4582.0,1.0,1,H100,1697105154519,1697105159101.0,120,91.0,20.0,"[152, 1330, 77, 291, 65, 85, 563, 307, 84, 61, 81, 78, 359, 69, 86, 466, 161, 94, 92, 80]","[1697105154671, 1697105156001, 1697105156078, 1697105156369, 1697105156434, 1697105156519, 1697105157082, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159020, 1697105159100]"
293,280,8,[],200,EleutherAI/gpt-neox-20b,128,1,4878.0,1.0,1,H100,1697105182295,1697105187173.0,120,91.0,20.0,"[8, 2084, 83, 79, 78, 59, 215, 77, 58, 362, 74, 537, 88, 86, 406, 88, 79, 77, 59, 280]","[1697105182303, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185036, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186183, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186892, 1697105187172]"
294,557,1,[],200,EleutherAI/gpt-neox-20b,128,1,2279.0,1.0,1,H100,1697105156283,1697105158562.0,120,31.0,1.0,"[21, 2258]","[1697105156304, 1697105158562]"
295,635,9,[],200,EleutherAI/gpt-neox-20b,128,1,2762.0,1.0,1,H100,1697105177249,1697105180011.0,120,23.0,1.0,"[9, 2752]","[1697105177258, 1697105180010]"
296,916,2,[],200,EleutherAI/gpt-neox-20b,128,1,1054.0,1.0,1,H100,1697105158563,1697105159617.0,120,8.0,1.0,"[17, 1036]","[1697105158580, 1697105159616]"
297,348,3,[],200,EleutherAI/gpt-neox-20b,128,1,4542.0,1.0,1,H100,1697105159617,1697105164159.0,120,91.0,20.0,"[9, 1740, 93, 92, 87, 239, 89, 68, 68, 547, 85, 79, 361, 92, 87, 79, 251, 86, 85, 305]","[1697105159626, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159]"
298,718,1,[],200,EleutherAI/gpt-neox-20b,128,1,2053.0,1.0,1,H100,1697105155908,1697105157961.0,120,13.0,1.0,"[21, 2032]","[1697105155929, 1697105157961]"
299,639,9,[],200,EleutherAI/gpt-neox-20b,128,1,3420.0,1.0,1,H100,1697105187173,1697105190593.0,120,100.0,6.0,"[5, 2637, 90, 272, 165, 251]","[1697105187178, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593]"
300,63,10,[],200,EleutherAI/gpt-neox-20b,128,1,2747.0,1.0,1,H100,1697105180012,1697105182759.0,120,39.0,1.0,"[24, 2723]","[1697105180036, 1697105182759]"
301,444,7,[],200,EleutherAI/gpt-neox-20b,128,1,3363.0,1.0,1,H100,1697105177249,1697105180612.0,120,457.0,6.0,"[5, 2848, 85, 66, 280, 79]","[1697105177254, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612]"
302,425,11,[],200,EleutherAI/gpt-neox-20b,128,1,5946.0,1.0,1,H100,1697105182760,1697105188706.0,120,88.0,20.0,"[13, 2625, 74, 537, 87, 81, 412, 88, 79, 77, 59, 281, 83, 83, 83, 376, 89, 561, 94, 164]","[1697105182773, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186892, 1697105187173, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706]"
303,811,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105159103,1697105170014.0,120,,,"[36, 2738, 89, 68, 68, 547, 85, 79, 361, 92, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 342, 89, 82, 286, 68, 77, 469, 246, 209, 271, 116, 196, 133, 75, 460, 227, 76, 273, 231, 127, 144, 218, 181, 156]","[1697105159139, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165896, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005, 1697105169149, 1697105169367, 1697105169548, 1697105169704]"
304,68,10,[],200,EleutherAI/gpt-neox-20b,128,1,2083.0,1.0,1,H100,1697105190594,1697105192677.0,120,12.0,1.0,"[8, 2075]","[1697105190602, 1697105192677]"
305,149,2,[],200,EleutherAI/gpt-neox-20b,128,1,3675.0,1.0,1,H100,1697105157962,1697105161637.0,120,563.0,10.0,"[37, 2582, 93, 86, 87, 83, 436, 93, 92, 86]","[1697105157999, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637]"
306,707,4,[],200,EleutherAI/gpt-neox-20b,128,1,1501.0,1.0,1,H100,1697105164161,1697105165662.0,120,8.0,1.0,"[32, 1469]","[1697105164193, 1697105165662]"
307,267,1,[],200,EleutherAI/gpt-neox-20b,128,1,5022.0,1.0,1,H100,1697105155908,1697105160930.0,120,83.0,20.0,"[5, 2139, 69, 86, 466, 161, 94, 86, 87, 609, 92, 87, 85, 84, 79, 444, 92, 87, 87, 83]","[1697105155913, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159101, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930]"
308,132,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165663,1697105170013.0,120,,,"[8, 3208, 127, 143, 219, 181, 155]","[1697105165671, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
309,430,11,[],200,EleutherAI/gpt-neox-20b,128,1,2392.0,1.0,1,H100,1697105192678,1697105195070.0,120,15.0,1.0,"[9, 2383]","[1697105192687, 1697105195070]"
310,784,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105195071,1697105201998.0,120,,,"[9, 3609, 273, 410, 224, 231, 129, 150, 141, 79, 80, 219, 297, 80, 292, 160, 212]","[1697105195080, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200247, 1697105200326, 1697105200406, 1697105200625, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
311,621,2,[],200,EleutherAI/gpt-neox-20b,128,1,5889.0,1.0,1,H100,1697105160931,1697105166820.0,120,88.0,20.0,"[9, 2743, 86, 85, 306, 76, 371, 89, 89, 88, 79, 342, 88, 83, 286, 68, 78, 468, 247, 208]","[1697105160940, 1697105163683, 1697105163769, 1697105163854, 1697105164160, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165382, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166612, 1697105166820]"
312,787,12,[],200,EleutherAI/gpt-neox-20b,128,1,3422.0,1.0,1,H100,1697105188707,1697105192129.0,120,123.0,6.0,"[5, 2805, 162, 87, 281, 82]","[1697105188712, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129]"
313,884,1,[],200,EleutherAI/gpt-neox-20b,128,1,5760.0,1.0,1,H100,1697105160059,1697105165819.0,120,90.0,20.0,"[8, 3108, 91, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 343, 88, 82, 286, 68]","[1697105160067, 1697105163175, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819]"
314,229,0,[],200,EleutherAI/gpt-neox-20b,128,1,1380.0,1.0,1,H100,1697105154527,1697105155907.0,120,15.0,1.0,"[187, 1193]","[1697105154714, 1697105155907]"
315,586,1,[],200,EleutherAI/gpt-neox-20b,128,1,5022.0,1.0,1,H100,1697105155908,1697105160930.0,120,85.0,20.0,"[29, 2115, 69, 87, 465, 161, 94, 86, 87, 610, 91, 87, 85, 84, 79, 444, 93, 86, 87, 83]","[1697105155937, 1697105158052, 1697105158121, 1697105158208, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159101, 1697105159711, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930]"
316,885,0,[],200,EleutherAI/gpt-neox-20b,128,1,8658.0,1.0,1,H100,1697105154516,1697105163174.0,120,84.0,43.0,"[57, 1428, 76, 292, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86, 610, 92, 87, 85, 84, 78, 444, 93, 87, 86, 84, 436, 93, 92, 86, 240, 89, 68, 67, 548, 84, 79, 362]","[1697105154573, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160136, 1697105160580, 1697105160673, 1697105160760, 1697105160846, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162101, 1697105162649, 1697105162733, 1697105162812, 1697105163174]"
317,510,3,[],200,EleutherAI/gpt-neox-20b,128,1,2521.0,1.0,1,H100,1697105161639,1697105164160.0,120,79.0,2.0,"[4, 2517]","[1697105161643, 1697105164160]"
318,871,4,[],200,EleutherAI/gpt-neox-20b,128,1,3375.0,1.0,1,H100,1697105164161,1697105167536.0,120,123.0,6.0,"[40, 2619, 271, 116, 196, 133]","[1697105164201, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536]"
319,778,0,[],200,EleutherAI/gpt-neox-20b,128,1,9642.0,1.0,1,H100,1697105154517,1697105164159.0,120,16.0,50.0,"[65, 1419, 77, 291, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86, 610, 92, 87, 85, 84, 78, 445, 92, 87, 86, 84, 436, 93, 92, 86, 240, 89, 68, 67, 548, 84, 79, 362, 91, 88, 79, 251, 86, 85, 305]","[1697105154582, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160136, 1697105160581, 1697105160673, 1697105160760, 1697105160846, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162101, 1697105162649, 1697105162733, 1697105162812, 1697105163174, 1697105163265, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159]"
320,302,13,[],200,EleutherAI/gpt-neox-20b,128,1,5576.0,1.0,1,H100,1697105192130,1697105197706.0,120,85.0,20.0,"[4, 2602, 80, 79, 261, 325, 87, 116, 83, 176, 417, 282, 184, 264, 85, 62, 152, 158, 82, 77]","[1697105192134, 1697105194736, 1697105194816, 1697105194895, 1697105195156, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195943, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197389, 1697105197547, 1697105197629, 1697105197706]"
321,234,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105163355,1697105170013.0,120,,,"[12, 2294, 90, 68, 78, 468, 247, 208, 271, 116, 196, 133, 75, 460, 227, 76, 273, 232, 126, 144, 219, 181, 155]","[1697105163367, 1697105165661, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169005, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
322,274,6,[],200,EleutherAI/gpt-neox-20b,128,1,2790.0,1.0,1,H100,1697105176271,1697105179061.0,120,364.0,11.0,"[13, 1638, 94, 91, 88, 67, 86, 468, 91, 66, 88]","[1697105176284, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061]"
323,561,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105168299,1697105172155.0,120,,,"[4, 3460]","[1697105168303, 1697105171763]"
324,80,2,[],200,EleutherAI/gpt-neox-20b,128,1,1526.0,1.0,1,H100,1697105172158,1697105173684.0,120,13.0,1.0,"[14, 1512]","[1697105172172, 1697105173684]"
325,631,7,[],200,EleutherAI/gpt-neox-20b,128,1,10843.0,1.0,1,H100,1697105179062,1697105189905.0,120,216.0,50.0,"[4, 2658, 86, 76, 408, 89, 83, 384, 89, 88, 190, 87, 78, 373, 85, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 87, 81, 411, 88, 79, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90]","[1697105179066, 1697105181724, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183755, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905]"
326,656,14,[],200,EleutherAI/gpt-neox-20b,128,1,3128.0,1.0,1,H100,1697105197707,1697105200835.0,120,26.0,1.0,"[13, 3115]","[1697105197720, 1697105200835]"
327,597,4,[],200,EleutherAI/gpt-neox-20b,128,1,1656.0,1.0,1,H100,1697105170015,1697105171671.0,120,39.0,1.0,"[10, 1646]","[1697105170025, 1697105171671]"
328,83,15,[],200,EleutherAI/gpt-neox-20b,128,1,4511.0,1.0,1,H100,1697105200836,1697105205347.0,120,123.0,15.0,"[5, 2877, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87]","[1697105200841, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347]"
329,113,5,[],200,EleutherAI/gpt-neox-20b,128,1,1148.0,1.0,1,H100,1697105171673,1697105172821.0,120,13.0,1.0,"[32, 1116]","[1697105171705, 1697105172821]"
330,474,6,[],200,EleutherAI/gpt-neox-20b,128,1,6761.0,1.0,1,H100,1697105172825,1697105179586.0,120,109.0,33.0,"[32, 1824, 92, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69, 759, 82, 80, 63, 674, 94, 91, 88, 67, 86, 468, 91, 66, 88, 81, 356, 88]","[1697105172857, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586]"
331,205,0,[],200,EleutherAI/gpt-neox-20b,128,1,5275.0,1.0,1,H100,1697105154527,1697105159802.0,120,87.0,20.0,"[269, 1573, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 94, 86, 87, 609, 92]","[1697105154796, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159101, 1697105159710, 1697105159802]"
332,569,4,[],200,EleutherAI/gpt-neox-20b,128,1,3597.0,1.0,1,H100,1697105167612,1697105171209.0,120,16.0,1.0,"[17, 3580]","[1697105167629, 1697105171209]"
333,444,0,[],200,EleutherAI/gpt-neox-20b,128,1,2001.0,1.0,1,H100,1697105154518,1697105156519.0,120,457.0,6.0,"[170, 1313, 77, 291, 66, 84]","[1697105154688, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519]"
334,0,5,[],200,EleutherAI/gpt-neox-20b,128,1,10600.0,1.0,1,H100,1697105171210,1697105181810.0,120,244.0,50.0,"[61, 2513, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 98, 92, 89, 69, 88, 68, 69, 69, 759, 81, 81, 63, 674, 94, 91, 88, 67, 86, 468, 91, 66, 88, 81, 356, 88, 85, 65, 365, 86, 66, 280, 79, 75, 488, 81, 80, 387, 87]","[1697105171271, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175720, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177023, 1697105177104, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180101, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810]"
335,508,0,[],200,EleutherAI/gpt-neox-20b,128,1,4583.0,1.0,1,H100,1697105154518,1697105159101.0,120,86.0,20.0,"[105, 1378, 76, 292, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 94, 86, 86]","[1697105154623, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159100]"
336,394,0,[],200,EleutherAI/gpt-neox-20b,128,1,1759.0,1.0,1,H100,1697105154523,1697105156282.0,120,11.0,1.0,"[265, 1494]","[1697105154788, 1697105156282]"
337,807,1,[],200,EleutherAI/gpt-neox-20b,128,1,5582.0,1.0,1,H100,1697105156520,1697105162102.0,120,90.0,20.0,"[9, 3181, 92, 87, 85, 84, 79, 444, 93, 86, 86, 84, 436, 93, 92, 86, 240, 89, 68, 68]","[1697105156529, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160846, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102]"
338,757,1,[],200,EleutherAI/gpt-neox-20b,128,1,1678.0,1.0,1,H100,1697105156283,1697105157961.0,120,20.0,1.0,"[13, 1665]","[1697105156296, 1697105157961]"
339,233,1,[],200,EleutherAI/gpt-neox-20b,128,1,1679.0,1.0,1,H100,1697105156883,1697105158562.0,120,6.0,1.0,"[4, 1675]","[1697105156887, 1697105158562]"
340,409,7,[],200,EleutherAI/gpt-neox-20b,128,1,7041.0,1.0,1,H100,1697105174682,1697105181723.0,120,109.0,30.0,"[20, 2322, 81, 80, 63, 674, 95, 91, 87, 67, 86, 469, 90, 67, 87, 81, 356, 88, 85, 66, 365, 85, 66, 280, 79, 75, 488, 81, 80, 387]","[1697105174702, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178108, 1697105178195, 1697105178262, 1697105178348, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723]"
341,561,2,[],200,EleutherAI/gpt-neox-20b,128,1,4791.0,1.0,1,H100,1697105158563,1697105163354.0,120,87.0,20.0,"[17, 2001, 93, 86, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 85, 78, 362, 92, 88]","[1697105158580, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162812, 1697105163174, 1697105163266, 1697105163354]"
342,867,1,[],200,EleutherAI/gpt-neox-20b,128,1,5058.0,1.0,1,H100,1697105159102,1697105164160.0,120,91.0,20.0,"[9, 2255, 93, 92, 87, 239, 89, 68, 68, 547, 84, 80, 361, 92, 88, 78, 251, 86, 85, 306]","[1697105159111, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162733, 1697105162813, 1697105163174, 1697105163266, 1697105163354, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164160]"
343,614,0,[],200,EleutherAI/gpt-neox-20b,128,1,1390.0,1.0,1,H100,1697105154517,1697105155907.0,120,15.0,1.0,"[93, 1297]","[1697105154610, 1697105155907]"
344,724,1,[],200,EleutherAI/gpt-neox-20b,128,1,2278.0,1.0,1,H100,1697105156284,1697105158562.0,120,11.0,1.0,"[28, 2250]","[1697105156312, 1697105158562]"
345,47,1,[],200,EleutherAI/gpt-neox-20b,128,1,5022.0,1.0,1,H100,1697105155908,1697105160930.0,120,90.0,20.0,"[13, 2131, 69, 86, 466, 161, 94, 86, 87, 609, 92, 87, 85, 84, 79, 444, 93, 86, 87, 83]","[1697105155921, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159101, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930]"
346,239,2,[],200,EleutherAI/gpt-neox-20b,128,1,7046.0,1.0,1,H100,1697105162103,1697105169149.0,120,39.0,27.0,"[5, 2500, 88, 89, 88, 79, 343, 88, 82, 286, 68, 77, 470, 246, 208, 271, 116, 196, 133, 75, 460, 227, 76, 273, 231, 127, 144]","[1697105162108, 1697105164608, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165896, 1697105166366, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005, 1697105169149]"
347,567,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105169150,1697105172155.0,120,,,"[5, 2608]","[1697105169155, 1697105171763]"
348,927,4,[],200,EleutherAI/gpt-neox-20b,128,1,4107.0,1.0,1,H100,1697105172158,1697105176265.0,120,83.0,20.0,"[121, 1505, 80, 77, 72, 668, 93, 88, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 70]","[1697105172279, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174681, 1697105174774, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176265]"
349,126,2,[],200,EleutherAI/gpt-neox-20b,128,1,1830.0,1.0,1,H100,1697105158563,1697105160393.0,120,19.0,1.0,"[21, 1809]","[1697105158584, 1697105160393]"
350,478,1,[],200,EleutherAI/gpt-neox-20b,128,1,13097.0,1.0,1,H100,1697105155909,1697105169006.0,120,161.0,62.0,"[40, 2724, 161, 94, 88, 85, 610, 91, 87, 85, 84, 79, 444, 93, 86, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 84, 80, 361, 92, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 342, 88, 83, 286, 68, 77, 469, 246, 209, 271, 115, 197, 133, 75, 460, 227, 76, 273, 231, 127]","[1697105155949, 1697105158673, 1697105158834, 1697105158928, 1697105159016, 1697105159101, 1697105159711, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162733, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165382, 1697105165465, 1697105165751, 1697105165819, 1697105165896, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167206, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005]"
351,102,1,[],200,EleutherAI/gpt-neox-20b,128,1,5058.0,1.0,1,H100,1697105159102,1697105164160.0,120,84.0,20.0,"[17, 2247, 93, 92, 87, 239, 89, 68, 68, 547, 85, 79, 361, 92, 87, 79, 251, 86, 85, 306]","[1697105159119, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164160]"
352,376,2,[],200,EleutherAI/gpt-neox-20b,128,1,5889.0,1.0,1,H100,1697105160931,1697105166820.0,120,87.0,20.0,"[5, 2747, 86, 85, 306, 76, 371, 89, 89, 88, 79, 343, 88, 82, 286, 68, 78, 468, 246, 209]","[1697105160936, 1697105163683, 1697105163769, 1697105163854, 1697105164160, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820]"
353,837,1,[],200,EleutherAI/gpt-neox-20b,128,1,5760.0,1.0,1,H100,1697105160059,1697105165819.0,120,85.0,20.0,"[8, 3108, 91, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 343, 88, 82, 286, 68]","[1697105160067, 1697105163175, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819]"
354,321,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105168879,1697105172155.0,120,,,"[5, 2879]","[1697105168884, 1697105171763]"
355,426,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105169469,1697105172156.0,120,,,"[4, 2290]","[1697105169473, 1697105171763]"
356,659,0,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105154527,1697105170013.0,120,,,"[245, 1597, 66, 84, 562, 309, 83, 61, 81, 78, 359, 69, 86, 466, 161, 94, 92, 81, 609, 92, 87, 85, 84, 78, 445, 92, 87, 87, 83, 436, 93, 92, 86, 240, 89, 68, 67, 548, 84, 79, 362, 92, 87, 78, 252, 86, 85, 305, 77, 371, 89, 89, 87, 80, 342, 88, 83, 286, 68, 77, 469, 246, 209, 271, 115, 197, 133, 75, 460, 227, 76, 273, 231, 127, 144, 218, 181, 156]","[1697105154772, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157390, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159020, 1697105159101, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160136, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162101, 1697105162649, 1697105162733, 1697105162812, 1697105163174, 1697105163266, 1697105163353, 1697105163431, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164872, 1697105164952, 1697105165294, 1697105165382, 1697105165465, 1697105165751, 1697105165819, 1697105165896, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167206, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005, 1697105169149, 1697105169367, 1697105169548, 1697105169704]"
357,405,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105163977,1697105170013.0,120,,,"[4, 2385, 246, 208, 271, 116, 196, 133, 75, 460, 227, 76, 273, 232, 127, 143, 219, 181, 155]","[1697105163981, 1697105166366, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
358,494,0,[],200,EleutherAI/gpt-neox-20b,128,1,3017.0,1.0,1,H100,1697105154517,1697105157534.0,120,6.0,10.0,"[77, 1407, 77, 291, 66, 84, 562, 308, 84, 61]","[1697105154594, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534]"
359,234,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105164160,1697105170013.0,120,,,"[5, 2098, 102, 247, 208, 271, 116, 196, 133, 75, 460, 227, 76, 273, 232, 127, 143, 219, 181, 155]","[1697105164165, 1697105166263, 1697105166365, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
360,679,4,[],200,EleutherAI/gpt-neox-20b,128,1,1525.0,1.0,1,H100,1697105172159,1697105173684.0,120,15.0,1.0,"[56, 1469]","[1697105172215, 1697105173684]"
361,228,0,[],200,EleutherAI/gpt-neox-20b,128,1,5530.0,1.0,1,H100,1697105154528,1697105160058.0,120,100.0,20.0,"[344, 2210, 307, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86, 610, 92, 87, 85, 84]","[1697105154872, 1697105157082, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058]"
362,80,5,[],200,EleutherAI/gpt-neox-20b,128,1,1821.0,1.0,1,H100,1697105173686,1697105175507.0,120,13.0,1.0,"[44, 1777]","[1697105173730, 1697105175507]"
363,918,3,[],200,EleutherAI/gpt-neox-20b,128,1,3804.0,1.0,1,H100,1697105167404,1697105171208.0,120,23.0,1.0,"[5, 3799]","[1697105167409, 1697105171208]"
364,218,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170015,1697105172156.0,120,,,"[22, 1726]","[1697105170037, 1697105171763]"
365,345,4,[],200,EleutherAI/gpt-neox-20b,128,1,5054.0,1.0,1,H100,1697105171210,1697105176264.0,120,39.0,20.0,"[25, 2549, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 98, 92, 89, 69, 88, 68, 69, 69]","[1697105171235, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175720, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
366,545,4,[],200,EleutherAI/gpt-neox-20b,128,1,1855.0,1.0,1,H100,1697105172158,1697105174013.0,120,216.0,5.0,"[129, 1497, 80, 77, 72]","[1697105172287, 1697105173784, 1697105173864, 1697105173941, 1697105174013]"
367,748,7,[],200,EleutherAI/gpt-neox-20b,128,1,4267.0,1.0,1,H100,1697105176271,1697105180538.0,120,182.0,14.0,"[97, 2449, 90, 67, 87, 81, 356, 88, 85, 66, 365, 85, 66, 284]","[1697105176368, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180537]"
368,677,2,[],200,EleutherAI/gpt-neox-20b,128,1,1655.0,1.0,1,H100,1697105170016,1697105171671.0,120,9.0,1.0,"[153, 1502]","[1697105170169, 1697105171671]"
369,897,4,[],200,EleutherAI/gpt-neox-20b,128,1,4387.0,1.0,1,H100,1697105166821,1697105171208.0,120,9.0,1.0,"[16, 4371]","[1697105166837, 1697105171208]"
370,173,8,[],200,EleutherAI/gpt-neox-20b,128,1,4855.0,1.0,1,H100,1697105180544,1697105185399.0,120,96.0,20.0,"[9, 2297, 89, 88, 190, 87, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363]","[1697105180553, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398]"
371,699,3,[],200,EleutherAI/gpt-neox-20b,128,1,1849.0,1.0,1,H100,1697105163355,1697105165204.0,120,39.0,1.0,"[20, 1829]","[1697105163375, 1697105165204]"
372,776,8,[],200,EleutherAI/gpt-neox-20b,128,1,2604.0,1.0,1,H100,1697105180613,1697105183217.0,120,67.0,2.0,"[4, 2600]","[1697105180617, 1697105183217]"
373,124,4,[],200,EleutherAI/gpt-neox-20b,128,1,2866.0,1.0,1,H100,1697105165205,1697105168071.0,120,83.0,2.0,"[5, 2861]","[1697105165210, 1697105168071]"
374,202,9,[],200,EleutherAI/gpt-neox-20b,128,1,14411.0,1.0,1,H100,1697105183218,1697105197629.0,120,874.0,72.0,"[16, 2775, 88, 85, 406, 88, 79, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 162, 87, 281, 81, 276, 76, 286, 87, 83, 233, 83, 62, 305, 86, 190, 84, 64, 80, 266, 63, 85, 199, 80, 78, 261, 326, 87, 116, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82]","[1697105183234, 1697105186009, 1697105186097, 1697105186182, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192128, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193169, 1697105193252, 1697105193314, 1697105193619, 1697105193705, 1697105193895, 1697105193979, 1697105194043, 1697105194123, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629]"
375,130,2,[],200,EleutherAI/gpt-neox-20b,128,1,3030.0,1.0,1,H100,1697105165898,1697105168928.0,120,14.0,1.0,"[4, 3025]","[1697105165902, 1697105168927]"
376,480,3,[],200,EleutherAI/gpt-neox-20b,128,1,2279.0,1.0,1,H100,1697105168929,1697105171208.0,120,26.0,1.0,"[4, 2275]","[1697105168933, 1697105171208]"
377,840,4,[],200,EleutherAI/gpt-neox-20b,128,1,1610.0,1.0,1,H100,1697105171210,1697105172820.0,120,17.0,1.0,"[37, 1573]","[1697105171247, 1697105172820]"
378,269,5,[],200,EleutherAI/gpt-neox-20b,128,1,1757.0,1.0,1,H100,1697105172825,1697105174582.0,120,11.0,1.0,"[34, 1723]","[1697105172859, 1697105174582]"
379,603,6,[],200,EleutherAI/gpt-neox-20b,128,1,924.0,1.0,1,H100,1697105174583,1697105175507.0,120,9.0,1.0,"[9, 915]","[1697105174592, 1697105175507]"
380,34,7,[],200,EleutherAI/gpt-neox-20b,128,1,1421.0,1.0,1,H100,1697105175508,1697105176929.0,120,12.0,1.0,"[20, 1401]","[1697105175528, 1697105176929]"
381,392,8,[],200,EleutherAI/gpt-neox-20b,128,1,2380.0,1.0,1,H100,1697105176931,1697105179311.0,120,20.0,1.0,"[28, 2352]","[1697105176959, 1697105179311]"
382,751,9,[],200,EleutherAI/gpt-neox-20b,128,1,11281.0,1.0,1,H100,1697105179312,1697105190593.0,120,216.0,50.0,"[8, 2974, 89, 83, 384, 89, 88, 189, 88, 78, 373, 85, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 87, 81, 411, 88, 79, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 165, 250]","[1697105179320, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183216, 1697105183304, 1697105183382, 1697105183755, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592]"
383,342,2,[],200,EleutherAI/gpt-neox-20b,128,1,4345.0,1.0,1,H100,1697105161552,1697105165897.0,120,364.0,14.0,"[13, 2595, 77, 370, 89, 89, 88, 79, 342, 89, 82, 286, 68, 78]","[1697105161565, 1697105164160, 1697105164237, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897]"
384,532,9,[],200,EleutherAI/gpt-neox-20b,128,1,6282.0,1.0,1,H100,1697105185400,1697105191682.0,120,92.0,20.0,"[24, 3024, 94, 164, 81, 375, 87, 85, 481, 91, 271, 165, 250, 88, 251, 66, 87, 67, 366, 164]","[1697105185424, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189906, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191151, 1697105191517, 1697105191681]"
385,130,4,[],200,EleutherAI/gpt-neox-20b,128,1,2335.0,1.0,1,H100,1697105178108,1697105180443.0,120,14.0,1.0,"[9, 2326]","[1697105178117, 1697105180443]"
386,285,0,[],200,EleutherAI/gpt-neox-20b,128,1,6065.0,1.0,1,H100,1697105154516,1697105160581.0,120,100.0,27.0,"[61, 1424, 77, 291, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86, 610, 92, 87, 85, 84, 78, 445]","[1697105154577, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160136, 1697105160581]"
387,70,2,[],200,EleutherAI/gpt-neox-20b,128,1,4387.0,1.0,1,H100,1697105166821,1697105171208.0,120,39.0,1.0,"[16, 4371]","[1697105166837, 1697105171208]"
388,430,3,[],200,EleutherAI/gpt-neox-20b,128,1,1610.0,1.0,1,H100,1697105171210,1697105172820.0,120,15.0,1.0,"[25, 1585]","[1697105171235, 1697105172820]"
389,408,4,[],200,EleutherAI/gpt-neox-20b,128,1,1477.0,1.0,1,H100,1697105164786,1697105166263.0,120,16.0,1.0,"[5, 1472]","[1697105164791, 1697105166263]"
390,874,4,[],200,EleutherAI/gpt-neox-20b,128,1,9644.0,1.0,1,H100,1697105172822,1697105182466.0,120,140.0,50.0,"[5, 1853, 93, 89, 68, 86, 84, 522, 99, 91, 89, 70, 87, 68, 69, 69, 759, 82, 80, 63, 674, 94, 91, 88, 67, 86, 468, 91, 66, 88, 81, 356, 88, 85, 65, 366, 85, 66, 280, 79, 75, 488, 81, 80, 387, 87, 75, 408, 89, 84]","[1697105172827, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181885, 1697105182293, 1697105182382, 1697105182466]"
391,273,5,[],200,EleutherAI/gpt-neox-20b,128,1,3671.0,1.0,1,H100,1697105167537,1697105171208.0,120,19.0,1.0,"[12, 3659]","[1697105167549, 1697105171208]"
392,626,6,[],200,EleutherAI/gpt-neox-20b,128,1,1610.0,1.0,1,H100,1697105171210,1697105172820.0,120,10.0,1.0,"[41, 1569]","[1697105171251, 1697105172820]"
393,737,5,[],200,EleutherAI/gpt-neox-20b,128,1,5499.0,1.0,1,H100,1697105166264,1697105171763.0,120,216.0,2.0,"[4, 4940, 555]","[1697105166268, 1697105171208, 1697105171763]"
394,49,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105166821,1697105172156.0,120,,,"[4, 4938]","[1697105166825, 1697105171763]"
395,405,4,[],200,EleutherAI/gpt-neox-20b,128,1,4106.0,1.0,1,H100,1697105172159,1697105176265.0,120,87.0,20.0,"[222, 1403, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 70, 87, 69, 69, 69]","[1697105172381, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176196, 1697105176265]"
396,99,0,[],200,EleutherAI/gpt-neox-20b,128,1,1390.0,1.0,1,H100,1697105154517,1697105155907.0,120,10.0,1.0,"[69, 1321]","[1697105154586, 1697105155907]"
397,449,1,[],200,EleutherAI/gpt-neox-20b,128,1,5022.0,1.0,1,H100,1697105155908,1697105160930.0,120,86.0,20.0,"[9, 2135, 69, 86, 466, 161, 94, 86, 87, 609, 92, 87, 85, 84, 79, 444, 92, 87, 87, 83]","[1697105155917, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159101, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930]"
398,718,0,[],200,EleutherAI/gpt-neox-20b,128,1,1754.0,1.0,1,H100,1697105154528,1697105156282.0,120,13.0,1.0,"[292, 1462]","[1697105154820, 1697105156282]"
399,202,0,[],200,EleutherAI/gpt-neox-20b,128,1,13782.0,1.0,1,H100,1697105154516,1697105168298.0,120,874.0,72.0,"[38, 1447, 76, 292, 66, 84, 562, 308, 84, 61, 81, 78, 358, 69, 87, 466, 161, 93, 87, 86, 610, 92, 87, 85, 84, 78, 444, 93, 87, 86, 84, 436, 92, 93, 86, 240, 89, 68, 67, 548, 84, 79, 362, 91, 88, 79, 251, 86, 85, 305, 77, 371, 89, 89, 87, 80, 342, 88, 83, 286, 68, 77, 469, 246, 209, 271, 115, 197, 133, 75, 460, 227]","[1697105154554, 1697105156001, 1697105156077, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158120, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160136, 1697105160580, 1697105160673, 1697105160760, 1697105160846, 1697105160930, 1697105161366, 1697105161458, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162101, 1697105162649, 1697105162733, 1697105162812, 1697105163174, 1697105163265, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164872, 1697105164952, 1697105165294, 1697105165382, 1697105165465, 1697105165751, 1697105165819, 1697105165896, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167206, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298]"
400,233,1,[],200,EleutherAI/gpt-neox-20b,128,1,1677.0,1.0,1,H100,1697105156284,1697105157961.0,120,6.0,1.0,"[24, 1653]","[1697105156308, 1697105157961]"
401,389,1,[],200,EleutherAI/gpt-neox-20b,128,1,1678.0,1.0,1,H100,1697105156283,1697105157961.0,120,8.0,1.0,"[17, 1661]","[1697105156300, 1697105157961]"
402,593,2,[],200,EleutherAI/gpt-neox-20b,128,1,2712.0,1.0,1,H100,1697105157962,1697105160674.0,120,335.0,9.0,"[20, 1729, 91, 87, 85, 84, 79, 444, 93]","[1697105157982, 1697105159711, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674]"
403,754,2,[],200,EleutherAI/gpt-neox-20b,128,1,2175.0,1.0,1,H100,1697105157962,1697105160137.0,120,88.0,7.0,"[16, 1733, 91, 87, 85, 84, 79]","[1697105157978, 1697105159711, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137]"
404,185,3,[],200,EleutherAI/gpt-neox-20b,128,1,5681.0,1.0,1,H100,1697105160138,1697105165819.0,120,93.0,20.0,"[4, 3032, 92, 87, 79, 251, 86, 85, 305, 77, 372, 88, 89, 88, 79, 343, 88, 82, 286, 68]","[1697105160142, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164608, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819]"
405,538,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170016,1697105172156.0,120,,,"[21, 1726]","[1697105170037, 1697105171763]"
406,896,5,[],200,EleutherAI/gpt-neox-20b,128,1,1525.0,1.0,1,H100,1697105172159,1697105173684.0,120,15.0,1.0,"[237, 1288]","[1697105172396, 1697105173684]"
407,410,6,[],200,EleutherAI/gpt-neox-20b,128,1,2286.0,1.0,1,H100,1697105173685,1697105175971.0,120,364.0,12.0,"[24, 972, 92, 89, 68, 86, 84, 522, 99, 91, 89, 69]","[1697105173709, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970]"
408,186,2,[],200,EleutherAI/gpt-neox-20b,128,1,4772.0,1.0,1,H100,1697105157962,1697105162734.0,120,123.0,22.0,"[28, 1721, 91, 87, 85, 84, 79, 444, 93, 86, 87, 83, 436, 93, 92, 87, 239, 89, 68, 67, 548, 85]","[1697105157990, 1697105159711, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162101, 1697105162649, 1697105162734]"
409,312,2,[],200,EleutherAI/gpt-neox-20b,128,1,2744.0,1.0,1,H100,1697105165820,1697105168564.0,120,23.0,1.0,"[20, 2724]","[1697105165840, 1697105168564]"
410,675,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105168565,1697105172155.0,120,,,"[4, 3194]","[1697105168569, 1697105171763]"
411,769,8,[],200,EleutherAI/gpt-neox-20b,128,1,4953.0,1.0,1,H100,1697105181724,1697105186677.0,120,47.0,20.0,"[5, 2025, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 88, 81, 411, 88]","[1697105181729, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186178, 1697105186589, 1697105186677]"
412,103,4,[],200,EleutherAI/gpt-neox-20b,128,1,1526.0,1.0,1,H100,1697105172158,1697105173684.0,120,15.0,1.0,"[114, 1412]","[1697105172272, 1697105173684]"
413,436,5,[],200,EleutherAI/gpt-neox-20b,128,1,3563.0,1.0,1,H100,1697105173685,1697105177248.0,120,86.0,20.0,"[33, 963, 92, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 69, 68, 69, 760, 81, 80, 63]","[1697105173718, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176127, 1697105176195, 1697105176264, 1697105177024, 1697105177105, 1697105177185, 1697105177248]"
414,837,0,[],200,EleutherAI/gpt-neox-20b,128,1,4582.0,1.0,1,H100,1697105154518,1697105159100.0,120,85.0,20.0,"[84, 1399, 77, 291, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86]","[1697105154602, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100]"
415,431,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105164161,1697105170013.0,120,,,"[20, 2639, 271, 116, 196, 133, 75, 460, 227, 76, 273, 231, 128, 143, 219, 181, 155]","[1697105164181, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
416,598,5,[],200,EleutherAI/gpt-neox-20b,128,1,4412.0,1.0,1,H100,1697105171210,1697105175622.0,120,345.0,12.0,"[5, 2569, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522]","[1697105171215, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622]"
417,499,1,[],200,EleutherAI/gpt-neox-20b,128,1,5146.0,1.0,1,H100,1697105158208,1697105163354.0,120,88.0,20.0,"[5, 2368, 93, 86, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 85, 79, 362, 91, 88]","[1697105158213, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163175, 1697105163266, 1697105163354]"
418,702,2,[],200,EleutherAI/gpt-neox-20b,128,1,5851.0,1.0,1,H100,1697105161552,1697105167403.0,120,89.0,20.0,"[13, 2595, 77, 370, 89, 89, 88, 79, 342, 89, 82, 286, 68, 78, 468, 247, 208, 271, 116, 196]","[1697105161565, 1697105164160, 1697105164237, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403]"
419,422,2,[],200,EleutherAI/gpt-neox-20b,128,1,1564.0,1.0,1,H100,1697105164874,1697105166438.0,120,26.0,1.0,"[12, 1552]","[1697105164886, 1697105166438]"
420,313,1,[],200,EleutherAI/gpt-neox-20b,128,1,2001.0,1.0,1,H100,1697105157616,1697105159617.0,120,20.0,1.0,"[5, 1995]","[1697105157621, 1697105159616]"
421,670,2,[],200,EleutherAI/gpt-neox-20b,128,1,4152.0,1.0,1,H100,1697105159618,1697105163770.0,120,67.0,18.0,"[8, 1740, 93, 92, 87, 239, 89, 68, 68, 547, 85, 79, 361, 92, 87, 79, 251, 86]","[1697105159626, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769]"
422,856,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105163355,1697105170013.0,120,,,"[16, 2380, 68, 78, 468, 246, 209, 271, 116, 196, 133, 75, 460, 227, 76, 273, 232, 127, 143, 219, 181, 155]","[1697105163371, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
423,438,6,[],200,EleutherAI/gpt-neox-20b,128,1,1421.0,1.0,1,H100,1697105175508,1697105176929.0,120,9.0,1.0,"[20, 1401]","[1697105175528, 1697105176929]"
424,797,7,[],200,EleutherAI/gpt-neox-20b,128,1,1704.0,1.0,1,H100,1697105176931,1697105178635.0,120,26.0,1.0,"[24, 1680]","[1697105176955, 1697105178635]"
425,226,8,[],200,EleutherAI/gpt-neox-20b,128,1,10070.0,1.0,1,H100,1697105178636,1697105188706.0,120,216.0,47.0,"[5, 2431, 103, 81, 80, 387, 87, 76, 408, 89, 83, 384, 89, 88, 190, 87, 78, 373, 85, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 87, 81, 411, 88, 79, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164]","[1697105178641, 1697105181072, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183755, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706]"
426,710,5,[],200,EleutherAI/gpt-neox-20b,128,1,1461.0,1.0,1,H100,1697105176271,1697105177732.0,120,14.0,1.0,"[53, 1408]","[1697105176324, 1697105177732]"
427,119,0,[],200,EleutherAI/gpt-neox-20b,128,1,2323.0,1.0,1,H100,1697105154559,1697105156882.0,120,31.0,1.0,"[318, 2005]","[1697105154877, 1697105156882]"
428,13,0,[],200,EleutherAI/gpt-neox-20b,128,1,4582.0,1.0,1,H100,1697105154519,1697105159101.0,120,90.0,20.0,"[155, 1327, 77, 291, 65, 85, 562, 308, 84, 61, 81, 78, 359, 69, 86, 466, 161, 94, 90, 82]","[1697105154674, 1697105156001, 1697105156078, 1697105156369, 1697105156434, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159018, 1697105159100]"
429,476,1,[],200,EleutherAI/gpt-neox-20b,128,1,10653.0,1.0,1,H100,1697105156883,1697105167536.0,120,6.0,50.0,"[8, 2819, 92, 87, 85, 84, 79, 444, 92, 87, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 85, 79, 361, 92, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 342, 89, 82, 286, 68, 77, 469, 246, 209, 271, 115, 197, 133]","[1697105156891, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165896, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167206, 1697105167403, 1697105167536]"
430,699,3,[],200,EleutherAI/gpt-neox-20b,128,1,3173.0,1.0,1,H100,1697105165898,1697105169071.0,120,39.0,1.0,"[8, 3165]","[1697105165906, 1697105169071]"
431,151,9,[],200,EleutherAI/gpt-neox-20b,128,1,1998.0,1.0,1,H100,1697105174931,1697105176929.0,120,39.0,1.0,"[5, 1993]","[1697105174936, 1697105176929]"
432,595,10,[],200,EleutherAI/gpt-neox-20b,128,1,802.0,1.0,1,H100,1697105176930,1697105177732.0,120,8.0,1.0,"[13, 789]","[1697105176943, 1697105177732]"
433,101,4,[],200,EleutherAI/gpt-neox-20b,128,1,2137.0,1.0,1,H100,1697105169072,1697105171209.0,120,13.0,1.0,"[8, 2128]","[1697105169080, 1697105171208]"
434,22,11,[],200,EleutherAI/gpt-neox-20b,128,1,2277.0,1.0,1,H100,1697105177734,1697105180011.0,120,16.0,1.0,"[16, 2260]","[1697105177750, 1697105180010]"
435,458,5,[],200,EleutherAI/gpt-neox-20b,128,1,1610.0,1.0,1,H100,1697105171211,1697105172821.0,120,11.0,1.0,"[60, 1550]","[1697105171271, 1697105172821]"
436,376,12,[],200,EleutherAI/gpt-neox-20b,128,1,4891.0,1.0,1,H100,1697105180011,1697105184902.0,120,87.0,20.0,"[13, 2270, 89, 83, 384, 89, 88, 190, 87, 78, 373, 86, 84, 78, 384, 83, 79, 78, 59, 215]","[1697105180024, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183755, 1697105183841, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901]"
437,132,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170015,1697105172154.0,120,,,"[31, 1717]","[1697105170046, 1697105171763]"
438,812,6,[],200,EleutherAI/gpt-neox-20b,128,1,1757.0,1.0,1,H100,1697105172825,1697105174582.0,120,16.0,1.0,"[30, 1727]","[1697105172855, 1697105174582]"
439,493,4,[],200,EleutherAI/gpt-neox-20b,128,1,4109.0,1.0,1,H100,1697105172156,1697105176265.0,120,83.0,20.0,"[32, 1596, 80, 77, 72, 668, 92, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69]","[1697105172188, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
440,642,1,[],200,EleutherAI/gpt-neox-20b,128,1,5237.0,1.0,1,H100,1697105160582,1697105165819.0,120,89.0,20.0,"[4, 2589, 91, 88, 78, 251, 86, 85, 306, 76, 372, 88, 89, 88, 79, 343, 88, 82, 286, 68]","[1697105160586, 1697105163175, 1697105163266, 1697105163354, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164160, 1697105164236, 1697105164608, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819]"
441,698,1,[],200,EleutherAI/gpt-neox-20b,128,1,3463.0,1.0,1,H100,1697105159803,1697105163266.0,120,182.0,6.0,"[9, 2837, 85, 79, 361, 92]","[1697105159812, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266]"
442,771,7,[],200,EleutherAI/gpt-neox-20b,128,1,4562.0,1.0,1,H100,1697105175971,1697105180533.0,120,47.0,20.0,"[5, 1946, 94, 91, 88, 67, 86, 468, 91, 66, 88, 81, 356, 88, 85, 66, 365, 85, 66, 280]","[1697105175976, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180533]"
443,416,6,[],200,EleutherAI/gpt-neox-20b,128,1,10137.0,1.0,1,H100,1697105171673,1697105181810.0,120,286.0,50.0,"[24, 2087, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69, 759, 81, 81, 63, 674, 94, 91, 88, 67, 86, 468, 91, 66, 88, 81, 356, 88, 85, 65, 365, 86, 66, 280, 79, 75, 488, 81, 80, 387, 87]","[1697105171697, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177023, 1697105177104, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180101, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810]"
444,390,8,[],200,EleutherAI/gpt-neox-20b,128,1,5163.0,1.0,1,H100,1697105179738,1697105184901.0,120,84.0,20.0,"[16, 2540, 89, 83, 383, 90, 88, 190, 87, 78, 373, 85, 85, 78, 384, 83, 79, 78, 59, 215]","[1697105179754, 1697105182294, 1697105182383, 1697105182466, 1697105182849, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183755, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901]"
445,323,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105167612,1697105172155.0,120,,,"[13, 4138]","[1697105167625, 1697105171763]"
446,919,3,[],200,EleutherAI/gpt-neox-20b,128,1,1849.0,1.0,1,H100,1697105163355,1697105165204.0,120,14.0,1.0,"[20, 1829]","[1697105163375, 1697105165204]"
447,349,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165205,1697105170013.0,120,,,"[13, 2853, 227, 76, 273, 232, 127, 143, 219, 181, 155]","[1697105165218, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
448,732,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170015,1697105172156.0,120,,,"[11, 1737]","[1697105170026, 1697105171763]"
449,161,4,[],200,EleutherAI/gpt-neox-20b,128,1,2615.0,1.0,1,H100,1697105172159,1697105174774.0,120,109.0,7.0,"[57, 1568, 80, 77, 72, 668, 93]","[1697105172216, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174681, 1697105174774]"
450,462,2,[],200,EleutherAI/gpt-neox-20b,128,1,2102.0,1.0,1,H100,1697105164161,1697105166263.0,120,52.0,1.0,"[24, 2078]","[1697105164185, 1697105166263]"
451,811,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105166264,1697105172156.0,120,,,"[8, 5491]","[1697105166272, 1697105171763]"
452,703,5,[],200,EleutherAI/gpt-neox-20b,128,1,1655.0,1.0,1,H100,1697105170016,1697105171671.0,120,12.0,1.0,"[98, 1557]","[1697105170114, 1697105171671]"
453,613,0,[],200,EleutherAI/gpt-neox-20b,128,1,5275.0,1.0,1,H100,1697105154527,1697105159802.0,120,90.0,20.0,"[265, 1577, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 94, 92, 81, 609, 92]","[1697105154792, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159020, 1697105159101, 1697105159710, 1697105159802]"
454,239,4,[],200,EleutherAI/gpt-neox-20b,128,1,5948.0,1.0,1,H100,1697105172159,1697105178107.0,120,39.0,27.0,"[233, 1392, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 70, 87, 68, 69, 69, 759, 82, 80, 63, 674, 94, 91]","[1697105172392, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107]"
455,517,5,[],200,EleutherAI/gpt-neox-20b,128,1,2154.0,1.0,1,H100,1697105174775,1697105176929.0,120,15.0,1.0,"[4, 2150]","[1697105174779, 1697105176929]"
456,871,6,[],200,EleutherAI/gpt-neox-20b,128,1,2212.0,1.0,1,H100,1697105176930,1697105179142.0,120,123.0,6.0,"[13, 1874, 90, 67, 87, 81]","[1697105176943, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142]"
457,135,6,[],200,EleutherAI/gpt-neox-20b,128,1,2112.0,1.0,1,H100,1697105171672,1697105173784.0,120,52.0,2.0,"[5, 2107]","[1697105171677, 1697105173784]"
458,865,1,[],200,EleutherAI/gpt-neox-20b,128,1,1291.0,1.0,1,H100,1697105159102,1697105160393.0,120,9.0,1.0,"[5, 1286]","[1697105159107, 1697105160393]"
459,581,7,[],200,EleutherAI/gpt-neox-20b,128,1,4564.0,1.0,1,H100,1697105173785,1697105178349.0,120,47.0,20.0,"[13, 1824, 99, 91, 89, 70, 87, 69, 68, 69, 759, 81, 81, 63, 674, 94, 91, 88, 67, 87]","[1697105173798, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176264, 1697105177023, 1697105177104, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178349]"
460,298,3,[],200,EleutherAI/gpt-neox-20b,128,1,3597.0,1.0,1,H100,1697105167612,1697105171209.0,120,17.0,1.0,"[17, 3580]","[1697105167629, 1697105171209]"
461,38,1,[],200,EleutherAI/gpt-neox-20b,128,1,5580.0,1.0,1,H100,1697105159803,1697105165383.0,120,88.0,20.0,"[9, 2837, 85, 79, 361, 92, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 342, 89]","[1697105159812, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165383]"
462,301,7,[],200,EleutherAI/gpt-neox-20b,128,1,7445.0,1.0,1,H100,1697105179143,1697105186588.0,120,109.0,31.0,"[5, 2576, 86, 76, 408, 89, 83, 384, 89, 88, 189, 88, 78, 373, 85, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 87, 81, 411]","[1697105179148, 1697105181724, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183216, 1697105183304, 1697105183382, 1697105183755, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186588]"
463,401,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165384,1697105170013.0,120,,,"[4, 3259, 232, 127, 143, 219, 181, 155]","[1697105165388, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
464,729,3,[],200,EleutherAI/gpt-neox-20b,128,1,1748.0,1.0,1,H100,1697105170015,1697105171763.0,120,874.0,2.0,"[6, 1742]","[1697105170021, 1697105171763]"
465,160,4,[],200,EleutherAI/gpt-neox-20b,128,1,1057.0,1.0,1,H100,1697105171764,1697105172821.0,120,13.0,1.0,"[5, 1052]","[1697105171769, 1697105172821]"
466,657,4,[],200,EleutherAI/gpt-neox-20b,128,1,1610.0,1.0,1,H100,1697105171211,1697105172821.0,120,10.0,1.0,"[68, 1542]","[1697105171279, 1697105172821]"
467,517,5,[],200,EleutherAI/gpt-neox-20b,128,1,1757.0,1.0,1,H100,1697105172825,1697105174582.0,120,15.0,1.0,"[40, 1717]","[1697105172865, 1697105174582]"
468,289,2,[],200,EleutherAI/gpt-neox-20b,128,1,5425.0,1.0,1,H100,1697105160394,1697105165819.0,120,89.0,20.0,"[5, 2776, 91, 88, 78, 251, 86, 85, 306, 76, 372, 88, 89, 88, 79, 343, 88, 82, 286, 68]","[1697105160399, 1697105163175, 1697105163266, 1697105163354, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164160, 1697105164236, 1697105164608, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819]"
469,13,8,[],200,EleutherAI/gpt-neox-20b,128,1,5405.0,1.0,1,H100,1697105178350,1697105183755.0,120,90.0,20.0,"[13, 2170, 79, 76, 487, 81, 80, 387, 87, 76, 408, 89, 83, 384, 89, 88, 190, 87, 78, 373]","[1697105178363, 1697105180533, 1697105180612, 1697105180688, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183755]"
470,86,5,[],200,EleutherAI/gpt-neox-20b,128,1,4199.0,1.0,1,H100,1697105172825,1697105177024.0,120,335.0,17.0,"[28, 1828, 92, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69, 759]","[1697105172853, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177023]"
471,369,9,[],200,EleutherAI/gpt-neox-20b,128,1,4952.0,1.0,1,H100,1697105183755,1697105188707.0,120,216.0,15.0,"[9, 2825, 88, 79, 77, 60, 279, 84, 83, 83, 376, 89, 561, 94, 165]","[1697105183764, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186893, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188707]"
472,570,5,[],200,EleutherAI/gpt-neox-20b,128,1,2335.0,1.0,1,H100,1697105178108,1697105180443.0,120,18.0,1.0,"[9, 2326]","[1697105178117, 1697105180443]"
473,2,6,[],200,EleutherAI/gpt-neox-20b,128,1,2860.0,1.0,1,H100,1697105180444,1697105183304.0,120,58.0,6.0,"[8, 2398, 89, 88, 190, 87]","[1697105180452, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304]"
474,727,10,[],200,EleutherAI/gpt-neox-20b,128,1,3339.0,1.0,1,H100,1697105188708,1697105192047.0,120,58.0,5.0,"[28, 2781, 166, 83, 281]","[1697105188736, 1697105191517, 1697105191683, 1697105191766, 1697105192047]"
475,364,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105183307,1697105201998.0,120,,,"[14, 2688, 88, 85, 406, 89, 78, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 162, 87, 281, 81, 276, 76, 286, 87, 83, 234, 82, 62, 305, 87, 189, 84, 63, 81, 266, 63, 85, 199, 80, 78, 261, 326, 87, 116, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 326, 212, 117, 63, 264, 273, 411, 224, 230, 130, 150, 140, 81, 79, 219, 297, 80, 292, 160, 212]","[1697105183321, 1697105186009, 1697105186097, 1697105186182, 1697105186588, 1697105186677, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192128, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193619, 1697105193706, 1697105193895, 1697105193979, 1697105194042, 1697105194123, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198688, 1697105198961, 1697105199372, 1697105199596, 1697105199826, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200625, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
476,645,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165820,1697105170013.0,120,,,"[13, 3535, 181, 155]","[1697105165833, 1697105169368, 1697105169549, 1697105169704]"
477,262,2,[],200,EleutherAI/gpt-neox-20b,128,1,2975.0,1.0,1,H100,1697105165820,1697105168795.0,120,39.0,1.0,"[24, 2950]","[1697105165844, 1697105168794]"
478,74,4,[],200,EleutherAI/gpt-neox-20b,128,1,6247.0,1.0,1,H100,1697105170017,1697105176264.0,120,88.0,20.0,"[164, 3603, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 98, 92, 89, 69, 88, 68, 69, 69]","[1697105170181, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175720, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
479,625,3,[],200,EleutherAI/gpt-neox-20b,128,1,2968.0,1.0,1,H100,1697105168795,1697105171763.0,120,364.0,2.0,"[5, 2963]","[1697105168800, 1697105171763]"
480,203,1,[],200,EleutherAI/gpt-neox-20b,128,1,4486.0,1.0,1,H100,1697105164161,1697105168647.0,120,364.0,13.0,"[12, 2193, 246, 208, 271, 116, 196, 133, 75, 460, 227, 76, 273]","[1697105164173, 1697105166366, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647]"
481,54,4,[],200,EleutherAI/gpt-neox-20b,128,1,4500.0,1.0,1,H100,1697105171764,1697105176264.0,120,87.0,20.0,"[9, 2012, 79, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69]","[1697105171773, 1697105173785, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
482,564,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105168648,1697105172155.0,120,,,"[5, 3110]","[1697105168653, 1697105171763]"
483,14,1,[],200,EleutherAI/gpt-neox-20b,128,1,5057.0,1.0,1,H100,1697105159103,1697105164160.0,120,90.0,20.0,"[12, 2251, 93, 92, 87, 239, 89, 68, 68, 547, 84, 80, 362, 91, 87, 79, 251, 86, 85, 306]","[1697105159115, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162733, 1697105162813, 1697105163175, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164160]"
484,894,3,[],200,EleutherAI/gpt-neox-20b,128,1,1526.0,1.0,1,H100,1697105172158,1697105173684.0,120,14.0,1.0,"[10, 1516]","[1697105172168, 1697105173684]"
485,433,5,[],200,EleutherAI/gpt-neox-20b,128,1,1652.0,1.0,1,H100,1697105176271,1697105177923.0,120,109.0,2.0,"[57, 1595]","[1697105176328, 1697105177923]"
486,730,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105166821,1697105172155.0,120,,,"[4, 4938]","[1697105166825, 1697105171763]"
487,881,6,[],200,EleutherAI/gpt-neox-20b,128,1,2688.0,1.0,1,H100,1697105177924,1697105180612.0,120,58.0,6.0,"[12, 2166, 85, 67, 279, 79]","[1697105177936, 1697105180102, 1697105180187, 1697105180254, 1697105180533, 1697105180612]"
488,160,4,[],200,EleutherAI/gpt-neox-20b,128,1,1525.0,1.0,1,H100,1697105172159,1697105173684.0,120,13.0,1.0,"[226, 1299]","[1697105172385, 1697105173684]"
489,327,4,[],200,EleutherAI/gpt-neox-20b,128,1,2127.0,1.0,1,H100,1697105173685,1697105175812.0,120,563.0,10.0,"[4, 992, 92, 89, 68, 86, 84, 522, 99, 91]","[1697105173689, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812]"
490,314,7,[],200,EleutherAI/gpt-neox-20b,128,1,4422.0,1.0,1,H100,1697105180613,1697105185035.0,120,335.0,13.0,"[8, 3133, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57]","[1697105180621, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035]"
491,787,5,[],200,EleutherAI/gpt-neox-20b,128,1,2521.0,1.0,1,H100,1697105172159,1697105174680.0,120,123.0,6.0,"[221, 1404, 80, 77, 72, 667]","[1697105172380, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680]"
492,646,1,[],200,EleutherAI/gpt-neox-20b,128,1,1468.0,1.0,1,H100,1697105159803,1697105161271.0,120,14.0,1.0,"[13, 1455]","[1697105159816, 1697105161271]"
493,74,2,[],200,EleutherAI/gpt-neox-20b,128,1,5548.0,1.0,1,H100,1697105161272,1697105166820.0,120,88.0,20.0,"[12, 2399, 87, 84, 306, 77, 370, 89, 89, 88, 79, 342, 89, 82, 286, 68, 78, 468, 246, 209]","[1697105161284, 1697105163683, 1697105163770, 1697105163854, 1697105164160, 1697105164237, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820]"
494,415,5,[],200,EleutherAI/gpt-neox-20b,128,1,6023.0,1.0,1,H100,1697105176271,1697105182294.0,120,109.0,29.0,"[37, 1614, 95, 90, 88, 68, 86, 467, 91, 66, 88, 81, 356, 88, 85, 65, 366, 85, 66, 285, 74, 75, 488, 81, 80, 387, 87, 76, 408]","[1697105176308, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178263, 1697105178349, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180538, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294]"
495,684,5,[],200,EleutherAI/gpt-neox-20b,128,1,4720.0,1.0,1,H100,1697105175813,1697105180533.0,120,100.0,20.0,"[5, 2104, 94, 91, 88, 67, 86, 468, 91, 66, 88, 81, 357, 87, 85, 66, 365, 85, 66, 280]","[1697105175818, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179499, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180533]"
496,308,0,[],200,EleutherAI/gpt-neox-20b,128,1,5530.0,1.0,1,H100,1697105154528,1697105160058.0,120,87.0,20.0,"[340, 2214, 307, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86, 610, 92, 87, 85, 84]","[1697105154868, 1697105157082, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058]"
497,758,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170015,1697105172156.0,120,,,"[6, 1742]","[1697105170021, 1697105171763]"
498,189,5,[],200,EleutherAI/gpt-neox-20b,128,1,4105.0,1.0,1,H100,1697105172159,1697105176264.0,120,88.0,20.0,"[230, 1395, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 70, 87, 69, 68, 69]","[1697105172389, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176264]"
499,831,1,[],200,EleutherAI/gpt-neox-20b,128,1,2227.0,1.0,1,H100,1697105161367,1697105163594.0,120,11.0,1.0,"[5, 2222]","[1697105161372, 1697105163594]"
500,233,2,[],200,EleutherAI/gpt-neox-20b,128,1,2067.0,1.0,1,H100,1697105163595,1697105165662.0,120,6.0,1.0,"[17, 2050]","[1697105163612, 1697105165662]"
501,591,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165663,1697105170013.0,120,,,"[12, 3204, 127, 143, 219, 181, 155]","[1697105165675, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
502,664,1,[],200,EleutherAI/gpt-neox-20b,128,1,4101.0,1.0,1,H100,1697105160059,1697105164160.0,120,364.0,9.0,"[12, 3103, 92, 87, 79, 251, 86, 85, 306]","[1697105160071, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164160]"
503,21,4,[],200,EleutherAI/gpt-neox-20b,128,1,1655.0,1.0,1,H100,1697105170016,1697105171671.0,120,15.0,1.0,"[73, 1582]","[1697105170089, 1697105171671]"
504,404,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105166821,1697105172156.0,120,,,"[12, 4930]","[1697105166833, 1697105171763]"
505,542,6,[],200,EleutherAI/gpt-neox-20b,128,1,1461.0,1.0,1,H100,1697105176271,1697105177732.0,120,11.0,1.0,"[45, 1416]","[1697105176316, 1697105177732]"
506,900,7,[],200,EleutherAI/gpt-neox-20b,128,1,2879.0,1.0,1,H100,1697105177733,1697105180612.0,120,67.0,6.0,"[9, 2360, 85, 67, 279, 79]","[1697105177742, 1697105180102, 1697105180187, 1697105180254, 1697105180533, 1697105180612]"
507,759,4,[],200,EleutherAI/gpt-neox-20b,128,1,4105.0,1.0,1,H100,1697105172159,1697105176264.0,120,92.0,20.0,"[242, 1383, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 70, 87, 68, 69, 69]","[1697105172401, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
508,233,1,[],200,EleutherAI/gpt-neox-20b,128,1,3253.0,1.0,1,H100,1697105154708,1697105157961.0,120,6.0,1.0,"[193, 3060]","[1697105154901, 1697105157961]"
509,110,6,[],200,EleutherAI/gpt-neox-20b,128,1,2489.0,1.0,1,H100,1697105180538,1697105183027.0,120,96.0,4.0,"[6, 2306, 89, 88]","[1697105180544, 1697105182850, 1697105182939, 1697105183027]"
510,558,2,[],200,EleutherAI/gpt-neox-20b,128,1,4140.0,1.0,1,H100,1697105157962,1697105162102.0,120,58.0,20.0,"[12, 1737, 91, 87, 85, 84, 79, 444, 92, 87, 87, 83, 436, 93, 92, 87, 239, 89, 68, 68]","[1697105157974, 1697105159711, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102]"
511,305,8,[],200,EleutherAI/gpt-neox-20b,128,1,5484.0,1.0,1,H100,1697105180613,1697105186097.0,120,86.0,20.0,"[4, 2600, 87, 79, 371, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 88]","[1697105180617, 1697105183217, 1697105183304, 1697105183383, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186097]"
512,779,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105166439,1697105172155.0,120,,,"[5, 5319]","[1697105166444, 1697105171763]"
513,93,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105164161,1697105170013.0,120,,,"[28, 2177, 246, 208, 271, 116, 196, 133, 75, 460, 227, 76, 273, 232, 127, 143, 219, 181, 155]","[1697105164189, 1697105166366, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
514,899,5,[],200,EleutherAI/gpt-neox-20b,128,1,5722.0,1.0,1,H100,1697105174014,1697105179736.0,120,100.0,20.0,"[5, 3005, 81, 80, 63, 674, 95, 90, 88, 67, 87, 467, 91, 67, 87, 81, 356, 88, 85, 65]","[1697105174019, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178262, 1697105178349, 1697105178816, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736]"
515,857,1,[],200,EleutherAI/gpt-neox-20b,128,1,2081.0,1.0,1,H100,1697105157535,1697105159616.0,120,18.0,1.0,"[5, 2076]","[1697105157540, 1697105159616]"
516,919,3,[],200,EleutherAI/gpt-neox-20b,128,1,2413.0,1.0,1,H100,1697105162103,1697105164516.0,120,14.0,1.0,"[29, 2384]","[1697105162132, 1697105164516]"
517,376,2,[],200,EleutherAI/gpt-neox-20b,128,1,4542.0,1.0,1,H100,1697105159617,1697105164159.0,120,87.0,20.0,"[5, 1744, 93, 92, 87, 239, 89, 68, 68, 547, 85, 79, 361, 92, 87, 79, 251, 86, 85, 305]","[1697105159622, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159]"
518,350,4,[],200,EleutherAI/gpt-neox-20b,128,1,3456.0,1.0,1,H100,1697105164517,1697105167973.0,120,216.0,1.0,"[4, 3451]","[1697105164521, 1697105167972]"
519,710,5,[],200,EleutherAI/gpt-neox-20b,128,1,3235.0,1.0,1,H100,1697105167974,1697105171209.0,120,14.0,1.0,"[4, 3231]","[1697105167978, 1697105171209]"
520,112,6,[],200,EleutherAI/gpt-neox-20b,128,1,2574.0,1.0,1,H100,1697105171210,1697105173784.0,120,16.0,2.0,"[17, 2557]","[1697105171227, 1697105173784]"
521,735,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105164161,1697105170013.0,120,,,"[12, 2193, 246, 208, 271, 116, 196, 133, 75, 460, 227, 76, 273, 232, 127, 143, 219, 181, 155]","[1697105164173, 1697105166366, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
522,465,7,[],200,EleutherAI/gpt-neox-20b,128,1,1936.0,1.0,1,H100,1697105173785,1697105175721.0,120,364.0,3.0,"[5, 1832, 99]","[1697105173790, 1697105175622, 1697105175721]"
523,823,8,[],200,EleutherAI/gpt-neox-20b,128,1,4811.0,1.0,1,H100,1697105175722,1697105180533.0,120,90.0,20.0,"[5, 2195, 94, 91, 88, 67, 86, 468, 91, 66, 88, 81, 357, 87, 85, 66, 365, 85, 66, 280]","[1697105175727, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179499, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180533]"
524,328,6,[],200,EleutherAI/gpt-neox-20b,128,1,3201.0,1.0,1,H100,1697105179738,1697105182939.0,120,109.0,6.0,"[4, 2552, 89, 83, 384, 89]","[1697105179742, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939]"
525,547,7,[],200,EleutherAI/gpt-neox-20b,128,1,1386.0,1.0,1,H100,1697105177249,1697105178635.0,120,12.0,1.0,"[13, 1373]","[1697105177262, 1697105178635]"
526,779,8,[],200,EleutherAI/gpt-neox-20b,128,1,3666.0,1.0,1,H100,1697105183756,1697105187422.0,120,563.0,10.0,"[16, 2817, 88, 79, 77, 60, 279, 84, 83, 83]","[1697105183772, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186893, 1697105187172, 1697105187256, 1697105187339, 1697105187422]"
527,174,1,[],200,EleutherAI/gpt-neox-20b,128,1,5582.0,1.0,1,H100,1697105156520,1697105162102.0,120,87.0,20.0,"[9, 3181, 92, 87, 85, 84, 79, 444, 93, 86, 86, 84, 436, 93, 92, 86, 240, 89, 68, 68]","[1697105156529, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160846, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102]"
528,164,4,[],200,EleutherAI/gpt-neox-20b,128,1,1655.0,1.0,1,H100,1697105170016,1697105171671.0,120,15.0,1.0,"[61, 1594]","[1697105170077, 1697105171671]"
529,687,7,[],200,EleutherAI/gpt-neox-20b,128,1,5766.0,1.0,1,H100,1697105182940,1697105188706.0,120,96.0,20.0,"[4, 2454, 74, 537, 87, 82, 411, 88, 79, 77, 60, 280, 83, 83, 83, 376, 89, 561, 94, 164]","[1697105182944, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186178, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186893, 1697105187173, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706]"
530,905,8,[],200,EleutherAI/gpt-neox-20b,128,1,1807.0,1.0,1,H100,1697105178636,1697105180443.0,120,11.0,1.0,"[9, 1798]","[1697105178645, 1697105180443]"
531,308,9,[],200,EleutherAI/gpt-neox-20b,128,1,4954.0,1.0,1,H100,1697105180444,1697105185398.0,120,87.0,20.0,"[8, 2398, 89, 88, 190, 87, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 216, 76, 57, 363]","[1697105180452, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184902, 1697105184978, 1697105185035, 1697105185398]"
532,250,9,[],200,EleutherAI/gpt-neox-20b,128,1,2216.0,1.0,1,H100,1697105180544,1697105182760.0,120,31.0,1.0,"[13, 2203]","[1697105180557, 1697105182760]"
533,611,10,[],200,EleutherAI/gpt-neox-20b,128,1,2053.0,1.0,1,H100,1697105182761,1697105184814.0,120,14.0,1.0,"[16, 2037]","[1697105182777, 1697105184814]"
534,887,9,[],200,EleutherAI/gpt-neox-20b,128,1,10322.0,1.0,1,H100,1697105181725,1697105192047.0,120,244.0,50.0,"[8, 2021, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 88, 81, 411, 88, 78, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 162, 87, 281]","[1697105181733, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186178, 1697105186589, 1697105186677, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047]"
535,127,11,[],200,EleutherAI/gpt-neox-20b,128,1,2607.0,1.0,1,H100,1697105184815,1697105187422.0,120,100.0,5.0,"[4, 2354, 83, 84, 82]","[1697105184819, 1697105187173, 1697105187256, 1697105187340, 1697105187422]"
536,570,5,[],200,EleutherAI/gpt-neox-20b,128,1,3137.0,1.0,1,H100,1697105168072,1697105171209.0,120,18.0,1.0,"[5, 3132]","[1697105168077, 1697105171209]"
537,42,2,[],200,EleutherAI/gpt-neox-20b,128,1,2050.0,1.0,1,H100,1697105170020,1697105172070.0,120,10.0,1.0,"[162, 1888]","[1697105170182, 1697105172070]"
538,404,3,[],200,EleutherAI/gpt-neox-20b,128,1,4193.0,1.0,1,H100,1697105172071,1697105176264.0,120,87.0,20.0,"[5, 1708, 80, 77, 72, 668, 92, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69]","[1697105172076, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
539,928,6,[],200,EleutherAI/gpt-neox-20b,128,1,1609.0,1.0,1,H100,1697105171212,1697105172821.0,120,20.0,1.0,"[67, 1542]","[1697105171279, 1697105172821]"
540,123,8,[],200,EleutherAI/gpt-neox-20b,128,1,2136.0,1.0,1,H100,1697105188708,1697105190844.0,120,14.0,1.0,"[28, 2108]","[1697105188736, 1697105190844]"
541,451,9,[],200,EleutherAI/gpt-neox-20b,128,1,2240.0,1.0,1,H100,1697105190845,1697105193085.0,120,286.0,1.0,"[4, 2236]","[1697105190849, 1697105193085]"
542,810,10,[],200,EleutherAI/gpt-neox-20b,128,1,5338.0,1.0,1,H100,1697105193086,1697105198424.0,120,91.0,20.0,"[4, 2392, 87, 115, 84, 175, 417, 282, 186, 262, 85, 62, 151, 159, 82, 77, 326, 212, 117, 63]","[1697105193090, 1697105195482, 1697105195569, 1697105195684, 1697105195768, 1697105195943, 1697105196360, 1697105196642, 1697105196828, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424]"
543,362,7,[],200,EleutherAI/gpt-neox-20b,128,1,1757.0,1.0,1,H100,1697105172825,1697105174582.0,120,14.0,1.0,"[36, 1721]","[1697105172861, 1697105174582]"
544,231,11,[],200,EleutherAI/gpt-neox-20b,128,1,3156.0,1.0,1,H100,1697105198426,1697105201582.0,120,13.0,1.0,"[33, 3123]","[1697105198459, 1697105201582]"
545,723,8,[],200,EleutherAI/gpt-neox-20b,128,1,924.0,1.0,1,H100,1697105174583,1697105175507.0,120,14.0,1.0,"[8, 916]","[1697105174591, 1697105175507]"
546,591,12,[],200,EleutherAI/gpt-neox-20b,128,1,9899.0,1.0,1,H100,1697105201583,1697105211482.0,120,874.0,47.0,"[4, 2131, 88, 88, 87, 269, 87, 86, 84, 415, 93, 88, 88, 69, 87, 86, 389, 91, 85, 84, 731, 90, 89, 86, 80, 80, 60, 61, 617, 87, 82, 83, 63, 434, 88, 84, 79, 77, 385, 77, 618, 86, 83, 502, 81, 429, 168]","[1697105201587, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207359, 1697105207976, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208725, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210885, 1697105211314, 1697105211482]"
547,123,9,[],200,EleutherAI/gpt-neox-20b,128,1,1421.0,1.0,1,H100,1697105175508,1697105176929.0,120,14.0,1.0,"[16, 1405]","[1697105175524, 1697105176929]"
548,478,10,[],200,EleutherAI/gpt-neox-20b,128,1,11776.0,1.0,1,H100,1697105176930,1697105188706.0,120,161.0,62.0,"[17, 1870, 90, 67, 87, 81, 356, 88, 85, 66, 365, 85, 66, 280, 79, 75, 488, 81, 80, 388, 86, 76, 408, 89, 83, 384, 89, 88, 190, 87, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 87, 81, 411, 88, 79, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164]","[1697105176947, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181724, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706]"
549,734,4,[],200,EleutherAI/gpt-neox-20b,128,1,1992.0,1.0,1,H100,1697105176271,1697105178263.0,120,100.0,6.0,"[25, 1626, 94, 91, 88, 68]","[1697105176296, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178263]"
550,51,7,[],200,EleutherAI/gpt-neox-20b,128,1,7280.0,1.0,1,H100,1697105172822,1697105180102.0,120,364.0,36.0,"[7, 1851, 93, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69, 759, 82, 80, 63, 674, 94, 91, 88, 67, 86, 468, 91, 66, 88, 81, 356, 88, 85, 65, 366]","[1697105172829, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102]"
551,162,6,[],200,EleutherAI/gpt-neox-20b,128,1,4500.0,1.0,1,H100,1697105171764,1697105176264.0,120,90.0,20.0,"[5, 2015, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 98, 92, 89, 69, 88, 68, 69, 69]","[1697105171769, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175720, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
552,434,3,[],200,EleutherAI/gpt-neox-20b,128,1,3563.0,1.0,1,H100,1697105173685,1697105177248.0,120,85.0,20.0,"[16, 980, 92, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69, 759, 82, 80, 63]","[1697105173701, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177023, 1697105177105, 1697105177185, 1697105177248]"
553,372,1,[],200,EleutherAI/gpt-neox-20b,128,1,6362.0,1.0,1,H100,1697105159103,1697105165465.0,120,874.0,25.0,"[28, 2746, 89, 68, 68, 547, 85, 79, 361, 92, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 342, 89, 82]","[1697105159131, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165383, 1697105165465]"
554,372,1,[],200,EleutherAI/gpt-neox-20b,128,1,5771.0,1.0,1,H100,1697105159102,1697105164873.0,120,874.0,25.0,"[25, 2239, 93, 92, 87, 239, 89, 68, 68, 547, 85, 79, 361, 92, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88]","[1697105159127, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873]"
555,537,1,[],200,EleutherAI/gpt-neox-20b,128,1,5580.0,1.0,1,H100,1697105159803,1697105165383.0,120,83.0,20.0,"[5, 2841, 85, 79, 361, 92, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 342, 89]","[1697105159808, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165383]"
556,284,1,[],200,EleutherAI/gpt-neox-20b,128,1,6905.0,1.0,1,H100,1697105155908,1697105162813.0,120,90.0,31.0,"[9, 2135, 69, 86, 466, 161, 94, 86, 86, 610, 92, 87, 85, 84, 79, 444, 93, 86, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 85, 79]","[1697105155917, 1697105158052, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813]"
557,836,2,[],200,EleutherAI/gpt-neox-20b,128,1,3672.0,1.0,1,H100,1697105167537,1697105171209.0,120,11.0,1.0,"[5, 3666]","[1697105167542, 1697105171208]"
558,794,4,[],200,EleutherAI/gpt-neox-20b,128,1,2062.0,1.0,1,H100,1697105177249,1697105179311.0,120,11.0,1.0,"[17, 2045]","[1697105177266, 1697105179311]"
559,264,3,[],200,EleutherAI/gpt-neox-20b,128,1,5054.0,1.0,1,H100,1697105171210,1697105176264.0,120,86.0,20.0,"[5, 2569, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 98, 92, 89, 69, 88, 68, 69, 69]","[1697105171215, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175720, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
560,410,8,[],200,EleutherAI/gpt-neox-20b,128,1,4284.0,1.0,1,H100,1697105180103,1697105184387.0,120,364.0,12.0,"[4, 2743, 89, 88, 190, 87, 78, 372, 86, 85, 78, 384]","[1697105180107, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387]"
561,806,2,[],200,EleutherAI/gpt-neox-20b,128,1,5889.0,1.0,1,H100,1697105160931,1697105166820.0,120,89.0,20.0,"[13, 2739, 86, 85, 306, 76, 371, 89, 89, 88, 79, 342, 88, 83, 286, 68, 78, 468, 246, 209]","[1697105160944, 1697105163683, 1697105163769, 1697105163854, 1697105164160, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165382, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820]"
562,312,0,[],200,EleutherAI/gpt-neox-20b,128,1,1723.0,1.0,1,H100,1697105154559,1697105156282.0,120,23.0,1.0,"[317, 1406]","[1697105154876, 1697105156282]"
563,781,1,[],200,EleutherAI/gpt-neox-20b,128,1,3547.0,1.0,1,H100,1697105159102,1697105162649.0,120,335.0,10.0,"[5, 2259, 93, 92, 87, 239, 89, 68, 68, 547]","[1697105159107, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649]"
564,668,1,[],200,EleutherAI/gpt-neox-20b,128,1,2818.0,1.0,1,H100,1697105156283,1697105159101.0,120,109.0,6.0,"[5, 2385, 161, 94, 92, 81]","[1697105156288, 1697105158673, 1697105158834, 1697105158928, 1697105159020, 1697105159101]"
565,93,2,[],200,EleutherAI/gpt-neox-20b,128,1,5056.0,1.0,1,H100,1697105159103,1697105164159.0,120,88.0,20.0,"[24, 2239, 93, 92, 87, 239, 89, 68, 68, 547, 85, 79, 362, 91, 87, 79, 251, 86, 85, 305]","[1697105159127, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163175, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159]"
566,246,5,[],200,EleutherAI/gpt-neox-20b,128,1,8630.0,1.0,1,H100,1697105176271,1697105184901.0,120,58.0,47.0,"[25, 1626, 95, 90, 88, 67, 87, 467, 91, 66, 88, 81, 356, 88, 85, 65, 366, 85, 66, 284, 75, 75, 488, 81, 80, 387, 87, 76, 408, 89, 83, 383, 90, 88, 189, 88, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215]","[1697105176296, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178262, 1697105178349, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180537, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182849, 1697105182939, 1697105183027, 1697105183216, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901]"
567,679,5,[],200,EleutherAI/gpt-neox-20b,128,1,1526.0,1.0,1,H100,1697105172158,1697105173684.0,120,15.0,1.0,"[113, 1413]","[1697105172271, 1697105173684]"
568,378,5,[],200,EleutherAI/gpt-neox-20b,128,1,8630.0,1.0,1,H100,1697105176271,1697105184901.0,120,93.0,47.0,"[57, 1595, 94, 91, 87, 68, 86, 468, 90, 67, 87, 81, 356, 88, 85, 65, 366, 85, 66, 281, 78, 75, 488, 81, 80, 388, 86, 76, 408, 89, 83, 383, 90, 88, 189, 88, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215]","[1697105176328, 1697105177923, 1697105178017, 1697105178108, 1697105178195, 1697105178263, 1697105178349, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180534, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181724, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182849, 1697105182939, 1697105183027, 1697105183216, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901]"
569,212,2,[],200,EleutherAI/gpt-neox-20b,128,1,1865.0,1.0,1,H100,1697105162651,1697105164516.0,120,31.0,1.0,"[8, 1857]","[1697105162659, 1697105164516]"
570,540,3,[],200,EleutherAI/gpt-neox-20b,128,1,4130.0,1.0,1,H100,1697105164517,1697105168647.0,120,140.0,5.0,"[12, 3542, 227, 76, 273]","[1697105164529, 1697105168071, 1697105168298, 1697105168374, 1697105168647]"
571,286,1,[],200,EleutherAI/gpt-neox-20b,128,1,3236.0,1.0,1,H100,1697105157694,1697105160930.0,120,161.0,12.0,"[5, 2011, 92, 87, 85, 84, 79, 444, 92, 87, 87, 83]","[1697105157699, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930]"
572,895,4,[],200,EleutherAI/gpt-neox-20b,128,1,2559.0,1.0,1,H100,1697105168649,1697105171208.0,120,15.0,1.0,"[8, 2551]","[1697105168657, 1697105171208]"
573,152,11,[],200,EleutherAI/gpt-neox-20b,128,1,5658.0,1.0,1,H100,1697105192048,1697105197706.0,120,87.0,20.0,"[9, 2679, 80, 79, 260, 326, 87, 116, 83, 176, 417, 282, 189, 259, 85, 62, 152, 158, 82, 77]","[1697105192057, 1697105194736, 1697105194816, 1697105194895, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195943, 1697105196360, 1697105196642, 1697105196831, 1697105197090, 1697105197175, 1697105197237, 1697105197389, 1697105197547, 1697105197629, 1697105197706]"
574,746,8,[],200,EleutherAI/gpt-neox-20b,128,1,5458.0,1.0,1,H100,1697105186589,1697105192047.0,120,345.0,18.0,"[5, 2569, 86, 85, 481, 90, 272, 165, 251, 87, 251, 66, 87, 66, 367, 166, 83, 281]","[1697105186594, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191683, 1697105191766, 1697105192047]"
575,328,5,[],200,EleutherAI/gpt-neox-20b,128,1,3470.0,1.0,1,H100,1697105171210,1697105174680.0,120,109.0,6.0,"[13, 2561, 80, 77, 72, 667]","[1697105171223, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680]"
576,685,6,[],200,EleutherAI/gpt-neox-20b,128,1,2343.0,1.0,1,H100,1697105174681,1697105177024.0,120,364.0,2.0,"[5, 2337]","[1697105174686, 1697105177023]"
577,116,7,[],200,EleutherAI/gpt-neox-20b,128,1,2286.0,1.0,1,H100,1697105177025,1697105179311.0,120,23.0,1.0,"[8, 2278]","[1697105177033, 1697105179311]"
578,879,0,[],200,EleutherAI/gpt-neox-20b,128,1,10767.0,1.0,1,H100,1697105154527,1697105165294.0,120,39.0,55.0,"[265, 1577, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 94, 86, 87, 609, 92, 87, 85, 84, 78, 445, 92, 87, 87, 83, 436, 93, 92, 86, 240, 89, 68, 67, 548, 84, 79, 362, 92, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 342]","[1697105154792, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159101, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160136, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162101, 1697105162649, 1697105162733, 1697105162812, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294]"
579,444,8,[],200,EleutherAI/gpt-neox-20b,128,1,3071.0,1.0,1,H100,1697105179312,1697105182383.0,120,457.0,6.0,"[4, 2408, 86, 76, 408, 89]","[1697105179316, 1697105181724, 1697105181810, 1697105181886, 1697105182294, 1697105182383]"
580,802,9,[],200,EleutherAI/gpt-neox-20b,128,1,1279.0,1.0,1,H100,1697105182384,1697105183663.0,120,9.0,1.0,"[8, 1271]","[1697105182392, 1697105183663]"
581,232,10,[],200,EleutherAI/gpt-neox-20b,128,1,5499.0,1.0,1,H100,1697105183664,1697105189163.0,120,93.0,20.0,"[12, 2333, 88, 85, 407, 88, 78, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 165, 80, 376]","[1697105183676, 1697105186009, 1697105186097, 1697105186182, 1697105186589, 1697105186677, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188707, 1697105188787, 1697105189163]"
582,514,5,[],200,EleutherAI/gpt-neox-20b,128,1,4664.0,1.0,1,H100,1697105173685,1697105178349.0,120,85.0,20.0,"[41, 1896, 99, 91, 89, 70, 87, 69, 68, 69, 760, 81, 80, 63, 674, 94, 91, 88, 67, 86]","[1697105173726, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176264, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348]"
583,236,2,[],200,EleutherAI/gpt-neox-20b,128,1,1491.0,1.0,1,H100,1697105162103,1697105163594.0,120,8.0,1.0,"[9, 1482]","[1697105162112, 1697105163594]"
584,566,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105163595,1697105170013.0,120,,,"[13, 2143, 68, 78, 468, 247, 208, 271, 116, 196, 133, 75, 460, 227, 76, 273, 232, 127, 143, 219, 181, 155]","[1697105163608, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
585,292,2,[],200,EleutherAI/gpt-neox-20b,128,1,2102.0,1.0,1,H100,1697105164161,1697105166263.0,120,286.0,1.0,"[8, 2094]","[1697105164169, 1697105166263]"
586,183,1,[],200,EleutherAI/gpt-neox-20b,128,1,10601.0,1.0,1,H100,1697105159103,1697105169704.0,120,17.0,50.0,"[28, 2235, 93, 92, 87, 239, 89, 68, 68, 547, 85, 79, 361, 92, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 342, 89, 82, 286, 68, 77, 469, 246, 209, 271, 116, 196, 133, 75, 460, 227, 76, 273, 231, 127, 144, 218, 181, 156]","[1697105159131, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165896, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005, 1697105169149, 1697105169367, 1697105169548, 1697105169704]"
587,586,11,[],200,EleutherAI/gpt-neox-20b,128,1,5373.0,1.0,1,H100,1697105189164,1697105194537.0,120,85.0,20.0,"[12, 2871, 82, 275, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81, 265, 64, 84]","[1697105189176, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537]"
588,927,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170015,1697105172155.0,120,,,"[42, 1706]","[1697105170057, 1697105171763]"
589,218,6,[],200,EleutherAI/gpt-neox-20b,128,1,3336.0,1.0,1,H100,1697105174681,1697105178017.0,120,109.0,7.0,"[5, 2337, 82, 80, 63, 675, 94]","[1697105174686, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177923, 1697105178017]"
590,875,6,[],200,EleutherAI/gpt-neox-20b,128,1,6685.0,1.0,1,H100,1697105178350,1697105185035.0,120,31.0,31.0,"[21, 2072, 90, 79, 76, 487, 81, 80, 387, 87, 76, 408, 89, 83, 384, 89, 88, 190, 87, 78, 373, 85, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57]","[1697105178371, 1697105180443, 1697105180533, 1697105180612, 1697105180688, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183755, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035]"
591,578,7,[],200,EleutherAI/gpt-neox-20b,128,1,1993.0,1.0,1,H100,1697105178018,1697105180011.0,120,31.0,1.0,"[5, 1988]","[1697105178023, 1697105180011]"
592,722,2,[],200,EleutherAI/gpt-neox-20b,128,1,2662.0,1.0,1,H100,1697105160932,1697105163594.0,120,39.0,1.0,"[12, 2650]","[1697105160944, 1697105163594]"
593,3,8,[],200,EleutherAI/gpt-neox-20b,128,1,4890.0,1.0,1,H100,1697105180011,1697105184901.0,120,89.0,20.0,"[9, 2274, 89, 83, 384, 89, 88, 189, 88, 78, 373, 85, 85, 78, 384, 83, 79, 78, 59, 215]","[1697105180020, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183216, 1697105183304, 1697105183382, 1697105183755, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901]"
594,155,3,[],200,EleutherAI/gpt-neox-20b,128,1,5773.0,1.0,1,H100,1697105163595,1697105169368.0,120,90.0,20.0,"[5, 2151, 68, 78, 468, 246, 209, 271, 116, 196, 133, 75, 460, 227, 76, 273, 232, 127, 143, 219]","[1697105163600, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368]"
595,267,1,[],200,EleutherAI/gpt-neox-20b,128,1,5058.0,1.0,1,H100,1697105159102,1697105164160.0,120,83.0,20.0,"[13, 2251, 93, 92, 87, 239, 89, 68, 68, 547, 84, 80, 361, 91, 88, 79, 251, 86, 85, 306]","[1697105159115, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162733, 1697105162813, 1697105163174, 1697105163265, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164160]"
596,448,0,[],200,EleutherAI/gpt-neox-20b,128,1,3099.0,1.0,1,H100,1697105154516,1697105157615.0,120,335.0,12.0,"[18, 234, 1233, 76, 292, 65, 85, 562, 308, 84, 61, 81]","[1697105154534, 1697105154768, 1697105156001, 1697105156077, 1697105156369, 1697105156434, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615]"
597,432,2,[],200,EleutherAI/gpt-neox-20b,128,1,1781.0,1.0,1,H100,1697105162735,1697105164516.0,120,13.0,1.0,"[4, 1777]","[1697105162739, 1697105164516]"
598,369,1,[],200,EleutherAI/gpt-neox-20b,128,1,4519.0,1.0,1,H100,1697105158835,1697105163354.0,120,216.0,15.0,"[5, 2526, 93, 92, 86, 240, 89, 68, 68, 547, 85, 79, 362, 91, 88]","[1697105158840, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163175, 1697105163266, 1697105163354]"
599,531,2,[],200,EleutherAI/gpt-neox-20b,128,1,5508.0,1.0,1,H100,1697105162103,1697105167611.0,120,52.0,20.0,"[9, 2496, 88, 89, 88, 79, 343, 88, 82, 286, 68, 78, 468, 246, 209, 271, 116, 196, 133, 75]","[1697105162112, 1697105164608, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611]"
600,486,12,[],200,EleutherAI/gpt-neox-20b,128,1,5429.0,1.0,1,H100,1697105187424,1697105192853.0,120,14.0,20.0,"[8, 2383, 90, 272, 166, 250, 88, 250, 66, 87, 67, 366, 162, 87, 281, 81, 276, 76, 286, 87]","[1697105187432, 1697105189815, 1697105189905, 1697105190177, 1697105190343, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191151, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192128, 1697105192404, 1697105192480, 1697105192766, 1697105192853]"
601,835,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170015,1697105172154.0,120,,,"[35, 1713]","[1697105170050, 1697105171763]"
602,491,5,[],200,EleutherAI/gpt-neox-20b,128,1,2316.0,1.0,1,H100,1697105180444,1697105182760.0,120,14.0,1.0,"[16, 2300]","[1697105180460, 1697105182760]"
603,851,6,[],200,EleutherAI/gpt-neox-20b,128,1,2548.0,1.0,1,H100,1697105182761,1697105185309.0,120,23.0,1.0,"[24, 2524]","[1697105182785, 1697105185309]"
604,236,2,[],200,EleutherAI/gpt-neox-20b,128,1,1655.0,1.0,1,H100,1697105170016,1697105171671.0,120,8.0,1.0,"[58, 1597]","[1697105170074, 1697105171671]"
605,283,7,[],200,EleutherAI/gpt-neox-20b,128,1,5841.0,1.0,1,H100,1697105185310,1697105191151.0,120,85.0,20.0,"[8, 2480, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 166, 250, 88, 250, 66, 87, 67]","[1697105185318, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190343, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191151]"
606,183,13,[],200,EleutherAI/gpt-neox-20b,128,1,10101.0,1.0,1,H100,1697105202003,1697105212104.0,120,17.0,50.0,"[68, 1647, 88, 88, 87, 269, 87, 86, 84, 415, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84, 731, 90, 89, 86, 80, 80, 60, 60, 618, 87, 82, 83, 63, 435, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 81, 429, 168, 77, 456, 89]","[1697105202071, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207358, 1697105207976, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210885, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104]"
607,165,5,[],200,EleutherAI/gpt-neox-20b,128,1,5491.0,1.0,1,H100,1697105178264,1697105183755.0,120,83.0,20.0,"[4, 2265, 79, 75, 488, 81, 80, 387, 87, 76, 408, 89, 83, 384, 89, 88, 190, 87, 78, 372]","[1697105178268, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754]"
608,537,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105169705,1697105172156.0,120,,,"[5, 2053]","[1697105169710, 1697105171763]"
609,389,0,[],200,EleutherAI/gpt-neox-20b,128,1,1390.0,1.0,1,H100,1697105154517,1697105155907.0,120,8.0,1.0,"[65, 1325]","[1697105154582, 1697105155907]"
610,837,1,[],200,EleutherAI/gpt-neox-20b,128,1,5022.0,1.0,1,H100,1697105155908,1697105160930.0,120,85.0,20.0,"[17, 2127, 69, 87, 465, 161, 94, 86, 86, 610, 92, 87, 85, 84, 79, 444, 93, 86, 87, 83]","[1697105155925, 1697105158052, 1697105158121, 1697105158208, 1697105158673, 1697105158834, 1697105158928, 1697105159014, 1697105159100, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930]"
611,266,2,[],200,EleutherAI/gpt-neox-20b,128,1,2663.0,1.0,1,H100,1697105160931,1697105163594.0,120,9.0,1.0,"[21, 2642]","[1697105160952, 1697105163594]"
612,629,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105163597,1697105170013.0,120,,,"[15, 2753, 247, 208, 271, 116, 196, 133, 75, 460, 227, 76, 273, 232, 127, 143, 219, 181, 155]","[1697105163612, 1697105166365, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
613,543,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105212107,1697105220994.0,120,,,"[19, 3168, 85, 356, 90, 83, 511, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 82, 256, 79, 368, 81, 59, 366, 89, 75, 259, 62, 234, 79, 229, 81, 198]","[1697105212126, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
614,611,8,[],200,EleutherAI/gpt-neox-20b,128,1,1933.0,1.0,1,H100,1697105191152,1697105193085.0,120,14.0,1.0,"[12, 1921]","[1697105191164, 1697105193085]"
615,38,9,[],200,EleutherAI/gpt-neox-20b,128,1,5338.0,1.0,1,H100,1697105193086,1697105198424.0,120,88.0,20.0,"[4, 2392, 87, 115, 84, 175, 417, 282, 189, 259, 85, 62, 151, 159, 82, 77, 327, 211, 117, 63]","[1697105193090, 1697105195482, 1697105195569, 1697105195684, 1697105195768, 1697105195943, 1697105196360, 1697105196642, 1697105196831, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198033, 1697105198244, 1697105198361, 1697105198424]"
616,88,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170015,1697105172154.0,120,,,"[34, 1714]","[1697105170049, 1697105171763]"
617,538,2,[],200,EleutherAI/gpt-neox-20b,128,1,4109.0,1.0,1,H100,1697105172156,1697105176265.0,120,89.0,20.0,"[40, 1588, 80, 77, 72, 668, 92, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 70]","[1697105172196, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176265]"
618,391,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105198425,1697105201999.0,120,,,"[9, 3233]","[1697105198434, 1697105201667]"
619,751,11,[],200,EleutherAI/gpt-neox-20b,128,1,10101.0,1.0,1,H100,1697105202003,1697105212104.0,120,216.0,50.0,"[72, 1643, 88, 88, 87, 269, 87, 86, 84, 415, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84, 731, 90, 89, 86, 80, 80, 60, 60, 618, 87, 82, 83, 63, 435, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 81, 429, 168, 77, 456, 89]","[1697105202075, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207358, 1697105207976, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210885, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104]"
620,768,9,[],200,EleutherAI/gpt-neox-20b,128,1,3410.0,1.0,1,H100,1697105184388,1697105187798.0,120,47.0,6.0,"[9, 2776, 83, 84, 82, 376]","[1697105184397, 1697105187173, 1697105187256, 1697105187340, 1697105187422, 1697105187798]"
621,899,3,[],200,EleutherAI/gpt-neox-20b,128,1,4266.0,1.0,1,H100,1697105176271,1697105180537.0,120,100.0,20.0,"[17, 1634, 94, 91, 88, 67, 87, 467, 91, 66, 88, 81, 356, 88, 85, 65, 366, 85, 66, 280]","[1697105176288, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178349, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180533]"
622,704,2,[],200,EleutherAI/gpt-neox-20b,128,1,1389.0,1.0,1,H100,1697105164874,1697105166263.0,120,14.0,1.0,"[8, 1381]","[1697105164882, 1697105166263]"
623,329,4,[],200,EleutherAI/gpt-neox-20b,128,1,2216.0,1.0,1,H100,1697105180544,1697105182760.0,120,15.0,1.0,"[21, 2195]","[1697105180565, 1697105182760]"
624,683,5,[],200,EleutherAI/gpt-neox-20b,128,1,2637.0,1.0,1,H100,1697105182761,1697105185398.0,120,874.0,2.0,"[12, 2625]","[1697105182773, 1697105185398]"
625,108,6,[],200,EleutherAI/gpt-neox-20b,128,1,3049.0,1.0,1,H100,1697105185399,1697105188448.0,120,182.0,2.0,"[9, 3040]","[1697105185408, 1697105188448]"
626,438,7,[],200,EleutherAI/gpt-neox-20b,128,1,2394.0,1.0,1,H100,1697105188450,1697105190844.0,120,9.0,1.0,"[4, 2390]","[1697105188454, 1697105190844]"
627,796,8,[],200,EleutherAI/gpt-neox-20b,128,1,5515.0,1.0,1,H100,1697105190845,1697105196360.0,120,86.0,20.0,"[8, 2767, 86, 189, 84, 64, 81, 265, 63, 85, 199, 80, 78, 262, 325, 87, 116, 83, 175, 418]","[1697105190853, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195156, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360]"
628,303,5,[],200,EleutherAI/gpt-neox-20b,128,1,5420.0,1.0,1,H100,1697105182467,1697105187887.0,120,88.0,20.0,"[4, 2430, 77, 58, 362, 74, 537, 87, 81, 412, 88, 79, 77, 59, 280, 84, 83, 83, 376, 89]","[1697105182471, 1697105184901, 1697105184978, 1697105185036, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887]"
629,130,2,[],200,EleutherAI/gpt-neox-20b,128,1,1937.0,1.0,1,H100,1697105163267,1697105165204.0,120,14.0,1.0,"[4, 1933]","[1697105163271, 1697105165204]"
630,536,1,[],200,EleutherAI/gpt-neox-20b,128,1,5057.0,1.0,1,H100,1697105159103,1697105164160.0,120,83.0,20.0,"[20, 2243, 93, 92, 87, 239, 89, 68, 68, 547, 85, 79, 361, 92, 87, 79, 251, 86, 85, 306]","[1697105159123, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164160]"
631,200,8,[],200,EleutherAI/gpt-neox-20b,128,1,3301.0,1.0,1,H100,1697105180539,1697105183840.0,120,6.0,9.0,"[9, 2302, 89, 88, 190, 87, 78, 372, 86]","[1697105180548, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840]"
632,400,3,[],200,EleutherAI/gpt-neox-20b,128,1,2542.0,1.0,1,H100,1697105163355,1697105165897.0,120,123.0,7.0,"[4, 1936, 88, 82, 286, 68, 78]","[1697105163359, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897]"
633,449,1,[],200,EleutherAI/gpt-neox-20b,128,1,5580.0,1.0,1,H100,1697105159803,1697105165383.0,120,86.0,20.0,"[13, 2833, 85, 79, 361, 92, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 342, 89]","[1697105159816, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165383]"
634,330,0,[],200,EleutherAI/gpt-neox-20b,128,1,3601.0,1.0,1,H100,1697105154520,1697105158121.0,120,345.0,14.0,"[178, 1303, 77, 291, 66, 84, 562, 309, 83, 61, 81, 78, 359, 69]","[1697105154698, 1697105156001, 1697105156078, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157390, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158052, 1697105158121]"
635,748,9,[],200,EleutherAI/gpt-neox-20b,128,1,5441.0,1.0,1,H100,1697105184902,1697105190343.0,120,182.0,14.0,"[13, 2883, 89, 561, 94, 164, 81, 376, 86, 85, 481, 90, 272, 166]","[1697105184915, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190343]"
636,108,6,[],200,EleutherAI/gpt-neox-20b,128,1,996.0,1.0,1,H100,1697105173685,1697105174681.0,120,182.0,2.0,"[17, 979]","[1697105173702, 1697105174681]"
637,866,2,[],200,EleutherAI/gpt-neox-20b,128,1,5508.0,1.0,1,H100,1697105162103,1697105167611.0,120,93.0,20.0,"[5, 2500, 88, 89, 88, 79, 343, 88, 82, 286, 68, 77, 470, 246, 208, 271, 116, 196, 133, 75]","[1697105162108, 1697105164608, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165896, 1697105166366, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611]"
638,788,3,[],200,EleutherAI/gpt-neox-20b,128,1,1655.0,1.0,1,H100,1697105170016,1697105171671.0,120,31.0,1.0,"[66, 1589]","[1697105170082, 1697105171671]"
639,437,6,[],200,EleutherAI/gpt-neox-20b,128,1,6901.0,1.0,1,H100,1697105177024,1697105183925.0,120,91.0,29.0,"[9, 2465, 88, 85, 66, 365, 85, 66, 280, 79, 75, 488, 81, 81, 387, 86, 76, 408, 89, 83, 384, 89, 88, 190, 87, 78, 372, 86, 85]","[1697105177033, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181337, 1697105181724, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925]"
640,751,1,[],200,EleutherAI/gpt-neox-20b,128,1,10328.0,1.0,1,H100,1697105156283,1697105166611.0,120,216.0,50.0,"[25, 2365, 161, 94, 93, 80, 609, 92, 87, 85, 84, 79, 444, 93, 86, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 85, 79, 361, 92, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 342, 88, 83, 286, 68, 77, 469, 246]","[1697105156308, 1697105158673, 1697105158834, 1697105158928, 1697105159021, 1697105159101, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165382, 1697105165465, 1697105165751, 1697105165819, 1697105165896, 1697105166365, 1697105166611]"
641,184,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105169705,1697105172156.0,120,,,"[5, 2053]","[1697105169710, 1697105171763]"
642,646,3,[],200,EleutherAI/gpt-neox-20b,128,1,2807.0,1.0,1,H100,1697105166264,1697105169071.0,120,14.0,1.0,"[12, 2795]","[1697105166276, 1697105169071]"
643,640,2,[],200,EleutherAI/gpt-neox-20b,128,1,2663.0,1.0,1,H100,1697105160931,1697105163594.0,120,15.0,1.0,"[17, 2646]","[1697105160948, 1697105163594]"
644,77,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105169072,1697105172155.0,120,,,"[4, 2687]","[1697105169076, 1697105171763]"
645,182,9,[],200,EleutherAI/gpt-neox-20b,128,1,8058.0,1.0,1,H100,1697105192048,1697105200106.0,120,47.0,31.0,"[13, 2675, 80, 79, 260, 326, 87, 116, 83, 176, 417, 282, 184, 264, 85, 62, 152, 158, 82, 77, 327, 211, 117, 63, 265, 273, 410, 224, 231, 129, 150]","[1697105192061, 1697105194736, 1697105194816, 1697105194895, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195943, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197389, 1697105197547, 1697105197629, 1697105197706, 1697105198033, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106]"
646,547,5,[],200,EleutherAI/gpt-neox-20b,128,1,1525.0,1.0,1,H100,1697105172159,1697105173684.0,120,12.0,1.0,"[246, 1279]","[1697105172405, 1697105173684]"
647,71,3,[],200,EleutherAI/gpt-neox-20b,128,1,3941.0,1.0,1,H100,1697105163595,1697105167536.0,120,364.0,11.0,"[9, 2147, 68, 78, 468, 246, 209, 271, 116, 196, 133]","[1697105163604, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536]"
648,432,4,[],200,EleutherAI/gpt-neox-20b,128,1,3671.0,1.0,1,H100,1697105167537,1697105171208.0,120,13.0,1.0,"[4, 3667]","[1697105167541, 1697105171208]"
649,880,5,[],200,EleutherAI/gpt-neox-20b,128,1,2574.0,1.0,1,H100,1697105171210,1697105173784.0,120,84.0,2.0,"[29, 2545]","[1697105171239, 1697105173784]"
650,409,5,[],200,EleutherAI/gpt-neox-20b,128,1,6189.0,1.0,1,H100,1697105172159,1697105178348.0,120,109.0,30.0,"[229, 1396, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 70, 87, 69, 68, 70, 758, 81, 81, 63, 674, 94, 91, 88, 67, 86]","[1697105172388, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176265, 1697105177023, 1697105177104, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348]"
651,482,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105197707,1697105201998.0,120,,,"[5, 3210, 80, 292, 160, 212]","[1697105197712, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
652,311,6,[],200,EleutherAI/gpt-neox-20b,128,1,4564.0,1.0,1,H100,1697105173785,1697105178349.0,120,93.0,20.0,"[5, 1832, 99, 91, 89, 70, 87, 69, 68, 69, 760, 81, 80, 63, 674, 94, 91, 88, 67, 87]","[1697105173790, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176264, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178349]"
653,228,1,[],200,EleutherAI/gpt-neox-20b,128,1,5115.0,1.0,1,H100,1697105156436,1697105161551.0,120,100.0,20.0,"[4, 2233, 161, 94, 90, 83, 609, 92, 87, 85, 84, 79, 444, 93, 86, 87, 83, 436, 93, 92]","[1697105156440, 1697105158673, 1697105158834, 1697105158928, 1697105159018, 1697105159101, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551]"
654,767,7,[],200,EleutherAI/gpt-neox-20b,128,1,1383.0,1.0,1,H100,1697105183926,1697105185309.0,120,11.0,1.0,"[9, 1374]","[1697105183935, 1697105185309]"
655,795,6,[],200,EleutherAI/gpt-neox-20b,128,1,2762.0,1.0,1,H100,1697105177249,1697105180011.0,120,12.0,1.0,"[21, 2741]","[1697105177270, 1697105180011]"
656,195,8,[],200,EleutherAI/gpt-neox-20b,128,1,13379.0,1.0,1,H100,1697105185310,1697105198689.0,120,286.0,64.0,"[16, 3122, 94, 164, 81, 375, 87, 85, 481, 90, 272, 166, 250, 88, 250, 66, 87, 67, 366, 162, 87, 281, 82, 275, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 80, 266, 63, 85, 199, 80, 78, 261, 326, 87, 116, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 326, 212, 117, 63, 265]","[1697105185326, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190343, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191151, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194123, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689]"
657,220,7,[],200,EleutherAI/gpt-neox-20b,128,1,2283.0,1.0,1,H100,1697105180011,1697105182294.0,120,67.0,2.0,"[5, 2278]","[1697105180016, 1697105182294]"
658,843,13,[],200,EleutherAI/gpt-neox-20b,128,1,1624.0,1.0,1,H100,1697105202002,1697105203626.0,120,14.0,1.0,"[45, 1579]","[1697105202047, 1697105203626]"
659,574,8,[],200,EleutherAI/gpt-neox-20b,128,1,2606.0,1.0,1,H100,1697105182295,1697105184901.0,120,364.0,2.0,"[8, 2598]","[1697105182303, 1697105184901]"
660,4,9,[],200,EleutherAI/gpt-neox-20b,128,1,6249.0,1.0,1,H100,1697105184902,1697105191151.0,120,89.0,20.0,"[13, 2883, 89, 561, 94, 164, 81, 376, 86, 85, 481, 90, 272, 165, 251, 88, 250, 66, 87, 66]","[1697105184915, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191150]"
661,591,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105161552,1697105170013.0,120,,,"[17, 3038, 89, 89, 88, 79, 342, 89, 82, 286, 68, 78, 468, 247, 208, 271, 116, 196, 133, 75, 460, 227, 76, 273, 231, 127, 144, 218, 181, 156]","[1697105161569, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005, 1697105169149, 1697105169367, 1697105169548, 1697105169704]"
662,275,14,[],200,EleutherAI/gpt-neox-20b,128,1,2371.0,1.0,1,H100,1697105203627,1697105205998.0,120,161.0,4.0,"[4, 2191, 91, 85]","[1697105203631, 1697105205822, 1697105205913, 1697105205998]"
663,634,15,[],200,EleutherAI/gpt-neox-20b,128,1,714.0,1.0,1,H100,1697105206000,1697105206714.0,120,13.0,1.0,"[4, 710]","[1697105206004, 1697105206714]"
664,30,16,[],200,EleutherAI/gpt-neox-20b,128,1,5549.0,1.0,1,H100,1697105206715,1697105212264.0,120,93.0,20.0,"[21, 1990, 87, 84, 79, 78, 384, 77, 618, 86, 83, 502, 82, 428, 169, 76, 456, 89, 80, 79]","[1697105206736, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209054, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211483, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263]"
665,184,5,[],200,EleutherAI/gpt-neox-20b,128,1,4266.0,1.0,1,H100,1697105176271,1697105180537.0,120,87.0,20.0,"[53, 1599, 94, 90, 88, 68, 86, 468, 90, 67, 87, 81, 356, 88, 85, 65, 366, 85, 66, 281]","[1697105176324, 1697105177923, 1697105178017, 1697105178107, 1697105178195, 1697105178263, 1697105178349, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180534]"
666,102,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105163770,1697105170013.0,120,,,"[5, 2590, 247, 208, 271, 116, 196, 133, 75, 460, 227, 76, 273, 232, 127, 143, 219, 181, 155]","[1697105163775, 1697105166365, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
667,625,2,[],200,EleutherAI/gpt-neox-20b,128,1,2451.0,1.0,1,H100,1697105164161,1697105166612.0,120,364.0,2.0,"[16, 2435]","[1697105164177, 1697105166612]"
668,666,9,[],200,EleutherAI/gpt-neox-20b,128,1,6306.0,1.0,1,H100,1697105186098,1697105192404.0,120,84.0,20.0,"[4, 3061, 86, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 165, 84, 281, 82, 275]","[1697105186102, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191682, 1697105191766, 1697105192047, 1697105192129, 1697105192404]"
669,515,5,[],200,EleutherAI/gpt-neox-20b,128,1,1148.0,1.0,1,H100,1697105171673,1697105172821.0,120,11.0,1.0,"[40, 1108]","[1697105171713, 1697105172821]"
670,112,6,[],200,EleutherAI/gpt-neox-20b,128,1,2369.0,1.0,1,H100,1697105177733,1697105180102.0,120,16.0,2.0,"[5, 2364]","[1697105177738, 1697105180102]"
671,102,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105167404,1697105172155.0,120,,,"[5, 4354]","[1697105167409, 1697105171763]"
672,874,6,[],200,EleutherAI/gpt-neox-20b,128,1,9642.0,1.0,1,H100,1697105172824,1697105182466.0,120,140.0,50.0,"[19, 1837, 93, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69, 760, 81, 80, 63, 674, 94, 91, 88, 67, 86, 468, 91, 66, 88, 81, 356, 88, 85, 65, 366, 85, 66, 280, 79, 75, 488, 81, 80, 387, 87, 75, 409, 88, 84]","[1697105172843, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181885, 1697105182294, 1697105182382, 1697105182466]"
673,312,2,[],200,EleutherAI/gpt-neox-20b,128,1,2744.0,1.0,1,H100,1697105165820,1697105168564.0,120,23.0,1.0,"[21, 2723]","[1697105165841, 1697105168564]"
674,885,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105167612,1697105172155.0,120,,,"[9, 4142]","[1697105167621, 1697105171763]"
675,542,6,[],200,EleutherAI/gpt-neox-20b,128,1,2216.0,1.0,1,H100,1697105180544,1697105182760.0,120,11.0,1.0,"[8, 2207]","[1697105180552, 1697105182759]"
676,677,3,[],200,EleutherAI/gpt-neox-20b,128,1,2643.0,1.0,1,H100,1697105168565,1697105171208.0,120,9.0,1.0,"[8, 2635]","[1697105168573, 1697105171208]"
677,406,4,[],200,EleutherAI/gpt-neox-20b,128,1,1785.0,1.0,1,H100,1697105172156,1697105173941.0,120,244.0,4.0,"[51, 1477, 100, 80, 77]","[1697105172207, 1697105173684, 1697105173784, 1697105173864, 1697105173941]"
678,869,3,[],200,EleutherAI/gpt-neox-20b,128,1,3463.0,1.0,1,H100,1697105172159,1697105175622.0,120,244.0,12.0,"[145, 1480, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522]","[1697105172304, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622]"
679,763,5,[],200,EleutherAI/gpt-neox-20b,128,1,1565.0,1.0,1,H100,1697105173942,1697105175507.0,120,20.0,1.0,"[9, 1556]","[1697105173951, 1697105175507]"
680,107,4,[],200,EleutherAI/gpt-neox-20b,128,1,2574.0,1.0,1,H100,1697105171210,1697105173784.0,120,216.0,2.0,"[29, 2545]","[1697105171239, 1697105173784]"
681,552,5,[],200,EleutherAI/gpt-neox-20b,128,1,4564.0,1.0,1,H100,1697105173785,1697105178349.0,120,87.0,20.0,"[13, 1824, 99, 91, 89, 70, 87, 69, 68, 69, 759, 81, 81, 63, 674, 95, 90, 88, 67, 87]","[1697105173798, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176264, 1697105177023, 1697105177104, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178262, 1697105178349]"
682,12,2,[],200,EleutherAI/gpt-neox-20b,128,1,2663.0,1.0,1,H100,1697105160931,1697105163594.0,120,11.0,1.0,"[21, 2642]","[1697105160952, 1697105163594]"
683,367,3,[],200,EleutherAI/gpt-neox-20b,128,1,3017.0,1.0,1,H100,1697105163595,1697105166612.0,120,92.0,6.0,"[5, 2151, 68, 78, 468, 246]","[1697105163600, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611]"
684,724,4,[],200,EleutherAI/gpt-neox-20b,128,1,3315.0,1.0,1,H100,1697105166613,1697105169928.0,120,11.0,1.0,"[8, 3307]","[1697105166621, 1697105169928]"
685,241,5,[],200,EleutherAI/gpt-neox-20b,128,1,1279.0,1.0,1,H100,1697105169930,1697105171209.0,120,19.0,1.0,"[8, 1270]","[1697105169938, 1697105171208]"
686,607,6,[],200,EleutherAI/gpt-neox-20b,128,1,3806.0,1.0,1,H100,1697105171210,1697105175016.0,120,6.0,10.0,"[33, 2541, 80, 77, 72, 667, 93, 89, 68, 86]","[1697105171243, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016]"
687,886,10,[],200,EleutherAI/gpt-neox-20b,128,1,2123.0,1.0,1,H100,1697105191685,1697105193808.0,120,17.0,1.0,"[9, 2114]","[1697105191694, 1697105193808]"
688,35,7,[],200,EleutherAI/gpt-neox-20b,128,1,4720.0,1.0,1,H100,1697105175017,1697105179737.0,120,87.0,20.0,"[5, 2002, 81, 80, 63, 674, 95, 90, 88, 67, 86, 469, 90, 67, 87, 81, 356, 88, 85, 66]","[1697105175022, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737]"
689,911,6,[],200,EleutherAI/gpt-neox-20b,128,1,3944.0,1.0,1,H100,1697105178350,1697105182294.0,120,335.0,11.0,"[17, 2166, 79, 76, 487, 81, 80, 387, 87, 76, 408]","[1697105178367, 1697105180533, 1697105180612, 1697105180688, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294]"
690,316,11,[],200,EleutherAI/gpt-neox-20b,128,1,5788.0,1.0,1,H100,1697105193809,1697105199597.0,120,86.0,20.0,"[5, 2129, 417, 282, 188, 260, 85, 62, 152, 158, 82, 77, 326, 212, 117, 63, 265, 273, 410, 224]","[1697105193814, 1697105195943, 1697105196360, 1697105196642, 1697105196830, 1697105197090, 1697105197175, 1697105197237, 1697105197389, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596]"
691,737,5,[],200,EleutherAI/gpt-neox-20b,128,1,1652.0,1.0,1,H100,1697105176271,1697105177923.0,120,216.0,2.0,"[37, 1424, 190]","[1697105176308, 1697105177732, 1697105177922]"
692,167,6,[],200,EleutherAI/gpt-neox-20b,128,1,5294.0,1.0,1,H100,1697105177923,1697105183217.0,120,88.0,20.0,"[9, 2170, 85, 67, 279, 79, 75, 488, 81, 80, 387, 87, 75, 409, 89, 83, 384, 89, 88, 190]","[1697105177932, 1697105180102, 1697105180187, 1697105180254, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181885, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217]"
693,528,7,[],200,EleutherAI/gpt-neox-20b,128,1,5488.0,1.0,1,H100,1697105183218,1697105188706.0,120,52.0,20.0,"[8, 2172, 74, 537, 88, 81, 410, 88, 80, 77, 59, 281, 83, 84, 82, 376, 89, 561, 94, 164]","[1697105183226, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186178, 1697105186588, 1697105186676, 1697105186756, 1697105186833, 1697105186892, 1697105187173, 1697105187256, 1697105187340, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706]"
694,882,8,[],200,EleutherAI/gpt-neox-20b,128,1,4229.0,1.0,1,H100,1697105188707,1697105192936.0,120,345.0,11.0,"[13, 2797, 162, 87, 281, 82, 275, 76, 286, 87, 83]","[1697105188720, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936]"
695,312,9,[],200,EleutherAI/gpt-neox-20b,128,1,2455.0,1.0,1,H100,1697105192937,1697105195392.0,120,23.0,1.0,"[8, 2447]","[1697105192945, 1697105195392]"
696,641,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105195393,1697105201998.0,120,,,"[8, 2843, 117, 63, 265, 273, 410, 224, 231, 129, 150, 141, 80, 79, 219, 297, 80, 292, 160, 212]","[1697105195401, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200247, 1697105200327, 1697105200406, 1697105200625, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
697,901,15,[],200,EleutherAI/gpt-neox-20b,128,1,1575.0,1.0,1,H100,1697105220998,1697105222573.0,120,17.0,1.0,"[102, 1473]","[1697105221100, 1697105222573]"
698,373,1,[],200,EleutherAI/gpt-neox-20b,128,1,2225.0,1.0,1,H100,1697105157391,1697105159616.0,120,15.0,1.0,"[12, 2213]","[1697105157403, 1697105159616]"
699,441,16,[],200,EleutherAI/gpt-neox-20b,128,1,1366.0,1.0,1,H100,1697105205348,1697105206714.0,120,6.0,1.0,"[5, 1361]","[1697105205353, 1697105206714]"
700,802,17,[],200,EleutherAI/gpt-neox-20b,128,1,1151.0,1.0,1,H100,1697105206717,1697105207868.0,120,9.0,1.0,"[27, 1124]","[1697105206744, 1697105207868]"
701,204,18,[],200,EleutherAI/gpt-neox-20b,128,1,3018.0,1.0,1,H100,1697105207868,1697105210886.0,120,67.0,6.0,"[5, 2261, 86, 82, 502, 82]","[1697105207873, 1697105210134, 1697105210220, 1697105210302, 1697105210804, 1697105210886]"
702,329,16,[],200,EleutherAI/gpt-neox-20b,128,1,2570.0,1.0,1,H100,1697105222574,1697105225144.0,120,15.0,1.0,"[24, 2546]","[1697105222598, 1697105225144]"
703,852,5,[],200,EleutherAI/gpt-neox-20b,128,1,4267.0,1.0,1,H100,1697105176271,1697105180538.0,120,100.0,20.0,"[49, 1602, 95, 90, 88, 68, 86, 467, 91, 67, 87, 81, 356, 88, 85, 65, 366, 85, 66, 285]","[1697105176320, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178263, 1697105178349, 1697105178816, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180538]"
704,659,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225147,1697105228774.0,120,,,"[51, 1865, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105225198, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
705,709,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105176271,1697105201998.0,120,,,"[106, 2440, 90, 67, 87, 81, 356, 88, 85, 66, 365, 85, 66, 280, 79, 75, 488, 81, 80, 388, 86, 76, 408, 89, 83, 383, 90, 88, 190, 87, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 87, 81, 411, 88, 79, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 162, 87, 281, 81, 276, 76, 286, 87, 82, 235, 82, 62, 305, 87, 189, 84, 63, 81, 266, 63, 85, 199, 80, 78, 261, 326, 87, 116, 83, 175, 418, 282, 184, 263, 86, 62, 151, 159, 82, 77, 326, 212, 117, 63, 264, 273, 411, 224, 230, 130, 150, 140, 80, 80, 219, 297, 80, 292, 160, 212]","[1697105176377, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181724, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182849, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192128, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192935, 1697105193170, 1697105193252, 1697105193314, 1697105193619, 1697105193706, 1697105193895, 1697105193979, 1697105194042, 1697105194123, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197089, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198688, 1697105198961, 1697105199372, 1697105199596, 1697105199826, 1697105199956, 1697105200106, 1697105200246, 1697105200326, 1697105200406, 1697105200625, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
706,41,1,[],200,EleutherAI/gpt-neox-20b,128,1,9272.0,1.0,1,H100,1697105159102,1697105168374.0,120,39.0,43.0,"[9, 2255, 93, 92, 87, 239, 89, 68, 68, 547, 84, 80, 361, 92, 88, 78, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 342, 88, 83, 286, 68, 77, 469, 246, 209, 271, 115, 197, 133, 75, 460, 227, 76]","[1697105159111, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162733, 1697105162813, 1697105163174, 1697105163266, 1697105163354, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165382, 1697105165465, 1697105165751, 1697105165819, 1697105165896, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167206, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374]"
707,565,19,[],200,EleutherAI/gpt-neox-20b,128,1,5020.0,1.0,1,H100,1697105210889,1697105215909.0,120,91.0,20.0,"[7, 1995, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 65, 75, 652, 85, 356, 90, 84]","[1697105210896, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215909]"
708,85,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228782,1697105230476.0,120,,,[220],[1697105229002]
709,447,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105234920.0,120,,,"[195, 2383, 600, 617]","[1697105230673, 1697105233056, 1697105233656, 1697105234273]"
710,237,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105166821,1697105172154.0,120,,,"[12, 4930]","[1697105166833, 1697105171763]"
711,805,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234925,1697105238408.0,120,,,[263],[1697105235188]
712,207,1,[],200,EleutherAI/gpt-neox-20b,128,1,1501.0,1.0,1,H100,1697105164161,1697105165662.0,120,10.0,1.0,"[4, 1497]","[1697105164165, 1697105165662]"
713,236,21,[],200,EleutherAI/gpt-neox-20b,128,1,1855.0,1.0,1,H100,1697105238411,1697105240266.0,120,8.0,1.0,"[88, 1766]","[1697105238499, 1697105240265]"
714,923,20,[],200,EleutherAI/gpt-neox-20b,128,1,3579.0,1.0,1,H100,1697105215910,1697105219489.0,120,140.0,6.0,"[4, 2980, 81, 59, 366, 89]","[1697105215914, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489]"
715,572,4,[],200,EleutherAI/gpt-neox-20b,128,1,1528.0,1.0,1,H100,1697105172156,1697105173684.0,120,16.0,1.0,"[35, 1493]","[1697105172191, 1697105173684]"
716,679,22,[],200,EleutherAI/gpt-neox-20b,128,1,938.0,1.0,1,H100,1697105240267,1697105241205.0,120,15.0,1.0,"[60, 878]","[1697105240327, 1697105241205]"
717,108,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241206,1697105243753.0,120,,,[25],[1697105241231]
718,565,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165663,1697105170013.0,120,,,"[4, 2980, 232, 127, 143, 219, 181, 155]","[1697105165667, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
719,462,24,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105243758,1697105245427.0,120,52.0,1.0,"[21, 1648]","[1697105243779, 1697105245427]"
720,348,21,[],200,EleutherAI/gpt-neox-20b,128,1,5169.0,1.0,1,H100,1697105219491,1697105224660.0,120,91.0,20.0,"[6, 2468, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105219497, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
721,404,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105168375,1697105172155.0,120,,,"[4, 3384]","[1697105168379, 1697105171763]"
722,696,2,[],200,EleutherAI/gpt-neox-20b,128,1,4140.0,1.0,1,H100,1697105157962,1697105162102.0,120,83.0,20.0,"[12, 1737, 91, 87, 85, 84, 79, 444, 92, 87, 87, 83, 436, 93, 92, 87, 239, 89, 68, 68]","[1697105157974, 1697105159711, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102]"
723,822,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245428,1697105247242.0,120,,,[8],[1697105245436]
724,895,3,[],200,EleutherAI/gpt-neox-20b,128,1,1655.0,1.0,1,H100,1697105170017,1697105171672.0,120,15.0,1.0,"[160, 1494]","[1697105170177, 1697105171671]"
725,254,26,[],200,EleutherAI/gpt-neox-20b,128,1,1390.0,1.0,1,H100,1697105247246,1697105248636.0,120,58.0,1.0,"[27, 1363]","[1697105247273, 1697105248636]"
726,324,4,[],200,EleutherAI/gpt-neox-20b,128,1,10137.0,1.0,1,H100,1697105171673,1697105181810.0,120,17.0,50.0,"[32, 2079, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 98, 92, 89, 69, 88, 68, 69, 69, 759, 81, 81, 63, 674, 94, 91, 88, 67, 86, 468, 91, 66, 88, 81, 356, 88, 85, 65, 365, 86, 66, 280, 79, 75, 488, 81, 80, 387, 87]","[1697105171705, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175720, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177023, 1697105177104, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180101, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810]"
727,849,3,[],200,EleutherAI/gpt-neox-20b,128,1,1526.0,1.0,1,H100,1697105172158,1697105173684.0,120,10.0,1.0,"[9, 1517]","[1697105172167, 1697105173684]"
728,273,4,[],200,EleutherAI/gpt-neox-20b,128,1,897.0,1.0,1,H100,1697105173685,1697105174582.0,120,19.0,1.0,"[21, 876]","[1697105173706, 1697105174582]"
729,629,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105174585,1697105202006.0,120,,,"[19, 2419, 82, 80, 63, 675, 94, 91, 87, 68, 86, 468, 90, 67, 87, 81, 356, 88, 85, 65, 366, 85, 66, 280, 79, 75, 488, 81, 80, 387, 87, 76, 408, 89, 83, 383, 90, 88, 189, 88, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 87, 81, 411, 88, 79, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 162, 87, 281, 81, 276, 76, 286, 87, 82, 235, 82, 62, 305, 86, 190, 84, 63, 81, 266, 63, 85, 198, 81, 78, 261, 326, 87, 116, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 326, 212, 117, 63, 264, 273, 411, 224, 230, 130, 150, 140, 80, 80, 219, 297, 80, 292, 160, 212]","[1697105174604, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177923, 1697105178017, 1697105178108, 1697105178195, 1697105178263, 1697105178349, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182849, 1697105182939, 1697105183027, 1697105183216, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192128, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192935, 1697105193170, 1697105193252, 1697105193314, 1697105193619, 1697105193705, 1697105193895, 1697105193979, 1697105194042, 1697105194123, 1697105194389, 1697105194452, 1697105194537, 1697105194735, 1697105194816, 1697105194894, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198688, 1697105198961, 1697105199372, 1697105199596, 1697105199826, 1697105199956, 1697105200106, 1697105200246, 1697105200326, 1697105200406, 1697105200625, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
730,734,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165898,1697105170014.0,120,,,"[4, 3647, 155]","[1697105165902, 1697105169549, 1697105169704]"
731,24,2,[],200,EleutherAI/gpt-neox-20b,128,1,3742.0,1.0,1,H100,1697105161552,1697105165294.0,120,79.0,9.0,"[9, 2599, 77, 370, 89, 89, 88, 79, 342]","[1697105161561, 1697105164160, 1697105164237, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294]"
732,163,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170017,1697105172155.0,120,,,[157],[1697105170174]
733,809,2,[],200,EleutherAI/gpt-neox-20b,128,1,1850.0,1.0,1,H100,1697105165384,1697105167234.0,120,16.0,1.0,"[8, 1842]","[1697105165392, 1697105167234]"
734,739,6,[],200,EleutherAI/gpt-neox-20b,128,1,2183.0,1.0,1,H100,1697105184902,1697105187085.0,120,216.0,1.0,"[5, 2178]","[1697105184907, 1697105187085]"
735,257,7,[],200,EleutherAI/gpt-neox-20b,128,1,1982.0,1.0,1,H100,1697105187087,1697105189069.0,120,14.0,1.0,"[8, 1974]","[1697105187095, 1697105189069]"
736,610,8,[],200,EleutherAI/gpt-neox-20b,128,1,5467.0,1.0,1,H100,1697105189070,1697105194537.0,120,89.0,20.0,"[17, 2960, 82, 275, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81, 265, 64, 84]","[1697105189087, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537]"
737,522,6,[],200,EleutherAI/gpt-neox-20b,128,1,1526.0,1.0,1,H100,1697105172158,1697105173684.0,120,20.0,1.0,"[139, 1387]","[1697105172297, 1697105173684]"
738,884,7,[],200,EleutherAI/gpt-neox-20b,128,1,4664.0,1.0,1,H100,1697105173685,1697105178349.0,120,90.0,20.0,"[45, 1892, 99, 91, 89, 70, 87, 69, 68, 69, 760, 81, 80, 63, 674, 95, 90, 88, 67, 86]","[1697105173730, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176264, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178262, 1697105178348]"
739,240,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105167235,1697105172154.0,120,,,"[5, 4523]","[1697105167240, 1697105171763]"
740,572,4,[],200,EleutherAI/gpt-neox-20b,128,1,1528.0,1.0,1,H100,1697105172156,1697105173684.0,120,16.0,1.0,"[44, 1484]","[1697105172200, 1697105173684]"
741,148,10,[],200,EleutherAI/gpt-neox-20b,128,1,2333.0,1.0,1,H100,1697105190344,1697105192677.0,120,16.0,1.0,"[4, 2329]","[1697105190348, 1697105192677]"
742,926,5,[],200,EleutherAI/gpt-neox-20b,128,1,5376.0,1.0,1,H100,1697105173685,1697105179061.0,120,563.0,30.0,"[9, 987, 92, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69, 759, 82, 80, 63, 674, 94, 91, 88, 67, 86, 468, 91, 66, 88]","[1697105173694, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061]"
743,507,11,[],200,EleutherAI/gpt-neox-20b,128,1,5746.0,1.0,1,H100,1697105192678,1697105198424.0,120,83.0,20.0,"[5, 2798, 87, 116, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 327, 211, 117, 63]","[1697105192683, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198033, 1697105198244, 1697105198361, 1697105198424]"
744,901,6,[],200,EleutherAI/gpt-neox-20b,128,1,1821.0,1.0,1,H100,1697105173686,1697105175507.0,120,17.0,1.0,"[48, 1773]","[1697105173734, 1697105175507]"
745,301,7,[],200,EleutherAI/gpt-neox-20b,128,1,6302.0,1.0,1,H100,1697105175508,1697105181810.0,120,109.0,31.0,"[12, 1504, 81, 80, 63, 674, 94, 91, 88, 67, 86, 469, 90, 67, 87, 81, 356, 88, 85, 66, 365, 85, 66, 280, 79, 75, 488, 81, 80, 387, 87]","[1697105175520, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810]"
746,379,5,[],200,EleutherAI/gpt-neox-20b,128,1,4591.0,1.0,1,H100,1697105171673,1697105176264.0,120,182.0,20.0,"[24, 2087, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69]","[1697105171697, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
747,279,8,[],200,EleutherAI/gpt-neox-20b,128,1,4954.0,1.0,1,H100,1697105178350,1697105183304.0,120,67.0,18.0,"[5, 2178, 79, 75, 488, 81, 80, 387, 87, 76, 408, 88, 84, 384, 89, 88, 190, 87]","[1697105178355, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182382, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304]"
748,210,4,[],200,EleutherAI/gpt-neox-20b,128,1,1627.0,1.0,1,H100,1697105172158,1697105173785.0,120,140.0,2.0,"[22, 1604]","[1697105172180, 1697105173784]"
749,464,7,[],200,EleutherAI/gpt-neox-20b,128,1,1786.0,1.0,1,H100,1697105183028,1697105184814.0,120,12.0,1.0,"[5, 1781]","[1697105183033, 1697105184814]"
750,646,10,[],200,EleutherAI/gpt-neox-20b,128,1,2790.0,1.0,1,H100,1697105195157,1697105197947.0,120,14.0,1.0,"[16, 2773]","[1697105195173, 1697105197946]"
751,72,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105197948,1697105201998.0,120,,,"[4, 3342, 160, 212]","[1697105197952, 1697105201294, 1697105201454, 1697105201666]"
752,287,1,[],200,EleutherAI/gpt-neox-20b,128,1,2319.0,1.0,1,H100,1697105160675,1697105162994.0,120,10.0,1.0,"[4, 2315]","[1697105160679, 1697105162994]"
753,646,2,[],200,EleutherAI/gpt-neox-20b,128,1,2209.0,1.0,1,H100,1697105162995,1697105165204.0,120,14.0,1.0,"[8, 2201]","[1697105163003, 1697105165204]"
754,469,7,[],200,EleutherAI/gpt-neox-20b,128,1,2656.0,1.0,1,H100,1697105180103,1697105182759.0,120,17.0,1.0,"[4, 2652]","[1697105180107, 1697105182759]"
755,567,3,[],200,EleutherAI/gpt-neox-20b,128,1,4592.0,1.0,1,H100,1697105171672,1697105176264.0,120,90.0,20.0,"[5, 2107, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69]","[1697105171677, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
756,911,8,[],200,EleutherAI/gpt-neox-20b,128,1,3972.0,1.0,1,H100,1697105184815,1697105188787.0,120,335.0,11.0,"[4, 2354, 83, 84, 82, 376, 89, 561, 94, 164, 81]","[1697105184819, 1697105187173, 1697105187256, 1697105187340, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787]"
757,97,10,[],200,EleutherAI/gpt-neox-20b,128,1,5301.0,1.0,1,H100,1697105192405,1697105197706.0,120,6.0,20.0,"[5, 2326, 81, 78, 261, 325, 87, 116, 83, 176, 417, 282, 184, 264, 85, 62, 152, 158, 82, 77]","[1697105192410, 1697105194736, 1697105194817, 1697105194895, 1697105195156, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195943, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197389, 1697105197547, 1697105197629, 1697105197706]"
758,573,5,[],200,EleutherAI/gpt-neox-20b,128,1,3081.0,1.0,1,H100,1697105173942,1697105177023.0,120,874.0,2.0,"[4, 3077]","[1697105173946, 1697105177023]"
759,587,9,[],200,EleutherAI/gpt-neox-20b,128,1,2136.0,1.0,1,H100,1697105188708,1697105190844.0,120,13.0,1.0,"[20, 2116]","[1697105188728, 1697105190844]"
760,526,0,[],200,EleutherAI/gpt-neox-20b,128,1,5275.0,1.0,1,H100,1697105154527,1697105159802.0,120,89.0,20.0,"[289, 1553, 66, 84, 562, 308, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93, 87, 86, 610, 92]","[1697105154816, 1697105156369, 1697105156435, 1697105156519, 1697105157081, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927, 1697105159014, 1697105159100, 1697105159710, 1697105159802]"
761,25,3,[],200,EleutherAI/gpt-neox-20b,128,1,2319.0,1.0,1,H100,1697105160675,1697105162994.0,120,12.0,1.0,"[4, 2315]","[1697105160679, 1697105162994]"
762,892,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165384,1697105170013.0,120,,,"[8, 3255, 232, 127, 143, 219, 181, 155]","[1697105165392, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
763,348,3,[],200,EleutherAI/gpt-neox-20b,128,1,6013.0,1.0,1,H100,1697105163355,1697105169368.0,120,91.0,20.0,"[12, 2384, 68, 78, 468, 247, 208, 271, 116, 196, 133, 75, 460, 227, 76, 273, 232, 127, 143, 219]","[1697105163367, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368]"
764,395,8,[],200,EleutherAI/gpt-neox-20b,128,1,5163.0,1.0,1,H100,1697105179738,1697105184901.0,120,88.0,20.0,"[17, 2539, 89, 83, 384, 89, 88, 190, 87, 78, 373, 85, 85, 78, 384, 83, 79, 78, 59, 215]","[1697105179755, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183755, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901]"
765,70,11,[],200,EleutherAI/gpt-neox-20b,128,1,1622.0,1.0,1,H100,1697105202004,1697105203626.0,120,39.0,1.0,"[87, 1534]","[1697105202091, 1697105203625]"
766,834,7,[],200,EleutherAI/gpt-neox-20b,128,1,4962.0,1.0,1,H100,1697105179587,1697105184549.0,120,85.0,20.0,"[5, 2132, 86, 76, 408, 89, 83, 384, 89, 88, 189, 88, 78, 373, 85, 85, 78, 384, 83, 79]","[1697105179592, 1697105181724, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183216, 1697105183304, 1697105183382, 1697105183755, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549]"
767,429,12,[],200,EleutherAI/gpt-neox-20b,128,1,10790.0,1.0,1,H100,1697105203627,1697105214417.0,120,244.0,50.0,"[24, 2172, 90, 85, 84, 731, 90, 89, 86, 80, 80, 60, 61, 618, 86, 83, 82, 64, 434, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 82, 428, 168, 77, 456, 89, 80, 79, 75, 71, 482, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246]","[1697105203651, 1697105205823, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212409, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417]"
768,733,13,[],200,EleutherAI/gpt-neox-20b,128,1,2182.0,1.0,1,H100,1697105184903,1697105187085.0,120,31.0,1.0,"[20, 2162]","[1697105184923, 1697105187085]"
769,707,4,[],200,EleutherAI/gpt-neox-20b,128,1,1840.0,1.0,1,H100,1697105169369,1697105171209.0,120,8.0,1.0,"[12, 1828]","[1697105169381, 1697105171209]"
770,107,5,[],200,EleutherAI/gpt-neox-20b,128,1,2574.0,1.0,1,H100,1697105171210,1697105173784.0,120,216.0,2.0,"[13, 2561]","[1697105171223, 1697105173784]"
771,524,7,[],200,EleutherAI/gpt-neox-20b,128,1,7033.0,1.0,1,H100,1697105176271,1697105183304.0,120,100.0,30.0,"[102, 2444, 90, 67, 87, 81, 356, 88, 85, 66, 365, 85, 66, 284, 75, 75, 488, 81, 80, 388, 86, 76, 408, 89, 83, 383, 90, 88, 189, 88]","[1697105176373, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180537, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181724, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182849, 1697105182939, 1697105183027, 1697105183216, 1697105183304]"
772,1,5,[],200,EleutherAI/gpt-neox-20b,128,1,7571.0,1.0,1,H100,1697105173685,1697105181256.0,120,47.0,43.0,"[25, 971, 92, 89, 68, 86, 84, 522, 99, 91, 89, 70, 87, 69, 68, 69, 760, 81, 80, 63, 674, 94, 91, 88, 67, 86, 468, 91, 66, 88, 81, 356, 88, 85, 65, 366, 85, 66, 280, 79, 75, 488, 81]","[1697105173710, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176264, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256]"
773,661,6,[],200,EleutherAI/gpt-neox-20b,128,1,4241.0,1.0,1,H100,1697105187888,1697105192129.0,120,161.0,10.0,"[5, 3038, 66, 87, 67, 366, 162, 87, 281, 82]","[1697105187893, 1697105190931, 1697105190997, 1697105191084, 1697105191151, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129]"
774,196,7,[],200,EleutherAI/gpt-neox-20b,128,1,1461.0,1.0,1,H100,1697105176271,1697105177732.0,120,13.0,1.0,"[101, 1360]","[1697105176372, 1697105177732]"
775,553,8,[],200,EleutherAI/gpt-neox-20b,128,1,5484.0,1.0,1,H100,1697105177733,1697105183217.0,120,88.0,20.0,"[5, 2364, 85, 66, 280, 79, 75, 489, 80, 80, 387, 87, 76, 408, 89, 83, 384, 89, 88, 190]","[1697105177738, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181176, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217]"
776,839,2,[],200,EleutherAI/gpt-neox-20b,128,1,2284.0,1.0,1,H100,1697105158563,1697105160847.0,120,58.0,5.0,"[5, 2013, 93, 86, 87]","[1697105158568, 1697105160581, 1697105160674, 1697105160760, 1697105160847]"
777,562,9,[],200,EleutherAI/gpt-neox-20b,128,1,9095.0,1.0,1,H100,1697105183841,1697105192936.0,120,67.0,39.0,"[5, 2743, 88, 79, 77, 60, 279, 84, 83, 83, 376, 89, 561, 94, 165, 80, 376, 86, 85, 481, 90, 272, 165, 251, 87, 251, 66, 87, 66, 367, 162, 87, 281, 82, 275, 76, 286, 87, 83]","[1697105183846, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186893, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188707, 1697105188787, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936]"
778,219,4,[],200,EleutherAI/gpt-neox-20b,128,1,4592.0,1.0,1,H100,1697105171672,1697105176264.0,120,90.0,20.0,"[9, 2103, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69]","[1697105171681, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
779,375,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105164161,1697105170013.0,120,,,"[24, 2906, 116, 196, 133, 75, 460, 227, 76, 273, 231, 127, 144, 219, 181, 155]","[1697105164185, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
780,422,3,[],200,EleutherAI/gpt-neox-20b,128,1,2102.0,1.0,1,H100,1697105164161,1697105166263.0,120,26.0,1.0,"[32, 2070]","[1697105164193, 1697105166263]"
781,576,5,[],200,EleutherAI/gpt-neox-20b,128,1,1462.0,1.0,1,H100,1697105176270,1697105177732.0,120,14.0,1.0,"[34, 1428]","[1697105176304, 1697105177732]"
782,567,5,[],200,EleutherAI/gpt-neox-20b,128,1,4564.0,1.0,1,H100,1697105173785,1697105178349.0,120,90.0,20.0,"[17, 1820, 99, 91, 89, 70, 87, 69, 68, 69, 759, 81, 81, 63, 674, 95, 90, 88, 67, 87]","[1697105173802, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176264, 1697105177023, 1697105177104, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178262, 1697105178349]"
783,908,6,[],200,EleutherAI/gpt-neox-20b,128,1,9523.0,1.0,1,H100,1697105177733,1697105187256.0,120,6.0,50.0,"[13, 1753, 87, 85, 66, 365, 85, 66, 280, 79, 75, 489, 80, 80, 388, 86, 76, 408, 89, 83, 384, 89, 88, 190, 87, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 87, 81, 411, 88, 79, 78, 59, 280, 84]","[1697105177746, 1697105179499, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181176, 1697105181256, 1697105181336, 1697105181724, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256]"
784,704,2,[],200,EleutherAI/gpt-neox-20b,128,1,1849.0,1.0,1,H100,1697105163355,1697105165204.0,120,14.0,1.0,"[16, 1833]","[1697105163371, 1697105165204]"
785,667,10,[],200,EleutherAI/gpt-neox-20b,128,1,6366.0,1.0,1,H100,1697105185400,1697105191766.0,120,364.0,17.0,"[20, 3743, 86, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 166, 83]","[1697105185420, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191683, 1697105191766]"
786,843,13,[],200,EleutherAI/gpt-neox-20b,128,1,2538.0,1.0,1,H100,1697105192854,1697105195392.0,120,14.0,1.0,"[9, 2529]","[1697105192863, 1697105195392]"
787,2,6,[],200,EleutherAI/gpt-neox-20b,128,1,3078.0,1.0,1,H100,1697105177024,1697105180102.0,120,58.0,6.0,"[5, 2469, 88, 85, 66, 365]","[1697105177029, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102]"
788,454,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105197707,1697105201998.0,120,,,"[13, 3574, 160, 213]","[1697105197720, 1697105201294, 1697105201454, 1697105201667]"
789,804,12,[],200,EleutherAI/gpt-neox-20b,128,1,2145.0,1.0,1,H100,1697105202015,1697105204160.0,120,20.0,1.0,"[188, 1957]","[1697105202203, 1697105204160]"
790,321,13,[],200,EleutherAI/gpt-neox-20b,128,1,2831.0,1.0,1,H100,1697105204161,1697105206992.0,120,182.0,4.0,"[8, 2645, 89, 89]","[1697105204169, 1697105206814, 1697105206903, 1697105206992]"
791,129,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105166266,1697105170013.0,120,,,[15],[1697105166281]
792,697,1,[],200,EleutherAI/gpt-neox-20b,128,1,3710.0,1.0,1,H100,1697105160059,1697105163769.0,120,123.0,10.0,"[4, 2586, 85, 79, 361, 92, 87, 79, 251, 86]","[1697105160063, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769]"
793,480,3,[],200,EleutherAI/gpt-neox-20b,128,1,1392.0,1.0,1,H100,1697105160394,1697105161786.0,120,26.0,1.0,"[8, 1384]","[1697105160402, 1697105161786]"
794,248,6,[],200,EleutherAI/gpt-neox-20b,128,1,4357.0,1.0,1,H100,1697105180544,1697105184901.0,120,182.0,17.0,"[16, 2290, 89, 88, 190, 87, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215]","[1697105180560, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901]"
795,28,6,[],200,EleutherAI/gpt-neox-20b,128,1,4910.0,1.0,1,H100,1697105175623,1697105180533.0,120,86.0,20.0,"[4, 2295, 94, 91, 88, 67, 86, 469, 90, 67, 87, 81, 356, 88, 85, 66, 365, 85, 66, 280]","[1697105175627, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180533]"
796,920,1,[],200,EleutherAI/gpt-neox-20b,128,1,1833.0,1.0,1,H100,1697105158928,1697105160761.0,120,96.0,4.0,"[5, 1648, 93, 86]","[1697105158933, 1697105160581, 1697105160674, 1697105160760]"
797,351,2,[],200,EleutherAI/gpt-neox-20b,128,1,3475.0,1.0,1,H100,1697105160762,1697105164237.0,120,216.0,6.0,"[4, 2917, 86, 85, 306, 76]","[1697105160766, 1697105163683, 1697105163769, 1697105163854, 1697105164160, 1697105164236]"
798,565,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170016,1697105172155.0,120,,,"[62, 1685]","[1697105170078, 1697105171763]"
799,708,3,[],200,EleutherAI/gpt-neox-20b,128,1,2908.0,1.0,1,H100,1697105164238,1697105167146.0,120,140.0,1.0,"[4, 2904]","[1697105164242, 1697105167146]"
800,894,4,[],200,EleutherAI/gpt-neox-20b,128,1,1526.0,1.0,1,H100,1697105172158,1697105173684.0,120,14.0,1.0,"[65, 1461]","[1697105172223, 1697105173684]"
801,112,4,[],200,EleutherAI/gpt-neox-20b,128,1,4616.0,1.0,1,H100,1697105167147,1697105171763.0,120,16.0,2.0,"[5, 4611]","[1697105167152, 1697105171763]"
802,285,9,[],200,EleutherAI/gpt-neox-20b,128,1,6636.0,1.0,1,H100,1697105186678,1697105193314.0,120,100.0,27.0,"[16, 2469, 86, 86, 480, 90, 272, 165, 251, 87, 251, 66, 87, 66, 367, 166, 83, 281, 82, 275, 76, 286, 87, 83, 234, 82, 62]","[1697105186694, 1697105189163, 1697105189249, 1697105189335, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191683, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314]"
803,745,6,[],200,EleutherAI/gpt-neox-20b,128,1,1368.0,1.0,1,H100,1697105182295,1697105183663.0,120,17.0,1.0,"[4, 1364]","[1697105182299, 1697105183663]"
804,792,3,[],200,EleutherAI/gpt-neox-20b,128,1,1746.0,1.0,1,H100,1697105164517,1697105166263.0,120,11.0,1.0,"[16, 1730]","[1697105164533, 1697105166263]"
805,669,7,[],200,EleutherAI/gpt-neox-20b,128,1,5405.0,1.0,1,H100,1697105178350,1697105183755.0,120,83.0,20.0,"[13, 2170, 79, 76, 487, 81, 80, 387, 87, 76, 408, 89, 83, 384, 89, 88, 190, 87, 78, 372]","[1697105178363, 1697105180533, 1697105180612, 1697105180688, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754]"
806,512,4,[],200,EleutherAI/gpt-neox-20b,128,1,1840.0,1.0,1,H100,1697105169369,1697105171209.0,120,11.0,1.0,"[8, 1831]","[1697105169377, 1697105171208]"
807,872,5,[],200,EleutherAI/gpt-neox-20b,128,1,5054.0,1.0,1,H100,1697105171210,1697105176264.0,120,91.0,20.0,"[9, 2565, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 98, 92, 89, 69, 88, 68, 69, 69]","[1697105171219, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175720, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
808,102,3,[],200,EleutherAI/gpt-neox-20b,128,1,4591.0,1.0,1,H100,1697105171673,1697105176264.0,120,84.0,20.0,"[28, 2083, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69]","[1697105171701, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
809,223,4,[],200,EleutherAI/gpt-neox-20b,128,1,2807.0,1.0,1,H100,1697105166264,1697105169071.0,120,16.0,1.0,"[12, 2795]","[1697105166276, 1697105169071]"
810,577,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105169072,1697105172155.0,120,,,"[4, 2687]","[1697105169076, 1697105171763]"
811,905,6,[],200,EleutherAI/gpt-neox-20b,128,1,1525.0,1.0,1,H100,1697105172159,1697105173684.0,120,11.0,1.0,"[210, 1315]","[1697105172369, 1697105173684]"
812,332,7,[],200,EleutherAI/gpt-neox-20b,128,1,1821.0,1.0,1,H100,1697105173686,1697105175507.0,120,39.0,1.0,"[56, 1765]","[1697105173742, 1697105175507]"
813,693,8,[],200,EleutherAI/gpt-neox-20b,128,1,1516.0,1.0,1,H100,1697105175508,1697105177024.0,120,67.0,2.0,"[16, 1500]","[1697105175524, 1697105177024]"
814,300,6,[],200,EleutherAI/gpt-neox-20b,128,1,1464.0,1.0,1,H100,1697105176268,1697105177732.0,120,9.0,1.0,"[11, 1453]","[1697105176279, 1697105177732]"
815,124,9,[],200,EleutherAI/gpt-neox-20b,128,1,2474.0,1.0,1,H100,1697105177025,1697105179499.0,120,83.0,2.0,"[12, 2461]","[1697105177037, 1697105179498]"
816,331,5,[],200,EleutherAI/gpt-neox-20b,128,1,1610.0,1.0,1,H100,1697105171210,1697105172820.0,120,26.0,1.0,"[17, 1593]","[1697105171227, 1697105172820]"
817,745,7,[],200,EleutherAI/gpt-neox-20b,128,1,2278.0,1.0,1,H100,1697105177733,1697105180011.0,120,17.0,1.0,"[17, 2260]","[1697105177750, 1697105180010]"
818,689,6,[],200,EleutherAI/gpt-neox-20b,128,1,1759.0,1.0,1,H100,1697105172823,1697105174582.0,120,15.0,1.0,"[13, 1746]","[1697105172836, 1697105174582]"
819,55,3,[],200,EleutherAI/gpt-neox-20b,128,1,3316.0,1.0,1,H100,1697105166613,1697105169929.0,120,12.0,1.0,"[8, 3307]","[1697105166621, 1697105169928]"
820,114,7,[],200,EleutherAI/gpt-neox-20b,128,1,5154.0,1.0,1,H100,1697105174583,1697105179737.0,120,88.0,20.0,"[4, 2437, 81, 80, 63, 674, 95, 90, 88, 67, 87, 468, 90, 67, 87, 81, 356, 88, 85, 65]","[1697105174587, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178262, 1697105178349, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736]"
821,271,4,[],200,EleutherAI/gpt-neox-20b,128,1,4109.0,1.0,1,H100,1697105172156,1697105176265.0,120,87.0,20.0,"[36, 1592, 80, 77, 72, 668, 92, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69]","[1697105172192, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
822,463,4,[],200,EleutherAI/gpt-neox-20b,128,1,1528.0,1.0,1,H100,1697105172156,1697105173684.0,120,39.0,1.0,"[52, 1476]","[1697105172208, 1697105173684]"
823,822,5,[],200,EleutherAI/gpt-neox-20b,128,1,3563.0,1.0,1,H100,1697105173685,1697105177248.0,120,88.0,20.0,"[20, 976, 92, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69, 760, 81, 80, 63]","[1697105173705, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177024, 1697105177105, 1697105177185, 1697105177248]"
824,405,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105169929,1697105172156.0,120,,,"[5, 1829]","[1697105169934, 1697105171763]"
825,734,5,[],200,EleutherAI/gpt-neox-20b,128,1,2521.0,1.0,1,H100,1697105172159,1697105174680.0,120,100.0,6.0,"[217, 1408, 80, 77, 72, 667]","[1697105172376, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680]"
826,573,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170016,1697105172155.0,120,,,[94],[1697105170110]
827,343,9,[],200,EleutherAI/gpt-neox-20b,128,1,5749.0,1.0,1,H100,1697105188788,1697105194537.0,120,84.0,20.0,"[4, 3255, 82, 275, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81, 265, 64, 84]","[1697105188792, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537]"
828,541,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170016,1697105172155.0,120,,,[90],[1697105170106]
829,469,8,[],200,EleutherAI/gpt-neox-20b,128,1,2371.0,1.0,1,H100,1697105179738,1697105182109.0,120,17.0,1.0,"[21, 2350]","[1697105179759, 1697105182109]"
830,913,9,[],200,EleutherAI/gpt-neox-20b,128,1,4567.0,1.0,1,H100,1697105182110,1697105186677.0,120,88.0,20.0,"[4, 1641, 85, 85, 79, 383, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 88, 81, 411, 88]","[1697105182114, 1697105183755, 1697105183840, 1697105183925, 1697105184004, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186178, 1697105186589, 1697105186677]"
831,900,4,[],200,EleutherAI/gpt-neox-20b,128,1,2521.0,1.0,1,H100,1697105172159,1697105174680.0,120,67.0,6.0,"[141, 1484, 80, 77, 72, 667]","[1697105172300, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680]"
832,164,6,[],200,EleutherAI/gpt-neox-20b,128,1,825.0,1.0,1,H100,1697105174682,1697105175507.0,120,15.0,1.0,"[12, 813]","[1697105174694, 1697105175507]"
833,289,10,[],200,EleutherAI/gpt-neox-20b,128,1,5516.0,1.0,1,H100,1697105187799,1697105193315.0,120,89.0,20.0,"[4, 2790, 88, 250, 66, 87, 67, 366, 162, 87, 281, 82, 276, 75, 286, 87, 83, 234, 82, 62]","[1697105187803, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191151, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192405, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314]"
834,650,11,[],200,EleutherAI/gpt-neox-20b,128,1,2076.0,1.0,1,H100,1697105193316,1697105195392.0,120,13.0,1.0,"[8, 2068]","[1697105193324, 1697105195392]"
835,528,7,[],200,EleutherAI/gpt-neox-20b,128,1,4229.0,1.0,1,H100,1697105175508,1697105179737.0,120,52.0,20.0,"[4, 1512, 81, 80, 63, 674, 95, 90, 88, 67, 86, 469, 90, 67, 87, 81, 356, 88, 85, 66]","[1697105175512, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737]"
836,79,12,[],200,EleutherAI/gpt-neox-20b,128,1,2767.0,1.0,1,H100,1697105195393,1697105198160.0,120,12.0,1.0,"[20, 2747]","[1697105195413, 1697105198160]"
837,438,13,[],200,EleutherAI/gpt-neox-20b,128,1,2673.0,1.0,1,H100,1697105198162,1697105200835.0,120,9.0,1.0,"[12, 2661]","[1697105198174, 1697105200835]"
838,299,4,[],200,EleutherAI/gpt-neox-20b,128,1,1306.0,1.0,1,H100,1697105175623,1697105176929.0,120,14.0,1.0,"[8, 1298]","[1697105175631, 1697105176929]"
839,788,14,[],200,EleutherAI/gpt-neox-20b,128,1,2143.0,1.0,1,H100,1697105200837,1697105202980.0,120,31.0,1.0,"[12, 2131]","[1697105200849, 1697105202980]"
840,660,5,[],200,EleutherAI/gpt-neox-20b,128,1,6374.0,1.0,1,H100,1697105176930,1697105183304.0,120,732.0,25.0,"[21, 2547, 88, 85, 66, 365, 85, 66, 280, 79, 75, 488, 81, 80, 388, 86, 76, 408, 89, 83, 384, 89, 88, 190, 87]","[1697105176951, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181724, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304]"
841,188,15,[],200,EleutherAI/gpt-neox-20b,128,1,4377.0,1.0,1,H100,1697105202982,1697105207359.0,120,85.0,20.0,"[32, 1908, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84, 732, 89, 89, 86, 81, 79, 60, 61]","[1697105203014, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359]"
842,359,7,[],200,EleutherAI/gpt-neox-20b,128,1,1354.0,1.0,1,H100,1697105180103,1697105181457.0,120,10.0,1.0,"[8, 1345]","[1697105180111, 1697105181456]"
843,719,8,[],200,EleutherAI/gpt-neox-20b,128,1,2930.0,1.0,1,H100,1697105181457,1697105184387.0,120,182.0,6.0,"[5, 2292, 86, 85, 78, 384]","[1697105181462, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387]"
844,694,0,[],200,EleutherAI/gpt-neox-20b,128,1,4400.0,1.0,1,H100,1697105154527,1697105158927.0,120,161.0,13.0,"[293, 2262, 307, 84, 61, 81, 78, 358, 70, 86, 466, 161, 93]","[1697105154820, 1697105157082, 1697105157389, 1697105157473, 1697105157534, 1697105157615, 1697105157693, 1697105158051, 1697105158121, 1697105158207, 1697105158673, 1697105158834, 1697105158927]"
845,346,10,[],200,EleutherAI/gpt-neox-20b,128,1,5727.0,1.0,1,H100,1697105186678,1697105192405.0,120,85.0,20.0,"[12, 2473, 86, 85, 481, 90, 272, 165, 251, 87, 251, 66, 87, 66, 367, 166, 83, 281, 82, 275]","[1697105186690, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191683, 1697105191766, 1697105192047, 1697105192129, 1697105192404]"
846,124,1,[],200,EleutherAI/gpt-neox-20b,128,1,1653.0,1.0,1,H100,1697105158928,1697105160581.0,120,83.0,2.0,"[5, 1648]","[1697105158933, 1697105160581]"
847,295,2,[],200,EleutherAI/gpt-neox-20b,128,1,2608.0,1.0,1,H100,1697105161552,1697105164160.0,120,52.0,2.0,"[4, 2604]","[1697105161556, 1697105164160]"
848,172,10,[],200,EleutherAI/gpt-neox-20b,128,1,2083.0,1.0,1,H100,1697105190594,1697105192677.0,120,19.0,1.0,"[12, 2071]","[1697105190606, 1697105192677]"
849,617,11,[],200,EleutherAI/gpt-neox-20b,128,1,5746.0,1.0,1,H100,1697105192678,1697105198424.0,120,87.0,20.0,"[5, 2798, 88, 115, 84, 174, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 327, 211, 117, 63]","[1697105192683, 1697105195481, 1697105195569, 1697105195684, 1697105195768, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198033, 1697105198244, 1697105198361, 1697105198424]"
850,649,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105164161,1697105170013.0,120,,,"[36, 2623, 271, 116, 196, 133, 75, 460, 227, 76, 273, 231, 128, 143, 219, 181, 155]","[1697105164197, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
851,47,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105198425,1697105201999.0,120,,,"[13, 3229]","[1697105198438, 1697105201667]"
852,679,14,[],200,EleutherAI/gpt-neox-20b,128,1,2265.0,1.0,1,H100,1697105206994,1697105209259.0,120,15.0,1.0,"[8, 2257]","[1697105207002, 1697105209259]"
853,727,2,[],200,EleutherAI/gpt-neox-20b,128,1,2021.0,1.0,1,H100,1697105159617,1697105161638.0,120,58.0,5.0,"[5, 1744, 93, 92, 87]","[1697105159622, 1697105161366, 1697105161459, 1697105161551, 1697105161638]"
854,887,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105159804,1697105170014.0,120,,,"[16, 2829, 85, 79, 361, 92, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 342, 89, 82, 286, 68, 78, 468, 246, 209, 271, 116, 196, 133, 75, 460, 227, 76, 273, 231, 127, 144, 218, 182, 155]","[1697105159820, 1697105162649, 1697105162734, 1697105162813, 1697105163174, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005, 1697105169149, 1697105169367, 1697105169549, 1697105169704]"
855,115,15,[],200,EleutherAI/gpt-neox-20b,128,1,2663.0,1.0,1,H100,1697105209260,1697105211923.0,120,13.0,1.0,"[9, 2654]","[1697105209269, 1697105211923]"
856,409,13,[],200,EleutherAI/gpt-neox-20b,128,1,6059.0,1.0,1,H100,1697105202004,1697105208063.0,120,109.0,30.0,"[91, 1623, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 390, 90, 85, 84, 732, 89, 89, 86, 80, 80, 60, 60, 619, 86]","[1697105202095, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205823, 1697105205913, 1697105205998, 1697105206082, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207358, 1697105207977, 1697105208063]"
857,474,16,[],200,EleutherAI/gpt-neox-20b,128,1,7110.0,1.0,1,H100,1697105211924,1697105219034.0,120,109.0,33.0,"[9, 1898, 93, 90, 89, 68, 246, 85, 65, 75, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 82, 256, 79, 368, 81, 59]","[1697105211933, 1697105213831, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034]"
858,74,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170018,1697105172155.0,120,,,[84],[1697105170102]
859,433,5,[],200,EleutherAI/gpt-neox-20b,128,1,1628.0,1.0,1,H100,1697105172156,1697105173784.0,120,109.0,2.0,"[39, 1589]","[1697105172195, 1697105173784]"
860,762,6,[],200,EleutherAI/gpt-neox-20b,128,1,4564.0,1.0,1,H100,1697105173785,1697105178349.0,120,92.0,20.0,"[9, 1828, 99, 91, 89, 70, 87, 69, 68, 69, 759, 82, 80, 63, 674, 94, 91, 88, 67, 87]","[1697105173794, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176264, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178349]"
861,882,8,[],200,EleutherAI/gpt-neox-20b,128,1,3587.0,1.0,1,H100,1697105183305,1697105186892.0,120,345.0,11.0,"[4, 2089, 74, 537, 88, 83, 408, 88, 79, 78, 59]","[1697105183309, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186180, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892]"
862,769,14,[],200,EleutherAI/gpt-neox-20b,128,1,6107.0,1.0,1,H100,1697105208064,1697105214171.0,120,47.0,20.0,"[4, 3246, 168, 77, 456, 89, 80, 80, 74, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68]","[1697105208068, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212264, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171]"
863,198,7,[],200,EleutherAI/gpt-neox-20b,128,1,5405.0,1.0,1,H100,1697105178350,1697105183755.0,120,96.0,20.0,"[9, 2174, 79, 76, 487, 81, 80, 387, 87, 76, 408, 88, 84, 384, 89, 88, 190, 87, 78, 372]","[1697105178359, 1697105180533, 1697105180612, 1697105180688, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182382, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754]"
864,232,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105196361,1697105201999.0,120,,,"[13, 3453, 129, 150, 140, 81, 79, 220, 296, 80, 292, 160, 212]","[1697105196374, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
865,212,3,[],200,EleutherAI/gpt-neox-20b,128,1,2413.0,1.0,1,H100,1697105162103,1697105164516.0,120,31.0,1.0,"[13, 2400]","[1697105162116, 1697105164516]"
866,570,4,[],200,EleutherAI/gpt-neox-20b,128,1,1746.0,1.0,1,H100,1697105164517,1697105166263.0,120,18.0,1.0,"[12, 1734]","[1697105164529, 1697105166263]"
867,0,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105166264,1697105172155.0,120,,,"[8, 5491]","[1697105166272, 1697105171763]"
868,358,6,[],200,EleutherAI/gpt-neox-20b,128,1,1706.0,1.0,1,H100,1697105172158,1697105173864.0,120,216.0,3.0,"[21, 1605, 80]","[1697105172179, 1697105173784, 1697105173864]"
869,644,2,[],200,EleutherAI/gpt-neox-20b,128,1,1700.0,1.0,1,H100,1697105162816,1697105164516.0,120,19.0,1.0,"[8, 1692]","[1697105162824, 1697105164516]"
870,72,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105164517,1697105170013.0,120,,,"[8, 2878, 133, 75, 460, 227, 76, 273, 231, 127, 144, 219, 181, 155]","[1697105164525, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
871,35,9,[],200,EleutherAI/gpt-neox-20b,128,1,6384.0,1.0,1,H100,1697105194538,1697105200922.0,120,87.0,20.0,"[5, 3004, 82, 77, 327, 211, 117, 63, 265, 273, 410, 225, 230, 129, 150, 140, 81, 79, 220, 296]","[1697105194543, 1697105197547, 1697105197629, 1697105197706, 1697105198033, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199597, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922]"
872,384,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165295,1697105170013.0,120,,,"[5, 2998, 76, 273, 232, 127, 143, 219, 181, 155]","[1697105165300, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
873,719,7,[],200,EleutherAI/gpt-neox-20b,128,1,4058.0,1.0,1,H100,1697105173865,1697105177923.0,120,182.0,6.0,"[8, 3150, 82, 80, 63, 674]","[1697105173873, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177922]"
874,840,4,[],200,EleutherAI/gpt-neox-20b,128,1,1807.0,1.0,1,H100,1697105161787,1697105163594.0,120,17.0,1.0,"[5, 1802]","[1697105161792, 1697105163594]"
875,591,10,[],200,EleutherAI/gpt-neox-20b,128,1,9475.0,1.0,1,H100,1697105202007,1697105211482.0,120,874.0,47.0,"[164, 1547, 88, 88, 87, 269, 87, 87, 83, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84, 732, 89, 89, 86, 80, 80, 60, 61, 618, 86, 82, 83, 63, 435, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 81, 429, 168]","[1697105202171, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210885, 1697105211314, 1697105211482]"
876,440,7,[],200,EleutherAI/gpt-neox-20b,128,1,5055.0,1.0,1,H100,1697105174682,1697105179737.0,120,84.0,20.0,"[16, 2325, 82, 80, 63, 674, 95, 91, 87, 68, 85, 469, 90, 67, 87, 81, 356, 88, 85, 66]","[1697105174698, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178108, 1697105178195, 1697105178263, 1697105178348, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737]"
877,875,6,[],200,EleutherAI/gpt-neox-20b,128,1,7227.0,1.0,1,H100,1697105174583,1697105181810.0,120,31.0,31.0,"[13, 2333, 94, 82, 80, 63, 674, 95, 90, 88, 67, 87, 468, 90, 67, 87, 81, 356, 88, 85, 65, 366, 85, 66, 280, 79, 75, 488, 81, 80, 387, 87]","[1697105174596, 1697105176929, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178262, 1697105178349, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810]"
878,116,8,[],200,EleutherAI/gpt-neox-20b,128,1,2087.0,1.0,1,H100,1697105177924,1697105180011.0,120,23.0,1.0,"[12, 2075]","[1697105177936, 1697105180011]"
879,272,5,[],200,EleutherAI/gpt-neox-20b,128,1,5773.0,1.0,1,H100,1697105163595,1697105169368.0,120,86.0,20.0,"[9, 2147, 68, 78, 468, 247, 208, 271, 116, 196, 133, 75, 460, 227, 76, 273, 232, 127, 143, 219]","[1697105163604, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368]"
880,736,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105176273,1697105201998.0,120,,,"[103, 2441, 90, 67, 87, 81, 356, 88, 85, 66, 365, 85, 66, 285, 74, 75, 488, 81, 80, 388, 86, 76, 408, 89, 83, 383, 90, 88, 190, 87, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 87, 81, 411, 88, 79, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 162, 87, 281, 81, 276, 76, 286, 87, 82, 235, 82, 62, 305, 87, 189, 84, 63, 81, 266, 63, 85, 199, 80, 78, 261, 326, 87, 116, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 326, 212, 117, 63, 264, 273, 411, 224, 230, 130, 150, 140, 80, 80, 219, 297, 80, 292, 160, 212]","[1697105176376, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180538, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181724, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182849, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192128, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192935, 1697105193170, 1697105193252, 1697105193314, 1697105193619, 1697105193706, 1697105193895, 1697105193979, 1697105194042, 1697105194123, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198688, 1697105198961, 1697105199372, 1697105199596, 1697105199826, 1697105199956, 1697105200106, 1697105200246, 1697105200326, 1697105200406, 1697105200625, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
881,601,6,[],200,EleutherAI/gpt-neox-20b,128,1,6249.0,1.0,1,H100,1697105184902,1697105191151.0,120,83.0,20.0,"[9, 2887, 89, 561, 94, 164, 81, 376, 86, 85, 481, 90, 272, 165, 251, 87, 251, 66, 87, 66]","[1697105184911, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150]"
882,467,5,[],200,EleutherAI/gpt-neox-20b,128,1,4500.0,1.0,1,H100,1697105171764,1697105176264.0,120,93.0,20.0,"[9, 2011, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 98, 92, 89, 69, 88, 68, 69, 69]","[1697105171773, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175720, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
883,449,9,[],200,EleutherAI/gpt-neox-20b,128,1,6249.0,1.0,1,H100,1697105184902,1697105191151.0,120,86.0,20.0,"[17, 2879, 89, 561, 94, 164, 81, 376, 86, 85, 481, 90, 272, 166, 250, 88, 250, 66, 87, 67]","[1697105184919, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190343, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191151]"
884,452,10,[],200,EleutherAI/gpt-neox-20b,128,1,2891.0,1.0,1,H100,1697105191152,1697105194043.0,120,216.0,4.0,"[20, 2636, 87, 84, 64]","[1697105191172, 1697105193808, 1697105193895, 1697105193979, 1697105194043]"
885,825,6,[],200,EleutherAI/gpt-neox-20b,128,1,4267.0,1.0,1,H100,1697105176271,1697105180538.0,120,96.0,20.0,"[98, 1554, 94, 91, 87, 68, 86, 468, 90, 67, 87, 81, 356, 88, 85, 65, 366, 85, 66, 285]","[1697105176369, 1697105177923, 1697105178017, 1697105178108, 1697105178195, 1697105178263, 1697105178349, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180538]"
886,646,10,[],200,EleutherAI/gpt-neox-20b,128,1,2076.0,1.0,1,H100,1697105193316,1697105195392.0,120,14.0,1.0,"[8, 2068]","[1697105193324, 1697105195392]"
887,673,1,[],200,EleutherAI/gpt-neox-20b,128,1,5760.0,1.0,1,H100,1697105160059,1697105165819.0,120,93.0,20.0,"[4, 3112, 91, 87, 79, 251, 86, 85, 305, 77, 371, 89, 89, 88, 79, 343, 88, 82, 286, 68]","[1697105160063, 1697105163175, 1697105163266, 1697105163353, 1697105163432, 1697105163683, 1697105163769, 1697105163854, 1697105164159, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819]"
888,73,11,[],200,EleutherAI/gpt-neox-20b,128,1,2767.0,1.0,1,H100,1697105195393,1697105198160.0,120,9.0,1.0,"[12, 2755]","[1697105195405, 1697105198160]"
889,430,12,[],200,EleutherAI/gpt-neox-20b,128,1,2674.0,1.0,1,H100,1697105198161,1697105200835.0,120,15.0,1.0,"[9, 2665]","[1697105198170, 1697105200835]"
890,760,13,[],200,EleutherAI/gpt-neox-20b,128,1,13334.0,1.0,1,H100,1697105200837,1697105214171.0,120,335.0,64.0,"[8, 2873, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84, 731, 90, 89, 86, 80, 80, 60, 60, 618, 87, 82, 83, 63, 435, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 81, 429, 168, 77, 456, 89, 80, 79, 75, 71, 482, 88, 89, 82, 75, 605, 94, 90, 89, 68]","[1697105200845, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207358, 1697105207976, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210885, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212409, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171]"
891,103,2,[],200,EleutherAI/gpt-neox-20b,128,1,2311.0,1.0,1,H100,1697105165820,1697105168131.0,120,15.0,1.0,"[8, 2303]","[1697105165828, 1697105168131]"
892,460,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105168132,1697105172155.0,120,,,"[4, 3627]","[1697105168136, 1697105171763]"
893,204,9,[],200,EleutherAI/gpt-neox-20b,128,1,3170.0,1.0,1,H100,1697105187423,1697105190593.0,120,67.0,6.0,"[4, 2388, 90, 272, 165, 251]","[1697105187427, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593]"
894,903,7,[],200,EleutherAI/gpt-neox-20b,128,1,3249.0,1.0,1,H100,1697105182760,1697105186009.0,120,244.0,7.0,"[9, 2132, 77, 58, 362, 74, 537]","[1697105182769, 1697105184901, 1697105184978, 1697105185036, 1697105185398, 1697105185472, 1697105186009]"
895,818,4,[],200,EleutherAI/gpt-neox-20b,128,1,1526.0,1.0,1,H100,1697105172158,1697105173684.0,120,13.0,1.0,"[119, 1407]","[1697105172277, 1697105173684]"
896,257,3,[],200,EleutherAI/gpt-neox-20b,128,1,1655.0,1.0,1,H100,1697105170016,1697105171671.0,120,14.0,1.0,"[158, 1497]","[1697105170174, 1697105171671]"
897,623,4,[],200,EleutherAI/gpt-neox-20b,128,1,2192.0,1.0,1,H100,1697105171672,1697105173864.0,120,140.0,3.0,"[9, 2103, 80]","[1697105171681, 1697105173784, 1697105173864]"
898,53,5,[],200,EleutherAI/gpt-neox-20b,128,1,10522.0,1.0,1,H100,1697105173865,1697105184387.0,120,216.0,55.0,"[4, 1753, 99, 91, 89, 70, 87, 69, 68, 69, 759, 82, 80, 63, 674, 95, 90, 88, 67, 87, 467, 91, 66, 88, 81, 356, 88, 85, 65, 366, 85, 66, 280, 79, 75, 488, 81, 80, 387, 87, 75, 409, 88, 84, 383, 90, 88, 189, 88, 78, 372, 86, 85, 78, 384]","[1697105173869, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176264, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178262, 1697105178349, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181885, 1697105182294, 1697105182382, 1697105182466, 1697105182849, 1697105182939, 1697105183027, 1697105183216, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387]"
899,424,8,[],200,EleutherAI/gpt-neox-20b,128,1,6394.0,1.0,1,H100,1697105186010,1697105192404.0,120,88.0,20.0,"[5, 3148, 86, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 162, 87, 281, 82, 275]","[1697105186015, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192404]"
900,461,4,[],200,EleutherAI/gpt-neox-20b,128,1,6112.0,1.0,1,H100,1697105176271,1697105182383.0,120,216.0,30.0,"[41, 1610, 95, 90, 88, 68, 86, 467, 91, 66, 88, 81, 356, 88, 85, 65, 366, 85, 66, 285, 74, 75, 488, 81, 80, 387, 87, 76, 408, 89]","[1697105176312, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178263, 1697105178349, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180538, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383]"
901,648,12,[],200,EleutherAI/gpt-neox-20b,128,1,6485.0,1.0,1,H100,1697105199597,1697105206082.0,120,84.0,20.0,"[5, 4116, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84]","[1697105199602, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
902,196,6,[],200,EleutherAI/gpt-neox-20b,128,1,1421.0,1.0,1,H100,1697105175508,1697105176929.0,120,13.0,1.0,"[12, 1409]","[1697105175520, 1697105176929]"
903,551,7,[],200,EleutherAI/gpt-neox-20b,128,1,4794.0,1.0,1,H100,1697105176930,1697105181724.0,120,90.0,20.0,"[21, 1866, 90, 67, 87, 81, 356, 88, 85, 66, 365, 85, 66, 280, 79, 75, 488, 81, 80, 388]","[1697105176951, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181724]"
904,333,7,[],200,EleutherAI/gpt-neox-20b,128,1,3177.0,1.0,1,H100,1697105182295,1697105185472.0,120,563.0,11.0,"[4, 2088, 83, 79, 78, 59, 215, 77, 58, 362, 74]","[1697105182299, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185036, 1697105185398, 1697105185472]"
905,295,3,[],200,EleutherAI/gpt-neox-20b,128,1,1940.0,1.0,1,H100,1697105163355,1697105165295.0,120,52.0,2.0,"[4, 1936]","[1697105163359, 1697105165295]"
906,386,4,[],200,EleutherAI/gpt-neox-20b,128,1,2824.0,1.0,1,H100,1697105162995,1697105165819.0,120,140.0,6.0,"[4, 2296, 88, 82, 286, 68]","[1697105162999, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819]"
907,481,2,[],200,EleutherAI/gpt-neox-20b,128,1,1204.0,1.0,1,H100,1697105160582,1697105161786.0,120,10.0,1.0,"[8, 1196]","[1697105160590, 1697105161786]"
908,486,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165206,1697105170013.0,120,,,"[12, 1873, 116, 196, 133, 75, 460, 227, 76, 273, 231, 127, 144, 219, 181, 155]","[1697105165218, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
909,717,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165820,1697105170013.0,120,,,"[4, 3325, 219, 181, 155]","[1697105165824, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
910,835,3,[],200,EleutherAI/gpt-neox-20b,128,1,5824.0,1.0,1,H100,1697105161787,1697105167611.0,120,87.0,20.0,"[5, 2816, 88, 89, 88, 79, 343, 88, 82, 286, 68, 77, 469, 247, 208, 271, 116, 196, 133, 75]","[1697105161792, 1697105164608, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165896, 1697105166365, 1697105166612, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611]"
911,147,9,[],200,EleutherAI/gpt-neox-20b,128,1,2697.0,1.0,1,H100,1697105184388,1697105187085.0,120,182.0,1.0,"[5, 2692]","[1697105184393, 1697105187085]"
912,320,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170015,1697105172156.0,120,,,"[19, 1729]","[1697105170034, 1697105171763]"
913,167,14,[],200,EleutherAI/gpt-neox-20b,128,1,5319.0,1.0,1,H100,1697105187086,1697105192405.0,120,88.0,20.0,"[5, 2072, 86, 86, 480, 90, 272, 165, 251, 87, 251, 66, 87, 66, 367, 162, 87, 281, 82, 275]","[1697105187091, 1697105189163, 1697105189249, 1697105189335, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192404]"
914,674,4,[],200,EleutherAI/gpt-neox-20b,128,1,21460.0,1.0,1,H100,1697105172160,1697105193620.0,120,161.0,119.0,"[141, 1483, 80, 77, 72, 667, 94, 88, 68, 86, 84, 522, 99, 91, 89, 70, 87, 69, 68, 70, 758, 81, 81, 63, 674, 94, 91, 88, 67, 86, 468, 91, 66, 88, 81, 356, 88, 85, 65, 366, 85, 66, 280, 79, 75, 488, 81, 80, 387, 87, 75, 408, 89, 84, 383, 90, 88, 189, 88, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 87, 81, 411, 88, 79, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 162, 87, 281, 81, 276, 76, 286, 87, 82, 235, 82, 62, 305]","[1697105172301, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174774, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176265, 1697105177023, 1697105177104, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181885, 1697105182293, 1697105182382, 1697105182466, 1697105182849, 1697105182939, 1697105183027, 1697105183216, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192128, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192935, 1697105193170, 1697105193252, 1697105193314, 1697105193619]"
915,705,11,[],200,EleutherAI/gpt-neox-20b,128,1,7701.0,1.0,1,H100,1697105192405,1697105200106.0,120,79.0,27.0,"[21, 3055, 88, 115, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 327, 211, 117, 63, 265, 273, 410, 224, 231, 129, 150]","[1697105192426, 1697105195481, 1697105195569, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198033, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106]"
916,702,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105224662,1697105228773.0,120,,,"[5, 1585, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105224667, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
917,562,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105168299,1697105172155.0,120,,,"[5, 3459]","[1697105168304, 1697105171763]"
918,138,12,[],200,EleutherAI/gpt-neox-20b,128,1,5975.0,1.0,1,H100,1697105200107,1697105206082.0,120,91.0,20.0,"[5, 3606, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84]","[1697105200112, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
919,890,2,[],200,EleutherAI/gpt-neox-20b,128,1,4107.0,1.0,1,H100,1697105172158,1697105176265.0,120,93.0,20.0,"[109, 1517, 80, 77, 72, 668, 93, 88, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 70]","[1697105172267, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174681, 1697105174774, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176265]"
920,733,4,[],200,EleutherAI/gpt-neox-20b,128,1,1655.0,1.0,1,H100,1697105170016,1697105171671.0,120,31.0,1.0,"[74, 1581]","[1697105170090, 1697105171671]"
921,133,5,[],200,EleutherAI/gpt-neox-20b,128,1,1148.0,1.0,1,H100,1697105171673,1697105172821.0,120,15.0,1.0,"[16, 1132]","[1697105171689, 1697105172821]"
922,841,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105164874,1697105170013.0,120,,,"[8, 3189, 227, 76, 273, 232, 127, 143, 218, 182, 155]","[1697105164882, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169367, 1697105169549, 1697105169704]"
923,492,6,[],200,EleutherAI/gpt-neox-20b,128,1,4423.0,1.0,1,H100,1697105172825,1697105177248.0,120,47.0,20.0,"[19, 1836, 93, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69, 760, 81, 80, 63]","[1697105172844, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177024, 1697105177105, 1697105177185, 1697105177248]"
924,474,9,[],200,EleutherAI/gpt-neox-20b,128,1,7410.0,1.0,1,H100,1697105180012,1697105187422.0,120,109.0,33.0,"[20, 2818, 89, 88, 190, 87, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 87, 82, 410, 88, 79, 78, 59, 280, 84, 83, 83]","[1697105180032, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186178, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422]"
925,352,5,[],200,EleutherAI/gpt-neox-20b,128,1,1706.0,1.0,1,H100,1697105172158,1697105173864.0,120,11.0,3.0,"[110, 1416, 100, 80]","[1697105172268, 1697105173684, 1697105173784, 1697105173864]"
926,712,6,[],200,EleutherAI/gpt-neox-20b,128,1,4484.0,1.0,1,H100,1697105173865,1697105178349.0,120,88.0,20.0,"[4, 1753, 99, 91, 89, 70, 87, 69, 68, 69, 759, 82, 80, 63, 674, 95, 90, 88, 67, 87]","[1697105173869, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176264, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178262, 1697105178349]"
927,799,8,[],200,EleutherAI/gpt-neox-20b,128,1,5163.0,1.0,1,H100,1697105179738,1697105184901.0,120,84.0,20.0,"[13, 2543, 89, 83, 383, 90, 88, 189, 88, 78, 373, 85, 85, 78, 384, 83, 79, 78, 59, 215]","[1697105179751, 1697105182294, 1697105182383, 1697105182466, 1697105182849, 1697105182939, 1697105183027, 1697105183216, 1697105183304, 1697105183382, 1697105183755, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901]"
928,19,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105194538,1697105201998.0,120,,,"[9, 3486, 211, 117, 63, 265, 273, 410, 225, 230, 129, 150, 140, 81, 79, 220, 296, 80, 292, 160, 212]","[1697105194547, 1697105198033, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199597, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
929,812,11,[],200,EleutherAI/gpt-neox-20b,128,1,1574.0,1.0,1,H100,1697105194044,1697105195618.0,120,16.0,1.0,"[8, 1566]","[1697105194052, 1697105195618]"
930,170,7,[],200,EleutherAI/gpt-neox-20b,128,1,4223.0,1.0,1,H100,1697105183664,1697105187887.0,120,335.0,15.0,"[4, 2341, 88, 86, 406, 88, 78, 78, 59, 280, 84, 83, 83, 376, 89]","[1697105183668, 1697105186009, 1697105186097, 1697105186183, 1697105186589, 1697105186677, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887]"
931,244,12,[],200,EleutherAI/gpt-neox-20b,128,1,2680.0,1.0,1,H100,1697105195619,1697105198299.0,120,9.0,1.0,"[5, 2675]","[1697105195624, 1697105198299]"
932,1,7,[],200,EleutherAI/gpt-neox-20b,128,1,8444.0,1.0,1,H100,1697105191152,1697105199596.0,120,47.0,43.0,"[4, 1610, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81, 265, 63, 85, 199, 80, 79, 261, 325, 87, 116, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 326, 212, 117, 63, 265, 273, 410, 224]","[1697105191156, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194816, 1697105194895, 1697105195156, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596]"
933,232,9,[],200,EleutherAI/gpt-neox-20b,128,1,5779.0,1.0,1,H100,1697105184902,1697105190681.0,120,93.0,20.0,"[9, 2262, 83, 84, 82, 376, 89, 561, 94, 164, 81, 376, 86, 85, 481, 90, 272, 165, 251, 88]","[1697105184911, 1697105187173, 1697105187256, 1697105187340, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190681]"
934,601,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105198300,1697105201999.0,120,,,"[9, 2985, 160, 213]","[1697105198309, 1697105201294, 1697105201454, 1697105201667]"
935,639,9,[],200,EleutherAI/gpt-neox-20b,128,1,2877.0,1.0,1,H100,1697105183305,1697105186182.0,120,100.0,6.0,"[8, 2085, 74, 537, 88, 85]","[1697105183313, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186182]"
936,64,10,[],200,EleutherAI/gpt-neox-20b,128,1,6216.0,1.0,1,H100,1697105186188,1697105192404.0,120,89.0,20.0,"[8, 2967, 86, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 166, 83, 281, 82, 275]","[1697105186196, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191683, 1697105191766, 1697105192047, 1697105192129, 1697105192404]"
937,913,10,[],200,EleutherAI/gpt-neox-20b,128,1,5515.0,1.0,1,H100,1697105190845,1697105196360.0,120,88.0,20.0,"[9, 2766, 86, 189, 84, 64, 81, 265, 63, 85, 199, 80, 78, 262, 325, 87, 116, 83, 175, 418]","[1697105190854, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195156, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360]"
938,547,16,[],200,EleutherAI/gpt-neox-20b,128,1,2619.0,1.0,1,H100,1697105207360,1697105209979.0,120,12.0,1.0,"[20, 2599]","[1697105207380, 1697105209979]"
939,654,4,[],200,EleutherAI/gpt-neox-20b,128,1,3351.0,1.0,1,H100,1697105165296,1697105168647.0,120,47.0,4.0,"[8, 2994, 76, 273]","[1697105165304, 1697105168298, 1697105168374, 1697105168647]"
940,246,7,[],200,EleutherAI/gpt-neox-20b,128,1,9887.0,1.0,1,H100,1697105174583,1697105184470.0,120,58.0,47.0,"[17, 2423, 82, 80, 63, 674, 95, 91, 87, 67, 87, 468, 90, 67, 87, 81, 356, 88, 85, 65, 366, 85, 66, 280, 79, 75, 488, 81, 80, 387, 87, 75, 409, 88, 84, 383, 90, 88, 189, 88, 78, 372, 86, 85, 78, 384, 83]","[1697105174600, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178108, 1697105178195, 1697105178262, 1697105178349, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181885, 1697105182294, 1697105182382, 1697105182466, 1697105182849, 1697105182939, 1697105183027, 1697105183216, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470]"
941,86,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105168648,1697105172155.0,120,,,"[5, 3110]","[1697105168653, 1697105171763]"
942,543,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165821,1697105172155.0,120,,,"[27, 5915]","[1697105165848, 1697105171763]"
943,457,6,[],200,EleutherAI/gpt-neox-20b,128,1,3238.0,1.0,1,H100,1697105173785,1697105177023.0,120,874.0,2.0,"[9, 3229]","[1697105173794, 1697105177023]"
944,413,6,[],200,EleutherAI/gpt-neox-20b,128,1,9652.0,1.0,1,H100,1697105172158,1697105181810.0,120,244.0,50.0,"[135, 1491, 80, 77, 72, 667, 94, 88, 68, 86, 84, 522, 99, 91, 89, 70, 87, 69, 68, 70, 758, 81, 81, 63, 674, 94, 91, 88, 67, 86, 468, 91, 66, 88, 81, 356, 88, 85, 65, 365, 86, 66, 280, 79, 75, 488, 81, 80, 387, 87]","[1697105172293, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174774, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176265, 1697105177023, 1697105177104, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180101, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810]"
945,897,5,[],200,EleutherAI/gpt-neox-20b,128,1,1525.0,1.0,1,H100,1697105172159,1697105173684.0,120,9.0,1.0,"[213, 1312]","[1697105172372, 1697105173684]"
946,817,7,[],200,EleutherAI/gpt-neox-20b,128,1,5442.0,1.0,1,H100,1697105177024,1697105182466.0,120,86.0,20.0,"[5, 2469, 88, 85, 66, 365, 85, 66, 280, 79, 75, 488, 81, 80, 388, 86, 76, 408, 89, 83]","[1697105177029, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181724, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466]"
947,294,6,[],200,EleutherAI/gpt-neox-20b,128,1,996.0,1.0,1,H100,1697105173685,1697105174681.0,120,9.0,2.0,"[8, 988]","[1697105173693, 1697105174681]"
948,652,7,[],200,EleutherAI/gpt-neox-20b,128,1,2247.0,1.0,1,H100,1697105174682,1697105176929.0,120,14.0,1.0,"[16, 2231]","[1697105174698, 1697105176929]"
949,81,8,[],200,EleutherAI/gpt-neox-20b,128,1,3323.0,1.0,1,H100,1697105176930,1697105180253.0,120,732.0,13.0,"[5, 1882, 90, 67, 87, 81, 356, 88, 85, 66, 365, 85, 66]","[1697105176935, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253]"
950,259,8,[],200,EleutherAI/gpt-neox-20b,128,1,6131.0,1.0,1,H100,1697105184550,1697105190681.0,120,87.0,20.0,"[5, 2618, 83, 84, 82, 376, 89, 561, 94, 164, 81, 376, 86, 85, 481, 90, 272, 165, 251, 87]","[1697105184555, 1697105187173, 1697105187256, 1697105187340, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190680]"
951,246,8,[],200,EleutherAI/gpt-neox-20b,128,1,10469.0,1.0,1,H100,1697105182467,1697105192936.0,120,58.0,47.0,"[9, 2425, 77, 58, 362, 74, 537, 87, 81, 412, 88, 79, 77, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 162, 87, 281, 81, 276, 76, 286, 87, 83]","[1697105182476, 1697105184901, 1697105184978, 1697105185036, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192128, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936]"
952,273,7,[],200,EleutherAI/gpt-neox-20b,128,1,1196.0,1.0,1,H100,1697105182467,1697105183663.0,120,19.0,1.0,"[14, 1182]","[1697105182481, 1697105183663]"
953,723,2,[],200,EleutherAI/gpt-neox-20b,128,1,2063.0,1.0,1,H100,1697105160931,1697105162994.0,120,14.0,1.0,"[17, 2046]","[1697105160948, 1697105162994]"
954,151,3,[],200,EleutherAI/gpt-neox-20b,128,1,2209.0,1.0,1,H100,1697105162995,1697105165204.0,120,39.0,1.0,"[8, 2201]","[1697105163003, 1697105165204]"
955,183,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105212105,1697105220994.0,120,,,"[13, 1713, 93, 90, 89, 68, 246, 85, 65, 75, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 82, 256, 79, 368, 81, 59, 366, 88, 76, 259, 62, 234, 79, 229, 81, 198]","[1697105212118, 1697105213831, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219488, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
956,589,9,[],200,EleutherAI/gpt-neox-20b,128,1,4475.0,1.0,1,H100,1697105190681,1697105195156.0,120,92.0,20.0,"[5, 2080, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81, 265, 63, 85, 199, 81, 78, 261]","[1697105190686, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194817, 1697105194895, 1697105195156]"
957,314,9,[],200,EleutherAI/gpt-neox-20b,128,1,4786.0,1.0,1,H100,1697105186893,1697105191679.0,120,335.0,13.0,"[5, 2917, 90, 272, 165, 251, 87, 251, 66, 87, 66, 367, 162]","[1697105186898, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679]"
958,695,1,[],200,EleutherAI/gpt-neox-20b,128,1,5232.0,1.0,1,H100,1697105158122,1697105163354.0,120,92.0,20.0,"[4, 2455, 93, 86, 87, 83, 436, 93, 92, 86, 240, 89, 68, 68, 547, 85, 79, 362, 91, 88]","[1697105158126, 1697105160581, 1697105160674, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161637, 1697105161877, 1697105161966, 1697105162034, 1697105162102, 1697105162649, 1697105162734, 1697105162813, 1697105163175, 1697105163266, 1697105163354]"
959,213,2,[],200,EleutherAI/gpt-neox-20b,128,1,2464.0,1.0,1,H100,1697105163355,1697105165819.0,120,123.0,6.0,"[8, 1932, 88, 82, 286, 68]","[1697105163363, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819]"
960,571,3,[],200,EleutherAI/gpt-neox-20b,128,1,3186.0,1.0,1,H100,1697105165820,1697105169006.0,120,67.0,2.0,"[4, 3182]","[1697105165824, 1697105169006]"
961,924,4,[],200,EleutherAI/gpt-neox-20b,128,1,2201.0,1.0,1,H100,1697105169007,1697105171208.0,120,9.0,1.0,"[5, 2196]","[1697105169012, 1697105171208]"
962,264,3,[],200,EleutherAI/gpt-neox-20b,128,1,5972.0,1.0,1,H100,1697105160848,1697105166820.0,120,86.0,20.0,"[8, 2827, 86, 85, 306, 76, 371, 89, 89, 88, 79, 343, 88, 82, 286, 68, 78, 468, 247, 208]","[1697105160856, 1697105163683, 1697105163769, 1697105163854, 1697105164160, 1697105164236, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166612, 1697105166820]"
963,351,5,[],200,EleutherAI/gpt-neox-20b,128,1,3470.0,1.0,1,H100,1697105171210,1697105174680.0,120,216.0,6.0,"[9, 2565, 80, 77, 72, 667]","[1697105171219, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680]"
964,708,6,[],200,EleutherAI/gpt-neox-20b,128,1,2247.0,1.0,1,H100,1697105174682,1697105176929.0,120,140.0,1.0,"[8, 2239]","[1697105174690, 1697105176929]"
965,111,7,[],200,EleutherAI/gpt-neox-20b,128,1,2131.0,1.0,1,H100,1697105176930,1697105179061.0,120,79.0,5.0,"[9, 1878, 90, 67, 87]","[1697105176939, 1697105178817, 1697105178907, 1697105178974, 1697105179061]"
966,14,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105195157,1697105201998.0,120,,,"[12, 3520, 273, 410, 224, 231, 129, 150, 140, 81, 79, 219, 297, 80, 292, 160, 212]","[1697105195169, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200625, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
967,474,8,[],200,EleutherAI/gpt-neox-20b,128,1,7694.0,1.0,1,H100,1697105179062,1697105186756.0,120,109.0,33.0,"[8, 2654, 86, 76, 408, 89, 83, 384, 89, 88, 190, 87, 78, 373, 85, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 87, 81, 411, 88, 79]","[1697105179070, 1697105181724, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183755, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186588, 1697105186676, 1697105186755]"
968,781,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105166264,1697105172155.0,120,,,"[4, 5495]","[1697105166268, 1697105171763]"
969,216,5,[],200,EleutherAI/gpt-neox-20b,128,1,4106.0,1.0,1,H100,1697105172159,1697105176265.0,120,91.0,20.0,"[218, 1407, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 70, 87, 69, 68, 70]","[1697105172377, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176265]"
970,853,7,[],200,EleutherAI/gpt-neox-20b,128,1,6133.0,1.0,1,H100,1697105177249,1697105183382.0,120,364.0,22.0,"[13, 2840, 85, 66, 280, 79, 75, 489, 80, 80, 387, 87, 76, 408, 89, 83, 384, 89, 88, 190, 87, 78]","[1697105177262, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181176, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382]"
971,328,5,[],200,EleutherAI/gpt-neox-20b,128,1,1331.0,1.0,1,H100,1697105173685,1697105175016.0,120,109.0,6.0,"[12, 984, 92, 89, 68, 86]","[1697105173697, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016]"
972,705,3,[],200,EleutherAI/gpt-neox-20b,128,1,8087.0,1.0,1,H100,1697105170020,1697105178107.0,120,79.0,27.0,"[166, 3598, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 98, 92, 89, 69, 88, 68, 69, 69, 759, 81, 81, 63, 674, 94, 91]","[1697105170186, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175720, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177023, 1697105177104, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107]"
973,689,6,[],200,EleutherAI/gpt-neox-20b,128,1,1911.0,1.0,1,H100,1697105175018,1697105176929.0,120,15.0,1.0,"[8, 1903]","[1697105175026, 1697105176929]"
974,426,12,[],200,EleutherAI/gpt-neox-20b,128,1,6893.0,1.0,1,H100,1697105202004,1697105208897.0,120,79.0,36.0,"[79, 1635, 88, 88, 87, 269, 87, 86, 84, 415, 92, 90, 87, 69, 87, 86, 389, 91, 85, 84, 731, 90, 89, 86, 80, 80, 60, 60, 618, 87, 82, 83, 63, 435, 87, 84]","[1697105202083, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205104, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207358, 1697105207976, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208726, 1697105208813, 1697105208897]"
975,382,7,[],200,EleutherAI/gpt-neox-20b,128,1,4860.0,1.0,1,H100,1697105180538,1697105185398.0,120,47.0,20.0,"[6, 2306, 89, 88, 190, 87, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 216, 76, 57, 363]","[1697105180544, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184902, 1697105184978, 1697105185035, 1697105185398]"
976,136,7,[],200,EleutherAI/gpt-neox-20b,128,1,2093.0,1.0,1,H100,1697105178350,1697105180443.0,120,31.0,1.0,"[9, 2084]","[1697105178359, 1697105180443]"
977,468,8,[],200,EleutherAI/gpt-neox-20b,128,1,4954.0,1.0,1,H100,1697105180444,1697105185398.0,120,31.0,20.0,"[12, 2304, 90, 89, 88, 190, 87, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 216, 76, 57, 363]","[1697105180456, 1697105182760, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184902, 1697105184978, 1697105185035, 1697105185398]"
978,175,8,[],200,EleutherAI/gpt-neox-20b,128,1,3206.0,1.0,1,H100,1697105180011,1697105183217.0,120,140.0,8.0,"[13, 2270, 89, 83, 384, 89, 88, 190]","[1697105180024, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217]"
979,71,1,[],200,EleutherAI/gpt-neox-20b,128,1,5096.0,1.0,1,H100,1697105164608,1697105169704.0,120,364.0,11.0,"[5, 3458, 227, 76, 273, 231, 127, 144, 218, 182, 155]","[1697105164613, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005, 1697105169149, 1697105169367, 1697105169549, 1697105169704]"
980,452,10,[],200,EleutherAI/gpt-neox-20b,128,1,2966.0,1.0,1,H100,1697105179500,1697105182466.0,120,216.0,4.0,"[9, 2600, 185, 89, 83]","[1697105179509, 1697105182109, 1697105182294, 1697105182383, 1697105182466]"
981,743,8,[],200,EleutherAI/gpt-neox-20b,128,1,3764.0,1.0,1,H100,1697105185399,1697105189163.0,120,123.0,6.0,"[13, 3036, 94, 164, 81, 375]","[1697105185412, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162]"
982,766,6,[],200,EleutherAI/gpt-neox-20b,128,1,2093.0,1.0,1,H100,1697105178350,1697105180443.0,120,11.0,1.0,"[25, 2068]","[1697105178375, 1697105180443]"
983,135,3,[],200,EleutherAI/gpt-neox-20b,128,1,2331.0,1.0,1,H100,1697105165205,1697105167536.0,120,52.0,2.0,"[9, 2322]","[1697105165214, 1697105167536]"
984,4,7,[],200,EleutherAI/gpt-neox-20b,128,1,4107.0,1.0,1,H100,1697105172158,1697105176265.0,120,89.0,20.0,"[125, 1501, 80, 77, 72, 668, 93, 88, 68, 86, 84, 522, 99, 91, 89, 69, 88, 69, 68, 70]","[1697105172283, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174681, 1697105174774, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176127, 1697105176195, 1697105176265]"
985,200,7,[],200,EleutherAI/gpt-neox-20b,128,1,2860.0,1.0,1,H100,1697105180444,1697105183304.0,120,6.0,9.0,"[12, 1838, 89, 83, 384, 89, 88, 190, 87]","[1697105180456, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304]"
986,924,4,[],200,EleutherAI/gpt-neox-20b,128,1,1462.0,1.0,1,H100,1697105176270,1697105177732.0,120,9.0,1.0,"[9, 1453]","[1697105176279, 1697105177732]"
987,353,5,[],200,EleutherAI/gpt-neox-20b,128,1,2521.0,1.0,1,H100,1697105177733,1697105180254.0,120,52.0,4.0,"[9, 2360, 85, 67]","[1697105177742, 1697105180102, 1697105180187, 1697105180254]"
988,712,6,[],200,EleutherAI/gpt-neox-20b,128,1,5144.0,1.0,1,H100,1697105180254,1697105185398.0,120,88.0,20.0,"[5, 2591, 89, 88, 190, 87, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363]","[1697105180259, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398]"
989,365,8,[],200,EleutherAI/gpt-neox-20b,128,1,1466.0,1.0,1,H100,1697105176266,1697105177732.0,120,23.0,1.0,"[18, 1448]","[1697105176284, 1697105177732]"
990,722,9,[],200,EleutherAI/gpt-neox-20b,128,1,2277.0,1.0,1,H100,1697105177734,1697105180011.0,120,39.0,1.0,"[20, 2257]","[1697105177754, 1697105180011]"
991,277,7,[],200,EleutherAI/gpt-neox-20b,128,1,2048.0,1.0,1,H100,1697105185037,1697105187085.0,120,18.0,1.0,"[8, 2040]","[1697105185045, 1697105187085]"
992,127,10,[],200,EleutherAI/gpt-neox-20b,128,1,2839.0,1.0,1,H100,1697105180011,1697105182850.0,120,100.0,5.0,"[5, 2278, 89, 83, 384]","[1697105180016, 1697105182294, 1697105182383, 1697105182466, 1697105182850]"
993,634,8,[],200,EleutherAI/gpt-neox-20b,128,1,1982.0,1.0,1,H100,1697105187087,1697105189069.0,120,13.0,1.0,"[8, 1974]","[1697105187095, 1697105189069]"
994,83,6,[],200,EleutherAI/gpt-neox-20b,128,1,4954.0,1.0,1,H100,1697105178350,1697105183304.0,120,123.0,15.0,"[17, 2808, 81, 80, 387, 87, 76, 408, 89, 83, 384, 89, 88, 190, 87]","[1697105178367, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304]"
995,218,5,[],200,EleutherAI/gpt-neox-20b,128,1,3154.0,1.0,1,H100,1697105179312,1697105182466.0,120,109.0,7.0,"[4, 2408, 86, 76, 408, 89, 83]","[1697105179316, 1697105181724, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466]"
996,273,14,[],200,EleutherAI/gpt-neox-20b,128,1,2767.0,1.0,1,H100,1697105195393,1697105198160.0,120,19.0,1.0,"[21, 2746]","[1697105195414, 1697105198160]"
997,631,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105198161,1697105201998.0,120,,,"[9, 3124, 160, 213]","[1697105198170, 1697105201294, 1697105201454, 1697105201667]"
998,31,16,[],200,EleutherAI/gpt-neox-20b,128,1,4080.0,1.0,1,H100,1697105202002,1697105206082.0,120,84.0,20.0,"[25, 1691, 88, 88, 87, 269, 87, 87, 83, 415, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84]","[1697105202027, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
999,80,13,[],200,EleutherAI/gpt-neox-20b,128,1,1784.0,1.0,1,H100,1697105206084,1697105207868.0,120,13.0,1.0,"[13, 1770]","[1697105206097, 1697105207867]"
1000,440,14,[],200,EleutherAI/gpt-neox-20b,128,1,5357.0,1.0,1,H100,1697105207868,1697105213225.0,120,84.0,20.0,"[9, 2257, 86, 82, 502, 82, 428, 168, 77, 457, 89, 79, 80, 74, 72, 481, 88, 89, 82, 75]","[1697105207877, 1697105210134, 1697105210220, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482, 1697105211559, 1697105212016, 1697105212105, 1697105212184, 1697105212264, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225]"
1001,85,6,[],200,EleutherAI/gpt-neox-20b,128,1,5858.0,1.0,1,H100,1697105183305,1697105189163.0,120,88.0,20.0,"[8, 2696, 88, 83, 408, 88, 79, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375]","[1697105183313, 1697105186009, 1697105186097, 1697105186180, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162]"
1002,19,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105211483,1697105220994.0,120,,,"[13, 2334, 94, 90, 89, 68, 246, 85, 64, 76, 653, 84, 356, 90, 84, 510, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 82, 256, 79, 368, 81, 59, 366, 84, 80, 259, 62, 234, 79, 228, 82, 197]","[1697105211496, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642, 1697105215295, 1697105215379, 1697105215735, 1697105215825, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219484, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220426, 1697105220508, 1697105220705]"
1003,480,10,[],200,EleutherAI/gpt-neox-20b,128,1,1982.0,1.0,1,H100,1697105187087,1697105189069.0,120,26.0,1.0,"[4, 1978]","[1697105187091, 1697105189069]"
1004,835,11,[],200,EleutherAI/gpt-neox-20b,128,1,5467.0,1.0,1,H100,1697105189070,1697105194537.0,120,87.0,20.0,"[9, 2968, 82, 275, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81, 265, 64, 84]","[1697105189079, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537]"
1005,585,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248637,1697105250347.0,120,,,[17],[1697105248654]
1006,16,28,[],200,EleutherAI/gpt-neox-20b,128,1,1660.0,1.0,1,H100,1697105250351,1697105252011.0,120,9.0,1.0,"[126, 1534]","[1697105250477, 1697105252011]"
1007,748,9,[],200,EleutherAI/gpt-neox-20b,128,1,5441.0,1.0,1,H100,1697105184902,1697105190343.0,120,182.0,14.0,"[21, 2875, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 166]","[1697105184923, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190343]"
1008,492,13,[],200,EleutherAI/gpt-neox-20b,128,1,5398.0,1.0,1,H100,1697105206084,1697105211482.0,120,47.0,20.0,"[9, 1884, 86, 83, 82, 64, 434, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 82, 428, 168]","[1697105206093, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482]"
1009,144,10,[],200,EleutherAI/gpt-neox-20b,128,1,4812.0,1.0,1,H100,1697105190344,1697105195156.0,120,96.0,20.0,"[4, 2418, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81, 265, 63, 85, 199, 81, 78, 261]","[1697105190348, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194817, 1697105194895, 1697105195156]"
1010,104,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228782,1697105232145.0,120,,,"[304, 2420, 75, 75, 74, 73]","[1697105229086, 1697105231506, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
1011,465,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233608.0,120,,,[8],[1697105232158]
1012,823,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233609,1697105234918.0,120,,,[21],[1697105233630]
1013,257,26,[],200,EleutherAI/gpt-neox-20b,128,1,1834.0,1.0,1,H100,1697105234922,1697105236756.0,120,14.0,1.0,"[81, 1753]","[1697105235003, 1697105236756]"
1014,611,27,[],200,EleutherAI/gpt-neox-20b,128,1,1138.0,1.0,1,H100,1697105236757,1697105237895.0,120,14.0,1.0,"[16, 1122]","[1697105236773, 1697105237895]"
1015,11,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105237896,1697105240331.0,120,,,[13],[1697105237909]
1016,365,29,[],200,EleutherAI/gpt-neox-20b,128,1,1596.0,1.0,1,H100,1697105240334,1697105241930.0,120,23.0,1.0,"[85, 1511]","[1697105240419, 1697105241930]"
1017,726,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241932,1697105243754.0,120,,,[40],[1697105241972]
1018,157,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243758,1697105247242.0,120,,,[242],[1697105244000]
1019,602,32,[],200,EleutherAI/gpt-neox-20b,128,1,1389.0,1.0,1,H100,1697105247247,1697105248636.0,120,15.0,1.0,"[21, 1368]","[1697105247268, 1697105248636]"
1020,30,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248637,1697105250347.0,120,,,[17],[1697105248654]
1021,390,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250350,1697105252036.0,120,,,[35],[1697105250385]
1022,747,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253711.0,120,,,[16],[1697105252057]
1023,827,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105164874,1697105170012.0,120,,,"[4, 3193, 227, 76, 273, 232, 127, 143, 218, 182, 155]","[1697105164878, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169367, 1697105169549, 1697105169704]"
1024,575,6,[],200,EleutherAI/gpt-neox-20b,128,1,4269.0,1.0,1,H100,1697105176268,1697105180537.0,120,86.0,20.0,"[14, 1640, 94, 91, 88, 67, 86, 468, 91, 66, 88, 81, 356, 88, 85, 65, 366, 85, 66, 280]","[1697105176282, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180533]"
1025,257,2,[],200,EleutherAI/gpt-neox-20b,128,1,1656.0,1.0,1,H100,1697105170015,1697105171671.0,120,14.0,1.0,"[38, 1618]","[1697105170053, 1697105171671]"
1026,702,3,[],200,EleutherAI/gpt-neox-20b,128,1,4591.0,1.0,1,H100,1697105171673,1697105176264.0,120,89.0,20.0,"[16, 2095, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69]","[1697105171689, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
1027,175,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253717,1697105256011.0,120,,,[355],[1697105254072]
1028,505,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258913.0,120,,,[169],[1697105256182]
1029,601,7,[],200,EleutherAI/gpt-neox-20b,128,1,5779.0,1.0,1,H100,1697105184902,1697105190681.0,120,83.0,20.0,"[5, 2266, 83, 84, 82, 376, 89, 561, 94, 164, 81, 376, 86, 85, 481, 90, 272, 165, 251, 88]","[1697105184907, 1697105187173, 1697105187256, 1697105187340, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190681]"
1030,863,38,[],200,EleutherAI/gpt-neox-20b,128,1,1517.0,1.0,1,H100,1697105258921,1697105260438.0,120,10.0,1.0,"[169, 1348]","[1697105259090, 1697105260438]"
1031,293,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260439,1697105262307.0,120,,,[20],[1697105260459]
1032,651,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262314,1697105264082.0,120,,,[266],[1697105262580]
1033,80,41,[],200,EleutherAI/gpt-neox-20b,128,1,1777.0,1.0,1,H100,1697105264086,1697105265863.0,120,13.0,1.0,"[122, 1655]","[1697105264208, 1697105265863]"
1034,410,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265864,1697105267796.0,120,,,[13],[1697105265877]
1035,920,11,[],200,EleutherAI/gpt-neox-20b,128,1,1585.0,1.0,1,H100,1697105211483,1697105213068.0,120,96.0,4.0,"[9, 1399, 88, 89]","[1697105211492, 1697105212891, 1697105212979, 1697105213068]"
1036,716,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105169369,1697105172155.0,120,,,"[8, 2386]","[1697105169377, 1697105171763]"
1037,117,7,[],200,EleutherAI/gpt-neox-20b,128,1,1887.0,1.0,1,H100,1697105176930,1697105178817.0,120,364.0,2.0,"[5, 1882]","[1697105176935, 1697105178817]"
1038,444,8,[],200,EleutherAI/gpt-neox-20b,128,1,2992.0,1.0,1,H100,1697105178818,1697105181810.0,120,457.0,6.0,"[4, 2353, 81, 80, 388, 86]","[1697105178822, 1697105181175, 1697105181256, 1697105181336, 1697105181724, 1697105181810]"
1039,524,8,[],200,EleutherAI/gpt-neox-20b,128,1,7796.0,1.0,1,H100,1697105187888,1697105195684.0,120,100.0,30.0,"[9, 3620, 162, 87, 281, 82, 275, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81, 265, 64, 84, 199, 80, 79, 260, 326, 87, 116]","[1697105187897, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194895, 1697105195155, 1697105195481, 1697105195568, 1697105195684]"
1040,810,1,[],200,EleutherAI/gpt-neox-20b,128,1,4486.0,1.0,1,H100,1697105157616,1697105162102.0,120,91.0,20.0,"[5, 2089, 92, 87, 85, 84, 79, 444, 92, 87, 87, 83, 436, 93, 92, 87, 239, 89, 68, 68]","[1697105157621, 1697105159710, 1697105159802, 1697105159889, 1697105159974, 1697105160058, 1697105160137, 1697105160581, 1697105160673, 1697105160760, 1697105160847, 1697105160930, 1697105161366, 1697105161459, 1697105161551, 1697105161638, 1697105161877, 1697105161966, 1697105162034, 1697105162102]"
1041,679,5,[],200,EleutherAI/gpt-neox-20b,128,1,1852.0,1.0,1,H100,1697105181811,1697105183663.0,120,15.0,1.0,"[12, 1840]","[1697105181823, 1697105183663]"
1042,111,6,[],200,EleutherAI/gpt-neox-20b,128,1,2925.0,1.0,1,H100,1697105183664,1697105186589.0,120,79.0,5.0,"[4, 2341, 88, 85, 406]","[1697105183668, 1697105186009, 1697105186097, 1697105186182, 1697105186588]"
1043,439,7,[],200,EleutherAI/gpt-neox-20b,128,1,2746.0,1.0,1,H100,1697105186589,1697105189335.0,120,13.0,4.0,"[5, 2569, 86, 85]","[1697105186594, 1697105189163, 1697105189249, 1697105189334]"
1044,134,4,[],200,EleutherAI/gpt-neox-20b,128,1,5646.0,1.0,1,H100,1697105178108,1697105183754.0,120,86.0,20.0,"[5, 2420, 79, 75, 488, 81, 80, 387, 87, 76, 408, 89, 83, 384, 89, 88, 190, 87, 78, 372]","[1697105178113, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754]"
1045,809,11,[],200,EleutherAI/gpt-neox-20b,128,1,1739.0,1.0,1,H100,1697105182467,1697105184206.0,120,16.0,1.0,"[18, 1721]","[1697105182485, 1697105184206]"
1046,240,12,[],200,EleutherAI/gpt-neox-20b,128,1,5608.0,1.0,1,H100,1697105184207,1697105189815.0,120,83.0,20.0,"[4, 2378, 88, 79, 77, 60, 279, 84, 83, 83, 376, 89, 561, 94, 164, 81, 376, 86, 85, 481]","[1697105184211, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186893, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189163, 1697105189249, 1697105189334, 1697105189815]"
1047,799,8,[],200,EleutherAI/gpt-neox-20b,128,1,5482.0,1.0,1,H100,1697105189335,1697105194817.0,120,84.0,20.0,"[9, 3060, 76, 286, 87, 83, 234, 82, 62, 305, 87, 189, 84, 64, 80, 266, 64, 84, 199, 80]","[1697105189344, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193619, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194123, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816]"
1048,360,8,[],200,EleutherAI/gpt-neox-20b,128,1,2317.0,1.0,1,H100,1697105199598,1697105201915.0,120,16.0,1.0,"[8, 2309]","[1697105199606, 1697105201915]"
1049,721,9,[],200,EleutherAI/gpt-neox-20b,128,1,2065.0,1.0,1,H100,1697105201916,1697105203981.0,120,286.0,5.0,"[4, 1798, 88, 88, 87]","[1697105201920, 1697105203718, 1697105203806, 1697105203894, 1697105203981]"
1050,421,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105169705,1697105172156.0,120,,,"[9, 2049]","[1697105169714, 1697105171763]"
1051,75,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165205,1697105170013.0,120,,,"[9, 2857, 227, 76, 273, 232, 127, 143, 219, 181, 155]","[1697105165214, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
1052,532,9,[],200,EleutherAI/gpt-neox-20b,128,1,5488.0,1.0,1,H100,1697105183218,1697105188706.0,120,92.0,20.0,"[4, 2176, 74, 537, 87, 82, 410, 88, 80, 77, 60, 280, 83, 83, 83, 376, 89, 561, 94, 164]","[1697105183222, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186178, 1697105186588, 1697105186676, 1697105186756, 1697105186833, 1697105186893, 1697105187173, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706]"
1053,145,9,[],200,EleutherAI/gpt-neox-20b,128,1,4007.0,1.0,1,H100,1697105189163,1697105193170.0,120,161.0,9.0,"[5, 2879, 82, 275, 76, 286, 87, 83, 234]","[1697105189168, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170]"
1054,432,4,[],200,EleutherAI/gpt-neox-20b,128,1,1656.0,1.0,1,H100,1697105170015,1697105171671.0,120,13.0,1.0,"[16, 1640]","[1697105170031, 1697105171671]"
1055,238,2,[],200,EleutherAI/gpt-neox-20b,128,1,2849.0,1.0,1,H100,1697105162103,1697105164952.0,120,563.0,6.0,"[21, 2484, 88, 89, 88, 79]","[1697105162124, 1697105164608, 1697105164696, 1697105164785, 1697105164873, 1697105164952]"
1056,763,5,[],200,EleutherAI/gpt-neox-20b,128,1,1149.0,1.0,1,H100,1697105171672,1697105172821.0,120,20.0,1.0,"[21, 1128]","[1697105171693, 1697105172821]"
1057,421,11,[],200,EleutherAI/gpt-neox-20b,128,1,6019.0,1.0,1,H100,1697105192405,1697105198424.0,120,85.0,20.0,"[13, 3063, 87, 116, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 327, 211, 117, 63]","[1697105192418, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198033, 1697105198244, 1697105198361, 1697105198424]"
1058,191,6,[],200,EleutherAI/gpt-neox-20b,128,1,4424.0,1.0,1,H100,1697105172824,1697105177248.0,120,85.0,20.0,"[16, 1841, 92, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69, 760, 81, 80, 63]","[1697105172840, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177024, 1697105177105, 1697105177185, 1697105177248]"
1059,228,9,[],200,EleutherAI/gpt-neox-20b,128,1,6637.0,1.0,1,H100,1697105194817,1697105201454.0,120,100.0,20.0,"[5, 3211, 211, 117, 63, 265, 273, 410, 224, 230, 130, 150, 141, 80, 79, 220, 296, 80, 292, 160]","[1697105194822, 1697105198033, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199826, 1697105199956, 1697105200106, 1697105200247, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454]"
1060,482,11,[],200,EleutherAI/gpt-neox-20b,128,1,5855.0,1.0,1,H100,1697105182851,1697105188706.0,120,91.0,20.0,"[4, 2543, 74, 537, 87, 82, 411, 88, 79, 77, 59, 281, 83, 83, 83, 376, 89, 561, 94, 164]","[1697105182855, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186178, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186892, 1697105187173, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706]"
1061,782,9,[],200,EleutherAI/gpt-neox-20b,128,1,6019.0,1.0,1,H100,1697105192405,1697105198424.0,120,90.0,20.0,"[9, 3067, 87, 116, 83, 176, 417, 282, 184, 264, 85, 62, 151, 159, 82, 77, 327, 211, 117, 63]","[1697105192414, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195943, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198033, 1697105198244, 1697105198361, 1697105198424]"
1062,880,8,[],200,EleutherAI/gpt-neox-20b,128,1,2030.0,1.0,1,H100,1697105181725,1697105183755.0,120,84.0,2.0,"[4, 2025]","[1697105181729, 1697105183754]"
1063,519,6,[],200,EleutherAI/gpt-neox-20b,128,1,10287.0,1.0,1,H100,1697105183756,1697105194043.0,120,58.0,47.0,"[12, 2821, 88, 79, 77, 60, 279, 84, 83, 83, 376, 89, 561, 94, 165, 80, 376, 86, 85, 481, 90, 272, 165, 251, 87, 251, 66, 87, 66, 367, 162, 87, 281, 82, 275, 76, 286, 87, 83, 234, 82, 62, 305, 87, 189, 84, 64]","[1697105183768, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186893, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188707, 1697105188787, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193619, 1697105193706, 1697105193895, 1697105193979, 1697105194043]"
1064,310,9,[],200,EleutherAI/gpt-neox-20b,128,1,2726.0,1.0,1,H100,1697105183756,1697105186482.0,120,26.0,1.0,"[16, 2710]","[1697105183772, 1697105186482]"
1065,664,10,[],200,EleutherAI/gpt-neox-20b,128,1,4109.0,1.0,1,H100,1697105186484,1697105190593.0,120,364.0,9.0,"[8, 2671, 86, 85, 481, 90, 272, 165, 251]","[1697105186492, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593]"
1066,729,2,[],200,EleutherAI/gpt-neox-20b,128,1,3182.0,1.0,1,H100,1697105165466,1697105168648.0,120,874.0,2.0,"[4, 3177]","[1697105165470, 1697105168647]"
1067,152,3,[],200,EleutherAI/gpt-neox-20b,128,1,5972.0,1.0,1,H100,1697105161639,1697105167611.0,120,87.0,20.0,"[4, 2964, 89, 89, 88, 79, 342, 89, 82, 286, 68, 77, 469, 246, 209, 271, 116, 196, 133, 75]","[1697105161643, 1697105164607, 1697105164696, 1697105164785, 1697105164873, 1697105164952, 1697105165294, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165896, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611]"
1068,97,11,[],200,EleutherAI/gpt-neox-20b,128,1,4224.0,1.0,1,H100,1697105190593,1697105194817.0,120,6.0,20.0,"[5, 1806, 76, 286, 87, 83, 234, 82, 62, 305, 87, 189, 84, 64, 80, 266, 64, 84, 199, 81]","[1697105190598, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193619, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194123, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194817]"
1069,557,8,[],200,EleutherAI/gpt-neox-20b,128,1,2144.0,1.0,1,H100,1697105183756,1697105185900.0,120,31.0,1.0,"[12, 2132]","[1697105183768, 1697105185900]"
1070,914,9,[],200,EleutherAI/gpt-neox-20b,128,1,6503.0,1.0,1,H100,1697105185901,1697105192404.0,120,84.0,20.0,"[5, 3257, 86, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 166, 83, 281, 82, 275]","[1697105185906, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191683, 1697105191766, 1697105192047, 1697105192129, 1697105192404]"
1071,511,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105167612,1697105172155.0,120,,,"[13, 4138]","[1697105167625, 1697105171763]"
1072,891,2,[],200,EleutherAI/gpt-neox-20b,128,1,2205.0,1.0,1,H100,1697105164161,1697105166366.0,120,52.0,2.0,"[20, 2185]","[1697105164181, 1697105166366]"
1073,316,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105166367,1697105172156.0,120,,,"[8, 5388]","[1697105166375, 1697105171763]"
1074,869,5,[],200,EleutherAI/gpt-neox-20b,128,1,3463.0,1.0,1,H100,1697105172159,1697105175622.0,120,244.0,12.0,"[137, 1488, 80, 77, 72, 667, 94, 88, 68, 86, 84, 522]","[1697105172296, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174774, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622]"
1075,768,9,[],200,EleutherAI/gpt-neox-20b,128,1,2072.0,1.0,1,H100,1697105179738,1697105181810.0,120,47.0,6.0,"[8, 1430, 80, 80, 388, 86]","[1697105179746, 1697105181176, 1697105181256, 1697105181336, 1697105181724, 1697105181810]"
1076,263,12,[],200,EleutherAI/gpt-neox-20b,128,1,2132.0,1.0,1,H100,1697105194538,1697105196670.0,120,15.0,1.0,"[9, 2123]","[1697105194547, 1697105196670]"
1077,173,10,[],200,EleutherAI/gpt-neox-20b,128,1,4866.0,1.0,1,H100,1697105181811,1697105186677.0,120,96.0,20.0,"[16, 1928, 85, 85, 79, 383, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 88, 81, 410, 89]","[1697105181827, 1697105183755, 1697105183840, 1697105183925, 1697105184004, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186178, 1697105186588, 1697105186677]"
1078,374,11,[],200,EleutherAI/gpt-neox-20b,128,1,5067.0,1.0,1,H100,1697105202011,1697105207078.0,120,85.0,20.0,"[180, 2059, 87, 87, 83, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84, 731, 90, 89, 86]","[1697105202191, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078]"
1079,822,14,[],200,EleutherAI/gpt-neox-20b,128,1,5420.0,1.0,1,H100,1697105211484,1697105216904.0,120,88.0,20.0,"[24, 2322, 94, 90, 89, 68, 246, 85, 64, 76, 653, 84, 356, 91, 83, 510, 89, 67, 83, 246]","[1697105211508, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642, 1697105215295, 1697105215379, 1697105215735, 1697105215826, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904]"
1080,617,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105196671,1697105201999.0,120,,,"[4, 3431, 140, 81, 80, 219, 296, 80, 292, 160, 212]","[1697105196675, 1697105200106, 1697105200246, 1697105200327, 1697105200407, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1081,591,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105166821,1697105172156.0,120,,,"[8, 4934]","[1697105166829, 1697105171763]"
1082,244,4,[],200,EleutherAI/gpt-neox-20b,128,1,1656.0,1.0,1,H100,1697105170015,1697105171671.0,120,9.0,1.0,"[15, 1641]","[1697105170030, 1697105171671]"
1083,298,3,[],200,EleutherAI/gpt-neox-20b,128,1,3597.0,1.0,1,H100,1697105167612,1697105171209.0,120,17.0,1.0,"[9, 3588]","[1697105167621, 1697105171209]"
1084,652,4,[],200,EleutherAI/gpt-neox-20b,128,1,1611.0,1.0,1,H100,1697105171210,1697105172821.0,120,14.0,1.0,"[65, 1546]","[1697105171275, 1697105172821]"
1085,82,5,[],200,EleutherAI/gpt-neox-20b,128,1,4426.0,1.0,1,H100,1697105172822,1697105177248.0,120,67.0,20.0,"[14, 1844, 93, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69, 759, 82, 80, 63]","[1697105172836, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177023, 1697105177105, 1697105177185, 1697105177248]"
1086,531,11,[],200,EleutherAI/gpt-neox-20b,128,1,5726.0,1.0,1,H100,1697105186678,1697105192404.0,120,52.0,20.0,"[12, 2473, 86, 85, 481, 90, 272, 165, 251, 87, 251, 66, 87, 66, 367, 166, 83, 281, 82, 275]","[1697105186690, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191683, 1697105191766, 1697105192047, 1697105192129, 1697105192404]"
1087,601,5,[],200,EleutherAI/gpt-neox-20b,128,1,4591.0,1.0,1,H100,1697105171673,1697105176264.0,120,83.0,20.0,"[20, 2091, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69]","[1697105171693, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
1088,398,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165295,1697105170013.0,120,,,"[5, 2998, 76, 273, 232, 127, 143, 219, 181, 155]","[1697105165300, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
1089,16,3,[],200,EleutherAI/gpt-neox-20b,128,1,1657.0,1.0,1,H100,1697105170014,1697105171671.0,120,9.0,1.0,"[20, 1637]","[1697105170034, 1697105171671]"
1090,373,4,[],200,EleutherAI/gpt-neox-20b,128,1,1148.0,1.0,1,H100,1697105171673,1697105172821.0,120,15.0,1.0,"[36, 1112]","[1697105171709, 1697105172821]"
1091,824,8,[],200,EleutherAI/gpt-neox-20b,128,1,2276.0,1.0,1,H100,1697105182760,1697105185036.0,120,58.0,4.0,"[5, 2136, 77, 58]","[1697105182765, 1697105184901, 1697105184978, 1697105185036]"
1092,94,8,[],200,EleutherAI/gpt-neox-20b,128,1,5408.0,1.0,1,H100,1697105183755,1697105189163.0,120,86.0,20.0,"[9, 2245, 88, 85, 407, 88, 79, 77, 60, 279, 84, 83, 83, 376, 89, 561, 94, 165, 80, 376]","[1697105183764, 1697105186009, 1697105186097, 1697105186182, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186893, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188707, 1697105188787, 1697105189163]"
1093,250,9,[],200,EleutherAI/gpt-neox-20b,128,1,2581.0,1.0,1,H100,1697105185037,1697105187618.0,120,31.0,1.0,"[8, 2573]","[1697105185045, 1697105187618]"
1094,608,10,[],200,EleutherAI/gpt-neox-20b,128,1,5234.0,1.0,1,H100,1697105187619,1697105192853.0,120,96.0,20.0,"[4, 2192, 90, 272, 166, 250, 88, 250, 66, 87, 67, 366, 162, 87, 281, 82, 275, 76, 286, 87]","[1697105187623, 1697105189815, 1697105189905, 1697105190177, 1697105190343, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191151, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853]"
1095,9,11,[],200,EleutherAI/gpt-neox-20b,128,1,5570.0,1.0,1,H100,1697105192854,1697105198424.0,120,85.0,20.0,"[5, 2623, 87, 115, 84, 174, 418, 282, 186, 262, 85, 62, 151, 159, 82, 77, 327, 211, 117, 63]","[1697105192859, 1697105195482, 1697105195569, 1697105195684, 1697105195768, 1697105195942, 1697105196360, 1697105196642, 1697105196828, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198033, 1697105198244, 1697105198361, 1697105198424]"
1096,373,12,[],200,EleutherAI/gpt-neox-20b,128,1,2779.0,1.0,1,H100,1697105198426,1697105201205.0,120,15.0,1.0,"[24, 2755]","[1697105198450, 1697105201205]"
1097,731,13,[],200,EleutherAI/gpt-neox-20b,128,1,4876.0,1.0,1,H100,1697105201206,1697105206082.0,120,89.0,20.0,"[5, 2507, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84]","[1697105201211, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
1098,493,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105167537,1697105172155.0,120,,,"[8, 4218]","[1697105167545, 1697105171763]"
1099,558,10,[],200,EleutherAI/gpt-neox-20b,128,1,4562.0,1.0,1,H100,1697105190594,1697105195156.0,120,58.0,20.0,"[8, 2164, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81, 265, 63, 85, 199, 81, 78, 261]","[1697105190602, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194817, 1697105194895, 1697105195156]"
1100,554,8,[],200,EleutherAI/gpt-neox-20b,128,1,2004.0,1.0,1,H100,1697105183305,1697105185309.0,120,26.0,1.0,"[12, 1992]","[1697105183317, 1697105185309]"
1101,593,3,[],200,EleutherAI/gpt-neox-20b,128,1,4415.0,1.0,1,H100,1697105164953,1697105169368.0,120,335.0,9.0,"[4, 3114, 227, 76, 273, 232, 127, 143, 219]","[1697105164957, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368]"
1102,847,5,[],200,EleutherAI/gpt-neox-20b,128,1,1525.0,1.0,1,H100,1697105172159,1697105173684.0,120,10.0,1.0,"[150, 1375]","[1697105172309, 1697105173684]"
1103,913,9,[],200,EleutherAI/gpt-neox-20b,128,1,5841.0,1.0,1,H100,1697105185310,1697105191151.0,120,88.0,20.0,"[8, 2480, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 166, 250, 88, 250, 66, 87, 67]","[1697105185318, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190343, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191151]"
1104,110,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105169369,1697105172156.0,120,,,"[4, 2390]","[1697105169373, 1697105171763]"
1105,335,7,[],200,EleutherAI/gpt-neox-20b,128,1,12699.0,1.0,1,H100,1697105187257,1697105199956.0,120,58.0,62.0,"[5, 2553, 90, 272, 166, 250, 88, 250, 66, 87, 67, 366, 162, 87, 281, 81, 276, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81, 265, 64, 84, 199, 80, 78, 261, 326, 87, 116, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 326, 212, 117, 63, 265, 273, 410, 224, 230, 130]","[1697105187262, 1697105189815, 1697105189905, 1697105190177, 1697105190343, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191151, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192128, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199826, 1697105199956]"
1106,273,6,[],200,EleutherAI/gpt-neox-20b,128,1,897.0,1.0,1,H100,1697105173685,1697105174582.0,120,19.0,1.0,"[41, 856]","[1697105173726, 1697105174582]"
1107,68,9,[],200,EleutherAI/gpt-neox-20b,128,1,2267.0,1.0,1,H100,1697105189070,1697105191337.0,120,12.0,1.0,"[13, 2254]","[1697105189083, 1697105191337]"
1108,464,5,[],200,EleutherAI/gpt-neox-20b,128,1,1525.0,1.0,1,H100,1697105172159,1697105173684.0,120,12.0,1.0,"[238, 1287]","[1697105172397, 1697105173684]"
1109,161,14,[],200,EleutherAI/gpt-neox-20b,128,1,2642.0,1.0,1,H100,1697105206084,1697105208726.0,120,109.0,7.0,"[29, 1864, 86, 83, 82, 64, 434]","[1697105206113, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726]"
1110,54,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170015,1697105172155.0,120,,,"[39, 1709]","[1697105170054, 1697105171763]"
1111,601,7,[],200,EleutherAI/gpt-neox-20b,128,1,5154.0,1.0,1,H100,1697105174583,1697105179737.0,120,83.0,20.0,"[17, 2423, 82, 80, 63, 674, 95, 90, 88, 67, 87, 468, 90, 67, 87, 81, 356, 88, 85, 65]","[1697105174600, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178262, 1697105178349, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736]"
1112,548,7,[],200,EleutherAI/gpt-neox-20b,128,1,5217.0,1.0,1,H100,1697105177249,1697105182466.0,120,86.0,20.0,"[9, 2240, 88, 85, 66, 365, 85, 66, 280, 79, 75, 488, 81, 80, 388, 86, 76, 408, 89, 83]","[1697105177258, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181724, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466]"
1113,515,15,[],200,EleutherAI/gpt-neox-20b,128,1,2401.0,1.0,1,H100,1697105208727,1697105211128.0,120,11.0,1.0,"[5, 2396]","[1697105208732, 1697105211128]"
1114,825,6,[],200,EleutherAI/gpt-neox-20b,128,1,4663.0,1.0,1,H100,1697105173685,1697105178348.0,120,96.0,20.0,"[37, 1900, 99, 91, 89, 70, 87, 69, 68, 69, 760, 81, 80, 63, 674, 94, 91, 88, 67, 86]","[1697105173722, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176264, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348]"
1115,892,10,[],200,EleutherAI/gpt-neox-20b,128,1,5417.0,1.0,1,H100,1697105188707,1697105194124.0,120,87.0,20.0,"[9, 2801, 163, 86, 281, 82, 275, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81]","[1697105188716, 1697105191517, 1697105191680, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124]"
1116,269,4,[],200,EleutherAI/gpt-neox-20b,128,1,3597.0,1.0,1,H100,1697105167612,1697105171209.0,120,11.0,1.0,"[5, 3591]","[1697105167617, 1697105171208]"
1117,597,5,[],200,EleutherAI/gpt-neox-20b,128,1,1611.0,1.0,1,H100,1697105171210,1697105172821.0,120,39.0,1.0,"[41, 1570]","[1697105171251, 1697105172821]"
1118,29,6,[],200,EleutherAI/gpt-neox-20b,128,1,2194.0,1.0,1,H100,1697105172822,1697105175016.0,120,161.0,6.0,"[17, 1841, 93, 89, 68, 86]","[1697105172839, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016]"
1119,385,7,[],200,EleutherAI/gpt-neox-20b,128,1,8823.0,1.0,1,H100,1697105175017,1697105183840.0,120,52.0,43.0,"[9, 1998, 81, 80, 63, 674, 95, 90, 88, 67, 86, 469, 90, 67, 87, 81, 356, 88, 85, 66, 365, 85, 66, 280, 79, 75, 488, 81, 80, 387, 87, 75, 409, 89, 83, 383, 90, 88, 189, 88, 78, 372, 86]","[1697105175026, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181885, 1697105182294, 1697105182383, 1697105182466, 1697105182849, 1697105182939, 1697105183027, 1697105183216, 1697105183304, 1697105183382, 1697105183754, 1697105183840]"
1120,291,11,[],200,EleutherAI/gpt-neox-20b,128,1,6122.0,1.0,1,H100,1697105194125,1697105200247.0,120,79.0,20.0,"[4, 2961, 85, 62, 152, 158, 82, 77, 326, 212, 117, 63, 265, 273, 410, 225, 230, 129, 150, 140]","[1697105194129, 1697105197090, 1697105197175, 1697105197237, 1697105197389, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199597, 1697105199827, 1697105199956, 1697105200106, 1697105200246]"
1121,844,4,[],200,EleutherAI/gpt-neox-20b,128,1,1655.0,1.0,1,H100,1697105170016,1697105171671.0,120,10.0,1.0,"[81, 1574]","[1697105170097, 1697105171671]"
1122,268,5,[],200,EleutherAI/gpt-neox-20b,128,1,1148.0,1.0,1,H100,1697105171673,1697105172821.0,120,19.0,1.0,"[28, 1120]","[1697105171701, 1697105172821]"
1123,602,6,[],200,EleutherAI/gpt-neox-20b,128,1,1757.0,1.0,1,H100,1697105172825,1697105174582.0,120,15.0,1.0,"[26, 1731]","[1697105172851, 1697105174582]"
1124,585,10,[],200,EleutherAI/gpt-neox-20b,128,1,10648.0,1.0,1,H100,1697105201456,1697105212104.0,120,244.0,50.0,"[16, 2246, 88, 88, 87, 269, 87, 86, 84, 415, 93, 88, 88, 69, 87, 86, 389, 91, 85, 84, 731, 90, 89, 86, 80, 80, 60, 60, 618, 87, 82, 83, 63, 434, 88, 84, 79, 77, 385, 77, 618, 86, 83, 502, 81, 429, 168, 77, 456, 89]","[1697105201472, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207358, 1697105207976, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208725, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210885, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104]"
1125,794,15,[],200,EleutherAI/gpt-neox-20b,128,1,1957.0,1.0,1,H100,1697105213226,1697105215183.0,120,11.0,1.0,"[13, 1944]","[1697105213239, 1697105215183]"
1126,634,8,[],200,EleutherAI/gpt-neox-20b,128,1,1645.0,1.0,1,H100,1697105183664,1697105185309.0,120,13.0,1.0,"[16, 1629]","[1697105183680, 1697105185309]"
1127,223,16,[],200,EleutherAI/gpt-neox-20b,128,1,1628.0,1.0,1,H100,1697105215184,1697105216812.0,120,16.0,1.0,"[13, 1615]","[1697105215197, 1697105216812]"
1128,30,7,[],200,EleutherAI/gpt-neox-20b,128,1,5154.0,1.0,1,H100,1697105174583,1697105179737.0,120,93.0,20.0,"[21, 2419, 82, 80, 63, 674, 95, 91, 87, 67, 87, 468, 90, 67, 87, 81, 356, 88, 85, 65]","[1697105174604, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178108, 1697105178195, 1697105178262, 1697105178349, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736]"
1129,370,29,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105252012,1697105253681.0,120,31.0,1.0,"[25, 1644]","[1697105252037, 1697105253681]"
1130,499,15,[],200,EleutherAI/gpt-neox-20b,128,1,6019.0,1.0,1,H100,1697105192405,1697105198424.0,120,88.0,20.0,"[17, 3059, 88, 115, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 327, 211, 117, 63]","[1697105192422, 1697105195481, 1697105195569, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198033, 1697105198244, 1697105198361, 1697105198424]"
1131,729,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253687,1697105255028.0,120,,,[102],[1697105253789]
1132,317,3,[],200,EleutherAI/gpt-neox-20b,128,1,9128.0,1.0,1,H100,1697105176270,1697105185398.0,120,244.0,50.0,"[22, 1630, 94, 91, 88, 67, 87, 467, 91, 66, 88, 81, 356, 88, 85, 65, 366, 85, 66, 282, 77, 75, 488, 81, 80, 387, 87, 76, 408, 89, 83, 383, 90, 88, 189, 88, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363]","[1697105176292, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178349, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180535, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182849, 1697105182939, 1697105183027, 1697105183216, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398]"
1133,316,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170016,1697105172155.0,120,,,"[78, 1669]","[1697105170094, 1697105171763]"
1134,679,3,[],200,EleutherAI/gpt-neox-20b,128,1,1526.0,1.0,1,H100,1697105172158,1697105173684.0,120,15.0,1.0,"[117, 1409]","[1697105172275, 1697105173684]"
1135,104,4,[],200,EleutherAI/gpt-neox-20b,128,1,3563.0,1.0,1,H100,1697105173685,1697105177248.0,120,93.0,20.0,"[29, 967, 92, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 69, 68, 69, 760, 81, 80, 63]","[1697105173714, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176127, 1697105176195, 1697105176264, 1697105177024, 1697105177105, 1697105177185, 1697105177248]"
1136,51,14,[],200,EleutherAI/gpt-neox-20b,128,1,7503.0,1.0,1,H100,1697105202012,1697105209515.0,120,364.0,36.0,"[187, 2051, 87, 87, 83, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84, 732, 89, 89, 86, 81, 79, 60, 61, 618, 86, 82, 83, 63, 435, 87, 84, 79, 77, 385, 77]","[1697105202199, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515]"
1137,356,6,[],200,EleutherAI/gpt-neox-20b,128,1,2114.0,1.0,1,H100,1697105179062,1697105181176.0,120,874.0,2.0,"[4, 2110]","[1697105179066, 1697105181176]"
1138,434,5,[],200,EleutherAI/gpt-neox-20b,128,1,5968.0,1.0,1,H100,1697105177249,1697105183217.0,120,85.0,20.0,"[17, 2836, 85, 67, 279, 79, 75, 489, 80, 80, 387, 87, 76, 408, 89, 83, 384, 89, 88, 190]","[1697105177266, 1697105180102, 1697105180187, 1697105180254, 1697105180533, 1697105180612, 1697105180687, 1697105181176, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217]"
1139,714,7,[],200,EleutherAI/gpt-neox-20b,128,1,5500.0,1.0,1,H100,1697105181177,1697105186677.0,120,83.0,20.0,"[4, 2573, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 88, 81, 411, 88]","[1697105181181, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186178, 1697105186589, 1697105186677]"
1140,19,5,[],200,EleutherAI/gpt-neox-20b,128,1,12876.0,1.0,1,H100,1697105172159,1697105185035.0,120,563.0,72.0,"[234, 1392, 79, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 70, 87, 68, 69, 69, 759, 81, 81, 63, 674, 94, 91, 88, 67, 86, 468, 91, 66, 88, 81, 356, 88, 85, 65, 366, 85, 66, 280, 79, 75, 488, 81, 80, 387, 87, 75, 408, 89, 84, 383, 90, 88, 189, 88, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57]","[1697105172393, 1697105173785, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177023, 1697105177104, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181885, 1697105182293, 1697105182382, 1697105182466, 1697105182849, 1697105182939, 1697105183027, 1697105183216, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035]"
1141,734,12,[],200,EleutherAI/gpt-neox-20b,128,1,3223.0,1.0,1,H100,1697105207079,1697105210302.0,120,100.0,6.0,"[5, 2354, 77, 618, 86, 83]","[1697105207084, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302]"
1142,166,13,[],200,EleutherAI/gpt-neox-20b,128,1,2490.0,1.0,1,H100,1697105210304,1697105212794.0,120,14.0,1.0,"[12, 2478]","[1697105210316, 1697105212794]"
1143,494,14,[],200,EleutherAI/gpt-neox-20b,128,1,3114.0,1.0,1,H100,1697105212795,1697105215909.0,120,6.0,10.0,"[9, 1613, 85, 65, 75, 652, 85, 356, 90, 83]","[1697105212804, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908]"
1144,436,6,[],200,EleutherAI/gpt-neox-20b,128,1,5217.0,1.0,1,H100,1697105177249,1697105182466.0,120,86.0,20.0,"[5, 2244, 88, 85, 66, 365, 85, 66, 280, 79, 75, 488, 81, 80, 388, 86, 76, 408, 89, 83]","[1697105177254, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181724, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466]"
1145,591,10,[],200,EleutherAI/gpt-neox-20b,128,1,9944.0,1.0,1,H100,1697105190682,1697105200626.0,120,874.0,47.0,"[8, 2480, 82, 62, 306, 86, 189, 84, 64, 81, 265, 63, 85, 199, 80, 79, 261, 325, 87, 116, 83, 175, 418, 282, 186, 262, 85, 62, 151, 159, 82, 77, 326, 212, 117, 63, 265, 273, 410, 224, 231, 129, 150, 140, 81, 79, 219]","[1697105190690, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194816, 1697105194895, 1697105195156, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196828, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200625]"
1146,545,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170015,1697105172154.0,120,,,"[43, 1705]","[1697105170058, 1697105171763]"
1147,903,5,[],200,EleutherAI/gpt-neox-20b,128,1,2617.0,1.0,1,H100,1697105172156,1697105174773.0,120,244.0,7.0,"[7, 1621, 80, 77, 72, 667, 93]","[1697105172163, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773]"
1148,492,5,[],200,EleutherAI/gpt-neox-20b,128,1,5408.0,1.0,1,H100,1697105183755,1697105189163.0,120,47.0,20.0,"[5, 2249, 88, 81, 411, 88, 78, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 165, 80, 376]","[1697105183760, 1697105186009, 1697105186097, 1697105186178, 1697105186589, 1697105186677, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188707, 1697105188787, 1697105189163]"
1149,153,10,[],200,EleutherAI/gpt-neox-20b,128,1,3010.0,1.0,1,H100,1697105203982,1697105206992.0,120,335.0,4.0,"[5, 2826, 90, 89]","[1697105203987, 1697105206813, 1697105206903, 1697105206992]"
1150,597,13,[],200,EleutherAI/gpt-neox-20b,128,1,2861.0,1.0,1,H100,1697105189816,1697105192677.0,120,39.0,1.0,"[9, 2852]","[1697105189825, 1697105192677]"
1151,332,5,[],200,EleutherAI/gpt-neox-20b,128,1,2247.0,1.0,1,H100,1697105174682,1697105176929.0,120,39.0,1.0,"[12, 2235]","[1697105174694, 1697105176929]"
1152,111,7,[],200,EleutherAI/gpt-neox-20b,128,1,3388.0,1.0,1,H100,1697105185399,1697105188787.0,120,79.0,5.0,"[9, 3040, 94, 164, 81]","[1697105185408, 1697105188448, 1697105188542, 1697105188706, 1697105188787]"
1153,686,6,[],200,EleutherAI/gpt-neox-20b,128,1,1705.0,1.0,1,H100,1697105176930,1697105178635.0,120,31.0,1.0,"[17, 1688]","[1697105176947, 1697105178635]"
1154,28,16,[],200,EleutherAI/gpt-neox-20b,128,1,4780.0,1.0,1,H100,1697105211129,1697105215909.0,120,86.0,20.0,"[13, 1749, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 64, 76, 652, 85, 356, 90, 84]","[1697105211142, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215909]"
1155,851,6,[],200,EleutherAI/gpt-neox-20b,128,1,2793.0,1.0,1,H100,1697105189164,1697105191957.0,120,23.0,1.0,"[16, 2776]","[1697105189180, 1697105191956]"
1156,116,7,[],200,EleutherAI/gpt-neox-20b,128,1,2436.0,1.0,1,H100,1697105178636,1697105181072.0,120,23.0,1.0,"[9, 2427]","[1697105178645, 1697105181072]"
1157,474,8,[],200,EleutherAI/gpt-neox-20b,128,1,8302.0,1.0,1,H100,1697105188788,1697105197090.0,120,109.0,33.0,"[5, 3254, 82, 275, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81, 265, 64, 84, 199, 80, 79, 260, 326, 87, 116, 83, 175, 418, 282, 184, 264]","[1697105188793, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194895, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090]"
1158,441,8,[],200,EleutherAI/gpt-neox-20b,128,1,2055.0,1.0,1,H100,1697105181073,1697105183128.0,120,6.0,1.0,"[8, 2047]","[1697105181081, 1697105183128]"
1159,317,1,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105163175,1697105170013.0,120,,,"[5, 2115, 88, 82, 286, 68, 78, 468, 246, 209, 271, 115, 197, 133, 75, 460, 227, 76, 273, 231, 127, 144, 218, 182, 155]","[1697105163180, 1697105165295, 1697105165383, 1697105165465, 1697105165751, 1697105165819, 1697105165897, 1697105166365, 1697105166611, 1697105166820, 1697105167091, 1697105167206, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005, 1697105169149, 1697105169367, 1697105169549, 1697105169704]"
1160,912,17,[],200,EleutherAI/gpt-neox-20b,128,1,4587.0,1.0,1,H100,1697105209980,1697105214567.0,120,92.0,20.0,"[8, 2028, 88, 81, 79, 74, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 69, 245, 85, 65]","[1697105209988, 1697105212016, 1697105212104, 1697105212185, 1697105212264, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214172, 1697105214417, 1697105214502, 1697105214567]"
1161,802,9,[],200,EleutherAI/gpt-neox-20b,128,1,2180.0,1.0,1,H100,1697105183129,1697105185309.0,120,9.0,1.0,"[4, 2176]","[1697105183133, 1697105185309]"
1162,446,9,[],200,EleutherAI/gpt-neox-20b,128,1,2506.0,1.0,1,H100,1697105180254,1697105182760.0,120,26.0,1.0,"[5, 2501]","[1697105180259, 1697105182760]"
1163,891,10,[],200,EleutherAI/gpt-neox-20b,128,1,2638.0,1.0,1,H100,1697105182760,1697105185398.0,120,52.0,2.0,"[9, 2629]","[1697105182769, 1697105185398]"
1164,322,11,[],200,EleutherAI/gpt-neox-20b,128,1,6282.0,1.0,1,H100,1697105185399,1697105191681.0,120,93.0,20.0,"[17, 3032, 94, 164, 81, 375, 87, 85, 481, 90, 273, 164, 251, 87, 251, 66, 87, 67, 366, 162]","[1697105185416, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190178, 1697105190342, 1697105190593, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191151, 1697105191517, 1697105191679]"
1165,129,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105168651,1697105172155.0,120,,,"[6, 3106]","[1697105168657, 1697105171763]"
1166,513,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165205,1697105170013.0,120,,,"[5, 2861, 227, 76, 273, 232, 127, 143, 219, 181, 155]","[1697105165210, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168879, 1697105169006, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
1167,488,4,[],200,EleutherAI/gpt-neox-20b,128,1,1525.0,1.0,1,H100,1697105172159,1697105173684.0,120,6.0,1.0,"[209, 1316]","[1697105172368, 1697105173684]"
1168,849,5,[],200,EleutherAI/gpt-neox-20b,128,1,1821.0,1.0,1,H100,1697105173686,1697105175507.0,120,10.0,1.0,"[52, 1769]","[1697105173738, 1697105175507]"
1169,872,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170015,1697105172155.0,120,,,"[55, 1693]","[1697105170070, 1697105171763]"
1170,274,6,[],200,EleutherAI/gpt-neox-20b,128,1,2841.0,1.0,1,H100,1697105175508,1697105178349.0,120,364.0,11.0,"[4, 1512, 81, 80, 63, 674, 94, 91, 88, 67, 86]","[1697105175512, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348]"
1171,275,6,[],200,EleutherAI/gpt-neox-20b,128,1,1782.0,1.0,1,H100,1697105172159,1697105173941.0,120,161.0,4.0,"[52, 1573, 80, 77]","[1697105172211, 1697105173784, 1697105173864, 1697105173941]"
1172,675,12,[],200,EleutherAI/gpt-neox-20b,128,1,3052.0,1.0,1,H100,1697105191684,1697105194736.0,120,563.0,5.0,"[7, 2698, 64, 84, 199]","[1697105191691, 1697105194389, 1697105194453, 1697105194537, 1697105194736]"
1173,90,7,[],200,EleutherAI/gpt-neox-20b,128,1,2519.0,1.0,1,H100,1697105192130,1697105194649.0,120,19.0,1.0,"[4, 2515]","[1697105192134, 1697105194649]"
1174,721,7,[],200,EleutherAI/gpt-neox-20b,128,1,2825.0,1.0,1,H100,1697105178350,1697105181175.0,120,286.0,5.0,"[5, 2178, 79, 75, 488]","[1697105178355, 1697105180533, 1697105180612, 1697105180687, 1697105181175]"
1175,787,13,[],200,EleutherAI/gpt-neox-20b,128,1,3111.0,1.0,1,H100,1697105214418,1697105217529.0,120,123.0,6.0,"[4, 2482, 85, 66, 385, 89]","[1697105214422, 1697105216904, 1697105216989, 1697105217055, 1697105217440, 1697105217529]"
1176,448,8,[],200,EleutherAI/gpt-neox-20b,128,1,5457.0,1.0,1,H100,1697105194650,1697105200107.0,120,335.0,12.0,"[5, 3378, 211, 117, 63, 265, 273, 410, 224, 231, 130, 149]","[1697105194655, 1697105198033, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199957, 1697105200106]"
1177,635,7,[],200,EleutherAI/gpt-neox-20b,128,1,1565.0,1.0,1,H100,1697105173942,1697105175507.0,120,23.0,1.0,"[8, 1557]","[1697105173950, 1697105175507]"
1178,59,8,[],200,EleutherAI/gpt-neox-20b,128,1,4229.0,1.0,1,H100,1697105175508,1697105179737.0,120,91.0,20.0,"[8, 1508, 81, 80, 63, 674, 94, 91, 88, 67, 86, 469, 90, 67, 87, 81, 356, 88, 85, 66]","[1697105175516, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737]"
1179,146,8,[],200,EleutherAI/gpt-neox-20b,128,1,5501.0,1.0,1,H100,1697105181176,1697105186677.0,120,96.0,20.0,"[5, 2573, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 88, 81, 410, 89]","[1697105181181, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186178, 1697105186588, 1697105186677]"
1180,100,13,[],200,EleutherAI/gpt-neox-20b,128,1,5670.0,1.0,1,H100,1697105194737,1697105200407.0,120,732.0,14.0,"[4, 3503, 117, 63, 265, 273, 410, 224, 230, 130, 150, 141, 79, 80]","[1697105194741, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199826, 1697105199956, 1697105200106, 1697105200247, 1697105200326, 1697105200406]"
1181,460,14,[],200,EleutherAI/gpt-neox-20b,128,1,5675.0,1.0,1,H100,1697105200407,1697105206082.0,120,87.0,20.0,"[5, 3306, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84]","[1697105200412, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
1182,361,6,[],200,EleutherAI/gpt-neox-20b,128,1,2668.0,1.0,1,H100,1697105181257,1697105183925.0,120,67.0,7.0,"[5, 1955, 87, 79, 371, 86, 85]","[1697105181262, 1697105183217, 1697105183304, 1697105183383, 1697105183754, 1697105183840, 1697105183925]"
1183,714,7,[],200,EleutherAI/gpt-neox-20b,128,1,5889.0,1.0,1,H100,1697105183926,1697105189815.0,120,83.0,20.0,"[5, 2658, 88, 79, 77, 60, 279, 84, 83, 83, 376, 89, 561, 94, 165, 80, 376, 86, 85, 481]","[1697105183931, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186893, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188707, 1697105188787, 1697105189163, 1697105189249, 1697105189334, 1697105189815]"
1184,792,15,[],200,EleutherAI/gpt-neox-20b,128,1,1784.0,1.0,1,H100,1697105206084,1697105207868.0,120,11.0,1.0,"[25, 1759]","[1697105206109, 1697105207868]"
1185,141,8,[],200,EleutherAI/gpt-neox-20b,128,1,5340.0,1.0,1,H100,1697105189816,1697105195156.0,120,89.0,20.0,"[4, 2946, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81, 265, 64, 84, 199, 81, 78, 260]","[1697105189820, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194817, 1697105194895, 1697105195155]"
1186,214,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170015,1697105172154.0,120,,,"[26, 1722]","[1697105170041, 1697105171763]"
1187,99,2,[],200,EleutherAI/gpt-neox-20b,128,1,1891.0,1.0,1,H100,1697105163771,1697105165662.0,120,10.0,1.0,"[8, 1883]","[1697105163779, 1697105165662]"
1188,568,4,[],200,EleutherAI/gpt-neox-20b,128,1,1528.0,1.0,1,H100,1697105172156,1697105173684.0,120,11.0,1.0,"[31, 1497]","[1697105172187, 1697105173684]"
1189,460,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105165663,1697105170013.0,120,,,"[16, 3470, 219, 181, 155]","[1697105165679, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
1190,899,5,[],200,EleutherAI/gpt-neox-20b,128,1,3563.0,1.0,1,H100,1697105173685,1697105177248.0,120,100.0,20.0,"[4, 992, 92, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69, 760, 81, 80, 63]","[1697105173689, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177024, 1697105177105, 1697105177185, 1697105177248]"
1191,180,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105166612,1697105172156.0,120,,,"[5, 5146]","[1697105166617, 1697105171763]"
1192,469,9,[],200,EleutherAI/gpt-neox-20b,128,1,2311.0,1.0,1,H100,1697105195157,1697105197468.0,120,17.0,1.0,"[8, 2303]","[1697105195165, 1697105197468]"
1193,531,3,[],200,EleutherAI/gpt-neox-20b,128,1,4105.0,1.0,1,H100,1697105172159,1697105176264.0,120,52.0,20.0,"[241, 1384, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 70, 87, 68, 69, 69]","[1697105172400, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
1194,830,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105197469,1697105201998.0,120,,,"[4, 3449, 80, 292, 160, 212]","[1697105197473, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1195,864,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105198425,1697105201999.0,120,,,"[5, 2864, 160, 213]","[1697105198430, 1697105201294, 1697105201454, 1697105201667]"
1196,821,4,[],200,EleutherAI/gpt-neox-20b,128,1,6244.0,1.0,1,H100,1697105170020,1697105176264.0,120,85.0,20.0,"[170, 3594, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 98, 92, 89, 69, 88, 68, 69, 69]","[1697105170190, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175720, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264]"
1197,32,6,[],200,EleutherAI/gpt-neox-20b,128,1,1992.0,1.0,1,H100,1697105176271,1697105178263.0,120,140.0,6.0,"[29, 1622, 95, 90, 88, 68]","[1697105176300, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178263]"
1198,32,8,[],200,EleutherAI/gpt-neox-20b,128,1,3024.0,1.0,1,H100,1697105190682,1697105193706.0,120,140.0,6.0,"[8, 2480, 82, 62, 306, 86]","[1697105190690, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706]"
1199,850,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105215910,1697105220995.0,120,,,"[16, 2968, 81, 59, 366, 89, 75, 259, 62, 234, 79, 229, 81, 198]","[1697105215926, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
1200,393,9,[],200,EleutherAI/gpt-neox-20b,128,1,6250.0,1.0,1,H100,1697105193707,1697105199957.0,120,182.0,22.0,"[4, 2232, 417, 282, 188, 260, 85, 62, 152, 158, 82, 77, 326, 212, 117, 63, 265, 273, 410, 224, 231, 129]","[1697105193711, 1697105195943, 1697105196360, 1697105196642, 1697105196830, 1697105197090, 1697105197175, 1697105197237, 1697105197389, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199956]"
1201,798,9,[],200,EleutherAI/gpt-neox-20b,128,1,2576.0,1.0,1,H100,1697105181811,1697105184387.0,120,79.0,6.0,"[8, 1936, 85, 85, 79, 383]","[1697105181819, 1697105183755, 1697105183840, 1697105183925, 1697105184004, 1697105184387]"
1202,771,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267799,1697105269598.0,120,,,[113],[1697105267912]
1203,807,10,[],200,EleutherAI/gpt-neox-20b,128,1,5208.0,1.0,1,H100,1697105191152,1697105196360.0,120,90.0,20.0,"[4, 2464, 86, 189, 84, 64, 81, 265, 64, 84, 199, 80, 78, 261, 326, 87, 116, 84, 174, 418]","[1697105191156, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195768, 1697105195942, 1697105196360]"
1204,733,5,[],200,EleutherAI/gpt-neox-20b,128,1,1757.0,1.0,1,H100,1697105172825,1697105174582.0,120,31.0,1.0,"[24, 1733]","[1697105172849, 1697105174582]"
1205,248,6,[],200,EleutherAI/gpt-neox-20b,128,1,4915.0,1.0,1,H100,1697105174583,1697105179498.0,120,182.0,17.0,"[4, 2436, 82, 80, 63, 674, 95, 90, 88, 67, 87, 467, 91, 67, 87, 81, 356]","[1697105174587, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178262, 1697105178349, 1697105178816, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498]"
1206,328,6,[],200,EleutherAI/gpt-neox-20b,128,1,3148.0,1.0,1,H100,1697105174774,1697105177922.0,120,109.0,6.0,"[5, 2245, 81, 80, 63, 674]","[1697105174779, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922]"
1207,928,14,[],200,EleutherAI/gpt-neox-20b,128,1,2145.0,1.0,1,H100,1697105202015,1697105204160.0,120,20.0,1.0,"[184, 1961]","[1697105202199, 1697105204160]"
1208,349,13,[],200,EleutherAI/gpt-neox-20b,128,1,4080.0,1.0,1,H100,1697105202002,1697105206082.0,120,88.0,20.0,"[13, 1703, 88, 88, 87, 269, 87, 87, 83, 415, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84]","[1697105202015, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
1209,25,14,[],200,EleutherAI/gpt-neox-20b,128,1,2714.0,1.0,1,H100,1697105192678,1697105195392.0,120,12.0,1.0,"[13, 2701]","[1697105192691, 1697105195392]"
1210,766,7,[],200,EleutherAI/gpt-neox-20b,128,1,2347.0,1.0,1,H100,1697105182467,1697105184814.0,120,11.0,1.0,"[18, 2329]","[1697105182485, 1697105184814]"
1211,199,8,[],200,EleutherAI/gpt-neox-20b,128,1,1667.0,1.0,1,H100,1697105184815,1697105186482.0,120,13.0,1.0,"[8, 1659]","[1697105184823, 1697105186482]"
1212,356,15,[],200,EleutherAI/gpt-neox-20b,128,1,3569.0,1.0,1,H100,1697105195393,1697105198962.0,120,874.0,2.0,"[4, 3565]","[1697105195397, 1697105198962]"
1213,714,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105198963,1697105201999.0,120,,,[5],[1697105198968]
1214,687,7,[],200,EleutherAI/gpt-neox-20b,128,1,5294.0,1.0,1,H100,1697105177923,1697105183217.0,120,96.0,20.0,"[5, 2174, 85, 67, 279, 79, 75, 489, 80, 80, 387, 87, 76, 408, 89, 83, 384, 89, 88, 190]","[1697105177928, 1697105180102, 1697105180187, 1697105180254, 1697105180533, 1697105180612, 1697105180687, 1697105181176, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217]"
1215,556,9,[],200,EleutherAI/gpt-neox-20b,128,1,2586.0,1.0,1,H100,1697105186483,1697105189069.0,120,9.0,1.0,"[9, 2577]","[1697105186492, 1697105189069]"
1216,139,17,[],200,EleutherAI/gpt-neox-20b,128,1,4809.0,1.0,1,H100,1697105202004,1697105206813.0,120,39.0,21.0,"[91, 1623, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 390, 90, 85, 84, 731]","[1697105202095, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205823, 1697105205913, 1697105205998, 1697105206082, 1697105206813]"
1217,99,11,[],200,EleutherAI/gpt-neox-20b,128,1,2040.0,1.0,1,H100,1697105191768,1697105193808.0,120,10.0,1.0,"[4, 2036]","[1697105191772, 1697105193808]"
1218,454,12,[],200,EleutherAI/gpt-neox-20b,128,1,3738.0,1.0,1,H100,1697105193809,1697105197547.0,120,182.0,6.0,"[5, 3276, 85, 62, 152, 158]","[1697105193814, 1697105197090, 1697105197175, 1697105197237, 1697105197389, 1697105197547]"
1219,813,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105197548,1697105201998.0,120,,,"[5, 3369, 80, 292, 160, 212]","[1697105197553, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1220,236,11,[],200,EleutherAI/gpt-neox-20b,128,1,2246.0,1.0,1,H100,1697105196362,1697105198608.0,120,8.0,1.0,"[16, 2230]","[1697105196378, 1697105198608]"
1221,324,14,[],200,EleutherAI/gpt-neox-20b,128,1,10102.0,1.0,1,H100,1697105202002,1697105212104.0,120,17.0,50.0,"[12, 1704, 88, 88, 87, 269, 87, 87, 83, 415, 93, 88, 88, 69, 87, 86, 389, 91, 85, 84, 731, 90, 89, 86, 80, 80, 60, 60, 618, 87, 82, 83, 63, 435, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 81, 429, 168, 77, 456, 89]","[1697105202014, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207358, 1697105207976, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210885, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104]"
1222,595,12,[],200,EleutherAI/gpt-neox-20b,128,1,2973.0,1.0,1,H100,1697105198609,1697105201582.0,120,8.0,1.0,"[4, 2969]","[1697105198613, 1697105201582]"
1223,919,10,[],200,EleutherAI/gpt-neox-20b,128,1,2267.0,1.0,1,H100,1697105189070,1697105191337.0,120,14.0,1.0,"[9, 2258]","[1697105189079, 1697105191337]"
1224,924,13,[],200,EleutherAI/gpt-neox-20b,128,1,1397.0,1.0,1,H100,1697105201583,1697105202980.0,120,9.0,1.0,"[8, 1389]","[1697105201591, 1697105202980]"
1225,344,11,[],200,EleutherAI/gpt-neox-20b,128,1,2469.0,1.0,1,H100,1697105191339,1697105193808.0,120,13.0,1.0,"[8, 2461]","[1697105191347, 1697105193808]"
1226,354,14,[],200,EleutherAI/gpt-neox-20b,128,1,4378.0,1.0,1,H100,1697105202981,1697105207359.0,120,91.0,20.0,"[25, 1916, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84, 732, 89, 89, 86, 81, 79, 60, 61]","[1697105203006, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359]"
1227,788,12,[],200,EleutherAI/gpt-neox-20b,128,1,1809.0,1.0,1,H100,1697105193809,1697105195618.0,120,31.0,1.0,"[9, 1800]","[1697105193818, 1697105195618]"
1228,422,10,[],200,EleutherAI/gpt-neox-20b,128,1,2102.0,1.0,1,H100,1697105191339,1697105193441.0,120,26.0,1.0,"[8, 2094]","[1697105191347, 1697105193441]"
1229,581,6,[],200,EleutherAI/gpt-neox-20b,128,1,4706.0,1.0,1,H100,1697105182467,1697105187173.0,120,47.0,20.0,"[9, 1911, 83, 79, 78, 59, 215, 77, 58, 362, 74, 537, 87, 84, 409, 88, 79, 77, 59, 281]","[1697105182476, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185036, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186180, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186892, 1697105187173]"
1230,280,7,[],200,EleutherAI/gpt-neox-20b,128,1,5432.0,1.0,1,H100,1697105191957,1697105197389.0,120,91.0,20.0,"[5, 2427, 64, 84, 199, 80, 79, 260, 327, 86, 116, 83, 176, 417, 282, 189, 259, 85, 62, 152]","[1697105191962, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194895, 1697105195155, 1697105195482, 1697105195568, 1697105195684, 1697105195767, 1697105195943, 1697105196360, 1697105196642, 1697105196831, 1697105197090, 1697105197175, 1697105197237, 1697105197389]"
1231,412,5,[],200,EleutherAI/gpt-neox-20b,128,1,2774.0,1.0,1,H100,1697105172156,1697105174930.0,120,244.0,9.0,"[43, 1585, 80, 77, 72, 668, 92, 89, 68]","[1697105172199, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174681, 1697105174773, 1697105174862, 1697105174930]"
1232,33,8,[],200,EleutherAI/gpt-neox-20b,128,1,3289.0,1.0,1,H100,1697105179738,1697105183027.0,120,140.0,7.0,"[8, 2548, 89, 83, 383, 90, 88]","[1697105179746, 1697105182294, 1697105182383, 1697105182466, 1697105182849, 1697105182939, 1697105183027]"
1233,886,8,[],200,EleutherAI/gpt-neox-20b,128,1,1719.0,1.0,1,H100,1697105179738,1697105181457.0,120,17.0,1.0,"[12, 1706]","[1697105179750, 1697105181456]"
1234,742,6,[],200,EleutherAI/gpt-neox-20b,128,1,4806.0,1.0,1,H100,1697105174931,1697105179737.0,120,89.0,20.0,"[5, 2088, 81, 80, 63, 674, 95, 91, 87, 67, 86, 469, 90, 67, 87, 81, 356, 88, 85, 66]","[1697105174936, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178108, 1697105178195, 1697105178262, 1697105178348, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737]"
1235,287,9,[],200,EleutherAI/gpt-neox-20b,128,1,2205.0,1.0,1,H100,1697105181458,1697105183663.0,120,10.0,1.0,"[8, 2197]","[1697105181466, 1697105183663]"
1236,610,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105197390,1697105201998.0,120,,,"[4, 3528, 80, 292, 160, 212]","[1697105197394, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1237,642,10,[],200,EleutherAI/gpt-neox-20b,128,1,5499.0,1.0,1,H100,1697105183664,1697105189163.0,120,89.0,20.0,"[8, 2337, 88, 86, 406, 88, 78, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375]","[1697105183672, 1697105186009, 1697105186097, 1697105186183, 1697105186589, 1697105186677, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162]"
1238,38,9,[],200,EleutherAI/gpt-neox-20b,128,1,4080.0,1.0,1,H100,1697105202002,1697105206082.0,120,88.0,20.0,"[13, 1703, 88, 88, 87, 269, 87, 87, 83, 415, 93, 88, 88, 69, 87, 86, 389, 91, 85, 84]","[1697105202015, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
1239,396,9,[],200,EleutherAI/gpt-neox-20b,128,1,5678.0,1.0,1,H100,1697105183028,1697105188706.0,120,89.0,20.0,"[4, 2366, 74, 537, 87, 82, 411, 87, 80, 77, 60, 280, 83, 83, 83, 376, 89, 561, 94, 164]","[1697105183032, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186178, 1697105186589, 1697105186676, 1697105186756, 1697105186833, 1697105186893, 1697105187173, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706]"
1240,390,17,[],200,EleutherAI/gpt-neox-20b,128,1,5399.0,1.0,1,H100,1697105206084,1697105211483.0,120,84.0,20.0,"[45, 1848, 86, 83, 82, 64, 434, 87, 84, 79, 78, 384, 77, 619, 86, 82, 502, 81, 430, 168]","[1697105206129, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209054, 1697105209438, 1697105209515, 1697105210134, 1697105210220, 1697105210302, 1697105210804, 1697105210885, 1697105211315, 1697105211483]"
1241,233,10,[],200,EleutherAI/gpt-neox-20b,128,1,2308.0,1.0,1,H100,1697105185310,1697105187618.0,120,6.0,1.0,"[12, 2296]","[1697105185322, 1697105187618]"
1242,387,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105215910,1697105220995.0,120,,,"[17, 2967, 81, 60, 365, 89, 75, 259, 62, 234, 79, 228, 82, 198]","[1697105215927, 1697105218894, 1697105218975, 1697105219035, 1697105219400, 1697105219489, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220426, 1697105220508, 1697105220706]"
1243,170,15,[],200,EleutherAI/gpt-neox-20b,128,1,4275.0,1.0,1,H100,1697105214173,1697105218448.0,120,335.0,15.0,"[8, 2238, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 82, 257]","[1697105214181, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218448]"
1244,68,9,[],200,EleutherAI/gpt-neox-20b,128,1,2308.0,1.0,1,H100,1697105185310,1697105187618.0,120,12.0,1.0,"[12, 2296]","[1697105185322, 1697105187618]"
1245,426,10,[],200,EleutherAI/gpt-neox-20b,128,1,7276.0,1.0,1,H100,1697105187619,1697105194895.0,120,79.0,36.0,"[4, 2192, 90, 272, 166, 250, 88, 250, 66, 87, 67, 366, 162, 87, 281, 82, 275, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81, 265, 64, 84, 199, 80, 79]","[1697105187623, 1697105189815, 1697105189905, 1697105190177, 1697105190343, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191151, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194895]"
1246,590,11,[],200,EleutherAI/gpt-neox-20b,128,1,5551.0,1.0,1,H100,1697105187619,1697105193170.0,120,88.0,20.0,"[8, 2550, 166, 250, 88, 250, 66, 87, 67, 366, 162, 87, 281, 82, 276, 75, 286, 87, 83, 234]","[1697105187627, 1697105190177, 1697105190343, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191151, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192405, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170]"
1247,857,16,[],200,EleutherAI/gpt-neox-20b,128,1,2780.0,1.0,1,H100,1697105198425,1697105201205.0,120,18.0,1.0,"[21, 2759]","[1697105198446, 1697105201205]"
1248,287,17,[],200,EleutherAI/gpt-neox-20b,128,1,1774.0,1.0,1,H100,1697105201206,1697105202980.0,120,10.0,1.0,"[13, 1761]","[1697105201219, 1697105202980]"
1249,154,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257115.0,120,,,[93],[1697105255123]
1250,483,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105260462.0,120,,,[190],[1697105257308]
1251,638,18,[],200,EleutherAI/gpt-neox-20b,128,1,4378.0,1.0,1,H100,1697105202981,1697105207359.0,120,88.0,20.0,"[29, 1912, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84, 732, 90, 88, 86, 81, 79, 60, 61]","[1697105203010, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206814, 1697105206904, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359]"
1252,748,18,[],200,EleutherAI/gpt-neox-20b,128,1,3261.0,1.0,1,H100,1697105220996,1697105224257.0,120,182.0,14.0,"[36, 1635, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 352]","[1697105221032, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224257]"
1253,846,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260464,1697105262306.0,120,,,[32],[1697105260496]
1254,278,34,[],200,EleutherAI/gpt-neox-20b,128,1,1677.0,1.0,1,H100,1697105262313,1697105263990.0,120,13.0,1.0,"[254, 1423]","[1697105262567, 1697105263990]"
1255,635,35,[],200,EleutherAI/gpt-neox-20b,128,1,1013.0,1.0,1,H100,1697105263991,1697105265004.0,120,23.0,1.0,"[37, 976]","[1697105264028, 1697105265004]"
1256,32,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265006,1697105267796.0,120,,,[29],[1697105265035]
1257,386,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[38],[1697105267836]
1258,746,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[69],[1697105269669]
1259,760,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105191684,1697105201999.0,120,,,"[6, 2699, 64, 84, 199, 80, 79, 260, 327, 86, 116, 84, 175, 417, 282, 184, 264, 85, 62, 151, 159, 82, 77, 326, 212, 117, 63, 265, 273, 410, 224, 231, 129, 150, 140, 81, 79, 219, 297, 80, 292, 160, 212]","[1697105191690, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194895, 1697105195155, 1697105195482, 1697105195568, 1697105195684, 1697105195768, 1697105195943, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200625, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1260,175,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270989,1697105271973.0,120,,,[4],[1697105270993]
1261,539,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271976,1697105273584.0,120,,,[18],[1697105271994]
1262,57,41,[],200,EleutherAI/gpt-neox-20b,128,1,1545.0,1.0,1,H100,1697105273587,1697105275132.0,120,13.0,1.0,"[15, 1530]","[1697105273602, 1697105275132]"
1263,456,12,[],200,EleutherAI/gpt-neox-20b,128,1,6636.0,1.0,1,H100,1697105194818,1697105201454.0,120,90.0,20.0,"[8, 3207, 211, 117, 63, 265, 273, 410, 224, 230, 130, 150, 141, 79, 80, 220, 296, 80, 292, 160]","[1697105194826, 1697105198033, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199826, 1697105199956, 1697105200106, 1697105200247, 1697105200326, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454]"
1264,15,11,[],200,EleutherAI/gpt-neox-20b,128,1,5511.0,1.0,1,H100,1697105212105,1697105217616.0,120,100.0,20.0,"[9, 2303, 85, 65, 75, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246, 85, 65, 386, 89, 87]","[1697105212114, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616]"
1265,215,14,[],200,EleutherAI/gpt-neox-20b,128,1,2507.0,1.0,1,H100,1697105217530,1697105220037.0,120,12.0,1.0,"[5, 2502]","[1697105217535, 1697105220037]"
1266,778,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105200108,1697105201999.0,120,,,[8],[1697105200116]
1267,207,10,[],200,EleutherAI/gpt-neox-20b,128,1,1622.0,1.0,1,H100,1697105202004,1697105203626.0,120,10.0,1.0,"[75, 1547]","[1697105202079, 1697105203626]"
1268,661,15,[],200,EleutherAI/gpt-neox-20b,128,1,3528.0,1.0,1,H100,1697105220038,1697105223566.0,120,161.0,10.0,"[4, 1923, 702, 87, 85, 82, 81, 401, 71, 92]","[1697105220042, 1697105221965, 1697105222667, 1697105222754, 1697105222839, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566]"
1269,413,9,[],200,EleutherAI/gpt-neox-20b,128,1,10855.0,1.0,1,H100,1697105179738,1697105190593.0,120,244.0,50.0,"[4, 2552, 89, 83, 384, 89, 88, 189, 88, 78, 373, 85, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 87, 81, 411, 88, 79, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 165, 250]","[1697105179742, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183216, 1697105183304, 1697105183382, 1697105183755, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592]"
1270,406,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170020,1697105172155.0,120,,,"[158, 1892]","[1697105170178, 1697105172070]"
1271,566,11,[],200,EleutherAI/gpt-neox-20b,128,1,9264.0,1.0,1,H100,1697105203627,1697105212891.0,120,109.0,36.0,"[36, 3150, 90, 89, 86, 80, 80, 60, 61, 618, 86, 83, 82, 64, 434, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 82, 428, 168, 77, 456, 89, 80, 79, 75, 71, 482]","[1697105203663, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212409, 1697105212891]"
1272,767,5,[],200,EleutherAI/gpt-neox-20b,128,1,1525.0,1.0,1,H100,1697105172159,1697105173684.0,120,11.0,1.0,"[214, 1311]","[1697105172373, 1697105173684]"
1273,90,16,[],200,EleutherAI/gpt-neox-20b,128,1,1577.0,1.0,1,H100,1697105223567,1697105225144.0,120,19.0,1.0,"[9, 1568]","[1697105223576, 1697105225144]"
1274,449,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225145,1697105228773.0,120,,,"[5, 1102, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105225150, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
1275,914,9,[],200,EleutherAI/gpt-neox-20b,128,1,5488.0,1.0,1,H100,1697105183218,1697105188706.0,120,84.0,20.0,"[4, 2176, 74, 537, 88, 81, 410, 88, 80, 77, 59, 281, 83, 83, 83, 376, 89, 561, 94, 164]","[1697105183222, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186178, 1697105186588, 1697105186676, 1697105186756, 1697105186833, 1697105186892, 1697105187173, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706]"
1276,195,6,[],200,EleutherAI/gpt-neox-20b,128,1,11786.0,1.0,1,H100,1697105173686,1697105185472.0,120,286.0,64.0,"[48, 1888, 99, 91, 89, 70, 87, 69, 68, 69, 760, 81, 80, 63, 674, 94, 91, 88, 67, 86, 468, 91, 66, 88, 81, 356, 88, 85, 65, 366, 85, 66, 280, 79, 75, 488, 81, 80, 387, 87, 76, 408, 88, 84, 383, 90, 88, 189, 88, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74]","[1697105173734, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176264, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182382, 1697105182466, 1697105182849, 1697105182939, 1697105183027, 1697105183216, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472]"
1277,312,10,[],200,EleutherAI/gpt-neox-20b,128,1,2136.0,1.0,1,H100,1697105188708,1697105190844.0,120,23.0,1.0,"[32, 2104]","[1697105188740, 1697105190844]"
1278,504,11,[],200,EleutherAI/gpt-neox-20b,128,1,6297.0,1.0,1,H100,1697105195157,1697105201454.0,120,58.0,20.0,"[4, 2872, 211, 117, 63, 265, 273, 410, 224, 230, 130, 150, 141, 79, 80, 220, 296, 80, 292, 160]","[1697105195161, 1697105198033, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199826, 1697105199956, 1697105200106, 1697105200247, 1697105200326, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454]"
1279,864,12,[],200,EleutherAI/gpt-neox-20b,128,1,4626.0,1.0,1,H100,1697105201456,1697105206082.0,120,83.0,20.0,"[12, 2250, 88, 88, 87, 269, 87, 86, 84, 415, 93, 88, 88, 69, 87, 86, 389, 91, 85, 84]","[1697105201468, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
1280,670,11,[],200,EleutherAI/gpt-neox-20b,128,1,4637.0,1.0,1,H100,1697105190845,1697105195482.0,120,67.0,18.0,"[5, 2320, 82, 62, 306, 86, 189, 84, 64, 81, 265, 64, 84, 199, 80, 79, 261, 325]","[1697105190850, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194895, 1697105195156, 1697105195481]"
1281,807,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230476.0,120,,,[112],[1697105228893]
1282,916,10,[],200,EleutherAI/gpt-neox-20b,128,1,2455.0,1.0,1,H100,1697105192937,1697105195392.0,120,8.0,1.0,"[4, 2451]","[1697105192941, 1697105195392]"
1283,95,12,[],200,EleutherAI/gpt-neox-20b,128,1,2816.0,1.0,1,H100,1697105195483,1697105198299.0,120,12.0,1.0,"[4, 2812]","[1697105195487, 1697105198299]"
1284,454,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105198300,1697105201999.0,120,,,"[5, 2989, 160, 213]","[1697105198305, 1697105201294, 1697105201454, 1697105201667]"
1285,206,19,[],200,EleutherAI/gpt-neox-20b,128,1,2517.0,1.0,1,H100,1697105230478,1697105232995.0,120,16.0,1.0,"[199, 2318]","[1697105230677, 1697105232995]"
1286,566,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232996,1697105234919.0,120,,,[20],[1697105233016]
1287,920,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236782.0,120,,,[57],[1697105234979]
1288,351,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236785,1697105238408.0,120,,,[41],[1697105236826]
1289,293,13,[],200,EleutherAI/gpt-neox-20b,128,1,5067.0,1.0,1,H100,1697105202011,1697105207078.0,120,91.0,20.0,"[176, 2063, 87, 87, 83, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84, 732, 89, 89, 86]","[1697105202187, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206814, 1697105206903, 1697105206992, 1697105207078]"
1290,815,14,[],200,EleutherAI/gpt-neox-20b,128,1,1889.0,1.0,1,H100,1697105202005,1697105203894.0,120,52.0,4.0,"[110, 1603, 88, 88]","[1697105202115, 1697105203718, 1697105203806, 1697105203894]"
1291,333,15,[],200,EleutherAI/gpt-neox-20b,128,1,4168.0,1.0,1,H100,1697105203895,1697105208063.0,120,563.0,11.0,"[5, 2913, 90, 89, 86, 81, 79, 60, 61, 618, 86]","[1697105203900, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063]"
1292,317,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105195393,1697105201999.0,120,,,"[16, 3963, 224, 231, 129, 150, 140, 81, 79, 220, 296, 80, 292, 160, 213]","[1697105195409, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201667]"
1293,772,10,[],200,EleutherAI/gpt-neox-20b,128,1,4563.0,1.0,1,H100,1697105190593,1697105195156.0,120,83.0,20.0,"[5, 2168, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81, 265, 63, 85, 199, 81, 78, 261]","[1697105190598, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194817, 1697105194895, 1697105195156]"
1294,756,2,[],200,EleutherAI/gpt-neox-20b,128,1,1655.0,1.0,1,H100,1697105170016,1697105171671.0,120,19.0,1.0,"[53, 1602]","[1697105170069, 1697105171671]"
1295,673,8,[],200,EleutherAI/gpt-neox-20b,128,1,6115.0,1.0,1,H100,1697105185036,1697105191151.0,120,93.0,20.0,"[5, 2757, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 166, 250, 88, 250, 66, 87, 67]","[1697105185041, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190343, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191151]"
1296,186,3,[],200,EleutherAI/gpt-neox-20b,128,1,5433.0,1.0,1,H100,1697105171672,1697105177105.0,120,123.0,22.0,"[13, 2099, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69, 759, 81]","[1697105171685, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177023, 1697105177104]"
1297,341,12,[],200,EleutherAI/gpt-neox-20b,128,1,5379.0,1.0,1,H100,1697105213069,1697105218448.0,120,87.0,20.0,"[9, 2217, 85, 355, 90, 84, 510, 89, 67, 83, 247, 84, 65, 386, 89, 87, 406, 87, 82, 256]","[1697105213078, 1697105215295, 1697105215380, 1697105215735, 1697105215825, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216905, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218447]"
1298,255,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105180544,1697105201999.0,120,,,"[12, 2294, 89, 88, 190, 87, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 87, 81, 411, 88, 79, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 162, 87, 281, 81, 276, 76, 286, 87, 82, 235, 82, 62, 305, 87, 189, 84, 64, 80, 266, 63, 85, 199, 80, 78, 261, 326, 87, 116, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 326, 212, 117, 63, 265, 273, 410, 224, 230, 130, 150, 140, 80, 80, 219, 297, 80, 292, 160, 212]","[1697105180556, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192128, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192935, 1697105193170, 1697105193252, 1697105193314, 1697105193619, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194123, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199826, 1697105199956, 1697105200106, 1697105200246, 1697105200326, 1697105200406, 1697105200625, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1299,675,12,[],200,EleutherAI/gpt-neox-20b,128,1,1978.0,1.0,1,H100,1697105202003,1697105203981.0,120,563.0,5.0,"[40, 1675, 88, 88, 87]","[1697105202043, 1697105203718, 1697105203806, 1697105203894, 1697105203981]"
1300,104,13,[],200,EleutherAI/gpt-neox-20b,128,1,5456.0,1.0,1,H100,1697105203982,1697105209438.0,120,93.0,20.0,"[5, 2827, 89, 89, 86, 81, 79, 60, 61, 618, 86, 83, 82, 64, 434, 87, 84, 79, 77, 385]","[1697105203987, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438]"
1301,228,10,[],200,EleutherAI/gpt-neox-20b,128,1,6293.0,1.0,1,H100,1697105184388,1697105190681.0,120,100.0,20.0,"[13, 2772, 83, 84, 82, 376, 89, 561, 94, 164, 81, 376, 86, 85, 481, 90, 272, 165, 251, 87]","[1697105184401, 1697105187173, 1697105187256, 1697105187340, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190680]"
1302,275,16,[],200,EleutherAI/gpt-neox-20b,128,1,1842.0,1.0,1,H100,1697105220996,1697105222838.0,120,161.0,4.0,"[28, 1643, 87, 84]","[1697105221024, 1697105222667, 1697105222754, 1697105222838]"
1303,635,17,[],200,EleutherAI/gpt-neox-20b,128,1,2304.0,1.0,1,H100,1697105222840,1697105225144.0,120,23.0,1.0,"[4, 2300]","[1697105222844, 1697105225144]"
1304,600,11,[],200,EleutherAI/gpt-neox-20b,128,1,2266.0,1.0,1,H100,1697105206993,1697105209259.0,120,23.0,1.0,"[9, 2257]","[1697105207002, 1697105209259]"
1305,25,12,[],200,EleutherAI/gpt-neox-20b,128,1,2663.0,1.0,1,H100,1697105209260,1697105211923.0,120,12.0,1.0,"[9, 2654]","[1697105209269, 1697105211923]"
1306,383,13,[],200,EleutherAI/gpt-neox-20b,128,1,1717.0,1.0,1,H100,1697105211924,1697105213641.0,120,15.0,1.0,"[9, 1708]","[1697105211933, 1697105213641]"
1307,737,14,[],200,EleutherAI/gpt-neox-20b,128,1,2777.0,1.0,1,H100,1697105213642,1697105216419.0,120,216.0,2.0,"[5, 2587, 185]","[1697105213647, 1697105216234, 1697105216419]"
1308,170,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105216420,1697105220995.0,120,,,"[4, 2976, 89, 75, 259, 62, 234, 79, 229, 81, 198]","[1697105216424, 1697105219400, 1697105219489, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
1309,63,18,[],200,EleutherAI/gpt-neox-20b,128,1,1808.0,1.0,1,H100,1697105225146,1697105226954.0,120,39.0,1.0,"[36, 1772]","[1697105225182, 1697105226954]"
1310,398,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226955,1697105228774.0,120,,,[12],[1697105226967]
1311,868,3,[],200,EleutherAI/gpt-neox-20b,128,1,4106.0,1.0,1,H100,1697105172159,1697105176265.0,120,85.0,20.0,"[149, 1476, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 99, 91, 89, 70, 87, 69, 68, 70]","[1697105172308, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176265]"
1312,783,13,[],200,EleutherAI/gpt-neox-20b,128,1,3025.0,1.0,1,H100,1697105208898,1697105211923.0,120,286.0,1.0,"[8, 3017]","[1697105208906, 1697105211923]"
1313,758,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230475.0,120,,,[196],[1697105228977]
1314,716,5,[],200,EleutherAI/gpt-neox-20b,128,1,6112.0,1.0,1,H100,1697105176271,1697105182383.0,120,79.0,30.0,"[17, 1634, 94, 91, 88, 67, 87, 467, 91, 66, 88, 81, 356, 88, 85, 65, 366, 85, 66, 280, 79, 75, 488, 81, 80, 387, 87, 76, 408, 89]","[1697105176288, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178349, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383]"
1315,188,14,[],200,EleutherAI/gpt-neox-20b,128,1,4980.0,1.0,1,H100,1697105211924,1697105216904.0,120,85.0,20.0,"[5, 1901, 94, 90, 89, 68, 246, 85, 65, 75, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246]","[1697105211929, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904]"
1316,500,16,[],200,EleutherAI/gpt-neox-20b,128,1,2743.0,1.0,1,H100,1697105220996,1697105223739.0,120,335.0,11.0,"[72, 1599, 87, 85, 82, 81, 401, 71, 92, 87, 86]","[1697105221068, 1697105222667, 1697105222754, 1697105222839, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739]"
1317,861,17,[],200,EleutherAI/gpt-neox-20b,128,1,1404.0,1.0,1,H100,1697105223740,1697105225144.0,120,10.0,1.0,"[5, 1399]","[1697105223745, 1697105225144]"
1318,286,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225146,1697105228774.0,120,,,"[48, 1869, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105225194, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
1319,119,8,[],200,EleutherAI/gpt-neox-20b,128,1,2091.0,1.0,1,H100,1697105183218,1697105185309.0,120,31.0,1.0,"[13, 2078]","[1697105183231, 1697105185309]"
1320,449,9,[],200,EleutherAI/gpt-neox-20b,128,1,5841.0,1.0,1,H100,1697105185310,1697105191151.0,120,86.0,20.0,"[4, 2484, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 166, 250, 88, 250, 66, 87, 67]","[1697105185314, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190343, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191151]"
1321,646,19,[],200,EleutherAI/gpt-neox-20b,128,1,2518.0,1.0,1,H100,1697105228788,1697105231306.0,120,14.0,1.0,"[302, 2216]","[1697105229090, 1697105231306]"
1322,215,13,[],200,EleutherAI/gpt-neox-20b,128,1,2680.0,1.0,1,H100,1697105195619,1697105198299.0,120,12.0,1.0,"[9, 2671]","[1697105195628, 1697105198299]"
1323,576,14,[],200,EleutherAI/gpt-neox-20b,128,1,2905.0,1.0,1,H100,1697105198300,1697105201205.0,120,14.0,1.0,"[5, 2900]","[1697105198305, 1697105201205]"
1324,810,10,[],200,EleutherAI/gpt-neox-20b,128,1,5679.0,1.0,1,H100,1697105191152,1697105196831.0,120,91.0,20.0,"[16, 2727, 84, 64, 81, 265, 64, 84, 199, 80, 78, 261, 327, 87, 115, 84, 174, 418, 282, 189]","[1697105191168, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195482, 1697105195569, 1697105195684, 1697105195768, 1697105195942, 1697105196360, 1697105196642, 1697105196831]"
1325,7,15,[],200,EleutherAI/gpt-neox-20b,128,1,3809.0,1.0,1,H100,1697105201206,1697105205015.0,120,345.0,11.0,"[4, 2508, 88, 88, 87, 269, 87, 86, 84, 415, 92]","[1697105201210, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014]"
1326,685,15,[],200,EleutherAI/gpt-neox-20b,128,1,2312.0,1.0,1,H100,1697105212105,1697105214417.0,120,364.0,2.0,"[5, 2307]","[1697105212110, 1697105214417]"
1327,561,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105197630,1697105201998.0,120,,,"[4, 3288, 80, 292, 160, 212]","[1697105197634, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1328,255,7,[],200,EleutherAI/gpt-neox-20b,128,1,22652.0,1.0,1,H100,1697105178350,1697105201002.0,120,216.0,119.0,"[21, 2804, 81, 80, 387, 87, 76, 408, 89, 83, 384, 89, 88, 190, 87, 78, 373, 85, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 87, 81, 411, 88, 79, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 161, 88, 281, 81, 276, 76, 286, 87, 82, 235, 82, 62, 305, 87, 189, 84, 63, 81, 266, 63, 85, 199, 80, 78, 261, 326, 87, 116, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 326, 212, 117, 63, 264, 273, 411, 224, 230, 130, 150, 140, 80, 80, 219, 297, 80]","[1697105178371, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183755, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191678, 1697105191766, 1697105192047, 1697105192128, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192935, 1697105193170, 1697105193252, 1697105193314, 1697105193619, 1697105193706, 1697105193895, 1697105193979, 1697105194042, 1697105194123, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198688, 1697105198961, 1697105199372, 1697105199596, 1697105199826, 1697105199956, 1697105200106, 1697105200246, 1697105200326, 1697105200406, 1697105200625, 1697105200922, 1697105201002]"
1329,74,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105231307,1697105234919.0,120,,,"[13, 1736, 600, 617]","[1697105231320, 1697105233056, 1697105233656, 1697105234273]"
1330,116,16,[],200,EleutherAI/gpt-neox-20b,128,1,1816.0,1.0,1,H100,1697105214418,1697105216234.0,120,23.0,1.0,"[12, 1804]","[1697105214430, 1697105216234]"
1331,403,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236782.0,120,,,[89],[1697105235011]
1332,762,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236785,1697105240330.0,120,,,[233],[1697105237018]
1333,348,5,[],200,EleutherAI/gpt-neox-20b,128,1,4267.0,1.0,1,H100,1697105176271,1697105180538.0,120,91.0,20.0,"[33, 1618, 95, 90, 88, 68, 86, 467, 91, 66, 88, 81, 356, 88, 85, 65, 366, 85, 66, 285]","[1697105176304, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178263, 1697105178349, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180538]"
1334,190,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241995.0,120,,,[61],[1697105240395]
1335,548,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242002,1697105243754.0,120,,,[178],[1697105242180]
1336,907,25,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105243758,1697105245427.0,120,10.0,1.0,"[238, 1431]","[1697105243996, 1697105245427]"
1337,307,26,[],200,EleutherAI/gpt-neox-20b,128,1,767.0,1.0,1,H100,1697105245429,1697105246196.0,120,26.0,1.0,"[53, 714]","[1697105245482, 1697105246196]"
1338,666,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105246197,1697105248695.0,120,,,[9],[1697105246206]
1339,95,28,[],200,EleutherAI/gpt-neox-20b,128,1,2485.0,1.0,1,H100,1697105248699,1697105251184.0,120,12.0,1.0,"[170, 2315]","[1697105248869, 1697105251184]"
1340,452,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105251186,1697105253711.0,120,,,"[28, 1350]","[1697105251214, 1697105252564]"
1341,898,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105255028.0,120,,,[169],[1697105253883]
1342,327,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[45],[1697105255075]
1343,910,7,[],200,EleutherAI/gpt-neox-20b,128,1,1895.0,1.0,1,H100,1697105187174,1697105189069.0,120,8.0,1.0,"[4, 1891]","[1697105187178, 1697105189069]"
1344,915,11,[],200,EleutherAI/gpt-neox-20b,128,1,1624.0,1.0,1,H100,1697105202002,1697105203626.0,120,182.0,1.0,"[17, 1606]","[1697105202019, 1697105203625]"
1345,342,18,[],200,EleutherAI/gpt-neox-20b,128,1,5317.0,1.0,1,H100,1697105214568,1697105219885.0,120,364.0,14.0,"[20, 3434, 88, 81, 256, 79, 368, 81, 59, 366, 89, 75, 260, 61]","[1697105214588, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219824, 1697105219885]"
1346,345,12,[],200,EleutherAI/gpt-neox-20b,128,1,3732.0,1.0,1,H100,1697105203627,1697105207359.0,120,39.0,20.0,"[12, 1283, 93, 89, 88, 68, 87, 86, 389, 91, 85, 84, 732, 90, 88, 86, 81, 79, 60, 61]","[1697105203639, 1697105204922, 1697105205015, 1697105205104, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206814, 1697105206904, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359]"
1347,68,11,[],200,EleutherAI/gpt-neox-20b,128,1,2793.0,1.0,1,H100,1697105189164,1697105191957.0,120,12.0,1.0,"[12, 2781]","[1697105189176, 1697105191957]"
1348,426,12,[],200,EleutherAI/gpt-neox-20b,128,1,8369.0,1.0,1,H100,1697105191958,1697105200327.0,120,79.0,36.0,"[4, 2427, 64, 84, 199, 80, 79, 260, 327, 86, 116, 83, 176, 417, 282, 189, 259, 85, 62, 152, 158, 82, 77, 326, 212, 117, 63, 265, 273, 410, 224, 231, 129, 150, 140, 81]","[1697105191962, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194895, 1697105195155, 1697105195482, 1697105195568, 1697105195684, 1697105195767, 1697105195943, 1697105196360, 1697105196642, 1697105196831, 1697105197090, 1697105197175, 1697105197237, 1697105197389, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327]"
1349,671,19,[],200,EleutherAI/gpt-neox-20b,128,1,2016.0,1.0,1,H100,1697105219887,1697105221903.0,120,12.0,1.0,"[8, 2008]","[1697105219895, 1697105221903]"
1350,96,20,[],200,EleutherAI/gpt-neox-20b,128,1,2258.0,1.0,1,H100,1697105221904,1697105224162.0,120,31.0,1.0,"[33, 2225]","[1697105221937, 1697105224162]"
1351,452,21,[],200,EleutherAI/gpt-neox-20b,128,1,1236.0,1.0,1,H100,1697105224163,1697105225399.0,120,216.0,4.0,"[20, 961, 95, 82, 78]","[1697105224183, 1697105225144, 1697105225239, 1697105225321, 1697105225399]"
1352,793,13,[],200,EleutherAI/gpt-neox-20b,128,1,8019.0,1.0,1,H100,1697105207360,1697105215379.0,120,92.0,31.0,"[16, 2758, 85, 83, 502, 82, 429, 167, 77, 457, 88, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 64, 76, 652, 85]","[1697105207376, 1697105210134, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211315, 1697105211482, 1697105211559, 1697105212016, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642, 1697105215294, 1697105215379]"
1353,808,22,[],200,EleutherAI/gpt-neox-20b,128,1,2511.0,1.0,1,H100,1697105225400,1697105227911.0,120,286.0,2.0,"[8, 2503]","[1697105225408, 1697105227911]"
1354,240,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105227912,1697105232145.0,120,,,"[5, 2598, 990, 76, 75, 74, 73]","[1697105227917, 1697105230515, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
1355,787,13,[],200,EleutherAI/gpt-neox-20b,128,1,3922.0,1.0,1,H100,1697105200328,1697105204250.0,120,123.0,6.0,"[4, 3386, 88, 88, 87, 269]","[1697105200332, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250]"
1356,803,17,[],200,EleutherAI/gpt-neox-20b,128,1,2867.0,1.0,1,H100,1697105219036,1697105221903.0,120,20.0,1.0,"[4, 2863]","[1697105219040, 1697105221903]"
1357,665,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105216813,1697105220995.0,120,,,"[5, 2582, 89, 75, 259, 62, 234, 79, 229, 81, 198]","[1697105216818, 1697105219400, 1697105219489, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
1358,771,7,[],200,EleutherAI/gpt-neox-20b,128,1,4866.0,1.0,1,H100,1697105181811,1697105186677.0,120,47.0,20.0,"[8, 1936, 85, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 88, 81, 411, 88]","[1697105181819, 1697105183755, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186178, 1697105186589, 1697105186677]"
1359,645,12,[],200,EleutherAI/gpt-neox-20b,128,1,5835.0,1.0,1,H100,1697105200247,1697105206082.0,120,86.0,20.0,"[5, 3466, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84]","[1697105200252, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
1360,924,12,[],200,EleutherAI/gpt-neox-20b,128,1,2221.0,1.0,1,H100,1697105193171,1697105195392.0,120,9.0,1.0,"[8, 2213]","[1697105193179, 1697105195392]"
1361,228,18,[],200,EleutherAI/gpt-neox-20b,128,1,4349.0,1.0,1,H100,1697105221904,1697105226253.0,120,100.0,20.0,"[8, 1491, 71, 92, 87, 87, 84, 82, 350, 91, 70, 88, 87, 68, 579, 82, 78, 74, 74, 705]","[1697105221912, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223740, 1697105223824, 1697105223906, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226252]"
1362,392,8,[],200,EleutherAI/gpt-neox-20b,128,1,2371.0,1.0,1,H100,1697105179738,1697105182109.0,120,20.0,1.0,"[25, 2346]","[1697105179763, 1697105182109]"
1363,751,9,[],200,EleutherAI/gpt-neox-20b,128,1,9937.0,1.0,1,H100,1697105182110,1697105192047.0,120,216.0,50.0,"[4, 1641, 86, 84, 79, 383, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 88, 81, 411, 88, 78, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 162, 87, 281]","[1697105182114, 1697105183755, 1697105183841, 1697105183925, 1697105184004, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186178, 1697105186589, 1697105186677, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047]"
1364,68,19,[],200,EleutherAI/gpt-neox-20b,128,1,2619.0,1.0,1,H100,1697105207360,1697105209979.0,120,12.0,1.0,"[12, 2607]","[1697105207372, 1697105209979]"
1365,396,20,[],200,EleutherAI/gpt-neox-20b,128,1,5928.0,1.0,1,H100,1697105209980,1697105215908.0,120,89.0,20.0,"[16, 2895, 88, 89, 82, 75, 606, 93, 90, 89, 68, 246, 85, 65, 75, 652, 85, 356, 90, 83]","[1697105209996, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213831, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908]"
1366,196,8,[],200,EleutherAI/gpt-neox-20b,128,1,2391.0,1.0,1,H100,1697105186678,1697105189069.0,120,13.0,1.0,"[16, 2375]","[1697105186694, 1697105189069]"
1367,80,13,[],200,EleutherAI/gpt-neox-20b,128,1,1784.0,1.0,1,H100,1697105206084,1697105207868.0,120,13.0,1.0,"[41, 1743]","[1697105206125, 1697105207868]"
1368,225,16,[],200,EleutherAI/gpt-neox-20b,128,1,2110.0,1.0,1,H100,1697105207869,1697105209979.0,120,23.0,1.0,"[28, 2082]","[1697105207897, 1697105209979]"
1369,583,17,[],200,EleutherAI/gpt-neox-20b,128,1,5928.0,1.0,1,H100,1697105209980,1697105215908.0,120,96.0,20.0,"[20, 2891, 88, 89, 82, 75, 606, 93, 90, 89, 68, 246, 85, 65, 75, 652, 85, 356, 90, 83]","[1697105210000, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213831, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908]"
1370,178,19,[],200,EleutherAI/gpt-neox-20b,128,1,886.0,1.0,1,H100,1697105224258,1697105225144.0,120,11.0,1.0,"[8, 878]","[1697105224266, 1697105225144]"
1371,511,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225146,1697105228773.0,120,,,"[40, 1877, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105225186, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
1372,394,10,[],200,EleutherAI/gpt-neox-20b,128,1,2056.0,1.0,1,H100,1697105200924,1697105202980.0,120,11.0,1.0,"[8, 2048]","[1697105200932, 1697105202980]"
1373,752,11,[],200,EleutherAI/gpt-neox-20b,128,1,2034.0,1.0,1,H100,1697105202981,1697105205015.0,120,39.0,3.0,"[5, 1936, 93]","[1697105202986, 1697105204922, 1697105205015]"
1374,331,6,[],200,EleutherAI/gpt-neox-20b,128,1,2762.0,1.0,1,H100,1697105177249,1697105180011.0,120,26.0,1.0,"[21, 2741]","[1697105177270, 1697105180011]"
1375,690,7,[],200,EleutherAI/gpt-neox-20b,128,1,2747.0,1.0,1,H100,1697105180012,1697105182759.0,120,39.0,1.0,"[24, 2723]","[1697105180036, 1697105182759]"
1376,159,12,[],200,EleutherAI/gpt-neox-20b,128,1,1698.0,1.0,1,H100,1697105205016,1697105206714.0,120,31.0,1.0,"[4, 1694]","[1697105205020, 1697105206714]"
1377,134,4,[],200,EleutherAI/gpt-neox-20b,128,1,4266.0,1.0,1,H100,1697105176271,1697105180537.0,120,86.0,20.0,"[21, 1630, 94, 91, 88, 67, 87, 467, 91, 66, 88, 81, 356, 88, 85, 65, 366, 85, 66, 280]","[1697105176292, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178349, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180533]"
1378,150,7,[],200,EleutherAI/gpt-neox-20b,128,1,1625.0,1.0,1,H100,1697105172159,1697105173784.0,120,216.0,2.0,"[154, 1471]","[1697105172313, 1697105173784]"
1379,503,8,[],200,EleutherAI/gpt-neox-20b,128,1,4564.0,1.0,1,H100,1697105173785,1697105178349.0,120,109.0,20.0,"[17, 1820, 99, 91, 89, 70, 87, 69, 68, 69, 759, 81, 81, 63, 674, 95, 90, 88, 67, 87]","[1697105173802, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176264, 1697105177023, 1697105177104, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178262, 1697105178349]"
1380,276,7,[],200,EleutherAI/gpt-neox-20b,128,1,4286.0,1.0,1,H100,1697105181811,1697105186097.0,120,732.0,13.0,"[16, 2560, 83, 79, 78, 59, 215, 77, 58, 362, 74, 537, 88]","[1697105181827, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185036, 1697105185398, 1697105185472, 1697105186009, 1697105186097]"
1381,652,14,[],200,EleutherAI/gpt-neox-20b,128,1,2180.0,1.0,1,H100,1697105207079,1697105209259.0,120,14.0,1.0,"[9, 2171]","[1697105207088, 1697105209259]"
1382,52,15,[],200,EleutherAI/gpt-neox-20b,128,1,3078.0,1.0,1,H100,1697105209260,1697105212338.0,120,58.0,6.0,"[5, 2750, 89, 80, 79, 75]","[1697105209265, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338]"
1383,98,9,[],200,EleutherAI/gpt-neox-20b,128,1,2289.0,1.0,1,H100,1697105191152,1697105193441.0,120,14.0,1.0,"[20, 2269]","[1697105191172, 1697105193441]"
1384,451,10,[],200,EleutherAI/gpt-neox-20b,128,1,2176.0,1.0,1,H100,1697105193442,1697105195618.0,120,286.0,1.0,"[4, 2172]","[1697105193446, 1697105195618]"
1385,143,8,[],200,EleutherAI/gpt-neox-20b,128,1,4319.0,1.0,1,H100,1697105186678,1697105190997.0,120,6.0,12.0,"[8, 2477, 86, 85, 481, 90, 272, 165, 251, 87, 251, 66]","[1697105186686, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190680, 1697105190931, 1697105190997]"
1386,781,11,[],200,EleutherAI/gpt-neox-20b,128,1,5007.0,1.0,1,H100,1697105195619,1697105200626.0,120,335.0,10.0,"[5, 3748, 224, 231, 129, 150, 140, 81, 79, 220]","[1697105195624, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626]"
1387,502,10,[],200,EleutherAI/gpt-neox-20b,128,1,2221.0,1.0,1,H100,1697105193171,1697105195392.0,120,19.0,1.0,"[4, 2217]","[1697105193175, 1697105195392]"
1388,859,11,[],200,EleutherAI/gpt-neox-20b,128,1,2554.0,1.0,1,H100,1697105195393,1697105197947.0,120,23.0,1.0,"[12, 2542]","[1697105195405, 1697105197947]"
1389,289,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105197947,1697105201998.0,120,,,"[5, 2970, 80, 292, 160, 212]","[1697105197952, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1390,647,13,[],200,EleutherAI/gpt-neox-20b,128,1,4080.0,1.0,1,H100,1697105202002,1697105206082.0,120,83.0,20.0,"[17, 1699, 88, 88, 87, 269, 87, 87, 83, 415, 93, 88, 88, 69, 87, 86, 389, 91, 85, 84]","[1697105202019, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
1391,254,6,[],200,EleutherAI/gpt-neox-20b,128,1,2762.0,1.0,1,H100,1697105177249,1697105180011.0,120,58.0,1.0,"[25, 2736]","[1697105177274, 1697105180010]"
1392,608,7,[],200,EleutherAI/gpt-neox-20b,128,1,4891.0,1.0,1,H100,1697105180011,1697105184902.0,120,96.0,20.0,"[17, 2266, 89, 83, 384, 89, 88, 190, 87, 78, 373, 86, 84, 78, 384, 83, 79, 78, 59, 215]","[1697105180028, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183755, 1697105183841, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901]"
1393,248,5,[],200,EleutherAI/gpt-neox-20b,128,1,4422.0,1.0,1,H100,1697105173685,1697105178107.0,120,182.0,17.0,"[37, 1900, 99, 91, 89, 70, 87, 69, 68, 69, 760, 81, 80, 63, 674, 94, 91]","[1697105173722, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175971, 1697105176058, 1697105176127, 1697105176195, 1697105176264, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107]"
1394,73,2,[],200,EleutherAI/gpt-neox-20b,128,1,2153.0,1.0,1,H100,1697105165820,1697105167973.0,120,9.0,1.0,"[17, 2135]","[1697105165837, 1697105167972]"
1395,690,8,[],200,EleutherAI/gpt-neox-20b,128,1,2144.0,1.0,1,H100,1697105185474,1697105187618.0,120,39.0,1.0,"[4, 2140]","[1697105185478, 1697105187618]"
1396,335,16,[],200,EleutherAI/gpt-neox-20b,128,1,12424.0,1.0,1,H100,1697105205016,1697105217440.0,120,58.0,62.0,"[4, 1794, 89, 89, 86, 81, 79, 60, 61, 618, 86, 82, 83, 64, 434, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 82, 428, 168, 77, 456, 89, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 84, 65, 76, 652, 85, 355, 91, 83, 511, 89, 66, 84, 246, 85, 65, 386]","[1697105205020, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214501, 1697105214566, 1697105214642, 1697105215294, 1697105215379, 1697105215734, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216574, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440]"
1397,576,6,[],200,EleutherAI/gpt-neox-20b,128,1,2334.0,1.0,1,H100,1697105178109,1697105180443.0,120,14.0,1.0,"[12, 2322]","[1697105178121, 1697105180443]"
1398,120,9,[],200,EleutherAI/gpt-neox-20b,128,1,1993.0,1.0,1,H100,1697105187619,1697105189612.0,120,17.0,1.0,"[8, 1985]","[1697105187627, 1697105189612]"
1399,7,7,[],200,EleutherAI/gpt-neox-20b,128,1,3559.0,1.0,1,H100,1697105180444,1697105184003.0,120,345.0,11.0,"[4, 2402, 89, 88, 190, 87, 78, 372, 86, 85, 78]","[1697105180448, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003]"
1400,456,10,[],200,EleutherAI/gpt-neox-20b,128,1,5204.0,1.0,1,H100,1697105189613,1697105194817.0,120,90.0,20.0,"[5, 2786, 76, 286, 87, 83, 234, 82, 62, 305, 87, 189, 84, 63, 81, 266, 64, 84, 199, 81]","[1697105189618, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193619, 1697105193706, 1697105193895, 1697105193979, 1697105194042, 1697105194123, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194817]"
1401,604,8,[],200,EleutherAI/gpt-neox-20b,128,1,2869.0,1.0,1,H100,1697105184471,1697105187340.0,120,161.0,4.0,"[5, 2697, 83, 84]","[1697105184476, 1697105187173, 1697105187256, 1697105187340]"
1402,123,9,[],200,EleutherAI/gpt-neox-20b,128,1,2271.0,1.0,1,H100,1697105187341,1697105189612.0,120,14.0,1.0,"[5, 2266]","[1697105187346, 1697105189612]"
1403,813,11,[],200,EleutherAI/gpt-neox-20b,128,1,6636.0,1.0,1,H100,1697105194818,1697105201454.0,120,85.0,20.0,"[8, 3207, 211, 117, 63, 265, 273, 410, 224, 230, 130, 150, 141, 80, 79, 220, 296, 80, 292, 160]","[1697105194826, 1697105198033, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199826, 1697105199956, 1697105200106, 1697105200247, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454]"
1404,478,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105189613,1697105201999.0,120,,,"[9, 3144, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 80, 266, 64, 84, 199, 81, 78, 260, 326, 87, 116, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 326, 212, 117, 63, 265, 273, 410, 224, 230, 130, 150, 140, 81, 79, 219, 297, 80, 292, 160, 212]","[1697105189622, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194123, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194817, 1697105194895, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199826, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200625, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1405,191,14,[],200,EleutherAI/gpt-neox-20b,128,1,5187.0,1.0,1,H100,1697105204251,1697105209438.0,120,85.0,20.0,"[5, 2557, 90, 89, 86, 81, 79, 60, 61, 618, 86, 83, 82, 64, 434, 87, 84, 79, 78, 384]","[1697105204256, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209054, 1697105209438]"
1406,524,16,[],200,EleutherAI/gpt-neox-20b,128,1,8128.0,1.0,1,H100,1697105218449,1697105226577.0,120,100.0,30.0,"[20, 3496, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 84, 82, 351, 91, 70, 88, 87, 68, 579, 81, 78, 75, 73, 706, 91, 84, 66, 84]","[1697105218469, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223823, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225320, 1697105225398, 1697105225473, 1697105225546, 1697105226252, 1697105226343, 1697105226427, 1697105226493, 1697105226577]"
1407,445,7,[],200,EleutherAI/gpt-neox-20b,128,1,2885.0,1.0,1,H100,1697105189163,1697105192048.0,120,457.0,2.0,"[5, 2879]","[1697105189168, 1697105192047]"
1408,276,6,[],200,EleutherAI/gpt-neox-20b,128,1,3876.0,1.0,1,H100,1697105175623,1697105179499.0,120,732.0,13.0,"[9, 2290, 94, 91, 88, 67, 86, 469, 90, 66, 88, 81, 357]","[1697105175632, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178817, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179499]"
1409,97,18,[],200,EleutherAI/gpt-neox-20b,128,1,5254.0,1.0,1,H100,1697105220998,1697105226252.0,120,6.0,20.0,"[170, 2235, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 580, 81, 78, 74, 73, 706]","[1697105221168, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225240, 1697105225321, 1697105225399, 1697105225473, 1697105225546, 1697105226252]"
1410,748,18,[],200,EleutherAI/gpt-neox-20b,128,1,4342.0,1.0,1,H100,1697105211484,1697105215826.0,120,182.0,14.0,"[20, 2326, 94, 90, 89, 68, 246, 85, 64, 76, 653, 84, 356, 91]","[1697105211504, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642, 1697105215295, 1697105215379, 1697105215735, 1697105215826]"
1411,25,2,[],200,EleutherAI/gpt-neox-20b,128,1,2744.0,1.0,1,H100,1697105165820,1697105168564.0,120,12.0,1.0,"[9, 2735]","[1697105165829, 1697105168564]"
1412,584,19,[],200,EleutherAI/gpt-neox-20b,128,1,1454.0,1.0,1,H100,1697105226254,1697105227708.0,120,10.0,1.0,"[16, 1438]","[1697105226270, 1697105227708]"
1413,456,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226253,1697105228773.0,120,,,[9],[1697105226262]
1414,817,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228774,1697105230475.0,120,,,[12],[1697105228786]
1415,242,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230477,1697105232145.0,120,,,[41],[1697105230518]
1416,573,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233609.0,120,,,[24],[1697105232174]
1417,1,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233610,1697105234919.0,120,,,[72],[1697105233682]
1418,12,20,[],200,EleutherAI/gpt-neox-20b,128,1,1042.0,1.0,1,H100,1697105227709,1697105228751.0,120,11.0,1.0,"[17, 1025]","[1697105227726, 1697105228751]"
1419,383,3,[],200,EleutherAI/gpt-neox-20b,128,1,2643.0,1.0,1,H100,1697105168565,1697105171208.0,120,15.0,1.0,"[5, 2638]","[1697105168570, 1697105171208]"
1420,464,12,[],200,EleutherAI/gpt-neox-20b,128,1,2420.0,1.0,1,H100,1697105217617,1697105220037.0,120,12.0,1.0,"[17, 2403]","[1697105217634, 1697105220037]"
1421,359,24,[],200,EleutherAI/gpt-neox-20b,128,1,1834.0,1.0,1,H100,1697105234922,1697105236756.0,120,10.0,1.0,"[174, 1660]","[1697105235096, 1697105236756]"
1422,634,7,[],200,EleutherAI/gpt-neox-20b,128,1,1572.0,1.0,1,H100,1697105179500,1697105181072.0,120,13.0,1.0,"[8, 1564]","[1697105179508, 1697105181072]"
1423,63,8,[],200,EleutherAI/gpt-neox-20b,128,1,2055.0,1.0,1,H100,1697105181073,1697105183128.0,120,39.0,1.0,"[9, 2046]","[1697105181082, 1697105183128]"
1424,708,4,[],200,EleutherAI/gpt-neox-20b,128,1,1611.0,1.0,1,H100,1697105171210,1697105172821.0,120,140.0,1.0,"[37, 1573]","[1697105171247, 1697105172820]"
1425,414,9,[],200,EleutherAI/gpt-neox-20b,128,1,5577.0,1.0,1,H100,1697105183129,1697105188706.0,120,87.0,20.0,"[4, 2265, 74, 537, 88, 83, 409, 87, 80, 77, 60, 280, 83, 83, 83, 376, 89, 561, 94, 164]","[1697105183133, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186180, 1697105186589, 1697105186676, 1697105186756, 1697105186833, 1697105186893, 1697105187173, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706]"
1426,139,5,[],200,EleutherAI/gpt-neox-20b,128,1,5100.0,1.0,1,H100,1697105172822,1697105177922.0,120,39.0,21.0,"[11, 1847, 93, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69, 759, 82, 80, 63, 674]","[1697105172833, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177023, 1697105177105, 1697105177185, 1697105177248, 1697105177922]"
1427,718,25,[],200,EleutherAI/gpt-neox-20b,128,1,1628.0,1.0,1,H100,1697105236757,1697105238385.0,120,13.0,1.0,"[32, 1595]","[1697105236789, 1697105238384]"
1428,118,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238386,1697105240331.0,120,,,[8],[1697105238394]
1429,475,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241994.0,120,,,[242],[1697105240576]
1430,371,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228752,1697105230475.0,120,,,[20],[1697105228772]
1431,173,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105215827,1697105220994.0,120,,,"[8, 3059, 81, 59, 366, 87, 77, 259, 62, 234, 79, 229, 81, 198]","[1697105215835, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219487, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
1432,834,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243753.0,120,,,[74],[1697105242075]
1433,819,13,[],200,EleutherAI/gpt-neox-20b,128,1,1865.0,1.0,1,H100,1697105220038,1697105221903.0,120,13.0,1.0,"[12, 1853]","[1697105220050, 1697105221903]"
1434,761,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105215910,1697105220994.0,120,,,"[12, 2972, 81, 59, 366, 89, 75, 259, 62, 234, 79, 229, 81, 198]","[1697105215922, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
1435,247,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105221906,1697105228772.0,120,,,"[34, 2317, 90, 70, 88, 87, 68, 579, 82, 77, 75, 74, 706, 90, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105221940, 1697105224257, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225547, 1697105226253, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
1436,707,22,[],200,EleutherAI/gpt-neox-20b,128,1,828.0,1.0,1,H100,1697105230478,1697105231306.0,120,8.0,1.0,"[36, 792]","[1697105230514, 1697105231306]"
1437,135,23,[],200,EleutherAI/gpt-neox-20b,128,1,1749.0,1.0,1,H100,1697105231307,1697105233056.0,120,52.0,2.0,"[5, 1744]","[1697105231312, 1697105233056]"
1438,251,15,[],200,EleutherAI/gpt-neox-20b,128,1,2836.0,1.0,1,H100,1697105216905,1697105219741.0,120,31.0,1.0,"[13, 2823]","[1697105216918, 1697105219741]"
1439,495,24,[],200,EleutherAI/gpt-neox-20b,128,1,1825.0,1.0,1,H100,1697105233057,1697105234882.0,120,13.0,1.0,"[5, 1820]","[1697105233062, 1697105234882]"
1440,605,16,[],200,EleutherAI/gpt-neox-20b,128,1,2161.0,1.0,1,H100,1697105219742,1697105221903.0,120,8.0,1.0,"[8, 2153]","[1697105219750, 1697105221903]"
1441,38,17,[],200,EleutherAI/gpt-neox-20b,128,1,4349.0,1.0,1,H100,1697105221904,1697105226253.0,120,88.0,20.0,"[8, 1491, 71, 92, 87, 87, 84, 81, 351, 91, 70, 88, 87, 68, 580, 81, 78, 74, 74, 705]","[1697105221912, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223740, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225240, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226252]"
1442,536,20,[],200,EleutherAI/gpt-neox-20b,128,1,4243.0,1.0,1,H100,1697105220996,1697105225239.0,120,83.0,20.0,"[32, 1639, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579]","[1697105221028, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239]"
1443,849,25,[],200,EleutherAI/gpt-neox-20b,128,1,1872.0,1.0,1,H100,1697105234884,1697105236756.0,120,10.0,1.0,"[36, 1836]","[1697105234920, 1697105236756]"
1444,274,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236757,1697105238409.0,120,,,[16],[1697105236773]
1445,604,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238412,1697105240331.0,120,,,[191],[1697105238603]
1446,773,10,[],200,EleutherAI/gpt-neox-20b,128,1,5417.0,1.0,1,H100,1697105188707,1697105194124.0,120,90.0,20.0,"[13, 2797, 165, 84, 281, 82, 275, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81]","[1697105188720, 1697105191517, 1697105191682, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124]"
1447,191,22,[],200,EleutherAI/gpt-neox-20b,128,1,4243.0,1.0,1,H100,1697105220996,1697105225239.0,120,85.0,20.0,"[28, 1643, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579]","[1697105221024, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239]"
1448,366,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226253,1697105228773.0,120,,,[13],[1697105226266]
1449,729,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230476.0,120,,,[116],[1697105228897]
1450,792,6,[],200,EleutherAI/gpt-neox-20b,128,1,2091.0,1.0,1,H100,1697105183218,1697105185309.0,120,11.0,1.0,"[12, 2079]","[1697105183230, 1697105185309]"
1451,710,23,[],200,EleutherAI/gpt-neox-20b,128,1,1854.0,1.0,1,H100,1697105238412,1697105240266.0,120,14.0,1.0,"[175, 1678]","[1697105238587, 1697105240265]"
1452,114,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240267,1697105241994.0,120,,,[28],[1697105240295]
1453,469,25,[],200,EleutherAI/gpt-neox-20b,128,1,1553.0,1.0,1,H100,1697105242000,1697105243553.0,120,17.0,1.0,"[19, 1534]","[1697105242019, 1697105243553]"
1454,827,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243554,1697105245502.0,120,,,[5],[1697105243559]
1455,549,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225240,1697105228774.0,120,,,"[5, 1818, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105225245, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
1456,220,7,[],200,EleutherAI/gpt-neox-20b,128,1,2488.0,1.0,1,H100,1697105185310,1697105187798.0,120,67.0,2.0,"[4, 2484]","[1697105185314, 1697105187798]"
1457,264,11,[],200,EleutherAI/gpt-neox-20b,128,1,4080.0,1.0,1,H100,1697105202002,1697105206082.0,120,86.0,20.0,"[29, 1687, 88, 88, 87, 269, 87, 87, 83, 415, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84]","[1697105202031, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
1458,252,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105247243.0,120,,,[198],[1697105245704]
1459,864,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225240,1697105228774.0,120,,,"[5, 1819, 90, 89, 85, 583, 93, 84, 84, 83]","[1697105225245, 1697105227064, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
1460,287,8,[],200,EleutherAI/gpt-neox-20b,128,1,1925.0,1.0,1,H100,1697105183384,1697105185309.0,120,10.0,1.0,"[4, 1921]","[1697105183388, 1697105185309]"
1461,611,28,[],200,EleutherAI/gpt-neox-20b,128,1,2426.0,1.0,1,H100,1697105247255,1697105249681.0,120,14.0,1.0,"[268, 2158]","[1697105247523, 1697105249681]"
1462,616,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105185312,1697105201998.0,120,,,"[18, 3118, 94, 164, 81, 375, 87, 85, 481, 90, 272, 166, 250, 88, 250, 66, 87, 67, 366, 162, 87, 281, 82, 275, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 80, 266, 63, 85, 199, 80, 78, 261, 326, 87, 116, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 326, 212, 117, 63, 265, 273, 410, 224, 230, 130, 150, 140, 80, 80, 219, 297, 80, 292, 160, 212]","[1697105185330, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190343, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191151, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194123, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199826, 1697105199956, 1697105200106, 1697105200246, 1697105200326, 1697105200406, 1697105200625, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1463,694,16,[],200,EleutherAI/gpt-neox-20b,128,1,5004.0,1.0,1,H100,1697105208064,1697105213068.0,120,161.0,13.0,"[8, 3242, 168, 77, 456, 89, 80, 79, 75, 72, 481, 88, 89]","[1697105208072, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068]"
1464,122,8,[],200,EleutherAI/gpt-neox-20b,128,1,5127.0,1.0,1,H100,1697105182760,1697105187887.0,120,88.0,20.0,"[5, 2136, 77, 58, 362, 74, 537, 87, 81, 412, 88, 79, 77, 59, 280, 84, 83, 83, 376, 89]","[1697105182765, 1697105184901, 1697105184978, 1697105185036, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887]"
1465,413,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105212339,1697105220994.0,120,,,"[4, 2951, 85, 356, 90, 84, 510, 89, 66, 84, 247, 84, 66, 385, 89, 87, 406, 87, 82, 256, 79, 368, 81, 59, 366, 88, 76, 259, 62, 234, 79, 229, 81, 198]","[1697105212343, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215909, 1697105216419, 1697105216508, 1697105216574, 1697105216658, 1697105216905, 1697105216989, 1697105217055, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219488, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
1466,630,8,[],200,EleutherAI/gpt-neox-20b,128,1,2148.0,1.0,1,H100,1697105186098,1697105188246.0,120,6.0,1.0,"[8, 2140]","[1697105186106, 1697105188246]"
1467,63,9,[],200,EleutherAI/gpt-neox-20b,128,1,1750.0,1.0,1,H100,1697105188247,1697105189997.0,120,39.0,1.0,"[5, 1745]","[1697105188252, 1697105189997]"
1468,589,9,[],200,EleutherAI/gpt-neox-20b,128,1,5362.0,1.0,1,H100,1697105190998,1697105196360.0,120,92.0,20.0,"[5, 2617, 86, 189, 84, 64, 81, 265, 64, 84, 199, 80, 78, 261, 326, 88, 115, 83, 175, 418]","[1697105191003, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195481, 1697105195569, 1697105195684, 1697105195767, 1697105195942, 1697105196360]"
1469,883,9,[],200,EleutherAI/gpt-neox-20b,128,1,4862.0,1.0,1,H100,1697105195685,1697105200547.0,120,563.0,1.0,"[4, 4857]","[1697105195689, 1697105200546]"
1470,353,15,[],200,EleutherAI/gpt-neox-20b,128,1,2832.0,1.0,1,H100,1697105204160,1697105206992.0,120,52.0,4.0,"[5, 2649, 89, 89]","[1697105204165, 1697105206814, 1697105206903, 1697105206992]"
1471,315,10,[],200,EleutherAI/gpt-neox-20b,128,1,4713.0,1.0,1,H100,1697105200547,1697105205260.0,120,335.0,14.0,"[5, 3166, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69]","[1697105200552, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260]"
1472,711,16,[],200,EleutherAI/gpt-neox-20b,128,1,3140.0,1.0,1,H100,1697105206993,1697105210133.0,120,457.0,4.0,"[5, 2440, 77, 618]","[1697105206998, 1697105209438, 1697105209515, 1697105210133]"
1473,144,17,[],200,EleutherAI/gpt-neox-20b,128,1,5775.0,1.0,1,H100,1697105210134,1697105215909.0,120,96.0,20.0,"[5, 2752, 88, 89, 82, 75, 606, 93, 90, 89, 68, 246, 85, 65, 75, 652, 85, 356, 90, 83]","[1697105210139, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213831, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908]"
1474,421,10,[],200,EleutherAI/gpt-neox-20b,128,1,5158.0,1.0,1,H100,1697105189998,1697105195156.0,120,85.0,20.0,"[5, 2763, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81, 265, 63, 85, 199, 81, 78, 261]","[1697105190003, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194817, 1697105194895, 1697105195156]"
1475,186,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105232146.0,120,,,[57],[1697105230535]
1476,549,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105216905,1697105220995.0,120,,,"[13, 2906, 62, 233, 79, 229, 81, 198]","[1697105216918, 1697105219824, 1697105219886, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
1477,537,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232152,1697105234225.0,120,,,[147],[1697105232299]
1478,502,18,[],200,EleutherAI/gpt-neox-20b,128,1,1728.0,1.0,1,H100,1697105206814,1697105208542.0,120,19.0,1.0,"[5, 1723]","[1697105206819, 1697105208542]"
1479,859,19,[],200,EleutherAI/gpt-neox-20b,128,1,2585.0,1.0,1,H100,1697105208543,1697105211128.0,120,23.0,1.0,"[12, 2573]","[1697105208555, 1697105211128]"
1480,145,6,[],200,EleutherAI/gpt-neox-20b,128,1,3799.0,1.0,1,H100,1697105182384,1697105186183.0,120,161.0,9.0,"[4, 2513, 77, 58, 362, 74, 537, 87, 86]","[1697105182388, 1697105184901, 1697105184978, 1697105185036, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186182]"
1481,442,7,[],200,EleutherAI/gpt-neox-20b,128,1,6029.0,1.0,1,H100,1697105183305,1697105189334.0,120,39.0,22.0,"[12, 2692, 88, 86, 405, 89, 78, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375, 87, 85]","[1697105183317, 1697105186009, 1697105186097, 1697105186183, 1697105186588, 1697105186677, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334]"
1482,473,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105216235,1697105220995.0,120,,,"[9, 3156, 89, 75, 259, 62, 234, 79, 229, 81, 197]","[1697105216244, 1697105219400, 1697105219489, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220705]"
1483,376,20,[],200,EleutherAI/gpt-neox-20b,128,1,4780.0,1.0,1,H100,1697105211129,1697105215909.0,120,87.0,20.0,"[9, 1753, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 64, 76, 652, 85, 356, 90, 84]","[1697105211138, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215909]"
1484,909,16,[],200,EleutherAI/gpt-neox-20b,128,1,4241.0,1.0,1,H100,1697105220998,1697105225239.0,120,86.0,20.0,"[22, 1647, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579]","[1697105221020, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239]"
1485,401,3,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105167973,1697105172155.0,120,,,"[5, 3785]","[1697105167978, 1697105171763]"
1486,759,4,[],200,EleutherAI/gpt-neox-20b,128,1,4107.0,1.0,1,H100,1697105172158,1697105176265.0,120,92.0,20.0,"[123, 1503, 80, 77, 72, 668, 93, 88, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 70]","[1697105172281, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174681, 1697105174774, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176265]"
1487,807,18,[],200,EleutherAI/gpt-neox-20b,128,1,4243.0,1.0,1,H100,1697105220996,1697105225239.0,120,90.0,20.0,"[44, 1627, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579]","[1697105221040, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239]"
1488,675,2,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170015,1697105172154.0,120,,,"[30, 1718]","[1697105170045, 1697105171763]"
1489,908,8,[],200,EleutherAI/gpt-neox-20b,128,1,9580.0,1.0,1,H100,1697105182467,1697105192047.0,120,6.0,50.0,"[14, 1274, 86, 84, 79, 383, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 88, 82, 410, 88, 79, 77, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 162, 87, 281]","[1697105182481, 1697105183755, 1697105183841, 1697105183925, 1697105184004, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186179, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047]"
1490,76,3,[],200,EleutherAI/gpt-neox-20b,128,1,3466.0,1.0,1,H100,1697105172156,1697105175622.0,120,364.0,12.0,"[28, 1600, 80, 77, 72, 668, 92, 89, 68, 86, 84, 522]","[1697105172184, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622]"
1491,233,19,[],200,EleutherAI/gpt-neox-20b,128,1,1714.0,1.0,1,H100,1697105225240,1697105226954.0,120,6.0,1.0,"[13, 1701]","[1697105225253, 1697105226954]"
1492,337,17,[],200,EleutherAI/gpt-neox-20b,128,1,1714.0,1.0,1,H100,1697105225240,1697105226954.0,120,12.0,1.0,"[13, 1700]","[1697105225253, 1697105226953]"
1493,426,4,[],200,EleutherAI/gpt-neox-20b,128,1,7681.0,1.0,1,H100,1697105175623,1697105183304.0,120,79.0,36.0,"[5, 2294, 94, 91, 88, 67, 86, 469, 90, 67, 87, 81, 356, 88, 85, 66, 365, 85, 66, 280, 79, 75, 488, 81, 80, 387, 87, 75, 409, 89, 83, 383, 90, 88, 189, 88]","[1697105175628, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181885, 1697105182294, 1697105182383, 1697105182466, 1697105182849, 1697105182939, 1697105183027, 1697105183216, 1697105183304]"
1494,734,21,[],200,EleutherAI/gpt-neox-20b,128,1,3579.0,1.0,1,H100,1697105215910,1697105219489.0,120,100.0,6.0,"[4, 2980, 81, 59, 366, 89]","[1697105215914, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489]"
1495,162,22,[],200,EleutherAI/gpt-neox-20b,128,1,5169.0,1.0,1,H100,1697105219491,1697105224660.0,120,90.0,20.0,"[6, 2468, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105219497, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
1496,590,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226955,1697105228774.0,120,,,[20],[1697105226975]
1497,708,6,[],200,EleutherAI/gpt-neox-20b,128,1,2215.0,1.0,1,H100,1697105180544,1697105182759.0,120,140.0,1.0,"[5, 2210]","[1697105180549, 1697105182759]"
1498,136,7,[],200,EleutherAI/gpt-neox-20b,128,1,2548.0,1.0,1,H100,1697105182761,1697105185309.0,120,31.0,1.0,"[16, 2532]","[1697105182777, 1697105185309]"
1499,924,12,[],200,EleutherAI/gpt-neox-20b,128,1,1435.0,1.0,1,H100,1697105212892,1697105214327.0,120,9.0,1.0,"[5, 1430]","[1697105212897, 1697105214327]"
1500,323,13,[],200,EleutherAI/gpt-neox-20b,128,1,5072.0,1.0,1,H100,1697105214328,1697105219400.0,120,84.0,20.0,"[4, 2087, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 82, 257, 78, 368, 81, 59, 366]","[1697105214332, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218448, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400]"
1501,587,8,[],200,EleutherAI/gpt-neox-20b,128,1,2308.0,1.0,1,H100,1697105185310,1697105187618.0,120,13.0,1.0,"[16, 2292]","[1697105185326, 1697105187618]"
1502,263,29,[],200,EleutherAI/gpt-neox-20b,128,1,1672.0,1.0,1,H100,1697105243755,1697105245427.0,120,15.0,1.0,"[29, 1643]","[1697105243784, 1697105245427]"
1503,631,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105220998,1697105228774.0,120,,,"[10, 1659, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579, 82, 77, 75, 73, 706, 91, 85, 65, 84, 486, 91, 89, 85, 582, 94, 84, 84, 83]","[1697105221008, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225546, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227910, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
1504,18,9,[],200,EleutherAI/gpt-neox-20b,128,1,1993.0,1.0,1,H100,1697105187619,1697105189612.0,120,15.0,1.0,"[12, 1981]","[1697105187631, 1697105189612]"
1505,622,30,[],200,EleutherAI/gpt-neox-20b,128,1,768.0,1.0,1,H100,1697105245428,1697105246196.0,120,20.0,1.0,"[21, 747]","[1697105245449, 1697105246196]"
1506,375,10,[],200,EleutherAI/gpt-neox-20b,128,1,5123.0,1.0,1,H100,1697105189613,1697105194736.0,120,874.0,17.0,"[5, 3148, 87, 83, 234, 82, 62, 305, 87, 189, 84, 64, 80, 266, 64, 84, 199]","[1697105189618, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193619, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194123, 1697105194389, 1697105194453, 1697105194537, 1697105194736]"
1507,22,31,[],200,EleutherAI/gpt-neox-20b,128,1,1812.0,1.0,1,H100,1697105246197,1697105248009.0,120,16.0,1.0,"[25, 1787]","[1697105246222, 1697105248009]"
1508,547,3,[],200,EleutherAI/gpt-neox-20b,128,1,1781.0,1.0,1,H100,1697105162735,1697105164516.0,120,12.0,1.0,"[8, 1773]","[1697105162743, 1697105164516]"
1509,864,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228782,1697105230476.0,120,,,[232],[1697105229014]
1510,878,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105164517,1697105170013.0,120,,,"[4, 2299, 271, 116, 196, 133, 75, 460, 227, 76, 273, 231, 127, 144, 219, 181, 155]","[1697105164521, 1697105166820, 1697105167091, 1697105167207, 1697105167403, 1697105167536, 1697105167611, 1697105168071, 1697105168298, 1697105168374, 1697105168647, 1697105168878, 1697105169005, 1697105169149, 1697105169368, 1697105169549, 1697105169704]"
1511,729,11,[],200,EleutherAI/gpt-neox-20b,128,1,3296.0,1.0,1,H100,1697105194737,1697105198033.0,120,874.0,2.0,"[4, 3292]","[1697105194741, 1697105198033]"
1512,903,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230476.0,120,,,[229],[1697105229010]
1513,294,22,[],200,EleutherAI/gpt-neox-20b,128,1,2577.0,1.0,1,H100,1697105230479,1697105233056.0,120,9.0,2.0,"[226, 2351]","[1697105230705, 1697105233056]"
1514,648,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233057,1697105234920.0,120,,,[4],[1697105233061]
1515,81,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105238408.0,120,,,[178],[1697105235100]
1516,411,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238411,1697105240330.0,120,,,[88],[1697105238499]
1517,768,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241994.0,120,,,[150],[1697105240484]
1518,156,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105198034,1697105201998.0,120,,,"[8, 3252, 160, 213]","[1697105198042, 1697105201294, 1697105201454, 1697105201667]"
1519,197,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243753.0,120,,,[94],[1697105242095]
1520,154,20,[],200,EleutherAI/gpt-neox-20b,128,1,1647.0,1.0,1,H100,1697105230478,1697105232125.0,120,13.0,1.0,"[56, 1591]","[1697105230534, 1697105232125]"
1521,682,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105219401,1697105228772.0,120,,,"[13, 2551, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579, 81, 78, 75, 73, 706, 91, 84, 66, 84, 486, 91, 89, 85, 582, 94, 84, 84, 83]","[1697105219414, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225320, 1697105225398, 1697105225473, 1697105225546, 1697105226252, 1697105226343, 1697105226427, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227910, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
1522,557,28,[],200,EleutherAI/gpt-neox-20b,128,1,1671.0,1.0,1,H100,1697105243756,1697105245427.0,120,31.0,1.0,"[36, 1635]","[1697105243792, 1697105245427]"
1523,512,21,[],200,EleutherAI/gpt-neox-20b,128,1,869.0,1.0,1,H100,1697105232126,1697105232995.0,120,11.0,1.0,"[9, 860]","[1697105232135, 1697105232995]"
1524,914,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245428,1697105247243.0,120,,,[33],[1697105245461]
1525,660,8,[],200,EleutherAI/gpt-neox-20b,128,1,6076.0,1.0,1,H100,1697105181811,1697105187887.0,120,732.0,25.0,"[12, 2564, 83, 79, 78, 59, 215, 77, 58, 362, 74, 537, 88, 83, 409, 88, 79, 77, 59, 280, 84, 83, 83, 376, 89]","[1697105181823, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185036, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186180, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887]"
1526,833,10,[],200,EleutherAI/gpt-neox-20b,128,1,4343.0,1.0,1,H100,1697105187423,1697105191766.0,120,563.0,8.0,"[5, 3503, 66, 87, 67, 366, 162, 87]","[1697105187428, 1697105190931, 1697105190997, 1697105191084, 1697105191151, 1697105191517, 1697105191679, 1697105191766]"
1527,871,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232996,1697105234225.0,120,,,[4],[1697105233000]
1528,271,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234227,1697105236780.0,120,,,[64],[1697105234291]
1529,630,24,[],200,EleutherAI/gpt-neox-20b,128,1,1602.0,1.0,1,H100,1697105236783,1697105238385.0,120,6.0,1.0,"[18, 1584]","[1697105236801, 1697105238385]"
1530,261,11,[],200,EleutherAI/gpt-neox-20b,128,1,3389.0,1.0,1,H100,1697105191767,1697105195156.0,120,874.0,2.0,"[5, 3384]","[1697105191772, 1697105195156]"
1531,619,12,[],200,EleutherAI/gpt-neox-20b,128,1,2311.0,1.0,1,H100,1697105195157,1697105197468.0,120,10.0,1.0,"[20, 2291]","[1697105195177, 1697105197468]"
1532,21,13,[],200,EleutherAI/gpt-neox-20b,128,1,3078.0,1.0,1,H100,1697105197469,1697105200547.0,120,15.0,1.0,"[5, 3072]","[1697105197474, 1697105200546]"
1533,311,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247248,1697105248696.0,120,,,[146],[1697105247394]
1534,541,10,[],200,EleutherAI/gpt-neox-20b,128,1,5975.0,1.0,1,H100,1697105200107,1697105206082.0,120,90.0,20.0,"[5, 3606, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84]","[1697105200112, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
1535,58,25,[],200,EleutherAI/gpt-neox-20b,128,1,1879.0,1.0,1,H100,1697105238386,1697105240265.0,120,15.0,1.0,"[28, 1851]","[1697105238414, 1697105240265]"
1536,672,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105252036.0,120,,,[118],[1697105248817]
1537,101,32,[],200,EleutherAI/gpt-neox-20b,128,1,1640.0,1.0,1,H100,1697105252041,1697105253681.0,120,13.0,1.0,"[238, 1402]","[1697105252279, 1697105253681]"
1538,292,11,[],200,EleutherAI/gpt-neox-20b,128,1,3450.0,1.0,1,H100,1697105195157,1697105198607.0,120,286.0,1.0,"[4, 3446]","[1697105195161, 1697105198607]"
1539,461,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253685,1697105256010.0,120,,,"[21, 1352]","[1697105253706, 1697105255058]"
1540,416,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240267,1697105241993.0,120,,,[16],[1697105240283]
1541,649,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105198608,1697105201999.0,120,,,[5],[1697105198613]
1542,775,27,[],200,EleutherAI/gpt-neox-20b,128,1,1554.0,1.0,1,H100,1697105242000,1697105243554.0,120,17.0,1.0,"[35, 1519]","[1697105242035, 1697105243554]"
1543,83,13,[],200,EleutherAI/gpt-neox-20b,128,1,3344.0,1.0,1,H100,1697105202003,1697105205347.0,120,123.0,15.0,"[72, 1643, 88, 88, 87, 269, 87, 86, 84, 415, 93, 88, 89, 68, 87]","[1697105202075, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347]"
1544,291,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243555,1697105245502.0,120,,,[12],[1697105243567]
1545,818,34,[],200,EleutherAI/gpt-neox-20b,128,1,2017.0,1.0,1,H100,1697105256013,1697105258030.0,120,13.0,1.0,"[60, 1957]","[1697105256073, 1697105258030]"
1546,334,35,[],200,EleutherAI/gpt-neox-20b,128,1,1741.0,1.0,1,H100,1697105258031,1697105259772.0,120,15.0,1.0,"[24, 1717]","[1697105258055, 1697105259772]"
1547,693,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105259773,1697105262306.0,120,,,[28],[1697105259801]
1548,498,5,[],200,EleutherAI/gpt-neox-20b,128,1,2216.0,1.0,1,H100,1697105180544,1697105182760.0,120,9.0,1.0,"[17, 2199]","[1697105180561, 1697105182760]"
1549,855,6,[],200,EleutherAI/gpt-neox-20b,128,1,5945.0,1.0,1,H100,1697105182761,1697105188706.0,120,83.0,20.0,"[20, 2617, 74, 537, 87, 82, 411, 88, 79, 77, 59, 281, 83, 83, 83, 376, 89, 561, 94, 164]","[1697105182781, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186178, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186892, 1697105187173, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706]"
1550,652,29,[],200,EleutherAI/gpt-neox-20b,128,1,1662.0,1.0,1,H100,1697105245506,1697105247168.0,120,14.0,1.0,"[266, 1396]","[1697105245772, 1697105247168]"
1551,79,30,[],200,EleutherAI/gpt-neox-20b,128,1,839.0,1.0,1,H100,1697105247170,1697105248009.0,120,12.0,1.0,"[28, 811]","[1697105247198, 1697105248009]"
1552,437,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248010,1697105250348.0,120,,,[25],[1697105248035]
1553,551,4,[],200,EleutherAI/gpt-neox-20b,128,1,5360.0,1.0,1,H100,1697105177106,1697105182466.0,120,90.0,20.0,"[4, 2388, 88, 85, 66, 365, 85, 66, 280, 79, 75, 489, 80, 80, 388, 86, 76, 408, 89, 83]","[1697105177110, 1697105179498, 1697105179586, 1697105179671, 1697105179737, 1697105180102, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181176, 1697105181256, 1697105181336, 1697105181724, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466]"
1554,291,10,[],200,EleutherAI/gpt-neox-20b,128,1,5341.0,1.0,1,H100,1697105192048,1697105197389.0,120,79.0,20.0,"[5, 2336, 64, 84, 199, 80, 79, 260, 326, 87, 116, 83, 176, 417, 282, 189, 259, 85, 62, 152]","[1697105192053, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194895, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195943, 1697105196360, 1697105196642, 1697105196831, 1697105197090, 1697105197175, 1697105197237, 1697105197389]"
1555,342,8,[],200,EleutherAI/gpt-neox-20b,128,1,4825.0,1.0,1,H100,1697105189070,1697105193895.0,120,364.0,14.0,"[5, 2972, 82, 275, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189]","[1697105189075, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895]"
1556,650,11,[],200,EleutherAI/gpt-neox-20b,128,1,3157.0,1.0,1,H100,1697105197390,1697105200547.0,120,13.0,1.0,"[8, 3148]","[1697105197398, 1697105200546]"
1557,701,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105193897,1697105201998.0,120,,,"[4, 2459, 282, 189, 259, 85, 62, 152, 158, 82, 77, 326, 212, 117, 63, 265, 273, 410, 225, 230, 129, 150, 140, 81, 79, 220, 296, 80, 292, 160, 212]","[1697105193901, 1697105196360, 1697105196642, 1697105196831, 1697105197090, 1697105197175, 1697105197237, 1697105197389, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199597, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1558,75,12,[],200,EleutherAI/gpt-neox-20b,128,1,5365.0,1.0,1,H100,1697105200548,1697105205913.0,120,345.0,18.0,"[8, 3162, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 389, 91]","[1697105200556, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913]"
1559,171,7,[],200,EleutherAI/gpt-neox-20b,128,1,1719.0,1.0,1,H100,1697105179738,1697105181457.0,120,6.0,1.0,"[20, 1698]","[1697105179758, 1697105181456]"
1560,575,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232149,1697105233609.0,120,,,[25],[1697105232174]
1561,754,10,[],200,EleutherAI/gpt-neox-20b,128,1,3697.0,1.0,1,H100,1697105188707,1697105192404.0,120,88.0,7.0,"[9, 2801, 162, 87, 281, 82, 275]","[1697105188716, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192404]"
1562,3,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233610,1697105234919.0,120,,,[40],[1697105233650]
1563,357,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236782.0,120,,,[94],[1697105235016]
1564,717,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236785,1697105240330.0,120,,,[225],[1697105237010]
1565,142,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241995.0,120,,,[69],[1697105240403]
1566,549,15,[],200,EleutherAI/gpt-neox-20b,128,1,5128.0,1.0,1,H100,1697105209439,1697105214567.0,120,93.0,20.0,"[16, 2561, 88, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 69, 245, 85, 65]","[1697105209455, 1697105212016, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214172, 1697105214417, 1697105214502, 1697105214567]"
1567,508,9,[],200,EleutherAI/gpt-neox-20b,128,1,5726.0,1.0,1,H100,1697105186678,1697105192404.0,120,86.0,20.0,"[4, 2481, 86, 85, 481, 90, 272, 165, 251, 87, 251, 66, 87, 66, 367, 166, 83, 281, 82, 275]","[1697105186682, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191683, 1697105191766, 1697105192047, 1697105192129, 1697105192404]"
1568,903,16,[],200,EleutherAI/gpt-neox-20b,128,1,3623.0,1.0,1,H100,1697105214568,1697105218191.0,120,244.0,7.0,"[8, 2864, 89, 87, 406, 88, 81]","[1697105214576, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218110, 1697105218191]"
1569,522,23,[],200,EleutherAI/gpt-neox-20b,128,1,1404.0,1.0,1,H100,1697105224662,1697105226066.0,120,20.0,1.0,"[13, 1390]","[1697105224675, 1697105226065]"
1570,333,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105218192,1697105220995.0,120,,,"[4, 2231, 81, 198]","[1697105218196, 1697105220427, 1697105220508, 1697105220706]"
1571,780,11,[],200,EleutherAI/gpt-neox-20b,128,1,6772.0,1.0,1,H100,1697105194895,1697105201667.0,120,85.0,20.0,"[5, 3344, 117, 63, 265, 273, 410, 224, 231, 129, 150, 141, 79, 80, 220, 296, 80, 292, 160, 212]","[1697105194900, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200247, 1697105200326, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1572,349,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105195393,1697105201998.0,120,,,"[4, 3292, 273, 410, 224, 231, 129, 150, 140, 81, 79, 220, 296, 80, 292, 160, 212]","[1697105195397, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1573,91,7,[],200,EleutherAI/gpt-neox-20b,128,1,2216.0,1.0,1,H100,1697105180544,1697105182760.0,120,23.0,1.0,"[25, 2191]","[1697105180569, 1697105182760]"
1574,441,8,[],200,EleutherAI/gpt-neox-20b,128,1,902.0,1.0,1,H100,1697105182761,1697105183663.0,120,6.0,1.0,"[20, 882]","[1697105182781, 1697105183663]"
1575,876,24,[],200,EleutherAI/gpt-neox-20b,128,1,1640.0,1.0,1,H100,1697105226068,1697105227708.0,120,11.0,1.0,"[11, 1629]","[1697105226079, 1697105227708]"
1576,801,9,[],200,EleutherAI/gpt-neox-20b,128,1,5499.0,1.0,1,H100,1697105183664,1697105189163.0,120,47.0,20.0,"[8, 2337, 88, 85, 407, 88, 78, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 376]","[1697105183672, 1697105186009, 1697105186097, 1697105186182, 1697105186589, 1697105186677, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189163]"
1577,36,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241994.0,120,,,[170],[1697105240504]
1578,279,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105227709,1697105232144.0,120,,,"[5, 2801, 990, 76, 74, 74, 74]","[1697105227714, 1697105230515, 1697105231505, 1697105231581, 1697105231655, 1697105231729, 1697105231803]"
1579,706,14,[],200,EleutherAI/gpt-neox-20b,128,1,4080.0,1.0,1,H100,1697105202002,1697105206082.0,120,86.0,20.0,"[6, 1710, 88, 88, 87, 269, 87, 87, 83, 415, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84]","[1697105202008, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
1580,890,4,[],200,EleutherAI/gpt-neox-20b,128,1,4267.0,1.0,1,H100,1697105176271,1697105180538.0,120,93.0,20.0,"[29, 1622, 95, 90, 88, 68, 86, 467, 91, 66, 88, 81, 356, 88, 85, 65, 366, 85, 66, 285]","[1697105176300, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178263, 1697105178349, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180538]"
1581,300,25,[],200,EleutherAI/gpt-neox-20b,128,1,2516.0,1.0,1,H100,1697105230478,1697105232994.0,120,9.0,1.0,"[195, 2321]","[1697105230673, 1697105232994]"
1582,658,26,[],200,EleutherAI/gpt-neox-20b,128,1,1886.0,1.0,1,H100,1697105232996,1697105234882.0,120,11.0,1.0,"[24, 1862]","[1697105233020, 1697105234882]"
1583,90,27,[],200,EleutherAI/gpt-neox-20b,128,1,1119.0,1.0,1,H100,1697105234883,1697105236002.0,120,19.0,1.0,"[17, 1102]","[1697105234900, 1697105236002]"
1584,382,7,[],200,EleutherAI/gpt-neox-20b,128,1,5491.0,1.0,1,H100,1697105178264,1697105183755.0,120,47.0,20.0,"[4, 2265, 79, 75, 488, 81, 80, 387, 87, 76, 408, 89, 83, 384, 89, 88, 190, 87, 78, 372]","[1697105178268, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754]"
1585,196,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269601,1697105270988.0,120,,,[87],[1697105269688]
1586,382,14,[],200,EleutherAI/gpt-neox-20b,128,1,5535.0,1.0,1,H100,1697105200547,1697105206082.0,120,47.0,20.0,"[9, 3162, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84]","[1697105200556, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
1587,555,45,[],200,EleutherAI/gpt-neox-20b,128,1,1759.0,1.0,1,H100,1697105270989,1697105272748.0,120,11.0,1.0,"[49, 1710]","[1697105271038, 1697105272748]"
1588,622,12,[],200,EleutherAI/gpt-neox-20b,128,1,1784.0,1.0,1,H100,1697105206084,1697105207868.0,120,20.0,1.0,"[49, 1734]","[1697105206133, 1697105207867]"
1589,909,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105272749,1697105275208.0,120,,,[13],[1697105272762]
1590,47,13,[],200,EleutherAI/gpt-neox-20b,128,1,5357.0,1.0,1,H100,1697105207868,1697105213225.0,120,90.0,20.0,"[9, 2257, 86, 82, 502, 82, 428, 168, 77, 457, 88, 80, 79, 75, 72, 481, 88, 89, 82, 75]","[1697105207877, 1697105210134, 1697105210220, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482, 1697105211559, 1697105212016, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225]"
1591,518,13,[],200,EleutherAI/gpt-neox-20b,128,1,1825.0,1.0,1,H100,1697105206717,1697105208542.0,120,23.0,1.0,"[35, 1790]","[1697105206752, 1697105208542]"
1592,463,14,[],200,EleutherAI/gpt-neox-20b,128,1,2484.0,1.0,1,H100,1697105209439,1697105211923.0,120,39.0,1.0,"[20, 2464]","[1697105209459, 1697105211923]"
1593,791,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105211924,1697105220994.0,120,,,"[13, 1894, 93, 90, 90, 67, 246, 85, 65, 75, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 82, 256, 79, 368, 81, 59, 366, 88, 76, 259, 62, 234, 79, 229, 81, 198]","[1697105211937, 1697105213831, 1697105213924, 1697105214014, 1697105214104, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219488, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
1594,302,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170016,1697105172155.0,120,,,[154],[1697105170170]
1595,16,11,[],200,EleutherAI/gpt-neox-20b,128,1,2353.0,1.0,1,H100,1697105200627,1697105202980.0,120,9.0,1.0,"[4, 2349]","[1697105200631, 1697105202980]"
1596,214,12,[],200,EleutherAI/gpt-neox-20b,128,1,5455.0,1.0,1,H100,1697105200627,1697105206082.0,120,52.0,20.0,"[4, 3087, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84]","[1697105200631, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
1597,340,12,[],200,EleutherAI/gpt-neox-20b,128,1,4378.0,1.0,1,H100,1697105202981,1697105207359.0,120,85.0,20.0,"[13, 1928, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84, 732, 89, 89, 86, 81, 79, 60, 61]","[1697105202994, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359]"
1598,861,9,[],200,EleutherAI/gpt-neox-20b,128,1,2093.0,1.0,1,H100,1697105178350,1697105180443.0,120,10.0,1.0,"[25, 2068]","[1697105178375, 1697105180443]"
1599,736,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105206085,1697105220994.0,120,,,"[84, 2557, 87, 84, 79, 78, 384, 77, 619, 85, 83, 502, 82, 429, 168, 76, 456, 89, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 64, 76, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 81, 257, 79, 368, 81, 59, 366, 84, 80, 259, 62, 234, 79, 228, 82, 197]","[1697105206169, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209054, 1697105209438, 1697105209515, 1697105210134, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211315, 1697105211483, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218190, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219484, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220426, 1697105220508, 1697105220705]"
1600,438,14,[],200,EleutherAI/gpt-neox-20b,128,1,1366.0,1.0,1,H100,1697105205348,1697105206714.0,120,9.0,1.0,"[5, 1361]","[1697105205353, 1697105206714]"
1601,475,9,[],200,EleutherAI/gpt-neox-20b,128,1,5427.0,1.0,1,H100,1697105187888,1697105193315.0,120,89.0,20.0,"[5, 2700, 88, 250, 66, 87, 67, 366, 162, 87, 281, 82, 276, 75, 286, 87, 83, 234, 82, 62]","[1697105187893, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191151, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192405, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314]"
1602,288,10,[],200,EleutherAI/gpt-neox-20b,128,1,4954.0,1.0,1,H100,1697105180444,1697105185398.0,120,93.0,20.0,"[4, 2402, 89, 88, 190, 87, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363]","[1697105180448, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398]"
1603,828,9,[],200,EleutherAI/gpt-neox-20b,128,1,3763.0,1.0,1,H100,1697105185399,1697105189162.0,120,182.0,6.0,"[13, 3036, 94, 164, 81, 375]","[1697105185412, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162]"
1604,723,8,[],200,EleutherAI/gpt-neox-20b,128,1,1624.0,1.0,1,H100,1697105202002,1697105203626.0,120,14.0,1.0,"[9, 1614]","[1697105202011, 1697105203625]"
1605,260,10,[],200,EleutherAI/gpt-neox-20b,128,1,5374.0,1.0,1,H100,1697105189163,1697105194537.0,120,86.0,20.0,"[9, 2875, 82, 275, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81, 265, 64, 84]","[1697105189172, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537]"
1606,63,8,[],200,EleutherAI/gpt-neox-20b,128,1,2770.0,1.0,1,H100,1697105189907,1697105192677.0,120,39.0,1.0,"[4, 2766]","[1697105189911, 1697105192677]"
1607,148,9,[],200,EleutherAI/gpt-neox-20b,128,1,2006.0,1.0,1,H100,1697105203627,1697105205633.0,120,16.0,1.0,"[20, 1986]","[1697105203647, 1697105205633]"
1608,478,10,[],200,EleutherAI/gpt-neox-20b,128,1,11806.0,1.0,1,H100,1697105205634,1697105217440.0,120,161.0,62.0,"[4, 1176, 89, 89, 86, 81, 79, 60, 61, 618, 86, 82, 83, 64, 434, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 82, 428, 168, 77, 456, 89, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 84, 65, 76, 652, 85, 356, 90, 83, 511, 89, 66, 84, 246, 85, 65, 386]","[1697105205638, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214501, 1697105214566, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216574, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440]"
1609,685,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258911.0,120,,,[30],[1697105257147]
1610,896,23,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105234226,1697105236002.0,120,15.0,1.0,"[53, 1723]","[1697105234279, 1697105236002]"
1611,115,33,[],200,EleutherAI/gpt-neox-20b,128,1,1523.0,1.0,1,H100,1697105258915,1697105260438.0,120,13.0,1.0,"[10, 1512]","[1697105258925, 1697105260437]"
1612,476,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260439,1697105262307.0,120,,,[24],[1697105260463]
1613,412,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236003,1697105238408.0,120,,,[15],[1697105236018]
1614,803,35,[],200,EleutherAI/gpt-neox-20b,128,1,1676.0,1.0,1,H100,1697105262314,1697105263990.0,120,20.0,1.0,"[270, 1406]","[1697105262584, 1697105263990]"
1615,773,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238411,1697105240330.0,120,,,[72],[1697105238483]
1616,783,12,[],200,EleutherAI/gpt-neox-20b,128,1,3157.0,1.0,1,H100,1697105198425,1697105201582.0,120,286.0,1.0,"[17, 3140]","[1697105198442, 1697105201582]"
1617,364,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105184006,1697105201998.0,120,,,"[4, 3163, 83, 83, 83, 376, 89, 561, 94, 164, 81, 376, 86, 85, 481, 90, 272, 165, 251, 87, 251, 66, 87, 66, 367, 162, 87, 281, 82, 275, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 80, 266, 63, 85, 199, 80, 78, 261, 326, 87, 116, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 326, 212, 117, 63, 265, 273, 410, 224, 230, 130, 150, 140, 81, 79, 219, 297, 80, 292, 160, 212]","[1697105184010, 1697105187173, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194123, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199826, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200625, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1618,207,26,[],200,EleutherAI/gpt-neox-20b,128,1,1596.0,1.0,1,H100,1697105240334,1697105241930.0,120,10.0,1.0,"[149, 1447]","[1697105240483, 1697105241930]"
1619,231,36,[],200,EleutherAI/gpt-neox-20b,128,1,1013.0,1.0,1,H100,1697105263992,1697105265005.0,120,13.0,1.0,"[56, 957]","[1697105264048, 1697105265005]"
1620,564,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241931,1697105243755.0,120,,,[9],[1697105241940]
1621,585,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265006,1697105267796.0,120,,,[33],[1697105265039]
1622,894,28,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105243758,1697105245427.0,120,14.0,1.0,"[222, 1447]","[1697105243980, 1697105245427]"
1623,316,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245428,1697105247243.0,120,,,[37],[1697105245465]
1624,126,10,[],200,EleutherAI/gpt-neox-20b,128,1,2146.0,1.0,1,H100,1697105202014,1697105204160.0,120,19.0,1.0,"[181, 1965]","[1697105202195, 1697105204160]"
1625,480,11,[],200,EleutherAI/gpt-neox-20b,128,1,2553.0,1.0,1,H100,1697105204161,1697105206714.0,120,26.0,1.0,"[16, 2537]","[1697105204177, 1697105206714]"
1626,810,12,[],200,EleutherAI/gpt-neox-20b,128,1,5548.0,1.0,1,H100,1697105206715,1697105212263.0,120,91.0,20.0,"[9, 2002, 87, 84, 79, 78, 384, 77, 618, 86, 83, 502, 82, 429, 168, 76, 456, 89, 80, 79]","[1697105206724, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209054, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211315, 1697105211483, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263]"
1627,19,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105270302.0,120,,,[176],[1697105267977]
1628,673,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247250,1697105248696.0,120,,,[157],[1697105247407]
1629,376,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270303,1697105271972.0,120,,,[49],[1697105270352]
1630,708,40,[],200,EleutherAI/gpt-neox-20b,128,1,1579.0,1.0,1,H100,1697105271976,1697105273555.0,120,140.0,1.0,"[110, 1469]","[1697105272086, 1697105273555]"
1631,104,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105250347.0,120,,,[18],[1697105248717]
1632,139,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273556,1697105275207.0,120,,,[34],[1697105273590]
1633,743,8,[],200,EleutherAI/gpt-neox-20b,128,1,3052.0,1.0,1,H100,1697105183841,1697105186893.0,120,123.0,6.0,"[5, 2743, 88, 79, 77, 60]","[1697105183846, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186893]"
1634,361,6,[],200,EleutherAI/gpt-neox-20b,128,1,2659.0,1.0,1,H100,1697105181811,1697105184470.0,120,67.0,7.0,"[4, 1939, 86, 85, 78, 384, 83]","[1697105181815, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470]"
1635,242,13,[],200,EleutherAI/gpt-neox-20b,128,1,4311.0,1.0,1,H100,1697105212264,1697105216575.0,120,345.0,9.0,"[5, 3025, 85, 356, 90, 84, 510, 89, 67]","[1697105212269, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215909, 1697105216419, 1697105216508, 1697105216575]"
1636,603,14,[],200,EleutherAI/gpt-neox-20b,128,1,2642.0,1.0,1,H100,1697105216576,1697105219218.0,120,9.0,1.0,"[4, 2637]","[1697105216580, 1697105219217]"
1637,168,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105186896,1697105201999.0,120,,,"[4, 2915, 90, 272, 165, 251, 88, 250, 66, 87, 66, 367, 162, 87, 281, 81, 276, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81, 265, 64, 84, 199, 80, 78, 261, 326, 87, 116, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 326, 212, 117, 63, 264, 274, 410, 224, 230, 130, 150, 140, 80, 80, 219, 297, 80, 292, 160, 212]","[1697105186900, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192128, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198688, 1697105198962, 1697105199372, 1697105199596, 1697105199826, 1697105199956, 1697105200106, 1697105200246, 1697105200326, 1697105200406, 1697105200625, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1638,34,15,[],200,EleutherAI/gpt-neox-20b,128,1,2684.0,1.0,1,H100,1697105219219,1697105221903.0,120,12.0,1.0,"[4, 2680]","[1697105219223, 1697105221903]"
1639,362,16,[],200,EleutherAI/gpt-neox-20b,128,1,2258.0,1.0,1,H100,1697105221904,1697105224162.0,120,14.0,1.0,"[29, 2229]","[1697105221933, 1697105224162]"
1640,437,14,[],200,EleutherAI/gpt-neox-20b,128,1,6773.0,1.0,1,H100,1697105207869,1697105214642.0,120,91.0,29.0,"[20, 2245, 86, 82, 502, 83, 428, 167, 77, 457, 89, 79, 80, 74, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 64, 76]","[1697105207889, 1697105210134, 1697105210220, 1697105210302, 1697105210804, 1697105210887, 1697105211315, 1697105211482, 1697105211559, 1697105212016, 1697105212105, 1697105212184, 1697105212264, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642]"
1641,186,11,[],200,EleutherAI/gpt-neox-20b,128,1,4898.0,1.0,1,H100,1697105202005,1697105206903.0,120,123.0,22.0,"[102, 1611, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84, 731, 90]","[1697105202107, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903]"
1642,718,7,[],200,EleutherAI/gpt-neox-20b,128,1,2011.0,1.0,1,H100,1697105184471,1697105186482.0,120,13.0,1.0,"[5, 2006]","[1697105184476, 1697105186482]"
1643,116,8,[],200,EleutherAI/gpt-neox-20b,128,1,2586.0,1.0,1,H100,1697105186483,1697105189069.0,120,23.0,1.0,"[5, 2581]","[1697105186488, 1697105189069]"
1644,469,9,[],200,EleutherAI/gpt-neox-20b,128,1,2267.0,1.0,1,H100,1697105189070,1697105191337.0,120,17.0,1.0,"[5, 2262]","[1697105189075, 1697105191337]"
1645,827,10,[],200,EleutherAI/gpt-neox-20b,128,1,5493.0,1.0,1,H100,1697105191338,1697105196831.0,120,96.0,20.0,"[5, 2553, 83, 64, 81, 265, 64, 84, 199, 80, 79, 260, 327, 87, 115, 84, 174, 418, 282, 189]","[1697105191343, 1697105193896, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194895, 1697105195155, 1697105195482, 1697105195569, 1697105195684, 1697105195768, 1697105195942, 1697105196360, 1697105196642, 1697105196831]"
1646,787,13,[],200,EleutherAI/gpt-neox-20b,128,1,2794.0,1.0,1,H100,1697105201456,1697105204250.0,120,123.0,6.0,"[4, 2258, 88, 88, 87, 269]","[1697105201460, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250]"
1647,836,11,[],200,EleutherAI/gpt-neox-20b,128,1,2145.0,1.0,1,H100,1697105202015,1697105204160.0,120,11.0,1.0,"[192, 1953]","[1697105202207, 1697105204160]"
1648,266,12,[],200,EleutherAI/gpt-neox-20b,128,1,2553.0,1.0,1,H100,1697105204161,1697105206714.0,120,9.0,1.0,"[16, 2537]","[1697105204177, 1697105206714]"
1649,620,13,[],200,EleutherAI/gpt-neox-20b,128,1,2098.0,1.0,1,H100,1697105206715,1697105208813.0,120,100.0,8.0,"[5, 1257, 86, 83, 82, 64, 434, 87]","[1697105206720, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813]"
1650,24,14,[],200,EleutherAI/gpt-neox-20b,128,1,3524.0,1.0,1,H100,1697105208814,1697105212338.0,120,79.0,9.0,"[9, 2492, 167, 77, 456, 89, 80, 79, 75]","[1697105208823, 1697105211315, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338]"
1651,406,5,[],200,EleutherAI/gpt-neox-20b,128,1,2839.0,1.0,1,H100,1697105180544,1697105183383.0,120,244.0,4.0,"[24, 2560, 89, 87, 79]","[1697105180568, 1697105183128, 1697105183217, 1697105183304, 1697105183383]"
1652,261,11,[],200,EleutherAI/gpt-neox-20b,128,1,4089.0,1.0,1,H100,1697105196833,1697105200922.0,120,874.0,2.0,"[7, 4082]","[1697105196840, 1697105200922]"
1653,832,9,[],200,EleutherAI/gpt-neox-20b,128,1,2312.0,1.0,1,H100,1697105186757,1697105189069.0,120,15.0,1.0,"[4, 2308]","[1697105186761, 1697105189069]"
1654,765,6,[],200,EleutherAI/gpt-neox-20b,128,1,2626.0,1.0,1,H100,1697105183383,1697105186009.0,120,84.0,2.0,"[5, 2621]","[1697105183388, 1697105186009]"
1655,257,10,[],200,EleutherAI/gpt-neox-20b,128,1,2266.0,1.0,1,H100,1697105189071,1697105191337.0,120,14.0,1.0,"[16, 2250]","[1697105189087, 1697105191337]"
1656,139,5,[],200,EleutherAI/gpt-neox-20b,128,1,4811.0,1.0,1,H100,1697105202002,1697105206813.0,120,39.0,21.0,"[33, 1683, 88, 88, 87, 269, 87, 86, 84, 415, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84, 731]","[1697105202035, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813]"
1657,296,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228783,1697105230476.0,120,,,[207],[1697105228990]
1658,651,23,[],200,EleutherAI/gpt-neox-20b,128,1,2578.0,1.0,1,H100,1697105230478,1697105233056.0,120,457.0,2.0,"[203, 2375]","[1697105230681, 1697105233056]"
1659,8,18,[],200,EleutherAI/gpt-neox-20b,128,1,2616.0,1.0,1,H100,1697105215910,1697105218526.0,120,39.0,3.0,"[8, 2529, 79]","[1697105215918, 1697105218447, 1697105218526]"
1660,80,24,[],200,EleutherAI/gpt-neox-20b,128,1,1825.0,1.0,1,H100,1697105233057,1697105234882.0,120,13.0,1.0,"[8, 1817]","[1697105233065, 1697105234882]"
1661,453,28,[],200,EleutherAI/gpt-neox-20b,128,1,1891.0,1.0,1,H100,1697105236004,1697105237895.0,120,26.0,1.0,"[17, 1874]","[1697105236021, 1697105237895]"
1662,661,6,[],200,EleutherAI/gpt-neox-20b,128,1,2858.0,1.0,1,H100,1697105172158,1697105175016.0,120,161.0,10.0,"[13, 1613, 80, 77, 72, 668, 92, 89, 68, 86]","[1697105172171, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016]"
1663,367,19,[],200,EleutherAI/gpt-neox-20b,128,1,4394.0,1.0,1,H100,1697105218527,1697105222921.0,120,92.0,6.0,"[5, 3433, 702, 87, 84, 83]","[1697105218532, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921]"
1664,200,7,[],200,EleutherAI/gpt-neox-20b,128,1,3239.0,1.0,1,H100,1697105186010,1697105189249.0,120,6.0,9.0,"[5, 1783, 89, 561, 94, 164, 81, 375, 87]","[1697105186015, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249]"
1665,692,20,[],200,EleutherAI/gpt-neox-20b,128,1,5333.0,1.0,1,H100,1697105222922,1697105228255.0,120,88.0,20.0,"[4, 2313, 82, 77, 75, 74, 706, 90, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105222926, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225547, 1697105226253, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
1666,557,8,[],200,EleutherAI/gpt-neox-20b,128,1,3065.0,1.0,1,H100,1697105189250,1697105192315.0,120,31.0,1.0,"[5, 3060]","[1697105189255, 1697105192315]"
1667,888,9,[],200,EleutherAI/gpt-neox-20b,128,1,2333.0,1.0,1,H100,1697105192316,1697105194649.0,120,19.0,1.0,"[4, 2329]","[1697105192320, 1697105194649]"
1668,309,10,[],200,EleutherAI/gpt-neox-20b,128,1,6804.0,1.0,1,H100,1697105194650,1697105201454.0,120,52.0,20.0,"[9, 3374, 211, 117, 63, 265, 273, 410, 224, 231, 130, 149, 141, 80, 79, 220, 296, 80, 292, 160]","[1697105194659, 1697105198033, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199957, 1697105200106, 1697105200247, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454]"
1669,86,7,[],200,EleutherAI/gpt-neox-20b,128,1,4482.0,1.0,1,H100,1697105175017,1697105179499.0,120,335.0,17.0,"[5, 2002, 81, 80, 63, 674, 95, 90, 88, 67, 86, 469, 90, 67, 87, 81, 356]","[1697105175022, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178017, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498]"
1670,384,17,[],200,EleutherAI/gpt-neox-20b,128,1,6183.0,1.0,1,H100,1697105212264,1697105218447.0,120,92.0,20.0,"[9, 3021, 85, 356, 90, 84, 510, 89, 66, 85, 246, 84, 66, 385, 89, 87, 406, 87, 82, 256]","[1697105212273, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215909, 1697105216419, 1697105216508, 1697105216574, 1697105216659, 1697105216905, 1697105216989, 1697105217055, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218447]"
1671,118,17,[],200,EleutherAI/gpt-neox-20b,128,1,5379.0,1.0,1,H100,1697105213069,1697105218448.0,120,85.0,20.0,"[5, 2221, 85, 355, 90, 84, 510, 89, 67, 83, 247, 84, 65, 386, 89, 87, 406, 87, 82, 256]","[1697105213074, 1697105215295, 1697105215380, 1697105215735, 1697105215825, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216905, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218447]"
1672,121,37,[],200,EleutherAI/gpt-neox-20b,128,1,1678.0,1.0,1,H100,1697105262312,1697105263990.0,120,13.0,1.0,"[168, 1510]","[1697105262480, 1697105263990]"
1673,480,38,[],200,EleutherAI/gpt-neox-20b,128,1,1013.0,1.0,1,H100,1697105263991,1697105265004.0,120,26.0,1.0,"[45, 968]","[1697105264036, 1697105265004]"
1674,280,7,[],200,EleutherAI/gpt-neox-20b,128,1,5417.0,1.0,1,H100,1697105188707,1697105194124.0,120,91.0,20.0,"[17, 2793, 165, 84, 281, 82, 275, 76, 286, 87, 82, 235, 82, 62, 306, 86, 189, 84, 64, 81]","[1697105188724, 1697105191517, 1697105191682, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192935, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124]"
1675,790,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252036.0,120,,,[25],[1697105250376]
1676,195,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253712.0,120,,,[233],[1697105252274]
1677,809,39,[],200,EleutherAI/gpt-neox-20b,128,1,2180.0,1.0,1,H100,1697105265006,1697105267186.0,120,16.0,1.0,"[9, 2171]","[1697105265015, 1697105267186]"
1678,234,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267187,1697105271972.0,120,,,"[12, 1716, 63, 669, 704, 685]","[1697105267199, 1697105268915, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
1679,552,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253717,1697105256010.0,120,,,[354],[1697105254071]
1680,912,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258913.0,120,,,[92],[1697105256105]
1681,125,21,[],200,EleutherAI/gpt-neox-20b,128,1,1395.0,1.0,1,H100,1697105228257,1697105229652.0,120,13.0,1.0,"[28, 1367]","[1697105228285, 1697105229652]"
1682,597,41,[],200,EleutherAI/gpt-neox-20b,128,1,1579.0,1.0,1,H100,1697105271976,1697105273555.0,120,39.0,1.0,"[106, 1473]","[1697105272082, 1697105273555]"
1683,344,36,[],200,EleutherAI/gpt-neox-20b,128,1,2509.0,1.0,1,H100,1697105258921,1697105261430.0,120,13.0,1.0,"[189, 2320]","[1697105259110, 1697105261430]"
1684,484,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105229653,1697105232146.0,120,,,"[28, 1824, 76, 75, 74, 73]","[1697105229681, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
1685,669,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105261431,1697105264082.0,120,,,[5],[1697105261436]
1686,100,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265928.0,120,,,[99],[1697105264184]
1687,25,42,[],200,EleutherAI/gpt-neox-20b,128,1,1576.0,1.0,1,H100,1697105273556,1697105275132.0,120,12.0,1.0,"[33, 1543]","[1697105273589, 1697105275132]"
1688,880,5,[],200,EleutherAI/gpt-neox-20b,128,1,2435.0,1.0,1,H100,1697105182467,1697105184902.0,120,84.0,2.0,"[4, 2430]","[1697105182471, 1697105184901]"
1689,310,6,[],200,EleutherAI/gpt-neox-20b,128,1,2715.0,1.0,1,H100,1697105184903,1697105187618.0,120,26.0,1.0,"[24, 2691]","[1697105184927, 1697105187618]"
1690,841,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232153,1697105234225.0,120,,,[218],[1697105232371]
1691,664,7,[],200,EleutherAI/gpt-neox-20b,128,1,3532.0,1.0,1,H100,1697105187619,1697105191151.0,120,364.0,9.0,"[12, 2547, 165, 250, 88, 250, 66, 87, 67]","[1697105187631, 1697105190178, 1697105190343, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191151]"
1692,453,39,[],200,EleutherAI/gpt-neox-20b,128,1,2981.0,1.0,1,H100,1697105265934,1697105268915.0,120,26.0,1.0,"[168, 2813]","[1697105266102, 1697105268915]"
1693,478,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105218449,1697105220995.0,120,,,[20],[1697105218469]
1694,814,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268916,1697105270302.0,120,,,[17],[1697105268933]
1695,831,19,[],200,EleutherAI/gpt-neox-20b,128,1,2312.0,1.0,1,H100,1697105220998,1697105223310.0,120,11.0,1.0,"[186, 2126]","[1697105221184, 1697105223310]"
1696,270,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234226,1697105236781.0,120,,,[20],[1697105234246]
1697,411,6,[],200,EleutherAI/gpt-neox-20b,128,1,11555.0,1.0,1,H100,1697105184388,1697105195943.0,120,85.0,55.0,"[8, 2777, 83, 83, 83, 376, 89, 561, 94, 164, 81, 376, 86, 85, 481, 90, 272, 165, 251, 87, 251, 66, 87, 66, 367, 162, 87, 281, 82, 275, 76, 286, 87, 83, 234, 82, 62, 305, 87, 189, 84, 64, 80, 266, 63, 85, 199, 80, 78, 261, 326, 87, 116, 83, 175]","[1697105184396, 1697105187173, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193619, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194123, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942]"
1698,693,8,[],200,EleutherAI/gpt-neox-20b,128,1,3760.0,1.0,1,H100,1697105199958,1697105203718.0,120,67.0,2.0,"[4, 3756]","[1697105199962, 1697105203718]"
1699,118,9,[],200,EleutherAI/gpt-neox-20b,128,1,5719.0,1.0,1,H100,1697105203719,1697105209438.0,120,85.0,20.0,"[4, 3090, 90, 89, 86, 80, 80, 60, 61, 618, 86, 83, 82, 64, 434, 87, 84, 79, 77, 385]","[1697105203723, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438]"
1700,832,11,[],200,EleutherAI/gpt-neox-20b,128,1,2137.0,1.0,1,H100,1697105188707,1697105190844.0,120,15.0,1.0,"[5, 2132]","[1697105188712, 1697105190844]"
1701,260,12,[],200,EleutherAI/gpt-neox-20b,128,1,5515.0,1.0,1,H100,1697105190845,1697105196360.0,120,86.0,20.0,"[13, 2762, 86, 189, 84, 64, 81, 265, 64, 84, 199, 80, 78, 261, 326, 88, 115, 83, 175, 418]","[1697105190858, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195481, 1697105195569, 1697105195684, 1697105195767, 1697105195942, 1697105196360]"
1702,309,10,[],200,EleutherAI/gpt-neox-20b,128,1,5208.0,1.0,1,H100,1697105191152,1697105196360.0,120,52.0,20.0,"[12, 2456, 86, 189, 84, 64, 81, 265, 64, 84, 199, 80, 78, 261, 327, 86, 116, 84, 174, 418]","[1697105191164, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195482, 1697105195568, 1697105195684, 1697105195768, 1697105195942, 1697105196360]"
1703,840,12,[],200,EleutherAI/gpt-neox-20b,128,1,2136.0,1.0,1,H100,1697105188708,1697105190844.0,120,17.0,1.0,"[24, 2112]","[1697105188732, 1697105190844]"
1704,704,10,[],200,EleutherAI/gpt-neox-20b,128,1,1928.0,1.0,1,H100,1697105194538,1697105196466.0,120,14.0,1.0,"[5, 1923]","[1697105194543, 1697105196466]"
1705,187,13,[],200,EleutherAI/gpt-neox-20b,128,1,2667.0,1.0,1,H100,1697105201583,1697105204250.0,120,161.0,6.0,"[4, 2131, 88, 88, 87, 269]","[1697105201587, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250]"
1706,265,13,[],200,EleutherAI/gpt-neox-20b,128,1,5515.0,1.0,1,H100,1697105190845,1697105196360.0,120,86.0,20.0,"[12, 2763, 86, 189, 84, 64, 81, 265, 64, 84, 199, 80, 78, 262, 325, 87, 116, 83, 175, 418]","[1697105190857, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195156, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360]"
1707,529,8,[],200,EleutherAI/gpt-neox-20b,128,1,2205.0,1.0,1,H100,1697105181458,1697105183663.0,120,10.0,1.0,"[4, 2201]","[1697105181462, 1697105183663]"
1708,225,14,[],200,EleutherAI/gpt-neox-20b,128,1,2979.0,1.0,1,H100,1697105215380,1697105218359.0,120,23.0,1.0,"[5, 2974]","[1697105215385, 1697105218359]"
1709,626,14,[],200,EleutherAI/gpt-neox-20b,128,1,2247.0,1.0,1,H100,1697105196361,1697105198608.0,120,10.0,1.0,"[9, 2238]","[1697105196370, 1697105198608]"
1710,207,10,[],200,EleutherAI/gpt-neox-20b,128,1,2780.0,1.0,1,H100,1697105198425,1697105201205.0,120,10.0,1.0,"[13, 2767]","[1697105198438, 1697105201205]"
1711,566,11,[],200,EleutherAI/gpt-neox-20b,128,1,7691.0,1.0,1,H100,1697105201206,1697105208897.0,120,109.0,36.0,"[8, 2504, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84, 731, 90, 89, 86, 80, 80, 60, 60, 618, 87, 82, 83, 63, 435, 87, 84]","[1697105201214, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207358, 1697105207976, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208726, 1697105208813, 1697105208897]"
1712,887,9,[],200,EleutherAI/gpt-neox-20b,128,1,10379.0,1.0,1,H100,1697105183664,1697105194043.0,120,244.0,50.0,"[12, 2333, 88, 85, 406, 89, 78, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 165, 80, 376, 86, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 162, 87, 281, 82, 275, 76, 286, 87, 83, 234, 82, 62, 305, 87, 189, 84, 64]","[1697105183676, 1697105186009, 1697105186097, 1697105186182, 1697105186588, 1697105186677, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188707, 1697105188787, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193619, 1697105193706, 1697105193895, 1697105193979, 1697105194043]"
1713,27,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105198609,1697105201999.0,120,,,[8],[1697105198617]
1714,828,9,[],200,EleutherAI/gpt-neox-20b,128,1,4363.0,1.0,1,H100,1697105197091,1697105201454.0,120,182.0,6.0,"[4, 3531, 296, 80, 292, 160]","[1697105197095, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454]"
1715,584,15,[],200,EleutherAI/gpt-neox-20b,128,1,1983.0,1.0,1,H100,1697105218360,1697105220343.0,120,10.0,1.0,"[5, 1978]","[1697105218365, 1697105220343]"
1716,257,10,[],200,EleutherAI/gpt-neox-20b,128,1,1524.0,1.0,1,H100,1697105201456,1697105202980.0,120,14.0,1.0,"[16, 1508]","[1697105201472, 1697105202980]"
1717,9,16,[],200,EleutherAI/gpt-neox-20b,128,1,4316.0,1.0,1,H100,1697105220344,1697105224660.0,120,85.0,20.0,"[5, 1616, 702, 87, 85, 82, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105220349, 1697105221965, 1697105222667, 1697105222754, 1697105222839, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
1718,616,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105202983,1697105220994.0,120,,,"[43, 2796, 91, 85, 84, 732, 89, 89, 86, 81, 79, 60, 61, 618, 86, 82, 83, 63, 435, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 82, 428, 168, 77, 456, 89, 80, 79, 75, 71, 482, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 84, 65, 76, 652, 85, 356, 90, 83, 511, 89, 66, 84, 246, 85, 65, 386, 89, 87, 406, 87, 81, 257, 79, 368, 81, 59, 366, 84, 80, 259, 62, 234, 79, 228, 82, 197]","[1697105203026, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212409, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214501, 1697105214566, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216574, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218190, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219484, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220426, 1697105220508, 1697105220705]"
1719,385,16,[],200,EleutherAI/gpt-neox-20b,128,1,8297.0,1.0,1,H100,1697105202005,1697105210302.0,120,52.0,43.0,"[102, 1611, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 390, 90, 85, 84, 731, 90, 89, 86, 80, 80, 60, 61, 618, 86, 82, 83, 63, 435, 87, 84, 79, 77, 385, 77, 618, 86, 83]","[1697105202107, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205823, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302]"
1720,20,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228782,1697105230476.0,120,,,[236],[1697105229018]
1721,377,22,[],200,EleutherAI/gpt-neox-20b,128,1,2516.0,1.0,1,H100,1697105230479,1697105232995.0,120,13.0,1.0,"[210, 2305]","[1697105230689, 1697105232994]"
1722,706,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232996,1697105234920.0,120,,,[8],[1697105233004]
1723,136,24,[],200,EleutherAI/gpt-neox-20b,128,1,2972.0,1.0,1,H100,1697105234923,1697105237895.0,120,31.0,1.0,"[249, 2723]","[1697105235172, 1697105237895]"
1724,674,4,[],200,EleutherAI/gpt-neox-20b,128,1,21461.0,1.0,1,H100,1697105172159,1697105193620.0,120,161.0,119.0,"[133, 1492, 80, 77, 72, 667, 94, 88, 68, 86, 84, 522, 99, 91, 89, 69, 88, 69, 68, 70, 758, 81, 81, 63, 674, 94, 91, 88, 67, 86, 468, 91, 66, 88, 81, 356, 88, 85, 65, 365, 86, 66, 280, 79, 75, 488, 81, 80, 387, 87, 75, 408, 89, 84, 383, 90, 88, 189, 88, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 87, 81, 411, 88, 79, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375, 87, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 162, 87, 281, 81, 276, 76, 286, 87, 82, 235, 82, 62, 305]","[1697105172292, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174774, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176127, 1697105176195, 1697105176265, 1697105177023, 1697105177104, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180101, 1697105180187, 1697105180253, 1697105180533, 1697105180612, 1697105180687, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181885, 1697105182293, 1697105182382, 1697105182466, 1697105182849, 1697105182939, 1697105183027, 1697105183216, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192128, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192935, 1697105193170, 1697105193252, 1697105193314, 1697105193619]"
1725,494,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105237896,1697105240331.0,120,,,[4],[1697105237900]
1726,718,17,[],200,EleutherAI/gpt-neox-20b,128,1,981.0,1.0,1,H100,1697105224163,1697105225144.0,120,13.0,1.0,"[8, 973]","[1697105224171, 1697105225144]"
1727,143,18,[],200,EleutherAI/gpt-neox-20b,128,1,2859.0,1.0,1,H100,1697105225145,1697105228004.0,120,6.0,12.0,"[9, 1099, 90, 85, 65, 84, 486, 91, 89, 85, 583, 93]","[1697105225154, 1697105226253, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004]"
1728,189,14,[],200,EleutherAI/gpt-neox-20b,128,1,5227.0,1.0,1,H100,1697105214173,1697105219400.0,120,88.0,20.0,"[12, 2234, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 82, 257, 78, 368, 81, 59, 366]","[1697105214185, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218448, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400]"
1729,501,19,[],200,EleutherAI/gpt-neox-20b,128,1,1647.0,1.0,1,H100,1697105228005,1697105229652.0,120,19.0,1.0,"[12, 1635]","[1697105228017, 1697105229652]"
1730,379,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248010,1697105250348.0,120,,,[5],[1697105248015]
1731,739,33,[],200,EleutherAI/gpt-neox-20b,128,1,1661.0,1.0,1,H100,1697105250350,1697105252011.0,120,216.0,1.0,"[16, 1645]","[1697105250366, 1697105252011]"
1732,678,4,[],200,EleutherAI/gpt-neox-20b,128,1,5752.0,1.0,1,H100,1697105185399,1697105191151.0,120,244.0,18.0,"[5, 3044, 94, 164, 81, 375, 87, 85, 481, 91, 271, 166, 250, 88, 250, 66, 87, 67]","[1697105185404, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189906, 1697105190177, 1697105190343, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191151]"
1733,351,14,[],200,EleutherAI/gpt-neox-20b,128,1,2005.0,1.0,1,H100,1697105220997,1697105223002.0,120,216.0,6.0,"[7, 1663, 87, 84, 83, 81]","[1697105221004, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002]"
1734,879,7,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105194044,1697105201998.0,120,,,"[4, 2594, 189, 259, 85, 62, 152, 158, 82, 77, 326, 212, 117, 63, 265, 273, 410, 225, 230, 129, 150, 140, 81, 79, 220, 296, 80, 292, 160, 212]","[1697105194048, 1697105196642, 1697105196831, 1697105197090, 1697105197175, 1697105197237, 1697105197389, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199597, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1735,715,15,[],200,EleutherAI/gpt-neox-20b,128,1,2141.0,1.0,1,H100,1697105223003,1697105225144.0,120,20.0,1.0,"[5, 2136]","[1697105223008, 1697105225144]"
1736,143,16,[],200,EleutherAI/gpt-neox-20b,128,1,2859.0,1.0,1,H100,1697105225145,1697105228004.0,120,6.0,12.0,"[13, 1094, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93]","[1697105225158, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004]"
1737,383,15,[],200,EleutherAI/gpt-neox-20b,128,1,1988.0,1.0,1,H100,1697105212339,1697105214327.0,120,15.0,1.0,"[8, 1980]","[1697105212347, 1697105214327]"
1738,546,15,[],200,EleutherAI/gpt-neox-20b,128,1,5259.0,1.0,1,H100,1697105219401,1697105224660.0,120,93.0,20.0,"[8, 2556, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105219409, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
1739,106,5,[],200,EleutherAI/gpt-neox-20b,128,1,5679.0,1.0,1,H100,1697105191152,1697105196831.0,120,161.0,20.0,"[16, 2727, 84, 64, 81, 265, 64, 84, 199, 80, 79, 260, 327, 87, 115, 84, 174, 418, 282, 189]","[1697105191168, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194895, 1697105195155, 1697105195482, 1697105195569, 1697105195684, 1697105195768, 1697105195942, 1697105196360, 1697105196642, 1697105196831]"
1740,638,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233608.0,120,,,[12],[1697105232162]
1741,744,16,[],200,EleutherAI/gpt-neox-20b,128,1,3202.0,1.0,1,H100,1697105214327,1697105217529.0,120,161.0,6.0,"[5, 2572, 85, 65, 386, 89]","[1697105214332, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529]"
1742,70,27,[],200,EleutherAI/gpt-neox-20b,128,1,1272.0,1.0,1,H100,1697105233610,1697105234882.0,120,39.0,1.0,"[52, 1220]","[1697105233662, 1697105234882]"
1743,622,12,[],200,EleutherAI/gpt-neox-20b,128,1,2057.0,1.0,1,H100,1697105200923,1697105202980.0,120,20.0,1.0,"[5, 2052]","[1697105200928, 1697105202980]"
1744,14,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105249682,1697105252037.0,120,,,[41],[1697105249723]
1745,24,13,[],200,EleutherAI/gpt-neox-20b,128,1,2841.0,1.0,1,H100,1697105202981,1697105205822.0,120,79.0,9.0,"[5, 1936, 93, 88, 89, 68, 87, 86, 389]","[1697105202986, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822]"
1746,375,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252042,1697105253712.0,120,,,[240],[1697105252282]
1747,425,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234883,1697105236781.0,120,,,[25],[1697105234908]
1748,381,14,[],200,EleutherAI/gpt-neox-20b,128,1,991.0,1.0,1,H100,1697105205823,1697105206814.0,120,140.0,2.0,"[5, 986]","[1697105205828, 1697105206814]"
1749,229,10,[],200,EleutherAI/gpt-neox-20b,128,1,2793.0,1.0,1,H100,1697105189164,1697105191957.0,120,15.0,1.0,"[16, 2776]","[1697105189180, 1697105191956]"
1750,734,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105255028.0,120,,,[183],[1697105253899]
1751,754,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105238409.0,120,,,[118],[1697105236902]
1752,732,15,[],200,EleutherAI/gpt-neox-20b,128,1,5201.0,1.0,1,H100,1697105206815,1697105212016.0,120,345.0,12.0,"[8, 2615, 77, 618, 86, 83, 502, 82, 428, 169, 76, 457]","[1697105206823, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211483, 1697105211559, 1697105212016]"
1753,160,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[169],[1697105255199]
1754,591,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105191958,1697105201999.0,120,,,"[8, 3190, 325, 87, 116, 83, 176, 417, 282, 184, 264, 85, 62, 151, 159, 82, 77, 327, 211, 117, 63, 265, 273, 410, 224, 231, 129, 150, 140, 81, 79, 220, 296, 80, 292, 160, 212]","[1697105191966, 1697105195156, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195943, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198033, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1755,179,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238412,1697105240331.0,120,,,[191],[1697105238603]
1756,496,15,[],200,EleutherAI/gpt-neox-20b,128,1,3634.0,1.0,1,H100,1697105209516,1697105213150.0,120,335.0,11.0,"[4, 2496, 88, 80, 79, 75, 72, 481, 88, 89, 82]","[1697105209520, 1697105212016, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150]"
1757,539,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241994.0,120,,,[161],[1697105240495]
1758,900,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242002,1697105243754.0,120,,,[93],[1697105242095]
1759,332,33,[],200,EleutherAI/gpt-neox-20b,128,1,1671.0,1.0,1,H100,1697105243756,1697105245427.0,120,39.0,1.0,"[52, 1619]","[1697105243808, 1697105245427]"
1760,110,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230476.0,120,,,[108],[1697105228889]
1761,468,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230479,1697105234918.0,120,,,"[234, 2281, 62, 600, 617]","[1697105230713, 1697105232994, 1697105233056, 1697105233656, 1697105234273]"
1762,700,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105218449,1697105220995.0,120,,,[16],[1697105218465]
1763,162,16,[],200,EleutherAI/gpt-neox-20b,128,1,5599.0,1.0,1,H100,1697105212017,1697105217616.0,120,90.0,20.0,"[8, 2392, 85, 65, 75, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246, 85, 65, 386, 89, 87]","[1697105212025, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616]"
1764,244,41,[],200,EleutherAI/gpt-neox-20b,128,1,1641.0,1.0,1,H100,1697105270304,1697105271945.0,120,9.0,1.0,"[28, 1613]","[1697105270332, 1697105271945]"
1765,610,8,[],200,EleutherAI/gpt-neox-20b,128,1,6797.0,1.0,1,H100,1697105194125,1697105200922.0,120,89.0,20.0,"[4, 3418, 82, 77, 327, 211, 117, 63, 265, 273, 410, 225, 230, 129, 150, 140, 81, 79, 220, 296]","[1697105194129, 1697105197547, 1697105197629, 1697105197706, 1697105198033, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199597, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922]"
1766,576,42,[],200,EleutherAI/gpt-neox-20b,128,1,803.0,1.0,1,H100,1697105271946,1697105272749.0,120,14.0,1.0,"[25, 777]","[1697105271971, 1697105272748]"
1767,231,20,[],200,EleutherAI/gpt-neox-20b,128,1,1833.0,1.0,1,H100,1697105223311,1697105225144.0,120,13.0,1.0,"[32, 1801]","[1697105223343, 1697105225144]"
1768,141,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170016,1697105172155.0,120,,,"[57, 1690]","[1697105170073, 1697105171763]"
1769,594,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225145,1697105228774.0,120,,,"[29, 1889, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105225174, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
1770,7,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105272749,1697105275207.0,120,,,[9],[1697105272758]
1771,495,7,[],200,EleutherAI/gpt-neox-20b,128,1,1526.0,1.0,1,H100,1697105172158,1697105173684.0,120,13.0,1.0,"[18, 1508]","[1697105172176, 1697105173684]"
1772,501,7,[],200,EleutherAI/gpt-neox-20b,128,1,2058.0,1.0,1,H100,1697105186188,1697105188246.0,120,19.0,1.0,"[8, 2050]","[1697105186196, 1697105188246]"
1773,506,18,[],200,EleutherAI/gpt-neox-20b,128,1,1928.0,1.0,1,H100,1697105215910,1697105217838.0,120,16.0,1.0,"[13, 1915]","[1697105215923, 1697105217838]"
1774,855,8,[],200,EleutherAI/gpt-neox-20b,128,1,5877.0,1.0,1,H100,1697105188247,1697105194124.0,120,83.0,20.0,"[5, 3265, 162, 87, 281, 82, 275, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81]","[1697105188252, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124]"
1775,381,6,[],200,EleutherAI/gpt-neox-20b,128,1,2762.0,1.0,1,H100,1697105185036,1697105187798.0,120,140.0,2.0,"[5, 2757]","[1697105185041, 1697105187798]"
1776,489,4,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.17 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.50 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 22.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105170016,1697105172155.0,120,,,"[65, 1682]","[1697105170081, 1697105171763]"
1777,341,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105196361,1697105201999.0,120,,,"[5, 3231, 230, 129, 150, 140, 81, 79, 220, 296, 80, 292, 160, 213]","[1697105196366, 1697105199597, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201667]"
1778,846,5,[],200,EleutherAI/gpt-neox-20b,128,1,2525.0,1.0,1,H100,1697105172156,1697105174681.0,120,140.0,6.0,"[47, 1581, 80, 77, 72, 668]","[1697105172203, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174681]"
1779,740,7,[],200,EleutherAI/gpt-neox-20b,128,1,5054.0,1.0,1,H100,1697105187799,1697105192853.0,120,563.0,14.0,"[8, 3124, 66, 87, 67, 366, 162, 87, 281, 82, 276, 75, 286, 87]","[1697105187807, 1697105190931, 1697105190997, 1697105191084, 1697105191151, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192405, 1697105192480, 1697105192766, 1697105192853]"
1780,835,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105217839,1697105220996.0,120,,,"[8, 2580, 82, 197]","[1697105217847, 1697105220427, 1697105220509, 1697105220706]"
1781,273,6,[],200,EleutherAI/gpt-neox-20b,128,1,2247.0,1.0,1,H100,1697105174682,1697105176929.0,120,19.0,1.0,"[24, 2223]","[1697105174706, 1697105176929]"
1782,284,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105194125,1697105201998.0,120,,,"[8, 3414, 82, 77, 327, 211, 117, 63, 265, 273, 410, 225, 230, 129, 150, 140, 81, 79, 220, 296, 80, 292, 160, 212]","[1697105194133, 1697105197547, 1697105197629, 1697105197706, 1697105198033, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199597, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1783,605,7,[],200,EleutherAI/gpt-neox-20b,128,1,1704.0,1.0,1,H100,1697105176931,1697105178635.0,120,8.0,1.0,"[24, 1680]","[1697105176955, 1697105178635]"
1784,264,20,[],200,EleutherAI/gpt-neox-20b,128,1,5255.0,1.0,1,H100,1697105220998,1697105226253.0,120,86.0,20.0,"[198, 2207, 71, 92, 87, 86, 85, 82, 350, 91, 70, 88, 87, 68, 580, 81, 78, 74, 74, 705]","[1697105221196, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223906, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225240, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226252]"
1785,33,8,[],200,EleutherAI/gpt-neox-20b,128,1,3250.0,1.0,1,H100,1697105178636,1697105181886.0,120,140.0,7.0,"[5, 2534, 81, 80, 387, 87, 76]","[1697105178641, 1697105181175, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886]"
1786,695,12,[],200,EleutherAI/gpt-neox-20b,128,1,4078.0,1.0,1,H100,1697105202004,1697105206082.0,120,92.0,20.0,"[87, 1627, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 390, 90, 85, 84]","[1697105202091, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205823, 1697105205913, 1697105205998, 1697105206082]"
1787,396,9,[],200,EleutherAI/gpt-neox-20b,128,1,4790.0,1.0,1,H100,1697105181887,1697105186677.0,120,89.0,20.0,"[4, 1864, 85, 85, 79, 383, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 88, 81, 410, 89]","[1697105181891, 1697105183755, 1697105183840, 1697105183925, 1697105184004, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186178, 1697105186588, 1697105186677]"
1788,619,11,[],200,EleutherAI/gpt-neox-20b,128,1,1928.0,1.0,1,H100,1697105194538,1697105196466.0,120,10.0,1.0,"[13, 1915]","[1697105194551, 1697105196466]"
1789,750,10,[],200,EleutherAI/gpt-neox-20b,128,1,5726.0,1.0,1,H100,1697105186678,1697105192404.0,120,88.0,20.0,"[8, 2477, 86, 85, 481, 90, 272, 165, 251, 87, 251, 66, 87, 66, 367, 166, 83, 281, 82, 275]","[1697105186686, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191683, 1697105191766, 1697105192047, 1697105192129, 1697105192404]"
1790,131,12,[],200,EleutherAI/gpt-neox-20b,128,1,2805.0,1.0,1,H100,1697105196467,1697105199272.0,120,8.0,1.0,"[9, 2796]","[1697105196476, 1697105199272]"
1791,485,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105199272,1697105202006.0,120,,,[5],[1697105199277]
1792,35,9,[],200,EleutherAI/gpt-neox-20b,128,1,5159.0,1.0,1,H100,1697105200923,1697105206082.0,120,87.0,20.0,"[5, 2790, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84]","[1697105200928, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
1793,235,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105196834,1697105201999.0,120,,,"[10, 3782, 296, 80, 292, 160, 212]","[1697105196844, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1794,845,14,[],200,EleutherAI/gpt-neox-20b,128,1,11135.0,1.0,1,H100,1697105202015,1697105213150.0,120,244.0,50.0,"[196, 2711, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84, 732, 89, 89, 86, 81, 79, 60, 61, 618, 86, 82, 83, 63, 435, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 82, 428, 168, 77, 456, 89, 80, 79, 75, 71, 482, 88, 89, 82]","[1697105202211, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212409, 1697105212891, 1697105212979, 1697105213068, 1697105213150]"
1795,477,10,[],200,EleutherAI/gpt-neox-20b,128,1,10680.0,1.0,1,H100,1697105209439,1697105220119.0,120,244.0,50.0,"[24, 2553, 88, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 69, 245, 85, 65, 75, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 81, 257, 79, 368, 81, 59, 366, 84, 80, 259, 62, 234]","[1697105209463, 1697105212016, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214172, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218190, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219484, 1697105219564, 1697105219823, 1697105219885, 1697105220119]"
1796,614,10,[],200,EleutherAI/gpt-neox-20b,128,1,1619.0,1.0,1,H100,1697105202007,1697105203626.0,120,15.0,1.0,"[168, 1451]","[1697105202175, 1697105203626]"
1797,50,11,[],200,EleutherAI/gpt-neox-20b,128,1,2371.0,1.0,1,H100,1697105203627,1697105205998.0,120,90.0,4.0,"[20, 2176, 90, 85]","[1697105203647, 1697105205823, 1697105205913, 1697105205998]"
1798,407,12,[],200,EleutherAI/gpt-neox-20b,128,1,714.0,1.0,1,H100,1697105206000,1697105206714.0,120,16.0,1.0,"[4, 710]","[1697105206004, 1697105206714]"
1799,766,13,[],200,EleutherAI/gpt-neox-20b,128,1,1825.0,1.0,1,H100,1697105206717,1697105208542.0,120,11.0,1.0,"[31, 1793]","[1697105206748, 1697105208541]"
1800,546,14,[],200,EleutherAI/gpt-neox-20b,128,1,5187.0,1.0,1,H100,1697105204251,1697105209438.0,120,93.0,20.0,"[9, 2554, 89, 89, 86, 81, 79, 60, 61, 618, 86, 82, 83, 63, 435, 87, 84, 79, 77, 385]","[1697105204260, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438]"
1801,588,29,[],200,EleutherAI/gpt-neox-20b,128,1,1551.0,1.0,1,H100,1697105242003,1697105243554.0,120,11.0,1.0,"[265, 1286]","[1697105242268, 1697105243554]"
1802,396,10,[],200,EleutherAI/gpt-neox-20b,128,1,5398.0,1.0,1,H100,1697105206084,1697105211482.0,120,89.0,20.0,"[13, 1880, 86, 83, 82, 64, 434, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 82, 428, 168]","[1697105206097, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482]"
1803,20,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243555,1697105245501.0,120,,,[40],[1697105243595]
1804,773,8,[],200,EleutherAI/gpt-neox-20b,128,1,5658.0,1.0,1,H100,1697105192048,1697105197706.0,120,90.0,20.0,"[13, 2675, 80, 79, 261, 325, 87, 116, 83, 176, 417, 282, 184, 264, 85, 62, 152, 158, 82, 77]","[1697105192061, 1697105194736, 1697105194816, 1697105194895, 1697105195156, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195943, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197389, 1697105197547, 1697105197629, 1697105197706]"
1805,381,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245503,1697105247242.0,120,,,[65],[1697105245568]
1806,740,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248696.0,120,,,[127],[1697105247374]
1807,165,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105252036.0,120,,,[106],[1697105248805]
1808,494,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252040,1697105253711.0,120,,,[167],[1697105252207]
1809,850,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105255027.0,120,,,[157],[1697105253871]
1810,282,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[41],[1697105255071]
1811,641,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258914.0,120,,,[42],[1697105257159]
1812,399,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243754.0,120,,,[174],[1697105242175]
1813,545,12,[],200,EleutherAI/gpt-neox-20b,128,1,3315.0,1.0,1,H100,1697105206904,1697105210219.0,120,216.0,5.0,"[5, 2529, 77, 618, 86]","[1697105206909, 1697105209438, 1697105209515, 1697105210133, 1697105210219]"
1814,579,8,[],200,EleutherAI/gpt-neox-20b,128,1,1812.0,1.0,1,H100,1697105187800,1697105189612.0,120,19.0,1.0,"[7, 1805]","[1697105187807, 1697105189612]"
1815,44,38,[],200,EleutherAI/gpt-neox-20b,128,1,2505.0,1.0,1,H100,1697105258926,1697105261431.0,120,12.0,1.0,"[264, 2240]","[1697105259190, 1697105261430]"
1816,908,9,[],200,EleutherAI/gpt-neox-20b,128,1,9983.0,1.0,1,H100,1697105189613,1697105199596.0,120,6.0,50.0,"[9, 1895, 166, 83, 281, 82, 275, 76, 286, 87, 82, 235, 82, 62, 306, 86, 189, 84, 64, 81, 265, 64, 84, 199, 80, 79, 260, 326, 87, 116, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 326, 212, 117, 63, 265, 273, 410, 224]","[1697105189622, 1697105191517, 1697105191683, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192935, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194895, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596]"
1817,492,6,[],200,EleutherAI/gpt-neox-20b,128,1,5294.0,1.0,1,H100,1697105177923,1697105183217.0,120,47.0,20.0,"[9, 2170, 85, 67, 279, 79, 75, 489, 80, 80, 387, 87, 76, 408, 89, 83, 384, 89, 88, 190]","[1697105177932, 1697105180102, 1697105180187, 1697105180254, 1697105180533, 1697105180612, 1697105180687, 1697105181176, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217]"
1818,614,10,[],200,EleutherAI/gpt-neox-20b,128,1,1622.0,1.0,1,H100,1697105202004,1697105203626.0,120,15.0,1.0,"[95, 1527]","[1697105202099, 1697105203626]"
1819,147,10,[],200,EleutherAI/gpt-neox-20b,128,1,2256.0,1.0,1,H100,1697105192048,1697105194304.0,120,182.0,1.0,"[5, 2251]","[1697105192053, 1697105194304]"
1820,485,13,[],200,EleutherAI/gpt-neox-20b,128,1,1804.0,1.0,1,H100,1697105202002,1697105203806.0,120,67.0,3.0,"[29, 1687, 88]","[1697105202031, 1697105203718, 1697105203806]"
1821,501,11,[],200,EleutherAI/gpt-neox-20b,128,1,2161.0,1.0,1,H100,1697105194305,1697105196466.0,120,19.0,1.0,"[4, 2157]","[1697105194309, 1697105196466]"
1822,740,8,[],200,EleutherAI/gpt-neox-20b,128,1,4043.0,1.0,1,H100,1697105183755,1697105187798.0,120,563.0,14.0,"[5, 2249, 88, 85, 407, 88, 79, 77, 60, 279, 84, 83, 83, 376]","[1697105183760, 1697105186009, 1697105186097, 1697105186182, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186893, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798]"
1823,62,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228782,1697105230476.0,120,,,[220],[1697105229002]
1824,662,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245428,1697105247242.0,120,,,[20],[1697105245448]
1825,419,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105232145.0,120,,,[40],[1697105230518]
1826,133,15,[],200,EleutherAI/gpt-neox-20b,128,1,1784.0,1.0,1,H100,1697105206084,1697105207868.0,120,15.0,1.0,"[85, 1699]","[1697105206169, 1697105207868]"
1827,770,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232152,1697105234225.0,120,,,[139],[1697105232291]
1828,200,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234226,1697105236781.0,120,,,[28],[1697105234254]
1829,528,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105240329.0,120,,,[190],[1697105236974]
1830,893,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240332,1697105241994.0,120,,,[252],[1697105240584]
1831,323,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242002,1697105243754.0,120,,,[210],[1697105242212]
1832,681,21,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105243758,1697105245427.0,120,23.0,1.0,"[235, 1434]","[1697105243993, 1697105245427]"
1833,82,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245428,1697105247242.0,120,,,[33],[1697105245461]
1834,493,14,[],200,EleutherAI/gpt-neox-20b,128,1,5668.0,1.0,1,H100,1697105213226,1697105218894.0,120,83.0,20.0,"[5, 2504, 91, 83, 510, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 88, 81, 256, 79, 368]","[1697105213231, 1697105215735, 1697105215826, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526, 1697105218894]"
1835,89,8,[],200,EleutherAI/gpt-neox-20b,128,1,4532.0,1.0,1,H100,1697105191152,1697105195684.0,120,52.0,20.0,"[8, 2010, 82, 62, 306, 86, 189, 84, 64, 81, 265, 63, 85, 199, 80, 78, 262, 325, 87, 116]","[1697105191160, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195156, 1697105195481, 1697105195568, 1697105195684]"
1836,573,13,[],200,EleutherAI/gpt-neox-20b,128,1,1893.0,1.0,1,H100,1697105206084,1697105207977.0,120,874.0,2.0,"[9, 1884]","[1697105206093, 1697105207977]"
1837,6,14,[],200,EleutherAI/gpt-neox-20b,128,1,7930.0,1.0,1,H100,1697105207978,1697105215908.0,120,100.0,29.0,"[4, 3332, 168, 77, 456, 89, 80, 80, 74, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 64, 76, 652, 85, 356, 90, 83]","[1697105207982, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212264, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908]"
1838,779,11,[],200,EleutherAI/gpt-neox-20b,128,1,4264.0,1.0,1,H100,1697105193442,1697105197706.0,120,563.0,10.0,"[5, 3195, 188, 260, 85, 62, 152, 158, 82, 77]","[1697105193447, 1697105196642, 1697105196830, 1697105197090, 1697105197175, 1697105197237, 1697105197389, 1697105197547, 1697105197629, 1697105197706]"
1839,177,12,[],200,EleutherAI/gpt-neox-20b,128,1,3128.0,1.0,1,H100,1697105197707,1697105200835.0,120,14.0,1.0,"[17, 3111]","[1697105197724, 1697105200835]"
1840,433,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248695.0,120,,,[123],[1697105247370]
1841,790,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248697,1697105250348.0,120,,,[72],[1697105248769]
1842,538,13,[],200,EleutherAI/gpt-neox-20b,128,1,5246.0,1.0,1,H100,1697105200836,1697105206082.0,120,89.0,20.0,"[5, 2877, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84]","[1697105200841, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
1843,220,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252036.0,120,,,[33],[1697105250384]
1844,128,14,[],200,EleutherAI/gpt-neox-20b,128,1,1575.0,1.0,1,H100,1697105220998,1697105222573.0,120,9.0,1.0,"[170, 1405]","[1697105221168, 1697105222573]"
1845,585,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252042,1697105253712.0,120,,,[184],[1697105252226]
1846,913,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[288],[1697105254004]
1847,488,15,[],200,EleutherAI/gpt-neox-20b,128,1,736.0,1.0,1,H100,1697105222574,1697105223310.0,120,6.0,1.0,"[16, 720]","[1697105222590, 1697105223310]"
1848,824,16,[],200,EleutherAI/gpt-neox-20b,128,1,2088.0,1.0,1,H100,1697105223311,1697105225399.0,120,58.0,4.0,"[16, 1912, 82, 78]","[1697105223327, 1697105225239, 1697105225321, 1697105225399]"
1849,419,9,[],200,EleutherAI/gpt-neox-20b,128,1,5746.0,1.0,1,H100,1697105192678,1697105198424.0,120,88.0,20.0,"[13, 2790, 88, 115, 84, 174, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 327, 211, 117, 63]","[1697105192691, 1697105195481, 1697105195569, 1697105195684, 1697105195768, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198033, 1697105198244, 1697105198361, 1697105198424]"
1850,854,8,[],200,EleutherAI/gpt-neox-20b,128,1,5289.0,1.0,1,H100,1697105173685,1697105178974.0,120,67.0,29.0,"[13, 983, 92, 89, 68, 86, 84, 522, 99, 91, 89, 69, 88, 68, 69, 69, 760, 81, 80, 63, 674, 94, 91, 88, 67, 86, 468, 91, 66]","[1697105173698, 1697105174681, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175721, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177024, 1697105177105, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107, 1697105178195, 1697105178262, 1697105178348, 1697105178816, 1697105178907, 1697105178973]"
1851,359,15,[],200,EleutherAI/gpt-neox-20b,128,1,2449.0,1.0,1,H100,1697105215910,1697105218359.0,120,10.0,1.0,"[20, 2429]","[1697105215930, 1697105218359]"
1852,27,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228783,1697105230476.0,120,,,[231],[1697105229014]
1853,690,16,[],200,EleutherAI/gpt-neox-20b,128,1,1983.0,1.0,1,H100,1697105218360,1697105220343.0,120,39.0,1.0,"[5, 1978]","[1697105218365, 1697105220343]"
1854,118,17,[],200,EleutherAI/gpt-neox-20b,128,1,4316.0,1.0,1,H100,1697105220344,1697105224660.0,120,85.0,20.0,"[9, 1612, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105220353, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
1855,595,12,[],200,EleutherAI/gpt-neox-20b,128,1,1618.0,1.0,1,H100,1697105202008,1697105203626.0,120,8.0,1.0,"[163, 1455]","[1697105202171, 1697105203626]"
1856,20,13,[],200,EleutherAI/gpt-neox-20b,128,1,5186.0,1.0,1,H100,1697105203627,1697105208813.0,120,83.0,20.0,"[16, 2180, 90, 85, 84, 731, 91, 88, 86, 80, 80, 60, 61, 618, 86, 83, 82, 64, 434, 87]","[1697105203643, 1697105205823, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206904, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813]"
1857,348,14,[],200,EleutherAI/gpt-neox-20b,128,1,5358.0,1.0,1,H100,1697105208814,1697105214172.0,120,91.0,20.0,"[5, 2495, 168, 77, 456, 89, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68]","[1697105208819, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171]"
1858,796,8,[],200,EleutherAI/gpt-neox-20b,128,1,5482.0,1.0,1,H100,1697105189335,1697105194817.0,120,86.0,20.0,"[5, 3064, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189, 84, 63, 82, 265, 64, 84, 199, 80]","[1697105189340, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194042, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816]"
1859,620,13,[],200,EleutherAI/gpt-neox-20b,128,1,4046.0,1.0,1,H100,1697105196361,1697105200407.0,120,100.0,8.0,"[5, 3231, 230, 129, 150, 140, 81, 79]","[1697105196366, 1697105199597, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406]"
1860,178,11,[],200,EleutherAI/gpt-neox-20b,128,1,2664.0,1.0,1,H100,1697105192406,1697105195070.0,120,11.0,1.0,"[24, 2640]","[1697105192430, 1697105195070]"
1861,625,12,[],200,EleutherAI/gpt-neox-20b,128,1,3618.0,1.0,1,H100,1697105195071,1697105198689.0,120,364.0,2.0,"[5, 3613]","[1697105195076, 1697105198689]"
1862,54,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105198690,1697105201999.0,120,,,[4],[1697105198694]
1863,413,14,[],200,EleutherAI/gpt-neox-20b,128,1,10096.0,1.0,1,H100,1697105202008,1697105212104.0,120,244.0,50.0,"[103, 1607, 88, 88, 87, 269, 87, 87, 83, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84, 731, 90, 89, 86, 80, 80, 60, 61, 618, 86, 82, 83, 63, 435, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 81, 429, 168, 77, 456, 89]","[1697105202111, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210885, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104]"
1864,27,14,[],200,EleutherAI/gpt-neox-20b,128,1,11696.0,1.0,1,H100,1697105200408,1697105212104.0,120,15.0,50.0,"[4, 3306, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84, 731, 90, 89, 86, 80, 80, 60, 60, 618, 87, 82, 83, 63, 434, 88, 84, 79, 77, 385, 77, 618, 86, 83, 502, 81, 429, 168, 77, 456, 89]","[1697105200412, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207358, 1697105207976, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208725, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210885, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104]"
1865,230,9,[],200,EleutherAI/gpt-neox-20b,128,1,3607.0,1.0,1,H100,1697105194817,1697105198424.0,120,86.0,5.0,"[5, 3211, 211, 117, 63]","[1697105194822, 1697105198033, 1697105198244, 1697105198361, 1697105198424]"
1866,434,13,[],200,EleutherAI/gpt-neox-20b,128,1,5568.0,1.0,1,H100,1697105205914,1697105211482.0,120,85.0,20.0,"[4, 2059, 86, 82, 83, 64, 434, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 82, 428, 168]","[1697105205918, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482]"
1867,809,11,[],200,EleutherAI/gpt-neox-20b,128,1,1783.0,1.0,1,H100,1697105220120,1697105221903.0,120,16.0,1.0,"[5, 1778]","[1697105220125, 1697105221903]"
1868,386,15,[],200,EleutherAI/gpt-neox-20b,128,1,3189.0,1.0,1,H100,1697105212105,1697105215294.0,120,140.0,6.0,"[5, 2307, 85, 65, 75, 652]","[1697105212110, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294]"
1869,241,12,[],200,EleutherAI/gpt-neox-20b,128,1,1406.0,1.0,1,H100,1697105221904,1697105223310.0,120,19.0,1.0,"[16, 1390]","[1697105221920, 1697105223310]"
1870,600,13,[],200,EleutherAI/gpt-neox-20b,128,1,1833.0,1.0,1,H100,1697105223311,1697105225144.0,120,23.0,1.0,"[29, 1804]","[1697105223340, 1697105225144]"
1871,744,16,[],200,EleutherAI/gpt-neox-20b,128,1,3740.0,1.0,1,H100,1697105215295,1697105219035.0,120,161.0,6.0,"[5, 3147, 79, 368, 81, 59]","[1697105215300, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034]"
1872,25,14,[],200,EleutherAI/gpt-neox-20b,128,1,1809.0,1.0,1,H100,1697105225145,1697105226954.0,120,12.0,1.0,"[25, 1783]","[1697105225170, 1697105226953]"
1873,243,12,[],200,EleutherAI/gpt-neox-20b,128,1,2439.0,1.0,1,H100,1697105201455,1697105203894.0,120,67.0,4.0,"[9, 2254, 88, 88]","[1697105201464, 1697105203718, 1697105203806, 1697105203894]"
1874,472,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226954,1697105228773.0,120,,,[5],[1697105226959]
1875,169,17,[],200,EleutherAI/gpt-neox-20b,128,1,1586.0,1.0,1,H100,1697105219036,1697105220622.0,120,10.0,1.0,"[4, 1582]","[1697105219040, 1697105220622]"
1876,428,10,[],200,EleutherAI/gpt-neox-20b,128,1,3363.0,1.0,1,H100,1697105192405,1697105195768.0,120,31.0,9.0,"[9, 2235, 87, 81, 78, 261, 325, 87, 116, 83]","[1697105192414, 1697105194649, 1697105194736, 1697105194817, 1697105194895, 1697105195156, 1697105195481, 1697105195568, 1697105195684, 1697105195767]"
1877,826,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230475.0,120,,,[200],[1697105228981]
1878,597,13,[],200,EleutherAI/gpt-neox-20b,128,1,2819.0,1.0,1,H100,1697105203895,1697105206714.0,120,39.0,1.0,"[5, 2814]","[1697105203900, 1697105206714]"
1879,298,13,[],200,EleutherAI/gpt-neox-20b,128,1,1784.0,1.0,1,H100,1697105206084,1697105207868.0,120,17.0,1.0,"[33, 1751]","[1697105206117, 1697105207868]"
1880,254,17,[],200,EleutherAI/gpt-neox-20b,128,1,1647.0,1.0,1,H100,1697105230478,1697105232125.0,120,58.0,1.0,"[119, 1528]","[1697105230597, 1697105232125]"
1881,627,14,[],200,EleutherAI/gpt-neox-20b,128,1,5356.0,1.0,1,H100,1697105207869,1697105213225.0,120,93.0,20.0,"[12, 2253, 86, 82, 502, 83, 427, 168, 77, 457, 89, 79, 80, 74, 72, 481, 88, 89, 82, 75]","[1697105207881, 1697105210134, 1697105210220, 1697105210302, 1697105210804, 1697105210887, 1697105211314, 1697105211482, 1697105211559, 1697105212016, 1697105212105, 1697105212184, 1697105212264, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225]"
1882,524,18,[],200,EleutherAI/gpt-neox-20b,128,1,5954.0,1.0,1,H100,1697105220623,1697105226577.0,120,100.0,30.0,"[5, 1338, 701, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579, 82, 77, 75, 73, 706, 91, 84, 66, 84]","[1697105220628, 1697105221966, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225546, 1697105226252, 1697105226343, 1697105226427, 1697105226493, 1697105226577]"
1883,764,7,[],200,EleutherAI/gpt-neox-20b,128,1,2355.0,1.0,1,H100,1697105195944,1697105198299.0,120,39.0,1.0,"[4, 2351]","[1697105195948, 1697105198299]"
1884,617,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232126,1697105234919.0,120,,,"[5, 925, 600, 617]","[1697105232131, 1697105233056, 1697105233656, 1697105234273]"
1885,49,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236781.0,120,,,[174],[1697105235096]
1886,852,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226578,1697105228773.0,120,,,[4],[1697105226582]
1887,278,8,[],200,EleutherAI/gpt-neox-20b,128,1,2904.0,1.0,1,H100,1697105198301,1697105201205.0,120,13.0,1.0,"[8, 2896]","[1697105198309, 1697105201205]"
1888,212,14,[],200,EleutherAI/gpt-neox-20b,128,1,2463.0,1.0,1,H100,1697105204251,1697105206714.0,120,31.0,1.0,"[13, 2450]","[1697105204264, 1697105206714]"
1889,378,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105238408.0,120,,,[22],[1697105236806]
1890,572,15,[],200,EleutherAI/gpt-neox-20b,128,1,1153.0,1.0,1,H100,1697105206715,1697105207868.0,120,16.0,1.0,"[13, 1139]","[1697105206728, 1697105207867]"
1891,164,34,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105252012,1697105253681.0,120,15.0,1.0,"[29, 1640]","[1697105252041, 1697105253681]"
1892,860,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105229653,1697105232145.0,120,,,"[8, 1844, 76, 75, 73, 74]","[1697105229661, 1697105231505, 1697105231581, 1697105231656, 1697105231729, 1697105231803]"
1893,733,21,[],200,EleutherAI/gpt-neox-20b,128,1,1854.0,1.0,1,H100,1697105238412,1697105240266.0,120,31.0,1.0,"[268, 1586]","[1697105238680, 1697105240266]"
1894,926,16,[],200,EleutherAI/gpt-neox-20b,128,1,7956.0,1.0,1,H100,1697105207869,1697105215825.0,120,563.0,30.0,"[16, 2919, 84, 426, 168, 77, 457, 89, 79, 80, 74, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 64, 76, 652, 85, 356, 90]","[1697105207885, 1697105210804, 1697105210888, 1697105211314, 1697105211482, 1697105211559, 1697105212016, 1697105212105, 1697105212184, 1697105212264, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825]"
1895,524,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253687,1697105255028.0,120,,,[83],[1697105253770]
1896,551,7,[],200,EleutherAI/gpt-neox-20b,128,1,6210.0,1.0,1,H100,1697105185473,1697105191683.0,120,90.0,20.0,"[5, 2970, 94, 164, 81, 375, 87, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 166]","[1697105185478, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191683]"
1897,382,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232151,1697105234225.0,120,,,[124],[1697105232275]
1898,285,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230476.0,120,,,[44],[1697105228825]
1899,740,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234226,1697105236781.0,120,,,[4],[1697105234230]
1900,647,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105232146.0,120,,,[102],[1697105230580]
1901,170,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105238409.0,120,,,[114],[1697105236898]
1902,76,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232151,1697105234225.0,120,,,[128],[1697105232279]
1903,430,23,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105234226,1697105236002.0,120,15.0,1.0,"[24, 1752]","[1697105234250, 1697105236002]"
1904,756,30,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105243758,1697105245427.0,120,19.0,1.0,"[226, 1443]","[1697105243984, 1697105245427]"
1905,877,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236003,1697105238408.0,120,,,[15],[1697105236018]
1906,181,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245428,1697105247243.0,120,,,[41],[1697105245469]
1907,302,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238411,1697105240330.0,120,,,[96],[1697105238507]
1908,628,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248695.0,120,,,[39],[1697105247286]
1909,521,24,[],200,EleutherAI/gpt-neox-20b,128,1,1854.0,1.0,1,H100,1697105238412,1697105240266.0,120,18.0,1.0,"[260, 1594]","[1697105238672, 1697105240266]"
1910,42,36,[],200,EleutherAI/gpt-neox-20b,128,1,915.0,1.0,1,H100,1697105255030,1697105255945.0,120,10.0,1.0,"[17, 897]","[1697105255047, 1697105255944]"
1911,398,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105261431,1697105264082.0,120,,,[9],[1697105261440]
1912,403,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255948,1697105257114.0,120,,,[11],[1697105255959]
1913,757,40,[],200,EleutherAI/gpt-neox-20b,128,1,1778.0,1.0,1,H100,1697105264085,1697105265863.0,120,20.0,1.0,"[103, 1675]","[1697105264188, 1697105265863]"
1914,759,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105258907.0,120,,,[13],[1697105257131]
1915,53,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248698,1697105250348.0,120,,,[87],[1697105248785]
1916,188,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258915,1697105260463.0,120,,,[18],[1697105258933]
1917,186,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265864,1697105267795.0,120,,,[29],[1697105265893]
1918,541,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260467,1697105262307.0,120,,,[230],[1697105260697]
1919,543,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267800,1697105270302.0,120,,,[188],[1697105267988]
1920,414,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252037.0,120,,,[158],[1697105250509]
1921,874,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270308,1697105271972.0,120,,,[52],[1697105270360]
1922,773,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252042,1697105253712.0,120,,,[257],[1697105252299]
1923,176,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[274],[1697105253990]
1924,530,37,[],200,EleutherAI/gpt-neox-20b,128,1,2017.0,1.0,1,H100,1697105256013,1697105258030.0,120,26.0,1.0,"[72, 1945]","[1697105256085, 1697105258030]"
1925,302,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271976,1697105273585.0,120,,,[50],[1697105272026]
1926,656,45,[],200,EleutherAI/gpt-neox-20b,128,1,1543.0,1.0,1,H100,1697105273589,1697105275132.0,120,26.0,1.0,"[182, 1361]","[1697105273771, 1697105275132]"
1927,892,12,[],200,EleutherAI/gpt-neox-20b,128,1,6019.0,1.0,1,H100,1697105192405,1697105198424.0,120,87.0,20.0,"[17, 3059, 88, 115, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 327, 211, 117, 63]","[1697105192422, 1697105195481, 1697105195569, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198033, 1697105198244, 1697105198361, 1697105198424]"
1928,872,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262313,1697105264082.0,120,,,[194],[1697105262507]
1929,861,12,[],200,EleutherAI/gpt-neox-20b,128,1,2805.0,1.0,1,H100,1697105196467,1697105199272.0,120,10.0,1.0,"[13, 2791]","[1697105196480, 1697105199271]"
1930,304,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265928.0,120,,,[35],[1697105264120]
1931,141,9,[],200,EleutherAI/gpt-neox-20b,128,1,5515.0,1.0,1,H100,1697105187799,1697105193314.0,120,89.0,20.0,"[4, 2790, 88, 250, 66, 87, 67, 366, 162, 87, 281, 82, 276, 75, 286, 87, 83, 234, 82, 62]","[1697105187803, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191151, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192405, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314]"
1932,411,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234883,1697105236781.0,120,,,[29],[1697105234912]
1933,898,11,[],200,EleutherAI/gpt-neox-20b,128,1,1893.0,1.0,1,H100,1697105206084,1697105207977.0,120,79.0,2.0,"[50, 1843]","[1697105206134, 1697105207977]"
1934,320,12,[],200,EleutherAI/gpt-neox-20b,128,1,9076.0,1.0,1,H100,1697105207978,1697105217054.0,120,109.0,36.0,"[8, 3328, 168, 77, 456, 89, 80, 80, 74, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 65, 75, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246, 85, 65]","[1697105207986, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212264, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054]"
1935,765,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105238409.0,120,,,[110],[1697105236894]
1936,197,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238412,1697105240331.0,120,,,[183],[1697105238595]
1937,556,28,[],200,EleutherAI/gpt-neox-20b,128,1,1596.0,1.0,1,H100,1697105240334,1697105241930.0,120,9.0,1.0,"[158, 1438]","[1697105240492, 1697105241930]"
1938,917,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241931,1697105243754.0,120,,,[9],[1697105241940]
1939,429,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243757,1697105245502.0,120,,,[131],[1697105243888]
1940,788,31,[],200,EleutherAI/gpt-neox-20b,128,1,1662.0,1.0,1,H100,1697105245506,1697105247168.0,120,31.0,1.0,"[195, 1467]","[1697105245701, 1697105247168]"
1941,664,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265933,1697105271973.0,120,,,"[153, 2892, 668, 705, 685]","[1697105266086, 1697105268978, 1697105269646, 1697105270351, 1697105271036]"
1942,213,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247169,1697105248696.0,120,,,[9],[1697105247178]
1943,897,29,[],200,EleutherAI/gpt-neox-20b,128,1,1443.0,1.0,1,H100,1697105237896,1697105239339.0,120,9.0,1.0,"[8, 1434]","[1697105237904, 1697105239338]"
1944,573,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105250348.0,120,,,[25],[1697105248724]
1945,87,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247252,1697105250347.0,120,,,[231],[1697105247483]
1946,328,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105239340,1697105241994.0,120,,,[13],[1697105239353]
1947,856,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105213151,1697105220994.0,120,,,"[12, 2132, 85, 355, 90, 84, 510, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 88, 81, 256, 79, 368, 81, 59, 366, 89, 75, 259, 62, 234, 79, 229, 81, 198]","[1697105213163, 1697105215295, 1697105215380, 1697105215735, 1697105215825, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
1948,606,7,[],200,EleutherAI/gpt-neox-20b,128,1,1573.0,1.0,1,H100,1697105179499,1697105181072.0,120,9.0,1.0,"[5, 1568]","[1697105179504, 1697105181072]"
1949,557,9,[],200,EleutherAI/gpt-neox-20b,128,1,3225.0,1.0,1,H100,1697105198690,1697105201915.0,120,31.0,1.0,"[4, 3221]","[1697105198694, 1697105201915]"
1950,36,8,[],200,EleutherAI/gpt-neox-20b,128,1,5604.0,1.0,1,H100,1697105181073,1697105186677.0,120,457.0,20.0,"[4, 2677, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 88, 81, 411, 88]","[1697105181077, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186178, 1697105186589, 1697105186677]"
1951,441,36,[],200,EleutherAI/gpt-neox-20b,128,1,1661.0,1.0,1,H100,1697105250350,1697105252011.0,120,6.0,1.0,"[47, 1614]","[1697105250397, 1697105252011]"
1952,919,10,[],200,EleutherAI/gpt-neox-20b,128,1,1064.0,1.0,1,H100,1697105201916,1697105202980.0,120,14.0,1.0,"[8, 1056]","[1697105201924, 1697105202980]"
1953,494,16,[],200,EleutherAI/gpt-neox-20b,128,1,3614.0,1.0,1,H100,1697105207869,1697105211483.0,120,6.0,10.0,"[20, 1549, 77, 618, 86, 83, 502, 82, 429, 168]","[1697105207889, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211315, 1697105211483]"
1954,319,11,[],200,EleutherAI/gpt-neox-20b,128,1,1755.0,1.0,1,H100,1697105202982,1697105204737.0,120,31.0,1.0,"[36, 1719]","[1697105203018, 1697105204737]"
1955,800,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252012,1697105253711.0,120,,,[5],[1697105252017]
1956,827,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236781.0,120,,,[17],[1697105234939]
1957,17,10,[],200,EleutherAI/gpt-neox-20b,128,1,2911.0,1.0,1,H100,1697105196361,1697105199272.0,120,23.0,1.0,"[13, 2897]","[1697105196374, 1697105199271]"
1958,375,11,[],200,EleutherAI/gpt-neox-20b,128,1,6550.0,1.0,1,H100,1697105199272,1697105205822.0,120,874.0,17.0,"[5, 4441, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 389]","[1697105199277, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822]"
1959,823,17,[],200,EleutherAI/gpt-neox-20b,128,1,5420.0,1.0,1,H100,1697105211484,1697105216904.0,120,90.0,20.0,"[32, 2314, 94, 90, 89, 68, 246, 85, 65, 75, 653, 84, 356, 91, 83, 510, 89, 67, 83, 246]","[1697105211516, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215295, 1697105215379, 1697105215735, 1697105215826, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904]"
1960,678,12,[],200,EleutherAI/gpt-neox-20b,128,1,4238.0,1.0,1,H100,1697105204738,1697105208976.0,120,244.0,18.0,"[8, 2068, 89, 89, 86, 81, 79, 60, 61, 617, 87, 82, 83, 64, 434, 87, 84, 79]","[1697105204746, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207976, 1697105208063, 1697105208145, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976]"
1961,393,9,[],200,EleutherAI/gpt-neox-20b,128,1,6088.0,1.0,1,H100,1697105186678,1697105192766.0,120,182.0,22.0,"[4, 2481, 86, 85, 481, 90, 272, 165, 251, 87, 251, 66, 87, 66, 367, 166, 83, 281, 82, 275, 76, 286]","[1697105186682, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191683, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766]"
1962,753,10,[],200,EleutherAI/gpt-neox-20b,128,1,5657.0,1.0,1,H100,1697105192767,1697105198424.0,120,83.0,20.0,"[4, 2710, 88, 115, 84, 174, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 327, 211, 117, 63]","[1697105192771, 1697105195481, 1697105195569, 1697105195684, 1697105195768, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198033, 1697105198244, 1697105198361, 1697105198424]"
1963,806,10,[],200,EleutherAI/gpt-neox-20b,128,1,5108.0,1.0,1,H100,1697105193316,1697105198424.0,120,89.0,20.0,"[4, 2162, 87, 115, 84, 175, 417, 282, 189, 259, 85, 62, 151, 159, 82, 77, 326, 212, 117, 63]","[1697105193320, 1697105195482, 1697105195569, 1697105195684, 1697105195768, 1697105195943, 1697105196360, 1697105196642, 1697105196831, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424]"
1964,252,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225400,1697105228772.0,120,,,"[4, 2507, 93, 84, 84, 83]","[1697105225404, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
1965,296,4,[],200,EleutherAI/gpt-neox-20b,128,1,1461.0,1.0,1,H100,1697105176271,1697105177732.0,120,6.0,1.0,"[45, 1416]","[1697105176316, 1697105177732]"
1966,711,15,[],200,EleutherAI/gpt-neox-20b,128,1,2942.0,1.0,1,H100,1697105207360,1697105210302.0,120,457.0,4.0,"[8, 2765, 87, 82]","[1697105207368, 1697105210133, 1697105210220, 1697105210302]"
1967,660,5,[],200,EleutherAI/gpt-neox-20b,128,1,6192.0,1.0,1,H100,1697105177733,1697105183925.0,120,732.0,25.0,"[13, 2356, 85, 67, 279, 79, 75, 489, 80, 80, 387, 87, 76, 408, 89, 83, 384, 89, 88, 190, 87, 78, 372, 86, 85]","[1697105177746, 1697105180102, 1697105180187, 1697105180254, 1697105180533, 1697105180612, 1697105180687, 1697105181176, 1697105181256, 1697105181336, 1697105181723, 1697105181810, 1697105181886, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925]"
1968,386,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105234919.0,120,,,"[123, 2455, 600, 617]","[1697105230601, 1697105233056, 1697105233656, 1697105234273]"
1969,139,16,[],200,EleutherAI/gpt-neox-20b,128,1,6116.0,1.0,1,H100,1697105210303,1697105216419.0,120,39.0,21.0,"[9, 2579, 88, 89, 82, 75, 606, 93, 90, 89, 68, 246, 85, 65, 75, 652, 85, 356, 90, 84, 510]","[1697105210312, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213831, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215909, 1697105216419]"
1970,710,24,[],200,EleutherAI/gpt-neox-20b,128,1,1833.0,1.0,1,H100,1697105234923,1697105236756.0,120,14.0,1.0,"[68, 1765]","[1697105234991, 1697105236756]"
1971,135,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236757,1697105238408.0,120,,,[24],[1697105236781]
1972,395,10,[],200,EleutherAI/gpt-neox-20b,128,1,5399.0,1.0,1,H100,1697105206084,1697105211483.0,120,88.0,20.0,"[17, 1876, 86, 83, 82, 64, 434, 87, 84, 79, 77, 385, 77, 619, 85, 83, 502, 82, 428, 168]","[1697105206101, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210134, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482]"
1973,495,26,[],200,EleutherAI/gpt-neox-20b,128,1,1854.0,1.0,1,H100,1697105238411,1697105240265.0,120,13.0,1.0,"[23, 1831]","[1697105238434, 1697105240265]"
1974,852,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240267,1697105241994.0,120,,,[20],[1697105240287]
1975,288,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243753.0,120,,,[70],[1697105242071]
1976,618,29,[],200,EleutherAI/gpt-neox-20b,128,1,2438.0,1.0,1,H100,1697105243758,1697105246196.0,120,9.0,1.0,"[250, 2188]","[1697105244008, 1697105246196]"
1977,47,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105246197,1697105248695.0,120,,,[5],[1697105246202]
1978,401,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248697,1697105250348.0,120,,,[76],[1697105248773]
1979,757,32,[],200,EleutherAI/gpt-neox-20b,128,1,1660.0,1.0,1,H100,1697105250351,1697105252011.0,120,20.0,1.0,"[118, 1542]","[1697105250469, 1697105252011]"
1980,185,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252012,1697105253711.0,120,,,[13],[1697105252025]
1981,631,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253715,1697105255028.0,120,,,[166],[1697105253881]
1982,67,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255031,1697105257114.0,120,,,[169],[1697105255200]
1983,425,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258920.0,120,,,[54],[1697105257171]
1984,748,7,[],200,EleutherAI/gpt-neox-20b,128,1,3587.0,1.0,1,H100,1697105181811,1697105185398.0,120,182.0,14.0,"[4, 1939, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363]","[1697105181815, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398]"
1985,784,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258926,1697105262306.0,120,,,[268],[1697105259194]
1986,209,38,[],200,EleutherAI/gpt-neox-20b,128,1,1680.0,1.0,1,H100,1697105262310,1697105263990.0,120,20.0,1.0,"[25, 1655]","[1697105262335, 1697105263990]"
1987,743,17,[],200,EleutherAI/gpt-neox-20b,128,1,2922.0,1.0,1,H100,1697105210303,1697105213225.0,120,123.0,6.0,"[5, 2583, 88, 89, 82, 75]","[1697105210308, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225]"
1988,534,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263991,1697105265927.0,120,,,[9],[1697105264000]
1989,894,40,[],200,EleutherAI/gpt-neox-20b,128,1,1841.0,1.0,1,H100,1697105265931,1697105267772.0,120,14.0,1.0,"[70, 1771]","[1697105266001, 1697105267772]"
1990,325,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267773,1697105271973.0,120,,,"[9, 1196, 669, 704, 685]","[1697105267782, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
1991,363,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105224662,1697105228773.0,120,,,"[17, 1573, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105224679, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
1992,688,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271976,1697105273585.0,120,,,[122],[1697105272098]
1993,87,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273589,1697105275208.0,120,,,[194],[1697105273783]
1994,179,8,[],200,EleutherAI/gpt-neox-20b,128,1,3307.0,1.0,1,H100,1697105185399,1697105188706.0,120,161.0,4.0,"[5, 3044, 94, 164]","[1697105185404, 1697105188448, 1697105188542, 1697105188706]"
1995,755,11,[],200,EleutherAI/gpt-neox-20b,128,1,6132.0,1.0,1,H100,1697105211484,1697105217616.0,120,286.0,25.0,"[16, 2330, 94, 90, 89, 68, 246, 85, 64, 76, 653, 84, 356, 91, 83, 510, 89, 67, 83, 246, 85, 65, 386, 89, 87]","[1697105211500, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642, 1697105215295, 1697105215379, 1697105215735, 1697105215826, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616]"
1996,782,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105195768,1697105201998.0,120,,,"[5, 2916, 273, 410, 224, 231, 129, 150, 140, 81, 79, 220, 296, 80, 292, 160, 212]","[1697105195773, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
1997,853,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241994.0,120,,,[165],[1697105240499]
1998,423,9,[],200,EleutherAI/gpt-neox-20b,128,1,5658.0,1.0,1,H100,1697105192048,1697105197706.0,120,84.0,20.0,"[9, 2679, 80, 79, 260, 326, 87, 116, 83, 176, 417, 282, 189, 259, 85, 62, 152, 158, 82, 77]","[1697105192057, 1697105194736, 1697105194816, 1697105194895, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195943, 1697105196360, 1697105196642, 1697105196831, 1697105197090, 1697105197175, 1697105197237, 1697105197389, 1697105197547, 1697105197629, 1697105197706]"
1999,282,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242000,1697105243753.0,120,,,[87],[1697105242087]
2000,660,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241994.0,120,,,[182],[1697105240516]
2001,93,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242000,1697105243754.0,120,,,[99],[1697105242099]
2002,846,14,[],200,EleutherAI/gpt-neox-20b,128,1,3352.0,1.0,1,H100,1697105203807,1697105207159.0,120,140.0,6.0,"[5, 3001, 90, 89, 86, 80]","[1697105203812, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158]"
2003,616,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105191340,1697105201999.0,120,,,"[11, 3038, 64, 84, 199, 80, 79, 260, 327, 86, 116, 84, 175, 417, 282, 189, 259, 85, 62, 151, 159, 82, 77, 326, 212, 117, 63, 265, 273, 410, 224, 231, 129, 150, 140, 81, 79, 219, 297, 80, 292, 160, 212]","[1697105191351, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194895, 1697105195155, 1697105195482, 1697105195568, 1697105195684, 1697105195768, 1697105195943, 1697105196360, 1697105196642, 1697105196831, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200625, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
2004,514,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258911.0,120,,,[66],[1697105257183]
2005,448,9,[],200,EleutherAI/gpt-neox-20b,128,1,4731.0,1.0,1,H100,1697105189164,1697105193895.0,120,335.0,12.0,"[8, 3232, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189]","[1697105189172, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895]"
2006,31,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258918,1697105262305.0,120,,,[167],[1697105259085]
2007,389,35,[],200,EleutherAI/gpt-neox-20b,128,1,1680.0,1.0,1,H100,1697105262310,1697105263990.0,120,8.0,1.0,"[12, 1668]","[1697105262322, 1697105263990]"
2008,752,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263991,1697105265927.0,120,,,[13],[1697105264004]
2009,184,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265932,1697105267796.0,120,,,[77],[1697105266009]
2010,277,15,[],200,EleutherAI/gpt-neox-20b,128,1,2819.0,1.0,1,H100,1697105207160,1697105209979.0,120,18.0,1.0,"[4, 2815]","[1697105207164, 1697105209979]"
2011,637,16,[],200,EleutherAI/gpt-neox-20b,128,1,4587.0,1.0,1,H100,1697105209980,1697105214567.0,120,96.0,20.0,"[8, 2028, 89, 80, 79, 74, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 69, 245, 85, 65]","[1697105209988, 1697105212016, 1697105212105, 1697105212185, 1697105212264, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214172, 1697105214417, 1697105214502, 1697105214567]"
2012,924,12,[],200,EleutherAI/gpt-neox-20b,128,1,2145.0,1.0,1,H100,1697105202015,1697105204160.0,120,9.0,1.0,"[188, 1957]","[1697105202203, 1697105204160]"
2013,352,13,[],200,EleutherAI/gpt-neox-20b,128,1,2742.0,1.0,1,H100,1697105204161,1697105206903.0,120,11.0,3.0,"[20, 2533, 100, 89]","[1697105204181, 1697105206714, 1697105206814, 1697105206903]"
2014,707,14,[],200,EleutherAI/gpt-neox-20b,128,1,963.0,1.0,1,H100,1697105206905,1697105207868.0,120,8.0,1.0,"[4, 959]","[1697105206909, 1697105207868]"
2015,512,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105270302.0,120,,,[184],[1697105267985]
2016,133,15,[],200,EleutherAI/gpt-neox-20b,128,1,2110.0,1.0,1,H100,1697105207869,1697105209979.0,120,15.0,1.0,"[24, 2086]","[1697105207893, 1697105209979]"
2017,868,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270308,1697105271973.0,120,,,[73],[1697105270381]
2018,292,13,[],200,EleutherAI/gpt-neox-20b,128,1,3708.0,1.0,1,H100,1697105199272,1697105202980.0,120,286.0,1.0,"[9, 3699]","[1697105199281, 1697105202980]"
2019,491,16,[],200,EleutherAI/gpt-neox-20b,128,1,1943.0,1.0,1,H100,1697105209980,1697105211923.0,120,14.0,1.0,"[20, 1923]","[1697105210000, 1697105211923]"
2020,821,17,[],200,EleutherAI/gpt-neox-20b,128,1,4981.0,1.0,1,H100,1697105211924,1697105216905.0,120,85.0,20.0,"[13, 1894, 93, 90, 89, 68, 246, 85, 65, 75, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246]","[1697105211937, 1697105213831, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904]"
2021,651,14,[],200,EleutherAI/gpt-neox-20b,128,1,1941.0,1.0,1,H100,1697105202981,1697105204922.0,120,457.0,2.0,"[17, 1924]","[1697105202998, 1697105204922]"
2022,171,15,[],200,EleutherAI/gpt-neox-20b,128,1,1791.0,1.0,1,H100,1697105204923,1697105206714.0,120,6.0,1.0,"[5, 1786]","[1697105204928, 1697105206714]"
2023,528,16,[],200,EleutherAI/gpt-neox-20b,128,1,5549.0,1.0,1,H100,1697105206715,1697105212264.0,120,52.0,20.0,"[25, 1986, 87, 84, 79, 78, 384, 77, 618, 86, 83, 502, 82, 428, 169, 76, 456, 89, 80, 79]","[1697105206740, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209054, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211483, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263]"
2024,502,10,[],200,EleutherAI/gpt-neox-20b,128,1,2076.0,1.0,1,H100,1697105193316,1697105195392.0,120,19.0,1.0,"[4, 2072]","[1697105193320, 1697105195392]"
2025,865,11,[],200,EleutherAI/gpt-neox-20b,128,1,2767.0,1.0,1,H100,1697105195393,1697105198160.0,120,9.0,1.0,"[24, 2743]","[1697105195417, 1697105198160]"
2026,294,12,[],200,EleutherAI/gpt-neox-20b,128,1,2762.0,1.0,1,H100,1697105198161,1697105200923.0,120,9.0,2.0,"[5, 2756]","[1697105198166, 1697105200922]"
2027,647,13,[],200,EleutherAI/gpt-neox-20b,128,1,5159.0,1.0,1,H100,1697105200923,1697105206082.0,120,83.0,20.0,"[9, 2786, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84]","[1697105200932, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
2028,5,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252037.0,120,,,[142],[1697105250493]
2029,777,10,[],200,EleutherAI/gpt-neox-20b,128,1,1496.0,1.0,1,H100,1697105193896,1697105195392.0,120,9.0,1.0,"[5, 1491]","[1697105193901, 1697105195392]"
2030,667,11,[],200,EleutherAI/gpt-neox-20b,128,1,4367.0,1.0,1,H100,1697105201455,1697105205822.0,120,364.0,17.0,"[9, 2254, 88, 88, 87, 269, 87, 86, 84, 415, 93, 88, 88, 69, 87, 86, 389]","[1697105201464, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822]"
2031,682,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243754.0,120,,,[102],[1697105242103]
2032,107,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243756,1697105245502.0,120,,,[47],[1697105243803]
2033,337,35,[],200,EleutherAI/gpt-neox-20b,128,1,1641.0,1.0,1,H100,1697105252041,1697105253682.0,120,12.0,1.0,"[137, 1504]","[1697105252178, 1697105253682]"
2034,211,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105195395,1697105201999.0,120,,,"[23, 3954, 224, 231, 129, 150, 140, 81, 79, 220, 296, 80, 292, 160, 213]","[1697105195418, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201667]"
2035,696,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253685,1697105255027.0,120,,,[33],[1697105253718]
2036,120,37,[],200,EleutherAI/gpt-neox-20b,128,1,916.0,1.0,1,H100,1697105255029,1697105255945.0,120,17.0,1.0,"[5, 910]","[1697105255034, 1697105255944]"
2037,475,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255948,1697105257114.0,120,,,[11],[1697105255959]
2038,466,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105247242.0,120,,,[18],[1697105245524]
2039,798,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248695.0,120,,,[63],[1697105247310]
2040,834,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105258913.0,120,,,[77],[1697105257195]
2041,572,12,[],200,EleutherAI/gpt-neox-20b,128,1,1615.0,1.0,1,H100,1697105202011,1697105203626.0,120,16.0,1.0,"[164, 1451]","[1697105202175, 1697105203626]"
2042,233,40,[],200,EleutherAI/gpt-neox-20b,128,1,1517.0,1.0,1,H100,1697105258921,1697105260438.0,120,6.0,1.0,"[176, 1341]","[1697105259097, 1697105260438]"
2043,599,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260439,1697105262307.0,120,,,[33],[1697105260472]
2044,1,13,[],200,EleutherAI/gpt-neox-20b,128,1,9523.0,1.0,1,H100,1697105203627,1697105213150.0,120,47.0,43.0,"[32, 2164, 90, 85, 84, 731, 90, 89, 86, 80, 80, 60, 61, 618, 86, 83, 82, 64, 434, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 82, 428, 168, 77, 456, 89, 80, 79, 75, 71, 482, 88, 89, 82]","[1697105203659, 1697105205823, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212409, 1697105212891, 1697105212979, 1697105213068, 1697105213150]"
2045,97,12,[],200,EleutherAI/gpt-neox-20b,128,1,3615.0,1.0,1,H100,1697105205823,1697105209438.0,120,6.0,20.0,"[9, 982, 89, 89, 86, 81, 79, 60, 61, 618, 86, 82, 83, 64, 434, 87, 84, 79, 77, 385]","[1697105205832, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438]"
2046,227,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248697,1697105250348.0,120,,,[44],[1697105248741]
2047,29,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262312,1697105264083.0,120,,,[99],[1697105262411]
2048,387,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264087,1697105265928.0,120,,,[17],[1697105264104]
2049,717,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265932,1697105271973.0,120,,,"[145, 2900, 669, 705, 685]","[1697105266077, 1697105268977, 1697105269646, 1697105270351, 1697105271036]"
2050,589,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252037.0,120,,,[146],[1697105250497]
2051,14,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253712.0,120,,,[61],[1697105252102]
2052,917,11,[],200,EleutherAI/gpt-neox-20b,128,1,3087.0,1.0,1,H100,1697105195157,1697105198244.0,120,123.0,2.0,"[12, 3075]","[1697105195169, 1697105198244]"
2053,373,38,[],200,EleutherAI/gpt-neox-20b,128,1,2229.0,1.0,1,H100,1697105253716,1697105255945.0,120,15.0,1.0,"[290, 1938]","[1697105254006, 1697105255944]"
2054,647,11,[],200,EleutherAI/gpt-neox-20b,128,1,4177.0,1.0,1,H100,1697105205261,1697105209438.0,120,83.0,20.0,"[4, 1549, 89, 89, 86, 81, 79, 60, 61, 618, 86, 82, 83, 64, 434, 87, 84, 79, 77, 385]","[1697105205265, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438]"
2055,344,28,[],200,EleutherAI/gpt-neox-20b,128,1,2017.0,1.0,1,H100,1697105256013,1697105258030.0,120,13.0,1.0,"[177, 1840]","[1697105256190, 1697105258030]"
2056,320,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105198245,1697105201999.0,120,,,"[5, 3044, 160, 213]","[1697105198250, 1697105201294, 1697105201454, 1697105201667]"
2057,9,8,[],200,EleutherAI/gpt-neox-20b,128,1,6249.0,1.0,1,H100,1697105184902,1697105191151.0,120,85.0,20.0,"[17, 2879, 89, 561, 94, 164, 81, 376, 86, 86, 480, 90, 272, 165, 251, 88, 250, 66, 87, 67]","[1697105184919, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189163, 1697105189249, 1697105189335, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191151]"
2058,698,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255946,1697105257114.0,120,,,[7],[1697105255953]
2059,131,40,[],200,EleutherAI/gpt-neox-20b,128,1,1732.0,1.0,1,H100,1697105257118,1697105258850.0,120,8.0,1.0,"[150, 1582]","[1697105257268, 1697105258850]"
2060,670,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105196361,1697105201999.0,120,,,"[9, 3457, 129, 150, 140, 81, 79, 220, 296, 80, 292, 160, 213]","[1697105196370, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201667]"
2061,465,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252036.0,120,,,[21],[1697105250372]
2062,153,11,[],200,EleutherAI/gpt-neox-20b,128,1,3242.0,1.0,1,H100,1697105198425,1697105201667.0,120,335.0,4.0,"[5, 2864, 160, 213]","[1697105198430, 1697105201294, 1697105201454, 1697105201667]"
2063,797,33,[],200,EleutherAI/gpt-neox-20b,128,1,1641.0,1.0,1,H100,1697105252041,1697105253682.0,120,26.0,1.0,"[48, 1593]","[1697105252089, 1697105253682]"
2064,514,12,[],200,EleutherAI/gpt-neox-20b,128,1,4414.0,1.0,1,H100,1697105201668,1697105206082.0,120,85.0,20.0,"[4, 2046, 88, 88, 87, 269, 87, 87, 83, 415, 93, 88, 88, 69, 87, 86, 389, 91, 85, 84]","[1697105201672, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
2065,819,5,[],200,EleutherAI/gpt-neox-20b,128,1,1279.0,1.0,1,H100,1697105182384,1697105183663.0,120,13.0,1.0,"[4, 1275]","[1697105182388, 1697105183663]"
2066,227,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253685,1697105255027.0,120,,,[29],[1697105253714]
2067,101,12,[],200,EleutherAI/gpt-neox-20b,128,1,2150.0,1.0,1,H100,1697105202010,1697105204160.0,120,13.0,1.0,"[177, 1973]","[1697105202187, 1697105204160]"
2068,458,13,[],200,EleutherAI/gpt-neox-20b,128,1,2553.0,1.0,1,H100,1697105204161,1697105206714.0,120,11.0,1.0,"[20, 2533]","[1697105204181, 1697105206714]"
2069,816,14,[],200,EleutherAI/gpt-neox-20b,128,1,2182.0,1.0,1,H100,1697105206715,1697105208897.0,120,182.0,4.0,"[9, 2002, 87, 84]","[1697105206724, 1697105208726, 1697105208813, 1697105208897]"
2070,217,15,[],200,EleutherAI/gpt-neox-20b,128,1,5274.0,1.0,1,H100,1697105208898,1697105214172.0,120,85.0,20.0,"[8, 2409, 167, 77, 456, 89, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68]","[1697105208906, 1697105211315, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171]"
2071,588,10,[],200,EleutherAI/gpt-neox-20b,128,1,2780.0,1.0,1,H100,1697105198425,1697105201205.0,120,11.0,1.0,"[21, 2759]","[1697105198446, 1697105201205]"
2072,581,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255029,1697105256009.0,120,,,[10],[1697105255039]
2073,784,5,[],200,EleutherAI/gpt-neox-20b,128,1,5402.0,1.0,1,H100,1697105183305,1697105188707.0,120,89.0,20.0,"[4, 2089, 74, 537, 88, 83, 408, 88, 79, 78, 59, 281, 83, 83, 83, 376, 89, 561, 94, 164]","[1697105183309, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186180, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892, 1697105187173, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706]"
2074,7,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256011,1697105258907.0,120,,,[7],[1697105256018]
2075,365,37,[],200,EleutherAI/gpt-neox-20b,128,1,1522.0,1.0,1,H100,1697105258916,1697105260438.0,120,23.0,1.0,"[61, 1461]","[1697105258977, 1697105260438]"
2076,155,11,[],200,EleutherAI/gpt-neox-20b,128,1,5301.0,1.0,1,H100,1697105192405,1697105197706.0,120,90.0,20.0,"[5, 2326, 80, 79, 261, 325, 87, 116, 83, 176, 417, 282, 184, 264, 85, 62, 152, 158, 82, 77]","[1697105192410, 1697105194736, 1697105194816, 1697105194895, 1697105195156, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195943, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197389, 1697105197547, 1697105197629, 1697105197706]"
2077,499,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105216420,1697105220995.0,120,,,"[4, 2976, 89, 75, 259, 62, 234, 79, 229, 81, 198]","[1697105216424, 1697105219400, 1697105219489, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
2078,697,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260439,1697105262307.0,120,,,[12],[1697105260451]
2079,128,39,[],200,EleutherAI/gpt-neox-20b,128,1,1677.0,1.0,1,H100,1697105262313,1697105263990.0,120,9.0,1.0,"[190, 1487]","[1697105262503, 1697105263990]"
2080,788,14,[],200,EleutherAI/gpt-neox-20b,128,1,2157.0,1.0,1,H100,1697105211484,1697105213641.0,120,31.0,1.0,"[24, 2133]","[1697105211508, 1697105213641]"
2081,191,15,[],200,EleutherAI/gpt-neox-20b,128,1,5253.0,1.0,1,H100,1697105213642,1697105218895.0,120,85.0,20.0,"[5, 2088, 91, 83, 510, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 81, 258, 78, 368]","[1697105213647, 1697105215735, 1697105215826, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218190, 1697105218448, 1697105218526, 1697105218894]"
2082,489,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263991,1697105265927.0,120,,,[33],[1697105264024]
2083,828,18,[],200,EleutherAI/gpt-neox-20b,128,1,2006.0,1.0,1,H100,1697105220996,1697105223002.0,120,182.0,6.0,"[44, 1627, 87, 84, 83, 81]","[1697105221040, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002]"
2084,256,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105223003,1697105228773.0,120,,,"[5, 2231, 82, 77, 75, 74, 706, 90, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105223008, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225547, 1697105226253, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2085,615,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230475.0,120,,,[129],[1697105228910]
2086,41,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105232145.0,120,,,[45],[1697105230523]
2087,404,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232153,1697105234225.0,120,,,[218],[1697105232371]
2088,509,12,[],200,EleutherAI/gpt-neox-20b,128,1,3295.0,1.0,1,H100,1697105197707,1697105201002.0,120,286.0,3.0,"[8, 3207, 80]","[1697105197715, 1697105200922, 1697105201002]"
2089,732,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234226,1697105236781.0,120,,,[8],[1697105234234]
2090,550,16,[],200,EleutherAI/gpt-neox-20b,128,1,5765.0,1.0,1,H100,1697105218895,1697105224660.0,120,91.0,20.0,"[9, 3061, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 84, 82, 351, 91, 70, 88, 87, 68]","[1697105218904, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223823, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
2091,91,6,[],200,EleutherAI/gpt-neox-20b,128,1,2556.0,1.0,1,H100,1697105183926,1697105186482.0,120,23.0,1.0,"[5, 2551]","[1697105183931, 1697105186482]"
2092,863,13,[],200,EleutherAI/gpt-neox-20b,128,1,1976.0,1.0,1,H100,1697105201004,1697105202980.0,120,10.0,1.0,"[4, 1972]","[1697105201008, 1697105202980]"
2093,294,14,[],200,EleutherAI/gpt-neox-20b,128,1,1270.0,1.0,1,H100,1697105202981,1697105204251.0,120,9.0,2.0,"[13, 1256]","[1697105202994, 1697105204250]"
2094,654,15,[],200,EleutherAI/gpt-neox-20b,128,1,2741.0,1.0,1,H100,1697105204251,1697105206992.0,120,47.0,4.0,"[9, 2553, 90, 89]","[1697105204260, 1697105206813, 1697105206903, 1697105206992]"
2095,173,16,[],200,EleutherAI/gpt-neox-20b,128,1,6075.0,1.0,1,H100,1697105206993,1697105213068.0,120,96.0,20.0,"[5, 2440, 77, 618, 86, 83, 502, 82, 429, 168, 76, 457, 88, 80, 79, 75, 72, 481, 88, 89]","[1697105206998, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211315, 1697105211483, 1697105211559, 1697105212016, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068]"
2096,419,7,[],200,EleutherAI/gpt-neox-20b,128,1,5921.0,1.0,1,H100,1697105186483,1697105192404.0,120,88.0,20.0,"[5, 2675, 86, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 166, 83, 281, 82, 275]","[1697105186488, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191683, 1697105191766, 1697105192047, 1697105192129, 1697105192404]"
2097,533,17,[],200,EleutherAI/gpt-neox-20b,128,1,2226.0,1.0,1,H100,1697105213069,1697105215295.0,120,216.0,2.0,"[4, 2221]","[1697105213073, 1697105215294]"
2098,574,16,[],200,EleutherAI/gpt-neox-20b,128,1,2732.0,1.0,1,H100,1697105214173,1697105216905.0,120,364.0,2.0,"[12, 2719]","[1697105214185, 1697105216904]"
2099,911,17,[],200,EleutherAI/gpt-neox-20b,128,1,3249.0,1.0,1,H100,1697105224662,1697105227911.0,120,335.0,11.0,"[25, 1565, 91, 85, 65, 84, 486, 91, 89, 85, 583]","[1697105224687, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911]"
2100,173,18,[],200,EleutherAI/gpt-neox-20b,128,1,5668.0,1.0,1,H100,1697105213226,1697105218894.0,120,96.0,20.0,"[13, 2496, 91, 83, 510, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 88, 81, 257, 78, 368]","[1697105213239, 1697105215735, 1697105215826, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218110, 1697105218191, 1697105218448, 1697105218526, 1697105218894]"
2101,866,10,[],200,EleutherAI/gpt-neox-20b,128,1,6019.0,1.0,1,H100,1697105192405,1697105198424.0,120,93.0,20.0,"[13, 3063, 88, 115, 83, 176, 417, 282, 184, 264, 85, 62, 151, 159, 82, 77, 327, 211, 117, 63]","[1697105192418, 1697105195481, 1697105195569, 1697105195684, 1697105195767, 1697105195943, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198033, 1697105198244, 1697105198361, 1697105198424]"
2102,210,12,[],200,EleutherAI/gpt-neox-20b,128,1,2240.0,1.0,1,H100,1697105202010,1697105204250.0,120,140.0,2.0,"[181, 2059]","[1697105202191, 1697105204250]"
2103,570,13,[],200,EleutherAI/gpt-neox-20b,128,1,2462.0,1.0,1,H100,1697105204252,1697105206714.0,120,18.0,1.0,"[16, 2446]","[1697105204268, 1697105206714]"
2104,531,19,[],200,EleutherAI/gpt-neox-20b,128,1,5765.0,1.0,1,H100,1697105218895,1697105224660.0,120,52.0,20.0,"[9, 3061, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105218904, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
2105,6,14,[],200,EleutherAI/gpt-neox-20b,128,1,7209.0,1.0,1,H100,1697105206715,1697105213924.0,120,100.0,29.0,"[17, 1994, 87, 84, 79, 78, 384, 77, 618, 86, 83, 502, 82, 428, 169, 76, 456, 89, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94]","[1697105206732, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209054, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211483, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924]"
2106,298,11,[],200,EleutherAI/gpt-neox-20b,128,1,3156.0,1.0,1,H100,1697105198426,1697105201582.0,120,17.0,1.0,"[30, 3126]","[1697105198456, 1697105201582]"
2107,628,12,[],200,EleutherAI/gpt-neox-20b,128,1,3339.0,1.0,1,H100,1697105201583,1697105204922.0,120,732.0,10.0,"[12, 2123, 88, 88, 87, 269, 87, 87, 83, 415]","[1697105201595, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922]"
2108,859,20,[],200,EleutherAI/gpt-neox-20b,128,1,1404.0,1.0,1,H100,1697105224662,1697105226066.0,120,23.0,1.0,"[13, 1390]","[1697105224675, 1697105226065]"
2109,51,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105213226,1697105220994.0,120,,,"[17, 3176, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 82, 257, 78, 368, 81, 59, 366, 88, 76, 259, 62, 234, 79, 229, 81, 198]","[1697105213243, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218448, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219488, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
2110,614,28,[],200,EleutherAI/gpt-neox-20b,128,1,1670.0,1.0,1,H100,1697105243757,1697105245427.0,120,15.0,1.0,"[143, 1527]","[1697105243900, 1697105245427]"
2111,41,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245428,1697105247243.0,120,,,[45],[1697105245473]
2112,53,13,[],200,EleutherAI/gpt-neox-20b,128,1,11496.0,1.0,1,H100,1697105204923,1697105216419.0,120,216.0,55.0,"[5, 1886, 89, 89, 86, 81, 79, 60, 61, 618, 86, 82, 83, 64, 434, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 82, 428, 168, 77, 456, 89, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 84, 65, 76, 652, 85, 356, 90, 83, 511]","[1697105204928, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214501, 1697105214566, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419]"
2113,880,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240267,1697105241994.0,120,,,[56],[1697105240323]
2114,289,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226069,1697105228772.0,120,,,[12],[1697105226081]
2115,280,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243754.0,120,,,[203],[1697105242204]
2116,641,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243758,1697105245501.0,120,,,[146],[1697105243904]
2117,647,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230475.0,120,,,[128],[1697105228909]
2118,77,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230477,1697105232145.0,120,,,"[29, 1000, 75, 75, 74, 73]","[1697105230506, 1697105231506, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
2119,435,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232151,1697105234225.0,120,,,[124],[1697105232275]
2120,879,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234226,1697105236781.0,120,,,[24],[1697105234250]
2121,304,8,[],200,EleutherAI/gpt-neox-20b,128,1,4080.0,1.0,1,H100,1697105202002,1697105206082.0,120,86.0,20.0,"[25, 1691, 88, 88, 87, 269, 87, 87, 83, 415, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84]","[1697105202027, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
2122,889,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258031,1697105260463.0,120,,,[8],[1697105258039]
2123,318,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260465,1697105262306.0,120,,,[119],[1697105260584]
2124,674,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262315,1697105265927.0,120,,,[301],[1697105262616]
2125,77,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267796.0,120,,,[50],[1697105265981]
2126,752,9,[],200,EleutherAI/gpt-neox-20b,128,1,1979.0,1.0,1,H100,1697105206084,1697105208063.0,120,39.0,3.0,"[45, 1848, 86]","[1697105206129, 1697105207977, 1697105208063]"
2127,183,10,[],200,EleutherAI/gpt-neox-20b,128,1,10830.0,1.0,1,H100,1697105208064,1697105218894.0,120,17.0,50.0,"[5, 2065, 86, 82, 502, 83, 428, 167, 77, 457, 89, 79, 80, 74, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 64, 76, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 81, 257, 79, 368]","[1697105208069, 1697105210134, 1697105210220, 1697105210302, 1697105210804, 1697105210887, 1697105211315, 1697105211482, 1697105211559, 1697105212016, 1697105212105, 1697105212184, 1697105212264, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218190, 1697105218447, 1697105218526, 1697105218894]"
2128,434,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267799,1697105269598.0,120,,,[105],[1697105267904]
2129,794,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[48],[1697105269648]
2130,222,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270990,1697105273585.0,120,,,[88],[1697105271078]
2131,579,45,[],200,EleutherAI/gpt-neox-20b,128,1,1543.0,1.0,1,H100,1697105273589,1697105275132.0,120,19.0,1.0,"[41, 1502]","[1697105273630, 1697105275132]"
2132,850,7,[],200,EleutherAI/gpt-neox-20b,128,1,5488.0,1.0,1,H100,1697105183218,1697105188706.0,120,109.0,20.0,"[8, 2172, 74, 537, 88, 81, 410, 88, 79, 78, 59, 281, 83, 83, 83, 376, 89, 561, 94, 164]","[1697105183226, 1697105185398, 1697105185472, 1697105186009, 1697105186097, 1697105186178, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892, 1697105187173, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706]"
2133,496,6,[],200,EleutherAI/gpt-neox-20b,128,1,3488.0,1.0,1,H100,1697105206814,1697105210302.0,120,335.0,11.0,"[5, 1907, 87, 84, 79, 78, 384, 77, 618, 86, 83]","[1697105206819, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209054, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302]"
2134,754,10,[],200,EleutherAI/gpt-neox-20b,128,1,4380.0,1.0,1,H100,1697105199957,1697105204337.0,120,88.0,7.0,"[5, 3756, 88, 88, 87, 269, 87]","[1697105199962, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337]"
2135,710,14,[],200,EleutherAI/gpt-neox-20b,128,1,1783.0,1.0,1,H100,1697105206084,1697105207867.0,120,14.0,1.0,"[5, 1778]","[1697105206089, 1697105207867]"
2136,156,11,[],200,EleutherAI/gpt-neox-20b,128,1,5100.0,1.0,1,H100,1697105204338,1697105209438.0,120,86.0,20.0,"[5, 2471, 89, 89, 86, 81, 79, 60, 61, 618, 86, 82, 83, 63, 435, 87, 84, 79, 77, 385]","[1697105204343, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438]"
2137,136,15,[],200,EleutherAI/gpt-neox-20b,128,1,2110.0,1.0,1,H100,1697105207869,1697105209979.0,120,31.0,1.0,"[24, 2086]","[1697105207893, 1697105209979]"
2138,797,15,[],200,EleutherAI/gpt-neox-20b,128,1,1825.0,1.0,1,H100,1697105206717,1697105208542.0,120,26.0,1.0,"[31, 1793]","[1697105206748, 1697105208541]"
2139,700,13,[],200,EleutherAI/gpt-neox-20b,128,1,8465.0,1.0,1,H100,1697105207360,1697105215825.0,120,140.0,33.0,"[16, 2758, 85, 83, 502, 82, 429, 167, 77, 457, 88, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 64, 76, 652, 85, 356, 90]","[1697105207376, 1697105210134, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211315, 1697105211482, 1697105211559, 1697105212016, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825]"
2140,192,16,[],200,EleutherAI/gpt-neox-20b,128,1,5628.0,1.0,1,H100,1697105208543,1697105214171.0,120,93.0,20.0,"[8, 2763, 168, 77, 456, 89, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68]","[1697105208551, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171]"
2141,494,16,[],200,EleutherAI/gpt-neox-20b,128,1,3089.0,1.0,1,H100,1697105209979,1697105213068.0,120,6.0,10.0,"[5, 2032, 88, 80, 79, 75, 72, 481, 88, 89]","[1697105209984, 1697105212016, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068]"
2142,884,17,[],200,EleutherAI/gpt-neox-20b,128,1,6183.0,1.0,1,H100,1697105212264,1697105218447.0,120,90.0,20.0,"[9, 3021, 85, 356, 90, 83, 511, 89, 66, 85, 246, 84, 66, 385, 89, 87, 406, 87, 82, 256]","[1697105212273, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216574, 1697105216659, 1697105216905, 1697105216989, 1697105217055, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218447]"
2143,229,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253715,1697105255028.0,120,,,[187],[1697105253902]
2144,848,17,[],200,EleutherAI/gpt-neox-20b,128,1,2114.0,1.0,1,H100,1697105213069,1697105215183.0,120,47.0,1.0,"[8, 2106]","[1697105213077, 1697105215183]"
2145,519,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105217617,1697105220996.0,120,,,"[5, 2498, 78, 229, 82, 197]","[1697105217622, 1697105220120, 1697105220198, 1697105220427, 1697105220509, 1697105220706]"
2146,284,8,[],200,EleutherAI/gpt-neox-20b,128,1,7061.0,1.0,1,H100,1697105188707,1697105195768.0,120,90.0,31.0,"[25, 2785, 166, 83, 281, 82, 275, 76, 286, 87, 82, 235, 82, 62, 306, 86, 189, 84, 64, 81, 265, 64, 84, 199, 80, 79, 260, 326, 87, 116, 83]","[1697105188732, 1697105191517, 1697105191683, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192935, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194895, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767]"
2147,365,18,[],200,EleutherAI/gpt-neox-20b,128,1,1628.0,1.0,1,H100,1697105215184,1697105216812.0,120,23.0,1.0,"[13, 1615]","[1697105215197, 1697105216812]"
2148,679,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[73],[1697105255103]
2149,231,18,[],200,EleutherAI/gpt-neox-20b,128,1,2553.0,1.0,1,H100,1697105236785,1697105239338.0,120,13.0,1.0,"[214, 2339]","[1697105236999, 1697105239338]"
2150,586,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105239340,1697105241995.0,120,,,[19],[1697105239359]
2151,726,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105216814,1697105220995.0,120,,,"[8, 2578, 85, 79, 260, 62, 233, 79, 229, 81, 198]","[1697105216822, 1697105219400, 1697105219485, 1697105219564, 1697105219824, 1697105219886, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
2152,734,12,[],200,EleutherAI/gpt-neox-20b,128,1,1336.0,1.0,1,H100,1697105205823,1697105207159.0,120,100.0,6.0,"[5, 986, 89, 89, 86, 81]","[1697105205828, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159]"
2153,138,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271977,1697105275207.0,120,,,[222],[1697105272199]
2154,309,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105218448,1697105220995.0,120,,,"[9, 1970, 81, 198]","[1697105218457, 1697105220427, 1697105220508, 1697105220706]"
2155,667,19,[],200,EleutherAI/gpt-neox-20b,128,1,4401.0,1.0,1,H100,1697105220998,1697105225399.0,120,364.0,17.0,"[106, 2299, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 580, 81, 78]","[1697105221104, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225240, 1697105225321, 1697105225399]"
2156,782,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105195157,1697105201998.0,120,,,"[8, 3524, 273, 410, 224, 231, 129, 150, 140, 81, 79, 219, 297, 80, 292, 160, 212]","[1697105195165, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200625, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
2157,162,13,[],200,EleutherAI/gpt-neox-20b,128,1,6065.0,1.0,1,H100,1697105207160,1697105213225.0,120,90.0,20.0,"[4, 2969, 86, 83, 502, 82, 429, 167, 77, 457, 88, 80, 79, 75, 72, 481, 88, 89, 82, 75]","[1697105207164, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211315, 1697105211482, 1697105211559, 1697105212016, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225]"
2158,253,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105216905,1697105220995.0,120,,,"[5, 2490, 86, 78, 259, 63, 233, 79, 229, 81, 198]","[1697105216910, 1697105219400, 1697105219486, 1697105219564, 1697105219823, 1697105219886, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
2159,698,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258031,1697105260463.0,120,,,[16],[1697105258047]
2160,612,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228778,1697105230475.0,120,,,[23],[1697105228801]
2161,490,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258851,1697105260463.0,120,,,[5],[1697105258856]
2162,848,42,[],200,EleutherAI/gpt-neox-20b,128,1,1775.0,1.0,1,H100,1697105260468,1697105262243.0,120,47.0,1.0,"[136, 1639]","[1697105260604, 1697105262243]"
2163,37,19,[],200,EleutherAI/gpt-neox-20b,128,1,829.0,1.0,1,H100,1697105230477,1697105231306.0,120,20.0,1.0,"[9, 820]","[1697105230486, 1697105231306]"
2164,390,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105231307,1697105234919.0,120,,,"[17, 1732, 600, 617]","[1697105231324, 1697105233056, 1697105233656, 1697105234273]"
2165,748,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105198426,1697105201999.0,120,,,"[16, 3225]","[1697105198442, 1697105201667]"
2166,836,21,[],200,EleutherAI/gpt-neox-20b,128,1,1834.0,1.0,1,H100,1697105234922,1697105236756.0,120,11.0,1.0,"[158, 1676]","[1697105235080, 1697105236756]"
2167,269,22,[],200,EleutherAI/gpt-neox-20b,128,1,1138.0,1.0,1,H100,1697105236757,1697105237895.0,120,11.0,1.0,"[20, 1118]","[1697105236777, 1697105237895]"
2168,173,11,[],200,EleutherAI/gpt-neox-20b,128,1,4078.0,1.0,1,H100,1697105202004,1697105206082.0,120,96.0,20.0,"[95, 1619, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 390, 90, 85, 84]","[1697105202099, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205823, 1697105205913, 1697105205998, 1697105206082]"
2169,276,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262244,1697105264082.0,120,,,[45],[1697105262289]
2170,632,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105237896,1697105240331.0,120,,,[21],[1697105237917]
2171,606,44,[],200,EleutherAI/gpt-neox-20b,128,1,1778.0,1.0,1,H100,1697105264085,1697105265863.0,120,9.0,1.0,"[10, 1768]","[1697105264095, 1697105265863]"
2172,493,14,[],200,EleutherAI/gpt-neox-20b,128,1,5668.0,1.0,1,H100,1697105213226,1697105218894.0,120,83.0,20.0,"[5, 2504, 91, 83, 510, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 88, 81, 257, 78, 368]","[1697105213231, 1697105215735, 1697105215826, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218110, 1697105218191, 1697105218448, 1697105218526, 1697105218894]"
2173,35,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265864,1697105267796.0,120,,,[5],[1697105265869]
2174,60,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241993.0,120,,,[145],[1697105240479]
2175,414,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242000,1697105243754.0,120,,,[23],[1697105242023]
2176,392,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105270302.0,120,,,[195],[1697105267996]
2177,124,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260465,1697105262306.0,120,,,[123],[1697105260588]
2178,135,11,[],200,EleutherAI/gpt-neox-20b,128,1,3360.0,1.0,1,H100,1697105196467,1697105199827.0,120,52.0,2.0,"[5, 3355]","[1697105196472, 1697105199827]"
2179,532,12,[],200,EleutherAI/gpt-neox-20b,128,1,5399.0,1.0,1,H100,1697105206084,1697105211483.0,120,92.0,20.0,"[25, 1868, 86, 83, 82, 64, 434, 87, 84, 79, 78, 384, 77, 619, 85, 83, 502, 82, 428, 168]","[1697105206109, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209054, 1697105209438, 1697105209515, 1697105210134, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482]"
2180,752,47,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270303,1697105271972.0,120,,,[33],[1697105270336]
2181,745,26,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105243758,1697105245427.0,120,17.0,1.0,"[210, 1459]","[1697105243968, 1697105245427]"
2182,268,48,[],200,EleutherAI/gpt-neox-20b,128,1,1579.0,1.0,1,H100,1697105271976,1697105273555.0,120,19.0,1.0,"[9, 1570]","[1697105271985, 1697105273555]"
2183,463,12,[],200,EleutherAI/gpt-neox-20b,128,1,3152.0,1.0,1,H100,1697105199828,1697105202980.0,120,39.0,1.0,"[5, 3147]","[1697105199833, 1697105202980]"
2184,814,13,[],200,EleutherAI/gpt-neox-20b,128,1,4378.0,1.0,1,H100,1697105202981,1697105207359.0,120,89.0,20.0,"[9, 1932, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84, 731, 90, 89, 86, 81, 79, 60, 61]","[1697105202990, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359]"
2185,482,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262314,1697105265927.0,120,,,[290],[1697105262604]
2186,170,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245428,1697105247242.0,120,,,[29],[1697105245457]
2187,530,28,[],200,EleutherAI/gpt-neox-20b,128,1,2430.0,1.0,1,H100,1697105247250,1697105249680.0,120,26.0,1.0,"[161, 2269]","[1697105247411, 1697105249680]"
2188,889,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105249681,1697105252037.0,120,,,[9],[1697105249690]
2189,293,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252039,1697105253711.0,120,,,[151],[1697105252190]
2190,647,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105255028.0,120,,,[92],[1697105253806]
2191,1,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267796.0,120,,,[13],[1697105265944]
2192,77,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[81],[1697105255111]
2193,361,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[9],[1697105267807]
2194,435,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105258913.0,120,,,[93],[1697105257211]
2195,627,49,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273556,1697105275207.0,120,,,[17],[1697105273573]
2196,790,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258920,1697105262305.0,120,,,[178],[1697105259098]
2197,721,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269599,1697105270302.0,120,,,[5],[1697105269604]
2198,919,11,[],200,EleutherAI/gpt-neox-20b,128,1,1774.0,1.0,1,H100,1697105201206,1697105202980.0,120,14.0,1.0,"[9, 1765]","[1697105201215, 1697105202980]"
2199,346,12,[],200,EleutherAI/gpt-neox-20b,128,1,4378.0,1.0,1,H100,1697105202981,1697105207359.0,120,85.0,20.0,"[17, 1924, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84, 732, 89, 89, 86, 81, 79, 60, 61]","[1697105202998, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359]"
2200,187,14,[],200,EleutherAI/gpt-neox-20b,128,1,3562.0,1.0,1,H100,1697105208542,1697105212104.0,120,161.0,6.0,"[5, 2767, 168, 77, 456, 89]","[1697105208547, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104]"
2201,893,13,[],200,EleutherAI/gpt-neox-20b,128,1,3158.0,1.0,1,H100,1697105211484,1697105214642.0,120,335.0,10.0,"[16, 2330, 94, 90, 89, 68, 246, 85, 64, 76]","[1697105211500, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642]"
2202,363,9,[],200,EleutherAI/gpt-neox-20b,128,1,5679.0,1.0,1,H100,1697105191152,1697105196831.0,120,286.0,22.0,"[8, 2460, 86, 189, 84, 64, 81, 265, 64, 84, 199, 80, 78, 261, 327, 87, 115, 84, 174, 418, 282, 186]","[1697105191160, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195482, 1697105195569, 1697105195684, 1697105195768, 1697105195942, 1697105196360, 1697105196642, 1697105196828]"
2203,164,24,[],200,EleutherAI/gpt-neox-20b,128,1,2554.0,1.0,1,H100,1697105236784,1697105239338.0,120,15.0,1.0,"[202, 2352]","[1697105236986, 1697105239338]"
2204,851,15,[],200,EleutherAI/gpt-neox-20b,128,1,2017.0,1.0,1,H100,1697105218896,1697105220913.0,120,23.0,1.0,"[16, 2001]","[1697105218912, 1697105220913]"
2205,536,9,[],200,EleutherAI/gpt-neox-20b,128,1,5417.0,1.0,1,H100,1697105188707,1697105194124.0,120,83.0,20.0,"[17, 2793, 162, 87, 281, 82, 275, 76, 286, 87, 82, 235, 82, 62, 306, 86, 189, 84, 64, 81]","[1697105188724, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192935, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124]"
2206,24,14,[],200,EleutherAI/gpt-neox-20b,128,1,2182.0,1.0,1,H100,1697105206715,1697105208897.0,120,79.0,9.0,"[5, 1257, 86, 83, 82, 64, 434, 87, 84]","[1697105206720, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897]"
2207,519,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105239340,1697105241995.0,120,,,[19],[1697105239359]
2208,877,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243754.0,120,,,[279],[1697105242280]
2209,302,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243758,1697105247242.0,120,,,[258],[1697105244016]
2210,749,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248695.0,120,,,[47],[1697105247294]
2211,181,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248698,1697105250348.0,120,,,[87],[1697105248785]
2212,326,14,[],200,EleutherAI/gpt-neox-20b,128,1,4921.0,1.0,1,H100,1697105214643,1697105219564.0,120,345.0,12.0,"[10, 3369, 88, 81, 256, 79, 368, 81, 59, 366, 89, 75]","[1697105214653, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564]"
2213,704,13,[],200,EleutherAI/gpt-neox-20b,128,1,2619.0,1.0,1,H100,1697105207360,1697105209979.0,120,14.0,1.0,"[12, 2606]","[1697105207372, 1697105209978]"
2214,129,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105209982,1697105220993.0,120,,,"[22, 2887, 88, 89, 82, 75, 606, 93, 90, 89, 68, 246, 85, 65, 75, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246, 85, 65, 386, 89, 87, 405, 88, 82, 256, 79, 368, 81, 59, 366, 84, 80, 259, 62, 234, 79, 228, 82, 198]","[1697105210004, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213831, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218021, 1697105218109, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219484, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220426, 1697105220508, 1697105220706]"
2215,840,2,[],200,EleutherAI/gpt-neox-20b,128,1,2201.0,1.0,1,H100,1697105169007,1697105171208.0,120,17.0,1.0,"[4, 2197]","[1697105169011, 1697105171208]"
2216,542,30,[],200,EleutherAI/gpt-neox-20b,128,1,1658.0,1.0,1,H100,1697105250353,1697105252011.0,120,11.0,1.0,"[220, 1438]","[1697105250573, 1697105252011]"
2217,239,3,[],200,EleutherAI/gpt-neox-20b,128,1,6897.0,1.0,1,H100,1697105171210,1697105178107.0,120,39.0,27.0,"[65, 2509, 80, 77, 72, 667, 93, 89, 68, 86, 84, 522, 98, 92, 89, 69, 88, 68, 69, 69, 759, 81, 81, 63, 674, 94, 91]","[1697105171275, 1697105173784, 1697105173864, 1697105173941, 1697105174013, 1697105174680, 1697105174773, 1697105174862, 1697105174930, 1697105175016, 1697105175100, 1697105175622, 1697105175720, 1697105175812, 1697105175901, 1697105175970, 1697105176058, 1697105176126, 1697105176195, 1697105176264, 1697105177023, 1697105177104, 1697105177185, 1697105177248, 1697105177922, 1697105178016, 1697105178107]"
2218,901,31,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105252012,1697105253681.0,120,17.0,1.0,"[33, 1636]","[1697105252045, 1697105253681]"
2219,798,15,[],200,EleutherAI/gpt-neox-20b,128,1,3883.0,1.0,1,H100,1697105214643,1697105218526.0,120,79.0,6.0,"[5, 3374, 88, 81, 256, 79]","[1697105214648, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526]"
2220,199,16,[],200,EleutherAI/gpt-neox-20b,128,1,1815.0,1.0,1,H100,1697105218528,1697105220343.0,120,13.0,1.0,"[4, 1811]","[1697105218532, 1697105220343]"
2221,553,17,[],200,EleutherAI/gpt-neox-20b,128,1,4316.0,1.0,1,H100,1697105220344,1697105224660.0,120,88.0,20.0,"[9, 1612, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105220353, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
2222,907,18,[],200,EleutherAI/gpt-neox-20b,128,1,1404.0,1.0,1,H100,1697105224662,1697105226066.0,120,10.0,1.0,"[25, 1379]","[1697105224687, 1697105226066]"
2223,496,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228005,1697105232145.0,120,,,"[9, 2501, 990, 76, 75, 74, 73]","[1697105228014, 1697105230515, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
2224,337,19,[],200,EleutherAI/gpt-neox-20b,128,1,1640.0,1.0,1,H100,1697105226068,1697105227708.0,120,12.0,1.0,"[8, 1632]","[1697105226076, 1697105227708]"
2225,699,20,[],200,EleutherAI/gpt-neox-20b,128,1,1942.0,1.0,1,H100,1697105227709,1697105229651.0,120,39.0,1.0,"[13, 1929]","[1697105227722, 1697105229651]"
2226,886,10,[],200,EleutherAI/gpt-neox-20b,128,1,2039.0,1.0,1,H100,1697105194125,1697105196164.0,120,17.0,1.0,"[8, 2031]","[1697105194133, 1697105196164]"
2227,100,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105229653,1697105232145.0,120,,,"[4, 1848, 76, 75, 73, 74]","[1697105229657, 1697105231505, 1697105231581, 1697105231656, 1697105231729, 1697105231803]"
2228,316,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105196165,1697105201999.0,120,,,"[5, 3202, 224, 231, 129, 150, 140, 81, 79, 220, 296, 80, 292, 160, 213]","[1697105196170, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201667]"
2229,334,15,[],200,EleutherAI/gpt-neox-20b,128,1,1627.0,1.0,1,H100,1697105213925,1697105215552.0,120,15.0,1.0,"[4, 1623]","[1697105213929, 1697105215552]"
2230,461,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232147,1697105233608.0,120,,,[7],[1697105232154]
2231,336,18,[],200,EleutherAI/gpt-neox-20b,128,1,3891.0,1.0,1,H100,1697105227912,1697105231803.0,120,58.0,7.0,"[5, 2598, 990, 76, 75, 74, 73]","[1697105227917, 1697105230515, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
2232,819,23,[],200,EleutherAI/gpt-neox-20b,128,1,1272.0,1.0,1,H100,1697105233610,1697105234882.0,120,13.0,1.0,"[20, 1252]","[1697105233630, 1697105234882]"
2233,694,16,[],200,EleutherAI/gpt-neox-20b,128,1,4645.0,1.0,1,H100,1697105215554,1697105220199.0,120,161.0,13.0,"[4, 2889, 79, 368, 81, 59, 366, 84, 80, 259, 62, 235, 78]","[1697105215558, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219484, 1697105219564, 1697105219823, 1697105219885, 1697105220120, 1697105220198]"
2234,75,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245504,1697105247242.0,120,,,[72],[1697105245576]
2235,432,29,[],200,EleutherAI/gpt-neox-20b,128,1,1390.0,1.0,1,H100,1697105247246,1697105248636.0,120,13.0,1.0,"[8, 1382]","[1697105247254, 1697105248636]"
2236,246,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234884,1697105236781.0,120,,,[32],[1697105234916]
2237,599,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105240330.0,120,,,[194],[1697105236978]
2238,786,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248637,1697105250348.0,120,,,[5],[1697105248642]
2239,183,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252037.0,120,,,[122],[1697105250473]
2240,15,12,[],200,EleutherAI/gpt-neox-20b,128,1,4241.0,1.0,1,H100,1697105220998,1697105225239.0,120,100.0,20.0,"[74, 1595, 87, 85, 82, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579]","[1697105221072, 1697105222667, 1697105222754, 1697105222839, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239]"
2241,114,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240332,1697105241994.0,120,,,[260],[1697105240592]
2242,541,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252042,1697105253712.0,120,,,[245],[1697105252287]
2243,696,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105231804,1697105234919.0,120,,,"[5, 1247, 600, 617]","[1697105231809, 1697105233056, 1697105233656, 1697105234273]"
2244,477,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243754.0,120,,,[194],[1697105242195]
2245,172,11,[],200,EleutherAI/gpt-neox-20b,128,1,2341.0,1.0,1,H100,1697105194125,1697105196466.0,120,19.0,1.0,"[12, 2329]","[1697105194137, 1697105196466]"
2246,903,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[311],[1697105254027]
2247,333,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258925.0,120,,,[77],[1697105256090]
2248,665,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258926,1697105262306.0,120,,,[276],[1697105259202]
2249,96,20,[],200,EleutherAI/gpt-neox-20b,128,1,2973.0,1.0,1,H100,1697105234922,1697105237895.0,120,31.0,1.0,"[190, 2783]","[1697105235112, 1697105237895]"
2250,532,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105196467,1697105201999.0,120,,,"[5, 3634, 141, 80, 79, 220, 296, 80, 292, 160, 212]","[1697105196472, 1697105200106, 1697105200247, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
2251,839,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243757,1697105245502.0,120,,,[126],[1697105243883]
2252,95,36,[],200,EleutherAI/gpt-neox-20b,128,1,1678.0,1.0,1,H100,1697105262312,1697105263990.0,120,12.0,1.0,"[159, 1519]","[1697105262471, 1697105263990]"
2253,269,29,[],200,EleutherAI/gpt-neox-20b,128,1,1662.0,1.0,1,H100,1697105245506,1697105247168.0,120,11.0,1.0,"[206, 1456]","[1697105245712, 1697105247168]"
2254,449,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263992,1697105265928.0,120,,,[40],[1697105264032]
2255,598,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247169,1697105248696.0,120,,,[13],[1697105247182]
2256,453,21,[],200,EleutherAI/gpt-neox-20b,128,1,1442.0,1.0,1,H100,1697105237896,1697105239338.0,120,26.0,1.0,"[4, 1438]","[1697105237900, 1697105239338]"
2257,373,13,[],200,EleutherAI/gpt-neox-20b,128,1,2467.0,1.0,1,H100,1697105225241,1697105227708.0,120,15.0,1.0,"[36, 2431]","[1697105225277, 1697105227708]"
2258,732,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105227709,1697105232144.0,120,,,"[9, 2797, 990, 76, 75, 73, 74]","[1697105227718, 1697105230515, 1697105231505, 1697105231581, 1697105231656, 1697105231729, 1697105231803]"
2259,803,38,[],200,EleutherAI/gpt-neox-20b,128,1,2981.0,1.0,1,H100,1697105265934,1697105268915.0,120,20.0,1.0,"[176, 2805]","[1697105266110, 1697105268915]"
2260,233,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268916,1697105270303.0,120,,,[9],[1697105268925]
2261,19,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248700,1697105252036.0,120,,,[206],[1697105248906]
2262,378,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253712.0,120,,,[60],[1697105252101]
2263,681,40,[],200,EleutherAI/gpt-neox-20b,128,1,1636.0,1.0,1,H100,1697105270309,1697105271945.0,120,23.0,1.0,"[84, 1552]","[1697105270393, 1697105271945]"
2264,160,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233608.0,120,,,[45],[1697105232195]
2265,735,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[312],[1697105254028]
2266,520,16,[],200,EleutherAI/gpt-neox-20b,128,1,1272.0,1.0,1,H100,1697105233610,1697105234882.0,120,11.0,1.0,"[48, 1224]","[1697105233658, 1697105234882]"
2267,36,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234883,1697105236781.0,120,,,[9],[1697105234892]
2268,47,11,[],200,EleutherAI/gpt-neox-20b,128,1,5811.0,1.0,1,H100,1697105203627,1697105209438.0,120,90.0,20.0,"[28, 3158, 90, 89, 86, 80, 80, 60, 61, 618, 86, 83, 82, 64, 434, 87, 84, 79, 77, 385]","[1697105203655, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438]"
2269,397,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105238408.0,120,,,[21],[1697105236805]
2270,114,17,[],200,EleutherAI/gpt-neox-20b,128,1,4461.0,1.0,1,H100,1697105220199,1697105224660.0,120,88.0,20.0,"[5, 1761, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105220204, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
2271,753,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238411,1697105240330.0,120,,,[68],[1697105238479]
2272,171,34,[],200,EleutherAI/gpt-neox-20b,128,1,2017.0,1.0,1,H100,1697105256013,1697105258030.0,120,6.0,1.0,"[86, 1931]","[1697105256099, 1697105258030]"
2273,310,26,[],200,EleutherAI/gpt-neox-20b,128,1,2554.0,1.0,1,H100,1697105236785,1697105239339.0,120,26.0,1.0,"[226, 2327]","[1697105237011, 1697105239338]"
2274,169,17,[],200,EleutherAI/gpt-neox-20b,128,1,2211.0,1.0,1,H100,1697105217530,1697105219741.0,120,10.0,1.0,"[5, 2206]","[1697105217535, 1697105219741]"
2275,181,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240333,1697105241994.0,120,,,[42],[1697105240375]
2276,535,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242002,1697105243754.0,120,,,[190],[1697105242192]
2277,865,22,[],200,EleutherAI/gpt-neox-20b,128,1,2438.0,1.0,1,H100,1697105243758,1697105246196.0,120,9.0,1.0,"[255, 2183]","[1697105244013, 1697105246196]"
2278,297,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105246197,1697105248696.0,120,,,[17],[1697105246214]
2279,671,27,[],200,EleutherAI/gpt-neox-20b,128,1,1865.0,1.0,1,H100,1697105239340,1697105241205.0,120,12.0,1.0,"[29, 1836]","[1697105239369, 1697105241205]"
2280,658,24,[],200,EleutherAI/gpt-neox-20b,128,1,2485.0,1.0,1,H100,1697105248699,1697105251184.0,120,11.0,1.0,"[178, 2307]","[1697105248877, 1697105251184]"
2281,88,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105251185,1697105253710.0,120,,,[9],[1697105251194]
2282,499,18,[],200,EleutherAI/gpt-neox-20b,128,1,4918.0,1.0,1,H100,1697105219742,1697105224660.0,120,88.0,20.0,"[8, 2215, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105219750, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
2283,414,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105255027.0,120,,,[103],[1697105253817]
2284,773,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255029,1697105257113.0,120,,,[29],[1697105255058]
2285,198,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258913.0,120,,,[6],[1697105257123]
2286,556,29,[],200,EleutherAI/gpt-neox-20b,128,1,1518.0,1.0,1,H100,1697105258920,1697105260438.0,120,9.0,1.0,"[153, 1365]","[1697105259073, 1697105260438]"
2287,919,30,[],200,EleutherAI/gpt-neox-20b,128,1,992.0,1.0,1,H100,1697105260439,1697105261431.0,120,14.0,1.0,"[20, 972]","[1697105260459, 1697105261431]"
2288,321,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105261432,1697105264083.0,120,,,[24],[1697105261456]
2289,95,28,[],200,EleutherAI/gpt-neox-20b,128,1,1484.0,1.0,1,H100,1697105241207,1697105242691.0,120,12.0,1.0,"[28, 1455]","[1697105241235, 1697105242690]"
2290,679,32,[],200,EleutherAI/gpt-neox-20b,128,1,1777.0,1.0,1,H100,1697105264086,1697105265863.0,120,15.0,1.0,"[188, 1589]","[1697105264274, 1697105265863]"
2291,426,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242692,1697105245502.0,120,,,[16],[1697105242708]
2292,105,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265864,1697105267796.0,120,,,[17],[1697105265881]
2293,459,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[70],[1697105267868]
2294,819,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[96],[1697105269696]
2295,335,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270990,1697105273585.0,120,,,[96],[1697105271086]
2296,780,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105247242.0,120,,,[22],[1697105245528]
2297,699,37,[],200,EleutherAI/gpt-neox-20b,128,1,2309.0,1.0,1,H100,1697105273589,1697105275898.0,120,39.0,1.0,"[209, 2100]","[1697105273798, 1697105275898]"
2298,853,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105224662,1697105228773.0,120,,,"[37, 1553, 91, 85, 65, 84, 486, 91, 89, 85, 582, 94, 84, 84, 83]","[1697105224699, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227910, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2299,213,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248695.0,120,,,[63],[1697105247310]
2300,571,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248697,1697105250348.0,120,,,[40],[1697105248737]
2301,501,35,[],200,EleutherAI/gpt-neox-20b,128,1,1741.0,1.0,1,H100,1697105258031,1697105259772.0,120,19.0,1.0,"[12, 1729]","[1697105258043, 1697105259772]"
2302,556,6,[],200,EleutherAI/gpt-neox-20b,128,1,3714.0,1.0,1,H100,1697105196833,1697105200547.0,120,9.0,1.0,"[7, 3706]","[1697105196840, 1697105200546]"
2303,4,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250354,1697105252038.0,120,,,[231],[1697105250585]
2304,334,34,[],200,EleutherAI/gpt-neox-20b,128,1,1638.0,1.0,1,H100,1697105252044,1697105253682.0,120,15.0,1.0,"[142, 1496]","[1697105252186, 1697105253682]"
2305,688,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253687,1697105255027.0,120,,,[55],[1697105253742]
2306,910,7,[],200,EleutherAI/gpt-neox-20b,128,1,2432.0,1.0,1,H100,1697105200548,1697105202980.0,120,8.0,1.0,"[12, 2420]","[1697105200560, 1697105202980]"
2307,112,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255029,1697105256010.0,120,,,[25],[1697105255054]
2308,876,14,[],200,EleutherAI/gpt-neox-20b,128,1,1436.0,1.0,1,H100,1697105208543,1697105209979.0,120,11.0,1.0,"[12, 1424]","[1697105208555, 1697105209979]"
2309,301,15,[],200,EleutherAI/gpt-neox-20b,128,1,8042.0,1.0,1,H100,1697105209980,1697105218022.0,120,109.0,31.0,"[16, 2895, 88, 89, 82, 75, 606, 93, 90, 89, 68, 246, 85, 65, 75, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406]","[1697105209996, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213831, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022]"
2310,283,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230476.0,120,,,[121],[1697105228902]
2311,645,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230479,1697105234918.0,120,,,"[226, 2351, 600, 617]","[1697105230705, 1697105233056, 1697105233656, 1697105234273]"
2312,77,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236782.0,120,,,[25],[1697105234947]
2313,407,23,[],200,EleutherAI/gpt-neox-20b,128,1,2554.0,1.0,1,H100,1697105236785,1697105239339.0,120,16.0,1.0,"[286, 2268]","[1697105237071, 1697105239339]"
2314,292,40,[],200,EleutherAI/gpt-neox-20b,128,1,1579.0,1.0,1,H100,1697105271976,1697105273555.0,120,286.0,1.0,"[130, 1449]","[1697105272106, 1697105273555]"
2315,765,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105239340,1697105241995.0,120,,,[15],[1697105239355]
2316,185,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242003,1697105243754.0,120,,,[265],[1697105242268]
2317,544,26,[],200,EleutherAI/gpt-neox-20b,128,1,2438.0,1.0,1,H100,1697105243758,1697105246196.0,120,26.0,1.0,"[263, 2175]","[1697105244021, 1697105246196]"
2318,650,41,[],200,EleutherAI/gpt-neox-20b,128,1,857.0,1.0,1,H100,1697105273558,1697105274415.0,120,13.0,1.0,"[19, 837]","[1697105273577, 1697105274414]"
2319,80,42,[],200,EleutherAI/gpt-neox-20b,128,1,1482.0,1.0,1,H100,1697105274416,1697105275898.0,120,13.0,1.0,"[32, 1450]","[1697105274448, 1697105275898]"
2320,902,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105246197,1697105248695.0,120,,,[9],[1697105246206]
2321,38,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105214568,1697105220994.0,120,,,"[20, 3434, 88, 81, 256, 79, 368, 81, 59, 366, 89, 75, 260, 61, 235, 78, 229, 81, 198]","[1697105214588, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219824, 1697105219885, 1697105220120, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
2322,425,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105252036.0,120,,,[102],[1697105248801]
2323,785,29,[],200,EleutherAI/gpt-neox-20b,128,1,1641.0,1.0,1,H100,1697105252041,1697105253682.0,120,10.0,1.0,"[44, 1597]","[1697105252085, 1697105253682]"
2324,513,12,[],200,EleutherAI/gpt-neox-20b,128,1,5128.0,1.0,1,H100,1697105209439,1697105214567.0,120,83.0,20.0,"[24, 2553, 88, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 69, 245, 85, 65]","[1697105209463, 1697105212016, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214172, 1697105214417, 1697105214502, 1697105214567]"
2325,254,18,[],200,EleutherAI/gpt-neox-20b,128,1,2835.0,1.0,1,H100,1697105216906,1697105219741.0,120,58.0,1.0,"[20, 2815]","[1697105216926, 1697105219741]"
2326,615,19,[],200,EleutherAI/gpt-neox-20b,128,1,4918.0,1.0,1,H100,1697105219742,1697105224660.0,120,93.0,20.0,"[4, 2219, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105219746, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
2327,213,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253686,1697105255027.0,120,,,[40],[1697105253726]
2328,573,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255029,1697105256009.0,120,,,[9],[1697105255038]
2329,111,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105258913.0,120,,,[90],[1697105257208]
2330,468,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258920,1697105260463.0,120,,,"[161, 1357]","[1697105259081, 1697105260438]"
2331,923,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256011,1697105258907.0,120,,,[10],[1697105256021]
2332,448,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105195685,1697105201999.0,120,,,"[8, 4554, 80, 80, 219, 296, 80, 292, 160, 212]","[1697105195693, 1697105200247, 1697105200327, 1697105200407, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
2333,45,20,[],200,EleutherAI/gpt-neox-20b,128,1,1404.0,1.0,1,H100,1697105224662,1697105226066.0,120,19.0,1.0,"[33, 1371]","[1697105224695, 1697105226066]"
2334,159,20,[],200,EleutherAI/gpt-neox-20b,128,1,2312.0,1.0,1,H100,1697105220998,1697105223310.0,120,31.0,1.0,"[194, 2118]","[1697105221192, 1697105223310]"
2335,322,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258915,1697105260462.0,120,,,[30],[1697105258945]
2336,398,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226068,1697105228773.0,120,,,[13],[1697105226081]
2337,681,34,[],200,EleutherAI/gpt-neox-20b,128,1,1779.0,1.0,1,H100,1697105260464,1697105262243.0,120,23.0,1.0,"[48, 1731]","[1697105260512, 1697105262243]"
2338,259,8,[],200,EleutherAI/gpt-neox-20b,128,1,5570.0,1.0,1,H100,1697105192854,1697105198424.0,120,87.0,20.0,"[5, 2622, 88, 115, 84, 174, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 327, 211, 117, 63]","[1697105192859, 1697105195481, 1697105195569, 1697105195684, 1697105195768, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198033, 1697105198244, 1697105198361, 1697105198424]"
2339,117,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262244,1697105264083.0,120,,,[17],[1697105262261]
2340,475,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264087,1697105267795.0,120,,,[216],[1697105264303]
2341,99,13,[],200,EleutherAI/gpt-neox-20b,128,1,2151.0,1.0,1,H100,1697105208977,1697105211128.0,120,10.0,1.0,"[5, 2146]","[1697105208982, 1697105211128]"
2342,780,10,[],200,EleutherAI/gpt-neox-20b,128,1,5063.0,1.0,1,H100,1697105202015,1697105207078.0,120,85.0,20.0,"[192, 2043, 87, 87, 83, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84, 731, 90, 89, 86]","[1697105202207, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078]"
2343,457,14,[],200,EleutherAI/gpt-neox-20b,128,1,1762.0,1.0,1,H100,1697105211129,1697105212891.0,120,874.0,2.0,"[9, 1753]","[1697105211138, 1697105212891]"
2344,194,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262310,1697105264082.0,120,,,[20],[1697105262330]
2345,550,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264086,1697105265928.0,120,,,[115],[1697105264201]
2346,296,12,[],200,EleutherAI/gpt-neox-20b,128,1,1623.0,1.0,1,H100,1697105202003,1697105203626.0,120,6.0,1.0,"[40, 1583]","[1697105202043, 1697105203626]"
2347,615,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226253,1697105228773.0,120,,,[5],[1697105226258]
2348,45,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230475.0,120,,,[197],[1697105228978]
2349,403,23,[],200,EleutherAI/gpt-neox-20b,128,1,1028.0,1.0,1,H100,1697105230478,1697105231506.0,120,874.0,2.0,"[24, 1004]","[1697105230502, 1697105231506]"
2350,243,14,[],200,EleutherAI/gpt-neox-20b,128,1,2942.0,1.0,1,H100,1697105207360,1697105210302.0,120,67.0,4.0,"[8, 2765, 86, 83]","[1697105207368, 1697105210133, 1697105210219, 1697105210302]"
2351,735,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105231506,1697105234919.0,120,,,"[5, 1545, 600, 617]","[1697105231511, 1697105233056, 1697105233656, 1697105234273]"
2352,255,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105183664,1697105201998.0,120,,,"[16, 2329, 88, 85, 407, 88, 78, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 165, 80, 376, 86, 85, 481, 90, 272, 165, 251, 87, 251, 66, 87, 66, 367, 162, 87, 281, 81, 276, 76, 286, 87, 83, 234, 82, 62, 305, 87, 189, 84, 64, 80, 266, 63, 85, 199, 80, 78, 261, 326, 87, 116, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82, 77, 326, 212, 117, 63, 265, 273, 410, 224, 230, 130, 150, 140, 80, 80, 219, 297, 80, 292, 160, 212]","[1697105183680, 1697105186009, 1697105186097, 1697105186182, 1697105186589, 1697105186677, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188707, 1697105188787, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192128, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193619, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194123, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199826, 1697105199956, 1697105200106, 1697105200246, 1697105200326, 1697105200406, 1697105200625, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
2353,870,13,[],200,EleutherAI/gpt-neox-20b,128,1,5399.0,1.0,1,H100,1697105206084,1697105211483.0,120,88.0,20.0,"[37, 1856, 86, 83, 82, 64, 434, 87, 84, 79, 78, 384, 77, 619, 85, 83, 502, 82, 428, 168]","[1697105206121, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209054, 1697105209438, 1697105209515, 1697105210134, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482]"
2354,880,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226578,1697105228773.0,120,,,[4],[1697105226582]
2355,309,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228782,1697105230475.0,120,,,[192],[1697105228974]
2356,279,16,[],200,EleutherAI/gpt-neox-20b,128,1,3591.0,1.0,1,H100,1697105220914,1697105224505.0,120,67.0,18.0,"[4, 1048, 701, 87, 84, 83, 81, 401, 71, 92, 87, 86, 84, 82, 351, 91, 70, 88]","[1697105220918, 1697105221966, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223823, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505]"
2357,518,15,[],200,EleutherAI/gpt-neox-20b,128,1,2221.0,1.0,1,H100,1697105212106,1697105214327.0,120,23.0,1.0,"[16, 2205]","[1697105212122, 1697105214327]"
2358,655,15,[],200,EleutherAI/gpt-neox-20b,128,1,4088.0,1.0,1,H100,1697105219565,1697105223653.0,120,335.0,11.0,"[5, 2395, 702, 87, 84, 83, 81, 401, 71, 92, 87]","[1697105219570, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653]"
2359,3,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105216905,1697105220995.0,120,,,"[9, 2910, 62, 233, 79, 229, 81, 198]","[1697105216914, 1697105219824, 1697105219886, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
2360,80,16,[],200,EleutherAI/gpt-neox-20b,128,1,1490.0,1.0,1,H100,1697105223654,1697105225144.0,120,13.0,1.0,"[5, 1485]","[1697105223659, 1697105225144]"
2361,159,12,[],200,EleutherAI/gpt-neox-20b,128,1,2420.0,1.0,1,H100,1697105217617,1697105220037.0,120,31.0,1.0,"[13, 2407]","[1697105217630, 1697105220037]"
2362,158,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240267,1697105241994.0,120,,,[53],[1697105240320]
2363,518,23,[],200,EleutherAI/gpt-neox-20b,128,1,1553.0,1.0,1,H100,1697105242001,1697105243554.0,120,23.0,1.0,"[186, 1367]","[1697105242187, 1697105243554]"
2364,875,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243555,1697105245503.0,120,,,"[32, 890]","[1697105243587, 1697105244477]"
2365,650,13,[],200,EleutherAI/gpt-neox-20b,128,1,2981.0,1.0,1,H100,1697105217056,1697105220037.0,120,13.0,1.0,"[4, 2977]","[1697105217060, 1697105220037]"
2366,78,14,[],200,EleutherAI/gpt-neox-20b,128,1,4622.0,1.0,1,H100,1697105220038,1697105224660.0,120,84.0,20.0,"[8, 1919, 702, 87, 85, 82, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105220046, 1697105221965, 1697105222667, 1697105222754, 1697105222839, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
2367,744,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105218448,1697105220995.0,120,,,"[5, 2253]","[1697105218453, 1697105220706]"
2368,172,19,[],200,EleutherAI/gpt-neox-20b,128,1,2312.0,1.0,1,H100,1697105220998,1697105223310.0,120,19.0,1.0,"[178, 2134]","[1697105221176, 1697105223310]"
2369,553,17,[],200,EleutherAI/gpt-neox-20b,128,1,5227.0,1.0,1,H100,1697105214173,1697105219400.0,120,88.0,20.0,"[16, 2230, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 82, 257, 78, 368, 81, 59, 366]","[1697105214189, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218448, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400]"
2370,536,20,[],200,EleutherAI/gpt-neox-20b,128,1,4944.0,1.0,1,H100,1697105223311,1697105228255.0,120,83.0,20.0,"[8, 1920, 82, 77, 75, 74, 705, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105223319, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225547, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2371,12,12,[],200,EleutherAI/gpt-neox-20b,128,1,1622.0,1.0,1,H100,1697105202004,1697105203626.0,120,11.0,1.0,"[99, 1523]","[1697105202103, 1697105203626]"
2372,372,13,[],200,EleutherAI/gpt-neox-20b,128,1,7177.0,1.0,1,H100,1697105203627,1697105210804.0,120,874.0,25.0,"[24, 3162, 90, 89, 86, 80, 80, 60, 61, 618, 86, 83, 82, 64, 434, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502]","[1697105203651, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804]"
2373,864,13,[],200,EleutherAI/gpt-neox-20b,128,1,5859.0,1.0,1,H100,1697105214568,1697105220427.0,120,83.0,20.0,"[12, 2860, 89, 87, 406, 88, 81, 256, 79, 368, 81, 59, 366, 89, 75, 260, 61, 235, 78, 229]","[1697105214580, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219824, 1697105219885, 1697105220120, 1697105220198, 1697105220427]"
2374,15,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242010,1697105243755.0,120,,,[274],[1697105242284]
2375,816,15,[],200,EleutherAI/gpt-neox-20b,128,1,2843.0,1.0,1,H100,1697105212892,1697105215735.0,120,182.0,4.0,"[5, 2398, 85, 355]","[1697105212897, 1697105215295, 1697105215380, 1697105215735]"
2376,336,16,[],200,EleutherAI/gpt-neox-20b,128,1,3664.0,1.0,1,H100,1697105215736,1697105219400.0,120,58.0,7.0,"[4, 2707, 79, 368, 81, 59, 366]","[1697105215740, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400]"
2377,697,17,[],200,EleutherAI/gpt-neox-20b,128,1,4165.0,1.0,1,H100,1697105219401,1697105223566.0,120,123.0,10.0,"[4, 2560, 702, 87, 84, 83, 81, 401, 71, 92]","[1697105219405, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566]"
2378,611,19,[],200,EleutherAI/gpt-neox-20b,128,1,2312.0,1.0,1,H100,1697105220998,1697105223310.0,120,14.0,1.0,"[118, 2194]","[1697105221116, 1697105223310]"
2379,294,14,[],200,EleutherAI/gpt-neox-20b,128,1,1538.0,1.0,1,H100,1697105220428,1697105221966.0,120,9.0,2.0,"[6, 1532]","[1697105220434, 1697105221966]"
2380,654,13,[],200,EleutherAI/gpt-neox-20b,128,1,1478.0,1.0,1,H100,1697105203626,1697105205104.0,120,47.0,4.0,"[5, 1291, 93, 89]","[1697105203631, 1697105204922, 1697105205015, 1697105205104]"
2381,41,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105223311,1697105228772.0,120,,,"[8, 1920, 82, 77, 75, 74, 705, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105223319, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225547, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2382,651,15,[],200,EleutherAI/gpt-neox-20b,128,1,2290.0,1.0,1,H100,1697105221967,1697105224257.0,120,457.0,2.0,"[4, 2286]","[1697105221971, 1697105224257]"
2383,56,16,[],200,EleutherAI/gpt-neox-20b,128,1,3997.0,1.0,1,H100,1697105224258,1697105228255.0,120,86.0,20.0,"[4, 977, 82, 78, 74, 74, 705, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105224262, 1697105225239, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2384,168,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234926,1697105238408.0,120,,,[262],[1697105235188]
2385,79,14,[],200,EleutherAI/gpt-neox-20b,128,1,1609.0,1.0,1,H100,1697105205105,1697105206714.0,120,12.0,1.0,"[4, 1605]","[1697105205109, 1697105206714]"
2386,439,15,[],200,EleutherAI/gpt-neox-20b,128,1,1431.0,1.0,1,H100,1697105206715,1697105208146.0,120,13.0,4.0,"[13, 1249, 86, 83]","[1697105206728, 1697105207977, 1697105208063, 1697105208146]"
2387,799,16,[],200,EleutherAI/gpt-neox-20b,128,1,6024.0,1.0,1,H100,1697105208147,1697105214171.0,120,84.0,20.0,"[4, 3163, 168, 77, 456, 89, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68]","[1697105208151, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171]"
2388,526,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238411,1697105240330.0,120,,,[20],[1697105238431]
2389,880,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240332,1697105241994.0,120,,,[36],[1697105240368]
2390,306,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243754.0,120,,,[102],[1697105242103]
2391,276,15,[],200,EleutherAI/gpt-neox-20b,128,1,4958.0,1.0,1,H100,1697105213151,1697105218109.0,120,732.0,13.0,"[12, 3256, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87]","[1697105213163, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109]"
2392,751,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243756,1697105245502.0,120,,,[44],[1697105243800]
2393,126,18,[],200,EleutherAI/gpt-neox-20b,128,1,1577.0,1.0,1,H100,1697105223567,1697105225144.0,120,19.0,1.0,"[5, 1572]","[1697105223572, 1697105225144]"
2394,480,19,[],200,EleutherAI/gpt-neox-20b,128,1,1807.0,1.0,1,H100,1697105225146,1697105226953.0,120,26.0,1.0,"[44, 1763]","[1697105225190, 1697105226953]"
2395,399,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228779,1697105230475.0,120,,,[38],[1697105228817]
2396,843,22,[],200,EleutherAI/gpt-neox-20b,128,1,2516.0,1.0,1,H100,1697105230478,1697105232994.0,120,14.0,1.0,"[131, 2385]","[1697105230609, 1697105232994]"
2397,273,23,[],200,EleutherAI/gpt-neox-20b,128,1,1886.0,1.0,1,H100,1697105232996,1697105234882.0,120,19.0,1.0,"[20, 1866]","[1697105233016, 1697105234882]"
2398,631,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234883,1697105236781.0,120,,,[21],[1697105234904]
2399,836,20,[],200,EleutherAI/gpt-neox-20b,128,1,1796.0,1.0,1,H100,1697105226955,1697105228751.0,120,11.0,1.0,"[24, 1772]","[1697105226979, 1697105228751]"
2400,56,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236785,1697105240330.0,120,,,[289],[1697105237074]
2401,236,21,[],200,EleutherAI/gpt-neox-20b,128,1,900.0,1.0,1,H100,1697105228752,1697105229652.0,120,8.0,1.0,"[16, 884]","[1697105228768, 1697105229652]"
2402,419,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241995.0,120,,,[69],[1697105240403]
2403,747,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242002,1697105243754.0,120,,,[194],[1697105242196]
2404,597,22,[],200,EleutherAI/gpt-neox-20b,128,1,1653.0,1.0,1,H100,1697105229653,1697105231306.0,120,39.0,1.0,"[28, 1625]","[1697105229681, 1697105231306]"
2405,180,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243757,1697105245501.0,120,,,[14],[1697105243771]
2406,28,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105231307,1697105234919.0,120,,,"[9, 1740, 600, 617]","[1697105231316, 1697105233056, 1697105233656, 1697105234273]"
2407,601,15,[],200,EleutherAI/gpt-neox-20b,128,1,5606.0,1.0,1,H100,1697105210303,1697105215909.0,120,83.0,20.0,"[5, 2583, 88, 89, 82, 75, 606, 93, 90, 89, 68, 246, 85, 65, 75, 652, 85, 356, 90, 84]","[1697105210308, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213831, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215909]"
2408,389,24,[],200,EleutherAI/gpt-neox-20b,128,1,1834.0,1.0,1,H100,1697105234922,1697105236756.0,120,8.0,1.0,"[77, 1757]","[1697105234999, 1697105236756]"
2409,743,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236757,1697105238409.0,120,,,[12],[1697105236769]
2410,638,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105218110,1697105220995.0,120,,,"[5, 2312, 82, 197]","[1697105218115, 1697105220427, 1697105220509, 1697105220706]"
2411,144,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238412,1697105240331.0,120,,,[163],[1697105238575]
2412,900,15,[],200,EleutherAI/gpt-neox-20b,128,1,2899.0,1.0,1,H100,1697105209439,1697105212338.0,120,67.0,6.0,"[16, 2560, 89, 80, 79, 75]","[1697105209455, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338]"
2413,843,41,[],200,EleutherAI/gpt-neox-20b,128,1,1838.0,1.0,1,H100,1697105265934,1697105267772.0,120,14.0,1.0,"[156, 1682]","[1697105266090, 1697105267772]"
2414,325,16,[],200,EleutherAI/gpt-neox-20b,128,1,6108.0,1.0,1,H100,1697105212339,1697105218447.0,120,85.0,20.0,"[4, 2951, 85, 356, 90, 84, 510, 89, 66, 84, 247, 84, 66, 385, 89, 87, 406, 87, 82, 256]","[1697105212343, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215909, 1697105216419, 1697105216508, 1697105216574, 1697105216658, 1697105216905, 1697105216989, 1697105217055, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218447]"
2415,539,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245505,1697105247243.0,120,,,[112],[1697105245617]
2416,605,9,[],200,EleutherAI/gpt-neox-20b,128,1,2455.0,1.0,1,H100,1697105192937,1697105195392.0,120,8.0,1.0,"[4, 2451]","[1697105192941, 1697105195392]"
2417,892,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247254,1697105250347.0,120,,,[253],[1697105247507]
2418,497,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241993.0,120,,,[137],[1697105240471]
2419,273,42,[],200,EleutherAI/gpt-neox-20b,128,1,1142.0,1.0,1,H100,1697105267774,1697105268916.0,120,19.0,1.0,"[12, 1129]","[1697105267786, 1697105268915]"
2420,859,28,[],200,EleutherAI/gpt-neox-20b,128,1,1554.0,1.0,1,H100,1697105241999,1697105243553.0,120,23.0,1.0,"[9, 1545]","[1697105242008, 1697105243553]"
2421,714,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268917,1697105270302.0,120,,,[20],[1697105268937]
2422,128,10,[],200,EleutherAI/gpt-neox-20b,128,1,2767.0,1.0,1,H100,1697105195393,1697105198160.0,120,9.0,1.0,"[16, 2751]","[1697105195409, 1697105198160]"
2423,294,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250350,1697105252038.0,120,,,[10],[1697105250360]
2424,289,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243554,1697105245502.0,120,,,[5],[1697105243559]
2425,648,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252042,1697105253713.0,120,,,[261],[1697105252303]
2426,485,11,[],200,EleutherAI/gpt-neox-20b,128,1,3293.0,1.0,1,H100,1697105198161,1697105201454.0,120,67.0,3.0,"[5, 3128, 160]","[1697105198166, 1697105201294, 1697105201454]"
2427,80,33,[],200,EleutherAI/gpt-neox-20b,128,1,2228.0,1.0,1,H100,1697105253716,1697105255944.0,120,13.0,1.0,"[363, 1865]","[1697105254079, 1697105255944]"
2428,439,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255945,1697105257114.0,120,,,[18],[1697105255963]
2429,844,12,[],200,EleutherAI/gpt-neox-20b,128,1,1524.0,1.0,1,H100,1697105201456,1697105202980.0,120,10.0,1.0,"[12, 1512]","[1697105201468, 1697105202980]"
2430,618,30,[],200,EleutherAI/gpt-neox-20b,128,1,1662.0,1.0,1,H100,1697105245506,1697105247168.0,120,9.0,1.0,"[30, 1632]","[1697105245536, 1697105247168]"
2431,52,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247169,1697105248696.0,120,,,[5],[1697105247174]
2432,265,13,[],200,EleutherAI/gpt-neox-20b,128,1,4377.0,1.0,1,H100,1697105202982,1697105207359.0,120,86.0,20.0,"[36, 1904, 93, 89, 88, 68, 87, 86, 389, 91, 85, 84, 732, 89, 89, 86, 81, 79, 60, 61]","[1697105203018, 1697105204922, 1697105205015, 1697105205104, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359]"
2433,406,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105252036.0,120,,,"[174, 2311]","[1697105248873, 1697105251184]"
2434,763,33,[],200,EleutherAI/gpt-neox-20b,128,1,1640.0,1.0,1,H100,1697105252041,1697105253681.0,120,20.0,1.0,"[36, 1604]","[1697105252077, 1697105253681]"
2435,37,16,[],200,EleutherAI/gpt-neox-20b,128,1,2804.0,1.0,1,H100,1697105215910,1697105218714.0,120,20.0,1.0,"[24, 2780]","[1697105215934, 1697105218714]"
2436,194,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253685,1697105256010.0,120,,,"[6, 1367]","[1697105253691, 1697105255058]"
2437,367,17,[],200,EleutherAI/gpt-neox-20b,128,1,4206.0,1.0,1,H100,1697105218715,1697105222921.0,120,92.0,6.0,"[4, 3246, 702, 87, 84, 83]","[1697105218719, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921]"
2438,637,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258914.0,120,,,[56],[1697105256069]
2439,177,12,[],200,EleutherAI/gpt-neox-20b,128,1,1312.0,1.0,1,H100,1697105201668,1697105202980.0,120,14.0,1.0,"[8, 1304]","[1697105201676, 1697105202980]"
2440,899,13,[],200,EleutherAI/gpt-neox-20b,128,1,5689.0,1.0,1,H100,1697105210220,1697105215909.0,120,100.0,20.0,"[5, 2666, 88, 89, 82, 75, 606, 93, 90, 89, 68, 246, 85, 65, 75, 652, 85, 356, 90, 83]","[1697105210225, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213831, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908]"
2441,297,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253686,1697105255027.0,120,,,[42],[1697105253728]
2442,66,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258921,1697105262306.0,120,,,[248],[1697105259169]
2443,518,13,[],200,EleutherAI/gpt-neox-20b,128,1,1865.0,1.0,1,H100,1697105220038,1697105221903.0,120,23.0,1.0,"[16, 1849]","[1697105220054, 1697105221903]"
2444,411,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105220998,1697105228772.0,120,,,"[106, 2299, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579, 82, 77, 75, 73, 707, 90, 85, 65, 84, 486, 91, 89, 85, 582, 94, 84, 84, 83]","[1697105221104, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225546, 1697105226253, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227910, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2445,327,14,[],200,EleutherAI/gpt-neox-20b,128,1,4598.0,1.0,1,H100,1697105215910,1697105220508.0,120,563.0,10.0,"[9, 3481, 89, 75, 259, 62, 234, 79, 229, 81]","[1697105215919, 1697105219400, 1697105219489, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508]"
2446,362,18,[],200,EleutherAI/gpt-neox-20b,128,1,2311.0,1.0,1,H100,1697105220999,1697105223310.0,120,14.0,1.0,"[205, 2106]","[1697105221204, 1697105223310]"
2447,872,14,[],200,EleutherAI/gpt-neox-20b,128,1,5339.0,1.0,1,H100,1697105221904,1697105227243.0,120,91.0,20.0,"[13, 2339, 91, 70, 88, 87, 68, 579, 82, 78, 74, 74, 706, 90, 85, 65, 84, 486, 91, 89]","[1697105221917, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226253, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243]"
2448,656,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[86],[1697105255116]
2449,807,19,[],200,EleutherAI/gpt-neox-20b,128,1,4944.0,1.0,1,H100,1697105223311,1697105228255.0,120,90.0,20.0,"[4, 1924, 82, 77, 75, 74, 706, 90, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105223315, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225547, 1697105226253, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2450,661,15,[],200,EleutherAI/gpt-neox-20b,128,1,3057.0,1.0,1,H100,1697105220509,1697105223566.0,120,161.0,10.0,"[5, 1451, 702, 87, 84, 83, 81, 401, 71, 92]","[1697105220514, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566]"
2451,81,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105258914.0,120,,,[150],[1697105257268]
2452,439,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258917,1697105260463.0,120,,,[160],[1697105259077]
2453,595,4,[],200,EleutherAI/gpt-neox-20b,128,1,1903.0,1.0,1,H100,1697105178108,1697105180011.0,120,8.0,1.0,"[5, 1898]","[1697105178113, 1697105180011]"
2454,20,5,[],200,EleutherAI/gpt-neox-20b,128,1,5386.0,1.0,1,H100,1697105180012,1697105185398.0,120,83.0,20.0,"[20, 2818, 89, 88, 190, 87, 78, 373, 86, 84, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363]","[1697105180032, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183755, 1697105183841, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398]"
2455,93,16,[],200,EleutherAI/gpt-neox-20b,128,1,4688.0,1.0,1,H100,1697105223567,1697105228255.0,120,88.0,20.0,"[9, 1663, 82, 78, 74, 74, 705, 91, 85, 65, 84, 487, 90, 89, 85, 583, 93, 84, 84, 83]","[1697105223576, 1697105225239, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227064, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2456,802,36,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105260467,1697105262243.0,120,9.0,1.0,"[218, 1558]","[1697105260685, 1697105262243]"
2457,205,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262244,1697105264083.0,120,,,[33],[1697105262277]
2458,897,13,[],200,EleutherAI/gpt-neox-20b,128,1,2150.0,1.0,1,H100,1697105202010,1697105204160.0,120,9.0,1.0,"[173, 1977]","[1697105202183, 1697105204160]"
2459,251,5,[],200,EleutherAI/gpt-neox-20b,128,1,1465.0,1.0,1,H100,1697105176267,1697105177732.0,120,31.0,1.0,"[15, 1450]","[1697105176282, 1697105177732]"
2460,576,6,[],200,EleutherAI/gpt-neox-20b,128,1,2277.0,1.0,1,H100,1697105177734,1697105180011.0,120,14.0,1.0,"[20, 2257]","[1697105177754, 1697105180011]"
2461,339,8,[],200,EleutherAI/gpt-neox-20b,128,1,4378.0,1.0,1,H100,1697105202981,1697105207359.0,120,87.0,20.0,"[9, 1932, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84, 732, 89, 89, 86, 81, 79, 60, 61]","[1697105202990, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359]"
2462,1,7,[],200,EleutherAI/gpt-neox-20b,128,1,9803.0,1.0,1,H100,1697105180012,1697105189815.0,120,47.0,43.0,"[16, 2822, 89, 88, 190, 87, 78, 373, 86, 84, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 87, 81, 411, 88, 79, 78, 59, 280, 84, 83, 83, 376, 89, 561, 94, 164, 81, 375, 87, 85, 481]","[1697105180028, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183755, 1697105183841, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186096, 1697105186177, 1697105186588, 1697105186676, 1697105186755, 1697105186833, 1697105186892, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815]"
2463,405,12,[],200,EleutherAI/gpt-neox-20b,128,1,5128.0,1.0,1,H100,1697105209439,1697105214567.0,120,87.0,20.0,"[8, 2568, 89, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 65]","[1697105209447, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567]"
2464,325,14,[],200,EleutherAI/gpt-neox-20b,128,1,5277.0,1.0,1,H100,1697105204161,1697105209438.0,120,85.0,20.0,"[4, 2648, 90, 89, 86, 81, 79, 60, 61, 618, 86, 83, 82, 64, 434, 87, 84, 79, 77, 385]","[1697105204165, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438]"
2465,95,44,[],200,EleutherAI/gpt-neox-20b,128,1,1577.0,1.0,1,H100,1697105271978,1697105273555.0,120,12.0,1.0,"[100, 1477]","[1697105272078, 1697105273555]"
2466,420,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273556,1697105275207.0,120,,,[5],[1697105273561]
2467,447,8,[],200,EleutherAI/gpt-neox-20b,128,1,4425.0,1.0,1,H100,1697105179500,1697105183925.0,120,161.0,13.0,"[4, 2790, 89, 83, 384, 89, 88, 189, 88, 78, 373, 85, 85]","[1697105179504, 1697105182294, 1697105182383, 1697105182466, 1697105182850, 1697105182939, 1697105183027, 1697105183216, 1697105183304, 1697105183382, 1697105183755, 1697105183840, 1697105183925]"
2468,440,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105224662,1697105228773.0,120,,,"[17, 1573, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105224679, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2469,847,15,[],200,EleutherAI/gpt-neox-20b,128,1,1727.0,1.0,1,H100,1697105218895,1697105220622.0,120,10.0,1.0,"[13, 1714]","[1697105218908, 1697105220622]"
2470,105,5,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105193621,1697105201998.0,120,,,"[4, 2735, 282, 189, 259, 85, 62, 152, 158, 82, 77, 326, 212, 117, 63, 265, 273, 410, 224, 231, 129, 150, 140, 81, 79, 220, 296, 80, 292, 160, 212]","[1697105193625, 1697105196360, 1697105196642, 1697105196831, 1697105197090, 1697105197175, 1697105197237, 1697105197389, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
2471,280,16,[],200,EleutherAI/gpt-neox-20b,128,1,4038.0,1.0,1,H100,1697105220623,1697105224661.0,120,91.0,20.0,"[5, 1338, 701, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105220628, 1697105221966, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
2472,392,18,[],200,EleutherAI/gpt-neox-20b,128,1,1577.0,1.0,1,H100,1697105220996,1697105222573.0,120,20.0,1.0,"[40, 1537]","[1697105221036, 1697105222573]"
2473,746,19,[],200,EleutherAI/gpt-neox-20b,128,1,4489.0,1.0,1,H100,1697105222574,1697105227063.0,120,345.0,18.0,"[4, 1679, 90, 70, 88, 87, 68, 579, 82, 77, 75, 73, 707, 90, 85, 65, 84, 486]","[1697105222578, 1697105224257, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225546, 1697105226253, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063]"
2474,766,13,[],200,EleutherAI/gpt-neox-20b,128,1,1666.0,1.0,1,H100,1697105214568,1697105216234.0,120,11.0,1.0,"[24, 1642]","[1697105214592, 1697105216234]"
2475,723,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228782,1697105230476.0,120,,,[123],[1697105228905]
2476,154,23,[],200,EleutherAI/gpt-neox-20b,128,1,1647.0,1.0,1,H100,1697105230478,1697105232125.0,120,13.0,1.0,"[44, 1603]","[1697105230522, 1697105232125]"
2477,162,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105216235,1697105220995.0,120,,,"[5, 2654, 81, 60, 365, 89, 75, 259, 62, 234, 79, 228, 82, 198]","[1697105216240, 1697105218894, 1697105218975, 1697105219035, 1697105219400, 1697105219489, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220426, 1697105220508, 1697105220706]"
2478,369,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243758,1697105245501.0,120,,,[215],[1697105243973]
2479,731,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245504,1697105247243.0,120,,,[92],[1697105245596]
2480,247,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247256,1697105250347.0,120,,,[263],[1697105247519]
2481,914,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265934,1697105271973.0,120,,,"[147, 2897, 668, 705, 685]","[1697105266081, 1697105268978, 1697105269646, 1697105270351, 1697105271036]"
2482,182,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245505,1697105247242.0,120,,,[14],[1697105245519]
2483,110,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271946,1697105273585.0,120,,,[9],[1697105271955]
2484,45,14,[],200,EleutherAI/gpt-neox-20b,128,1,1784.0,1.0,1,H100,1697105206084,1697105207868.0,120,19.0,1.0,"[29, 1755]","[1697105206113, 1697105207868]"
2485,403,15,[],200,EleutherAI/gpt-neox-20b,128,1,2936.0,1.0,1,H100,1697105207868,1697105210804.0,120,874.0,2.0,"[13, 2923]","[1697105207881, 1697105210804]"
2486,360,8,[],200,EleutherAI/gpt-neox-20b,128,1,2141.0,1.0,1,H100,1697105189816,1697105191957.0,120,16.0,1.0,"[5, 2135]","[1697105189821, 1697105191956]"
2487,718,9,[],200,EleutherAI/gpt-neox-20b,128,1,2346.0,1.0,1,H100,1697105191958,1697105194304.0,120,13.0,1.0,"[8, 2338]","[1697105191966, 1697105194304]"
2488,154,10,[],200,EleutherAI/gpt-neox-20b,128,1,2161.0,1.0,1,H100,1697105194305,1697105196466.0,120,13.0,1.0,"[4, 2157]","[1697105194309, 1697105196466]"
2489,852,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233609.0,120,,,[60],[1697105232210]
2490,484,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105196467,1697105201999.0,120,,,"[9, 3630, 140, 81, 80, 219, 296, 80, 292, 160, 212]","[1697105196476, 1697105200106, 1697105200246, 1697105200327, 1697105200407, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
2491,887,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105215296,1697105220994.0,120,,,"[16, 3135, 79, 368, 81, 59, 366, 84, 80, 259, 62, 235, 78, 229, 81, 198]","[1697105215312, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219484, 1697105219564, 1697105219823, 1697105219885, 1697105220120, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
2492,842,12,[],200,EleutherAI/gpt-neox-20b,128,1,3429.0,1.0,1,H100,1697105202004,1697105205433.0,120,161.0,16.0,"[79, 1635, 88, 88, 87, 269, 87, 86, 84, 415, 92, 90, 87, 69, 87, 86]","[1697105202083, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205104, 1697105205191, 1697105205260, 1697105205347, 1697105205433]"
2493,368,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233610,1697105234919.0,120,,,[44],[1697105233654]
2494,729,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236780.0,120,,,[153],[1697105235075]
2495,425,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243758,1697105245501.0,120,,,[219],[1697105243977]
2496,160,21,[],200,EleutherAI/gpt-neox-20b,128,1,1601.0,1.0,1,H100,1697105236784,1697105238385.0,120,13.0,1.0,"[114, 1487]","[1697105236898, 1697105238385]"
2497,521,22,[],200,EleutherAI/gpt-neox-20b,128,1,1879.0,1.0,1,H100,1697105238386,1697105240265.0,120,18.0,1.0,"[29, 1850]","[1697105238415, 1697105240265]"
2498,771,15,[],200,EleutherAI/gpt-neox-20b,128,1,5128.0,1.0,1,H100,1697105209439,1697105214567.0,120,47.0,20.0,"[12, 2565, 88, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 65]","[1697105209451, 1697105212016, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567]"
2499,317,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105220996,1697105228772.0,120,,,"[40, 1631, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 352, 90, 70, 88, 87, 68, 579, 82, 77, 75, 73, 706, 91, 85, 65, 84, 486, 91, 89, 85, 582, 94, 84, 84, 83]","[1697105221036, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224257, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225546, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227910, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2500,268,13,[],200,EleutherAI/gpt-neox-20b,128,1,1280.0,1.0,1,H100,1697105205434,1697105206714.0,120,19.0,1.0,"[5, 1275]","[1697105205439, 1697105206714]"
2501,896,14,[],200,EleutherAI/gpt-neox-20b,128,1,1784.0,1.0,1,H100,1697105206084,1697105207868.0,120,15.0,1.0,"[41, 1743]","[1697105206125, 1697105207868]"
2502,217,16,[],200,EleutherAI/gpt-neox-20b,128,1,4241.0,1.0,1,H100,1697105220998,1697105225239.0,120,85.0,20.0,"[14, 1655, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579]","[1697105221012, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239]"
2503,518,21,[],200,EleutherAI/gpt-neox-20b,128,1,1833.0,1.0,1,H100,1697105223311,1697105225144.0,120,23.0,1.0,"[25, 1808]","[1697105223336, 1697105225144]"
2504,847,22,[],200,EleutherAI/gpt-neox-20b,128,1,1809.0,1.0,1,H100,1697105225145,1697105226954.0,120,10.0,1.0,"[33, 1776]","[1697105225178, 1697105226954]"
2505,267,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226955,1697105228774.0,120,,,[24],[1697105226979]
2506,622,14,[],200,EleutherAI/gpt-neox-20b,128,1,1827.0,1.0,1,H100,1697105206715,1697105208542.0,120,20.0,1.0,"[29, 1797]","[1697105206744, 1697105208541]"
2507,50,15,[],200,EleutherAI/gpt-neox-20b,128,1,3017.0,1.0,1,H100,1697105208542,1697105211559.0,120,90.0,4.0,"[5, 2768, 167, 77]","[1697105208547, 1697105211315, 1697105211482, 1697105211559]"
2508,626,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228782,1697105230476.0,120,,,[224],[1697105229006]
2509,828,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260465,1697105262307.0,120,,,[15],[1697105260480]
2510,600,25,[],200,EleutherAI/gpt-neox-20b,128,1,2553.0,1.0,1,H100,1697105236785,1697105239338.0,120,23.0,1.0,"[221, 2332]","[1697105237006, 1697105239338]"
2511,326,15,[],200,EleutherAI/gpt-neox-20b,128,1,4541.0,1.0,1,H100,1697105207869,1697105212410.0,120,345.0,12.0,"[16, 2919, 83, 427, 168, 77, 457, 89, 79, 80, 74, 72]","[1697105207885, 1697105210804, 1697105210887, 1697105211314, 1697105211482, 1697105211559, 1697105212016, 1697105212105, 1697105212184, 1697105212264, 1697105212338, 1697105212410]"
2512,28,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105239340,1697105241995.0,120,,,[21],[1697105239361]
2513,55,25,[],200,EleutherAI/gpt-neox-20b,128,1,2515.0,1.0,1,H100,1697105230479,1697105232994.0,120,12.0,1.0,"[218, 2297]","[1697105230697, 1697105232994]"
2514,384,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243754.0,120,,,[206],[1697105242207]
2515,418,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232995,1697105234919.0,120,,,[5],[1697105233000]
2516,684,16,[],200,EleutherAI/gpt-neox-20b,128,1,6036.0,1.0,1,H100,1697105212411,1697105218447.0,120,100.0,20.0,"[4, 2879, 85, 356, 90, 84, 510, 89, 66, 85, 246, 84, 66, 385, 89, 87, 406, 87, 82, 256]","[1697105212415, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215909, 1697105216419, 1697105216508, 1697105216574, 1697105216659, 1697105216905, 1697105216989, 1697105217055, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218447]"
2517,288,17,[],200,EleutherAI/gpt-neox-20b,128,1,4241.0,1.0,1,H100,1697105220998,1697105225239.0,120,93.0,20.0,"[86, 1583, 87, 85, 82, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579]","[1697105221084, 1697105222667, 1697105222754, 1697105222839, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239]"
2518,746,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243758,1697105245501.0,120,,,[151],[1697105243909]
2519,68,20,[],200,EleutherAI/gpt-neox-20b,128,1,2308.0,1.0,1,H100,1697105225400,1697105227708.0,120,12.0,1.0,"[4, 2304]","[1697105225404, 1697105227708]"
2520,681,13,[],200,EleutherAI/gpt-neox-20b,128,1,2145.0,1.0,1,H100,1697105202015,1697105204160.0,120,23.0,1.0,"[196, 1949]","[1697105202211, 1697105204160]"
2521,261,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245504,1697105247242.0,120,,,[71],[1697105245575]
2522,201,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105218448,1697105220995.0,120,,,[13],[1697105218461]
2523,638,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105224662,1697105228773.0,120,,,"[29, 1561, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105224691, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2524,558,18,[],200,EleutherAI/gpt-neox-20b,128,1,5254.0,1.0,1,H100,1697105220998,1697105226252.0,120,58.0,20.0,"[110, 2295, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579, 82, 77, 75, 73, 706]","[1697105221108, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225546, 1697105226252]"
2525,432,21,[],200,EleutherAI/gpt-neox-20b,128,1,1042.0,1.0,1,H100,1697105227709,1697105228751.0,120,13.0,1.0,"[13, 1029]","[1697105227722, 1697105228751]"
2526,112,14,[],200,EleutherAI/gpt-neox-20b,128,1,2653.0,1.0,1,H100,1697105204161,1697105206814.0,120,16.0,2.0,"[8, 2644]","[1697105204169, 1697105206813]"
2527,751,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236782.0,120,,,[65],[1697105234987]
2528,469,15,[],200,EleutherAI/gpt-neox-20b,128,1,2444.0,1.0,1,H100,1697105206815,1697105209259.0,120,17.0,1.0,"[8, 2436]","[1697105206823, 1697105209259]"
2529,608,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252037.0,120,,,[70],[1697105250421]
2530,78,12,[],200,EleutherAI/gpt-neox-20b,128,1,5128.0,1.0,1,H100,1697105209439,1697105214567.0,120,84.0,20.0,"[4, 2572, 89, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 65]","[1697105209443, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567]"
2531,38,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252042,1697105253711.0,120,,,[152],[1697105252194]
2532,393,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253717,1697105256010.0,120,,,[307],[1697105254024]
2533,687,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226955,1697105228773.0,120,,,[12],[1697105226967]
2534,792,22,[],200,EleutherAI/gpt-neox-20b,128,1,900.0,1.0,1,H100,1697105228752,1697105229652.0,120,11.0,1.0,"[12, 888]","[1697105228764, 1697105229652]"
2535,747,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258921.0,120,,,[73],[1697105256086]
2536,89,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230475.0,120,,,[28],[1697105228809]
2537,820,16,[],200,EleutherAI/gpt-neox-20b,128,1,3719.0,1.0,1,H100,1697105209260,1697105212979.0,120,161.0,9.0,"[5, 2750, 89, 80, 79, 75, 72, 481, 88]","[1697105209265, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979]"
2538,148,28,[],200,EleutherAI/gpt-neox-20b,128,1,2505.0,1.0,1,H100,1697105258926,1697105261431.0,120,16.0,1.0,"[264, 2241]","[1697105259190, 1697105261431]"
2539,447,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105234920.0,120,,,"[127, 2451, 600, 617]","[1697105230605, 1697105233056, 1697105233656, 1697105234273]"
2540,220,23,[],200,EleutherAI/gpt-neox-20b,128,1,1852.0,1.0,1,H100,1697105229653,1697105231505.0,120,67.0,2.0,"[12, 1840]","[1697105229665, 1697105231505]"
2541,571,24,[],200,EleutherAI/gpt-neox-20b,128,1,1550.0,1.0,1,H100,1697105231506,1697105233056.0,120,67.0,2.0,"[5, 1545]","[1697105231511, 1697105233056]"
2542,436,13,[],200,EleutherAI/gpt-neox-20b,128,1,5318.0,1.0,1,H100,1697105214568,1697105219886.0,120,86.0,20.0,"[4, 2333, 84, 66, 385, 89, 87, 406, 88, 81, 256, 79, 368, 81, 59, 366, 89, 75, 260, 61]","[1697105214572, 1697105216905, 1697105216989, 1697105217055, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219824, 1697105219885]"
2543,901,25,[],200,EleutherAI/gpt-neox-20b,128,1,1825.0,1.0,1,H100,1697105233057,1697105234882.0,120,17.0,1.0,"[9, 1816]","[1697105233066, 1697105234882]"
2544,330,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234883,1697105236781.0,120,,,[13],[1697105234896]
2545,711,15,[],200,EleutherAI/gpt-neox-20b,128,1,2402.0,1.0,1,H100,1697105214173,1697105216575.0,120,457.0,4.0,"[8, 2238, 89, 67]","[1697105214181, 1697105216419, 1697105216508, 1697105216575]"
2546,214,11,[],200,EleutherAI/gpt-neox-20b,128,1,6146.0,1.0,1,H100,1697105207079,1697105213225.0,120,52.0,20.0,"[9, 3045, 86, 83, 502, 82, 429, 167, 77, 457, 88, 80, 79, 75, 72, 481, 88, 89, 82, 75]","[1697105207088, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211315, 1697105211482, 1697105211559, 1697105212016, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225]"
2547,691,27,[],200,EleutherAI/gpt-neox-20b,128,1,1601.0,1.0,1,H100,1697105236784,1697105238385.0,120,47.0,1.0,"[98, 1503]","[1697105236882, 1697105238385]"
2548,125,28,[],200,EleutherAI/gpt-neox-20b,128,1,953.0,1.0,1,H100,1697105238386,1697105239339.0,120,13.0,1.0,"[20, 933]","[1697105238406, 1697105239339]"
2549,453,29,[],200,EleutherAI/gpt-neox-20b,128,1,1865.0,1.0,1,H100,1697105239340,1697105241205.0,120,26.0,1.0,"[25, 1840]","[1697105239365, 1697105241205]"
2550,832,11,[],200,EleutherAI/gpt-neox-20b,128,1,2596.0,1.0,1,H100,1697105217441,1697105220037.0,120,15.0,1.0,"[5, 2590]","[1697105217446, 1697105220036]"
2551,807,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241206,1697105243753.0,120,,,[9],[1697105241215]
2552,234,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243755,1697105245502.0,120,,,"[28, 1644]","[1697105243783, 1697105245427]"
2553,417,17,[],200,EleutherAI/gpt-neox-20b,128,1,1395.0,1.0,1,H100,1697105228257,1697105229652.0,120,17.0,1.0,"[36, 1359]","[1697105228293, 1697105229652]"
2554,146,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270308,1697105271972.0,120,,,[60],[1697105270368]
2555,775,18,[],200,EleutherAI/gpt-neox-20b,128,1,1653.0,1.0,1,H100,1697105229653,1697105231306.0,120,17.0,1.0,"[24, 1629]","[1697105229677, 1697105231306]"
2556,205,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105231307,1697105234918.0,120,,,"[5, 1744, 600, 617]","[1697105231312, 1697105233056, 1697105233656, 1697105234273]"
2557,264,12,[],200,EleutherAI/gpt-neox-20b,128,1,4623.0,1.0,1,H100,1697105220037,1697105224660.0,120,86.0,20.0,"[5, 1923, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105220042, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
2558,572,12,[],200,EleutherAI/gpt-neox-20b,128,1,1957.0,1.0,1,H100,1697105213226,1697105215183.0,120,16.0,1.0,"[9, 1948]","[1697105213235, 1697105215183]"
2559,213,6,[],200,EleutherAI/gpt-neox-20b,128,1,3422.0,1.0,1,H100,1697105188707,1697105192129.0,120,123.0,6.0,"[21, 2789, 166, 83, 281, 82]","[1697105188728, 1697105191517, 1697105191683, 1697105191766, 1697105192047, 1697105192129]"
2560,693,17,[],200,EleutherAI/gpt-neox-20b,128,1,2678.0,1.0,1,H100,1697105217442,1697105220120.0,120,67.0,2.0,"[4, 2674]","[1697105217446, 1697105220120]"
2561,505,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271978,1697105275207.0,120,,,[236],[1697105272214]
2562,591,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105248695.0,120,,,[194],[1697105245700]
2563,123,18,[],200,EleutherAI/gpt-neox-20b,128,1,1782.0,1.0,1,H100,1697105220121,1697105221903.0,120,14.0,1.0,"[8, 1774]","[1697105220129, 1697105221903]"
2564,578,7,[],200,EleutherAI/gpt-neox-20b,128,1,2519.0,1.0,1,H100,1697105192130,1697105194649.0,120,31.0,1.0,"[8, 2511]","[1697105192138, 1697105194649]"
2565,926,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105215184,1697105220994.0,120,,,"[9, 2829, 88, 81, 256, 79, 368, 81, 59, 366, 84, 80, 259, 62, 235, 78, 229, 81, 198]","[1697105215193, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219484, 1697105219564, 1697105219823, 1697105219885, 1697105220120, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
2566,909,8,[],200,EleutherAI/gpt-neox-20b,128,1,6804.0,1.0,1,H100,1697105194650,1697105201454.0,120,86.0,20.0,"[5, 3378, 211, 117, 63, 265, 273, 410, 224, 231, 130, 149, 141, 80, 79, 220, 296, 80, 292, 160]","[1697105194655, 1697105198033, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199957, 1697105200106, 1697105200247, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454]"
2567,480,19,[],200,EleutherAI/gpt-neox-20b,128,1,2257.0,1.0,1,H100,1697105221905,1697105224162.0,120,26.0,1.0,"[31, 2226]","[1697105221936, 1697105224162]"
2568,838,20,[],200,EleutherAI/gpt-neox-20b,128,1,4092.0,1.0,1,H100,1697105224163,1697105228255.0,120,90.0,20.0,"[4, 1072, 82, 78, 74, 74, 705, 91, 85, 65, 84, 487, 90, 89, 85, 583, 93, 84, 84, 83]","[1697105224167, 1697105225239, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227064, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2569,21,33,[],200,EleutherAI/gpt-neox-20b,128,1,1624.0,1.0,1,H100,1697105248698,1697105250322.0,120,15.0,1.0,"[79, 1545]","[1697105248777, 1697105250322]"
2570,555,9,[],200,EleutherAI/gpt-neox-20b,128,1,2267.0,1.0,1,H100,1697105189070,1697105191337.0,120,11.0,1.0,"[13, 2254]","[1697105189083, 1697105191337]"
2571,916,10,[],200,EleutherAI/gpt-neox-20b,128,1,1339.0,1.0,1,H100,1697105191338,1697105192677.0,120,8.0,1.0,"[5, 1334]","[1697105191343, 1697105192677]"
2572,319,11,[],200,EleutherAI/gpt-neox-20b,128,1,2714.0,1.0,1,H100,1697105192678,1697105195392.0,120,31.0,1.0,"[9, 2705]","[1697105192687, 1697105195392]"
2573,470,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250323,1697105252038.0,120,,,[4],[1697105250327]
2574,237,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228257,1697105232145.0,120,,,"[20, 2238, 990, 76, 75, 74, 73]","[1697105228277, 1697105230515, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
2575,200,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105197707,1697105201999.0,120,,,"[5, 2914, 296, 80, 292, 160, 212]","[1697105197712, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
2576,561,10,[],200,EleutherAI/gpt-neox-20b,128,1,4079.0,1.0,1,H100,1697105202003,1697105206082.0,120,87.0,20.0,"[68, 1647, 88, 88, 87, 269, 87, 86, 84, 415, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84]","[1697105202071, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
2577,471,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258907.0,120,,,[17],[1697105256030]
2578,919,11,[],200,EleutherAI/gpt-neox-20b,128,1,1784.0,1.0,1,H100,1697105206084,1697105207868.0,120,14.0,1.0,"[21, 1762]","[1697105206105, 1697105207867]"
2579,323,12,[],200,EleutherAI/gpt-neox-20b,128,1,5357.0,1.0,1,H100,1697105207868,1697105213225.0,120,84.0,20.0,"[5, 2261, 86, 82, 502, 82, 428, 168, 77, 457, 88, 80, 80, 74, 72, 481, 88, 89, 82, 75]","[1697105207873, 1697105210134, 1697105210220, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482, 1697105211559, 1697105212016, 1697105212104, 1697105212184, 1697105212264, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225]"
2580,639,17,[],200,EleutherAI/gpt-neox-20b,128,1,1041.0,1.0,1,H100,1697105224506,1697105225547.0,120,100.0,6.0,"[4, 729, 82, 78, 74, 74]","[1697105224510, 1697105225239, 1697105225321, 1697105225399, 1697105225473, 1697105225547]"
2581,831,35,[],200,EleutherAI/gpt-neox-20b,128,1,1639.0,1.0,1,H100,1697105252042,1697105253681.0,120,11.0,1.0,"[173, 1466]","[1697105252215, 1697105253681]"
2582,356,14,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105220998,1697105222667.0,120,874.0,2.0,"[90, 1579]","[1697105221088, 1697105222667]"
2583,315,10,[],200,EleutherAI/gpt-neox-20b,128,1,4918.0,1.0,1,H100,1697105194044,1697105198962.0,120,335.0,14.0,"[4, 3042, 85, 62, 152, 158, 82, 77, 326, 212, 117, 63, 265, 273]","[1697105194048, 1697105197090, 1697105197175, 1697105197237, 1697105197389, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962]"
2584,239,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228257,1697105232145.0,120,,,"[33, 2226, 990, 75, 75, 74, 73]","[1697105228290, 1697105230516, 1697105231506, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
2585,681,15,[],200,EleutherAI/gpt-neox-20b,128,1,2476.0,1.0,1,H100,1697105222668,1697105225144.0,120,23.0,1.0,"[5, 2471]","[1697105222673, 1697105225144]"
2586,905,8,[],200,EleutherAI/gpt-neox-20b,128,1,2122.0,1.0,1,H100,1697105191686,1697105193808.0,120,11.0,1.0,"[11, 2111]","[1697105191697, 1697105193808]"
2587,304,9,[],200,EleutherAI/gpt-neox-20b,128,1,6018.0,1.0,1,H100,1697105193809,1697105199827.0,120,86.0,20.0,"[9, 2542, 282, 189, 259, 85, 62, 152, 158, 82, 77, 326, 212, 117, 63, 265, 273, 410, 225, 230]","[1697105193818, 1697105196360, 1697105196642, 1697105196831, 1697105197090, 1697105197175, 1697105197237, 1697105197389, 1697105197547, 1697105197629, 1697105197706, 1697105198032, 1697105198244, 1697105198361, 1697105198424, 1697105198689, 1697105198962, 1697105199372, 1697105199597, 1697105199827]"
2588,597,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105234225.0,120,,,[73],[1697105232223]
2589,22,23,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105234226,1697105236002.0,120,16.0,1.0,"[41, 1735]","[1697105234267, 1697105236002]"
2590,601,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230476.0,120,,,[88],[1697105228869]
2591,664,10,[],200,EleutherAI/gpt-neox-20b,128,1,4679.0,1.0,1,H100,1697105199828,1697105204507.0,120,364.0,9.0,"[8, 3882, 88, 88, 87, 269, 87, 86, 84]","[1697105199836, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507]"
2592,35,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105234920.0,120,,,"[135, 2443, 600, 617]","[1697105230613, 1697105233056, 1697105233656, 1697105234273]"
2593,113,16,[],200,EleutherAI/gpt-neox-20b,128,1,1808.0,1.0,1,H100,1697105225146,1697105226954.0,120,13.0,1.0,"[52, 1755]","[1697105225198, 1697105226953]"
2594,364,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234925,1697105238408.0,120,,,[267],[1697105235192]
2595,385,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236006,1697105238408.0,120,,,[27],[1697105236033]
2596,742,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238412,1697105240331.0,120,,,[203],[1697105238615]
2597,472,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226955,1697105228773.0,120,,,[16],[1697105226971]
2598,833,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230476.0,120,,,[100],[1697105228881]
2599,100,11,[],200,EleutherAI/gpt-neox-20b,128,1,3784.0,1.0,1,H100,1697105204508,1697105208292.0,120,732.0,14.0,"[5, 2301, 89, 89, 86, 81, 79, 60, 61, 618, 86, 82, 83, 64]","[1697105204513, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208292]"
2600,812,22,[],200,EleutherAI/gpt-neox-20b,128,1,1865.0,1.0,1,H100,1697105239340,1697105241205.0,120,16.0,1.0,"[45, 1820]","[1697105239385, 1697105241205]"
2601,859,36,[],200,EleutherAI/gpt-neox-20b,128,1,1658.0,1.0,1,H100,1697105259773,1697105261431.0,120,23.0,1.0,"[16, 1641]","[1697105259789, 1697105261430]"
2602,258,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105232146.0,120,,,[102],[1697105230580]
2603,89,9,[],200,EleutherAI/gpt-neox-20b,128,1,5282.0,1.0,1,H100,1697105187888,1697105193170.0,120,52.0,20.0,"[9, 2280, 166, 250, 88, 250, 66, 87, 67, 366, 162, 87, 281, 82, 276, 75, 286, 87, 83, 234]","[1697105187897, 1697105190177, 1697105190343, 1697105190593, 1697105190681, 1697105190931, 1697105190997, 1697105191084, 1697105191151, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192405, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170]"
2604,705,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232151,1697105234225.0,120,,,[132],[1697105232283]
2605,425,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262310,1697105264083.0,120,,,[73],[1697105262383]
2606,144,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241994.0,120,,,[173],[1697105240507]
2607,783,38,[],200,EleutherAI/gpt-neox-20b,128,1,3099.0,1.0,1,H100,1697105264087,1697105267186.0,120,286.0,1.0,"[288, 2811]","[1697105264375, 1697105267186]"
2608,473,42,[],200,EleutherAI/gpt-neox-20b,128,1,3779.0,1.0,1,H100,1697105273589,1697105277368.0,120,244.0,50.0,"[281, 2074, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 32, 33, 32, 33, 29, 28, 28, 28, 32, 27, 27, 27, 27, 31, 26, 26, 29, 26, 26, 28, 25, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 24, 26]","[1697105273870, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276501, 1697105276534, 1697105276566, 1697105276599, 1697105276628, 1697105276656, 1697105276684, 1697105276712, 1697105276744, 1697105276771, 1697105276798, 1697105276825, 1697105276852, 1697105276883, 1697105276909, 1697105276935, 1697105276964, 1697105276990, 1697105277016, 1697105277044, 1697105277069, 1697105277093, 1697105277118, 1697105277143, 1697105277168, 1697105277193, 1697105277218, 1697105277243, 1697105277268, 1697105277293, 1697105277318, 1697105277342, 1697105277368]"
2609,134,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234226,1697105236781.0,120,,,[16],[1697105234242]
2610,501,27,[],200,EleutherAI/gpt-neox-20b,128,1,1554.0,1.0,1,H100,1697105242000,1697105243554.0,120,19.0,1.0,"[39, 1515]","[1697105242039, 1697105243554]"
2611,318,13,[],200,EleutherAI/gpt-neox-20b,128,1,3242.0,1.0,1,H100,1697105198425,1697105201667.0,120,6.0,6.0,"[9, 2488, 80, 292, 160, 213]","[1697105198434, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201667]"
2612,851,7,[],200,EleutherAI/gpt-neox-20b,128,1,2490.0,1.0,1,H100,1697105210304,1697105212794.0,120,23.0,1.0,"[8, 2482]","[1697105210312, 1697105212794]"
2613,858,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243555,1697105245501.0,120,,,[44],[1697105243599]
2614,784,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245504,1697105247243.0,120,,,[88],[1697105245592]
2615,289,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245503,1697105247242.0,120,,,[69],[1697105245572]
2616,642,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247254,1697105250347.0,120,,,[237],[1697105247491]
2617,285,8,[],200,EleutherAI/gpt-neox-20b,128,1,6769.0,1.0,1,H100,1697105212795,1697105219564.0,120,100.0,27.0,"[9, 2490, 85, 356, 90, 84, 510, 89, 67, 83, 247, 84, 65, 386, 89, 87, 406, 87, 82, 256, 79, 368, 81, 59, 366, 89, 75]","[1697105212804, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216905, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564]"
2618,763,14,[],200,EleutherAI/gpt-neox-20b,128,1,1312.0,1.0,1,H100,1697105201668,1697105202980.0,120,20.0,1.0,"[4, 1308]","[1697105201672, 1697105202980]"
2619,209,30,[],200,EleutherAI/gpt-neox-20b,128,1,2426.0,1.0,1,H100,1697105247255,1697105249681.0,120,20.0,1.0,"[269, 2157]","[1697105247524, 1697105249681]"
2620,445,10,[],200,EleutherAI/gpt-neox-20b,128,1,2772.0,1.0,1,H100,1697105193171,1697105195943.0,120,457.0,2.0,"[4, 2768]","[1697105193175, 1697105195943]"
2621,567,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105249682,1697105252037.0,120,,,[29],[1697105249711]
2622,162,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250350,1697105252036.0,120,,,[47],[1697105250397]
2623,778,9,[],200,EleutherAI/gpt-neox-20b,128,1,10527.0,1.0,1,H100,1697105183926,1697105194453.0,120,16.0,50.0,"[9, 2654, 88, 79, 77, 60, 279, 84, 83, 83, 376, 89, 561, 94, 164, 81, 376, 86, 85, 481, 90, 272, 165, 251, 87, 251, 66, 87, 66, 367, 162, 87, 281, 82, 275, 76, 286, 87, 83, 234, 82, 62, 305, 87, 189, 84, 64, 80, 266, 64]","[1697105183935, 1697105186589, 1697105186677, 1697105186756, 1697105186833, 1697105186893, 1697105187172, 1697105187256, 1697105187339, 1697105187422, 1697105187798, 1697105187887, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189163, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190593, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193619, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194123, 1697105194389, 1697105194453]"
2624,521,32,[],200,EleutherAI/gpt-neox-20b,128,1,1640.0,1.0,1,H100,1697105252042,1697105253682.0,120,18.0,1.0,"[27, 1612]","[1697105252069, 1697105253681]"
2625,883,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253687,1697105255028.0,120,,,[106],[1697105253793]
2626,540,11,[],200,EleutherAI/gpt-neox-20b,128,1,3943.0,1.0,1,H100,1697105218895,1697105222838.0,120,140.0,5.0,"[5, 3065, 702, 87, 84]","[1697105218900, 1697105221965, 1697105222667, 1697105222754, 1697105222838]"
2627,313,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[166],[1697105255196]
2628,898,12,[],200,EleutherAI/gpt-neox-20b,128,1,2400.0,1.0,1,H100,1697105222839,1697105225239.0,120,79.0,2.0,"[5, 2395]","[1697105222844, 1697105225239]"
2629,892,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105195944,1697105201999.0,120,,,"[4, 3014, 410, 224, 231, 129, 150, 140, 81, 79, 220, 296, 80, 292, 160, 213]","[1697105195948, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201667]"
2630,637,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105258913.0,120,,,[85],[1697105257203]
2631,42,18,[],200,EleutherAI/gpt-neox-20b,128,1,2311.0,1.0,1,H100,1697105220999,1697105223310.0,120,10.0,1.0,"[190, 2121]","[1697105221189, 1697105223310]"
2632,401,19,[],200,EleutherAI/gpt-neox-20b,128,1,4944.0,1.0,1,H100,1697105223311,1697105228255.0,120,84.0,20.0,"[4, 1924, 82, 77, 75, 74, 706, 90, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105223315, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225547, 1697105226253, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2633,497,16,[],200,EleutherAI/gpt-neox-20b,128,1,2271.0,1.0,1,H100,1697105211560,1697105213831.0,120,67.0,2.0,"[5, 2265]","[1697105211565, 1697105213830]"
2634,862,17,[],200,EleutherAI/gpt-neox-20b,128,1,2588.0,1.0,1,H100,1697105213831,1697105216419.0,120,216.0,2.0,"[5, 2583]","[1697105213836, 1697105216419]"
2635,290,18,[],200,EleutherAI/gpt-neox-20b,128,1,2798.0,1.0,1,H100,1697105216420,1697105219218.0,120,14.0,1.0,"[9, 2789]","[1697105216429, 1697105219218]"
2636,769,17,[],200,EleutherAI/gpt-neox-20b,128,1,4241.0,1.0,1,H100,1697105220998,1697105225239.0,120,47.0,20.0,"[78, 1591, 87, 85, 82, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579]","[1697105221076, 1697105222667, 1697105222754, 1697105222839, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239]"
2637,650,19,[],200,EleutherAI/gpt-neox-20b,128,1,2684.0,1.0,1,H100,1697105219219,1697105221903.0,120,13.0,1.0,"[4, 2680]","[1697105219223, 1697105221903]"
2638,75,20,[],200,EleutherAI/gpt-neox-20b,128,1,3569.0,1.0,1,H100,1697105221904,1697105225473.0,120,345.0,18.0,"[4, 1495, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 580, 81, 78, 74]","[1697105221908, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225240, 1697105225321, 1697105225399, 1697105225473]"
2639,132,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105215826,1697105220994.0,120,,,"[5, 2616, 79, 368, 81, 59, 366, 85, 79, 259, 62, 234, 79, 229, 81, 198]","[1697105215831, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219485, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
2640,489,15,[],200,EleutherAI/gpt-neox-20b,128,1,6067.0,1.0,1,H100,1697105220996,1697105227063.0,120,79.0,30.0,"[32, 1639, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 352, 90, 70, 88, 87, 68, 579, 82, 77, 75, 73, 706, 91, 85, 65, 84, 486]","[1697105221028, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224257, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225546, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063]"
2641,616,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105195770,1697105201999.0,120,,,"[4, 4183, 149, 140, 81, 79, 220, 296, 80, 292, 160, 212]","[1697105195774, 1697105199957, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
2642,45,10,[],200,EleutherAI/gpt-neox-20b,128,1,1623.0,1.0,1,H100,1697105202003,1697105203626.0,120,19.0,1.0,"[44, 1579]","[1697105202047, 1697105203626]"
2643,404,11,[],200,EleutherAI/gpt-neox-20b,128,1,5186.0,1.0,1,H100,1697105203627,1697105208813.0,120,87.0,20.0,"[12, 2183, 91, 85, 84, 732, 89, 89, 86, 81, 79, 60, 60, 619, 86, 82, 83, 64, 434, 87]","[1697105203639, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207358, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208292, 1697105208726, 1697105208813]"
2644,197,18,[],200,EleutherAI/gpt-neox-20b,128,1,2848.0,1.0,1,H100,1697105225240,1697105228088.0,120,6.0,8.0,"[9, 1815, 91, 88, 85, 583, 93, 84]","[1697105225249, 1697105227064, 1697105227155, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088]"
2645,189,5,[],200,EleutherAI/gpt-neox-20b,128,1,4267.0,1.0,1,H100,1697105176271,1697105180538.0,120,88.0,20.0,"[49, 1603, 94, 90, 88, 68, 86, 468, 90, 67, 87, 81, 356, 88, 85, 65, 366, 85, 66, 285]","[1697105176320, 1697105177923, 1697105178017, 1697105178107, 1697105178195, 1697105178263, 1697105178349, 1697105178817, 1697105178907, 1697105178974, 1697105179061, 1697105179142, 1697105179498, 1697105179586, 1697105179671, 1697105179736, 1697105180102, 1697105180187, 1697105180253, 1697105180538]"
2646,179,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236785,1697105240330.0,120,,,[213],[1697105236998]
2647,506,29,[],200,EleutherAI/gpt-neox-20b,128,1,1639.0,1.0,1,H100,1697105261432,1697105263071.0,120,16.0,1.0,"[32, 1606]","[1697105261464, 1697105263070]"
2648,643,19,[],200,EleutherAI/gpt-neox-20b,128,1,1563.0,1.0,1,H100,1697105228089,1697105229652.0,120,18.0,1.0,"[5, 1558]","[1697105228094, 1697105229652]"
2649,868,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263072,1697105265927.0,120,,,[4],[1697105263076]
2650,539,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240333,1697105241995.0,120,,,[38],[1697105240371]
2651,69,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105229653,1697105232145.0,120,,,"[20, 1832, 76, 75, 74, 73]","[1697105229673, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
2652,221,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105212980,1697105220994.0,120,,,"[5, 2309, 86, 355, 90, 84, 510, 89, 67, 83, 247, 84, 65, 386, 89, 87, 406, 87, 82, 256, 79, 368, 81, 59, 366, 89, 75, 259, 62, 234, 79, 229, 81, 198]","[1697105212985, 1697105215294, 1697105215380, 1697105215735, 1697105215825, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216905, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
2653,338,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271977,1697105275207.0,120,,,[214],[1697105272191]
2654,754,12,[],200,EleutherAI/gpt-neox-20b,128,1,3370.0,1.0,1,H100,1697105208814,1697105212184.0,120,88.0,7.0,"[5, 2495, 168, 77, 456, 89, 80]","[1697105208819, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184]"
2655,231,11,[],200,EleutherAI/gpt-neox-20b,128,1,3156.0,1.0,1,H100,1697105198426,1697105201582.0,120,13.0,1.0,"[24, 3132]","[1697105198450, 1697105201582]"
2656,184,13,[],200,EleutherAI/gpt-neox-20b,128,1,5431.0,1.0,1,H100,1697105212185,1697105217616.0,120,87.0,20.0,"[5, 2227, 85, 65, 75, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246, 85, 65, 386, 89, 87]","[1697105212190, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616]"
2657,592,12,[],200,EleutherAI/gpt-neox-20b,128,1,10521.0,1.0,1,H100,1697105201583,1697105212104.0,120,15.0,50.0,"[8, 2127, 88, 88, 87, 269, 87, 86, 84, 415, 93, 88, 88, 69, 87, 86, 389, 91, 85, 84, 731, 90, 89, 86, 80, 80, 60, 60, 618, 87, 82, 83, 63, 435, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 81, 429, 168, 77, 456, 89]","[1697105201591, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207358, 1697105207976, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210885, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104]"
2658,543,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247256,1697105250347.0,120,,,[251],[1697105247507]
2659,579,18,[],200,EleutherAI/gpt-neox-20b,128,1,1575.0,1.0,1,H100,1697105220998,1697105222573.0,120,19.0,1.0,"[18, 1557]","[1697105221016, 1697105222573]"
2660,203,17,[],200,EleutherAI/gpt-neox-20b,128,1,3937.0,1.0,1,H100,1697105214173,1697105218110.0,120,364.0,13.0,"[4, 2242, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87]","[1697105214177, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109]"
2661,12,19,[],200,EleutherAI/gpt-neox-20b,128,1,1588.0,1.0,1,H100,1697105222574,1697105224162.0,120,11.0,1.0,"[16, 1572]","[1697105222590, 1697105224162]"
2662,613,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105198426,1697105201999.0,120,,,"[29, 3212]","[1697105198455, 1697105201667]"
2663,373,20,[],200,EleutherAI/gpt-neox-20b,128,1,981.0,1.0,1,H100,1697105224163,1697105225144.0,120,15.0,1.0,"[16, 965]","[1697105224179, 1697105225144]"
2664,43,10,[],200,EleutherAI/gpt-neox-20b,128,1,2420.0,1.0,1,H100,1697105202004,1697105204424.0,120,732.0,8.0,"[83, 1631, 88, 88, 87, 269, 87, 86]","[1697105202087, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423]"
2665,556,20,[],200,EleutherAI/gpt-neox-20b,128,1,1834.0,1.0,1,H100,1697105234922,1697105236756.0,120,9.0,1.0,"[61, 1773]","[1697105234983, 1697105236756]"
2666,875,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105214328,1697105220994.0,120,,,"[12, 1894, 185, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 82, 257, 78, 368, 81, 59, 366, 89, 75, 259, 62, 235, 78, 229, 81, 198]","[1697105214340, 1697105216234, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218448, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219823, 1697105219885, 1697105220120, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
2667,397,11,[],200,EleutherAI/gpt-neox-20b,128,1,2390.0,1.0,1,H100,1697105204424,1697105206814.0,120,67.0,2.0,"[5, 2385]","[1697105204429, 1697105206814]"
2668,71,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236757,1697105238409.0,120,,,[8],[1697105236765]
2669,39,17,[],200,EleutherAI/gpt-neox-20b,128,1,1577.0,1.0,1,H100,1697105220996,1697105222573.0,120,8.0,1.0,"[72, 1505]","[1697105221068, 1697105222573]"
2670,725,18,[],200,EleutherAI/gpt-neox-20b,128,1,5333.0,1.0,1,H100,1697105222922,1697105228255.0,120,90.0,20.0,"[4, 2313, 82, 77, 75, 74, 706, 90, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105222926, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225547, 1697105226253, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2671,282,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105247242.0,120,,,[65],[1697105245571]
2672,777,10,[],200,EleutherAI/gpt-neox-20b,128,1,3128.0,1.0,1,H100,1697105197707,1697105200835.0,120,9.0,1.0,"[9, 3119]","[1697105197716, 1697105200835]"
2673,641,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247249,1697105248695.0,120,,,[137],[1697105247386]
2674,396,18,[],200,EleutherAI/gpt-neox-20b,128,1,4669.0,1.0,1,H100,1697105222574,1697105227243.0,120,89.0,20.0,"[8, 1675, 90, 70, 88, 87, 68, 579, 82, 77, 75, 73, 707, 90, 85, 65, 84, 486, 91, 89]","[1697105222582, 1697105224257, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225546, 1697105226253, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243]"
2675,69,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105250348.0,120,,,[21],[1697105248720]
2676,212,11,[],200,EleutherAI/gpt-neox-20b,128,1,2144.0,1.0,1,H100,1697105200836,1697105202980.0,120,31.0,1.0,"[9, 2135]","[1697105200845, 1697105202980]"
2677,758,12,[],200,EleutherAI/gpt-neox-20b,128,1,6253.0,1.0,1,H100,1697105206815,1697105213068.0,120,84.0,20.0,"[12, 2611, 77, 618, 86, 83, 502, 82, 428, 169, 76, 456, 89, 80, 79, 75, 72, 481, 88, 89]","[1697105206827, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211483, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068]"
2678,569,12,[],200,EleutherAI/gpt-neox-20b,128,1,1756.0,1.0,1,H100,1697105202981,1697105204737.0,120,16.0,1.0,"[25, 1731]","[1697105203006, 1697105204737]"
2679,420,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250353,1697105252038.0,120,,,[229],[1697105250582]
2680,779,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252042,1697105253712.0,120,,,[249],[1697105252291]
2681,833,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258915,1697105260463.0,120,,,[10],[1697105258925]
2682,378,6,[],200,EleutherAI/gpt-neox-20b,128,1,10285.0,1.0,1,H100,1697105185399,1697105195684.0,120,93.0,47.0,"[21, 3028, 94, 164, 81, 375, 87, 85, 481, 91, 271, 165, 251, 87, 251, 66, 87, 67, 366, 162, 87, 281, 82, 275, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 80, 266, 64, 84, 199, 80, 78, 261, 326, 87, 116]","[1697105185420, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189906, 1697105190177, 1697105190342, 1697105190593, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191151, 1697105191517, 1697105191679, 1697105191766, 1697105192047, 1697105192129, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194123, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194894, 1697105195155, 1697105195481, 1697105195568, 1697105195684]"
2683,337,9,[],200,EleutherAI/gpt-neox-20b,128,1,1525.0,1.0,1,H100,1697105201455,1697105202980.0,120,12.0,1.0,"[5, 1520]","[1697105201460, 1697105202980]"
2684,0,13,[],200,EleutherAI/gpt-neox-20b,128,1,10556.0,1.0,1,H100,1697105204738,1697105215294.0,120,244.0,50.0,"[4, 2072, 89, 89, 86, 81, 79, 60, 61, 617, 87, 82, 83, 64, 434, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 82, 428, 168, 77, 456, 89, 80, 79, 75, 71, 482, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 84, 65, 76, 652]","[1697105204742, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207976, 1697105208063, 1697105208145, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212409, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214501, 1697105214566, 1697105214642, 1697105215294]"
2685,691,10,[],200,EleutherAI/gpt-neox-20b,128,1,1755.0,1.0,1,H100,1697105202982,1697105204737.0,120,47.0,1.0,"[40, 1715]","[1697105203022, 1697105204737]"
2686,160,13,[],200,EleutherAI/gpt-neox-20b,128,1,2114.0,1.0,1,H100,1697105213069,1697105215183.0,120,13.0,1.0,"[12, 2102]","[1697105213081, 1697105215183]"
2687,118,11,[],200,EleutherAI/gpt-neox-20b,128,1,4700.0,1.0,1,H100,1697105204738,1697105209438.0,120,85.0,20.0,"[4, 2072, 89, 89, 86, 81, 79, 60, 61, 617, 87, 82, 83, 63, 435, 87, 84, 79, 77, 385]","[1697105204742, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207976, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438]"
2688,236,39,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105260467,1697105262243.0,120,8.0,1.0,"[242, 1534]","[1697105260709, 1697105262243]"
2689,262,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253687,1697105255028.0,120,,,[110],[1697105253797]
2690,517,14,[],200,EleutherAI/gpt-neox-20b,128,1,2148.0,1.0,1,H100,1697105215185,1697105217333.0,120,15.0,1.0,"[16, 2132]","[1697105215201, 1697105217333]"
2691,646,11,[],200,EleutherAI/gpt-neox-20b,128,1,2952.0,1.0,1,H100,1697105198963,1697105201915.0,120,14.0,1.0,"[5, 2947]","[1697105198968, 1697105201915]"
2692,880,15,[],200,EleutherAI/gpt-neox-20b,128,1,2786.0,1.0,1,H100,1697105217334,1697105220120.0,120,84.0,2.0,"[5, 2781]","[1697105217339, 1697105220120]"
2693,75,12,[],200,EleutherAI/gpt-neox-20b,128,1,3997.0,1.0,1,H100,1697105201916,1697105205913.0,120,345.0,18.0,"[4, 1798, 88, 88, 87, 269, 87, 87, 83, 415, 93, 88, 88, 69, 87, 86, 389, 91]","[1697105201920, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913]"
2694,240,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241206,1697105243753.0,120,,,[5],[1697105241211]
2695,690,24,[],200,EleutherAI/gpt-neox-20b,128,1,1670.0,1.0,1,H100,1697105243757,1697105245427.0,120,39.0,1.0,"[123, 1547]","[1697105243880, 1697105245427]"
2696,436,13,[],200,EleutherAI/gpt-neox-20b,128,1,5568.0,1.0,1,H100,1697105205914,1697105211482.0,120,86.0,20.0,"[4, 2059, 86, 82, 83, 64, 434, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 82, 428, 168]","[1697105205918, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482]"
2697,115,25,[],200,EleutherAI/gpt-neox-20b,128,1,767.0,1.0,1,H100,1697105245429,1697105246196.0,120,13.0,1.0,"[49, 718]","[1697105245478, 1697105246196]"
2698,305,16,[],200,EleutherAI/gpt-neox-20b,128,1,4539.0,1.0,1,H100,1697105220121,1697105224660.0,120,86.0,20.0,"[4, 1840, 702, 87, 85, 82, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105220125, 1697105221965, 1697105222667, 1697105222754, 1697105222839, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
2699,473,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105246198,1697105248696.0,120,,,[32],[1697105246230]
2700,336,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105199597,1697105202005.0,120,,,[5],[1697105199602]
2701,696,11,[],200,EleutherAI/gpt-neox-20b,128,1,5063.0,1.0,1,H100,1697105202015,1697105207078.0,120,83.0,20.0,"[200, 2035, 87, 87, 83, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84, 731, 90, 89, 86]","[1697105202215, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078]"
2702,327,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225240,1697105228774.0,120,,,"[9, 2662, 93, 84, 84, 83]","[1697105225249, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2703,489,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105238408.0,120,,,[37],[1697105236821]
2704,663,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105224662,1697105228773.0,120,,,"[41, 1549, 91, 85, 65, 84, 486, 91, 89, 85, 582, 94, 84, 84, 83]","[1697105224703, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227910, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2705,62,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258919,1697105260463.0,120,,,[166],[1697105259085]
2706,656,14,[],200,EleutherAI/gpt-neox-20b,128,1,2522.0,1.0,1,H100,1697105228784,1697105231306.0,120,26.0,1.0,"[295, 2227]","[1697105229079, 1697105231306]"
2707,422,37,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105260467,1697105262243.0,120,26.0,1.0,"[246, 1530]","[1697105260713, 1697105262243]"
2708,129,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105206086,1697105220994.0,120,,,"[87, 1804, 86, 83, 82, 64, 434, 87, 84, 79, 78, 384, 77, 619, 86, 82, 502, 82, 428, 168, 77, 456, 89, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 64, 76, 652, 85, 356, 90, 83, 511, 89, 66, 84, 246, 85, 65, 386, 89, 87, 406, 87, 81, 257, 79, 368, 81, 59, 366, 84, 80, 259, 62, 234, 79, 228, 82, 197]","[1697105206173, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209054, 1697105209438, 1697105209515, 1697105210134, 1697105210220, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216574, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218190, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219484, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220426, 1697105220508, 1697105220705]"
2709,782,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262244,1697105264083.0,120,,,[17],[1697105262261]
2710,125,12,[],200,EleutherAI/gpt-neox-20b,128,1,2180.0,1.0,1,H100,1697105207079,1697105209259.0,120,13.0,1.0,"[13, 2167]","[1697105207092, 1697105209259]"
2711,215,39,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105264087,1697105265863.0,120,12.0,1.0,"[220, 1556]","[1697105264307, 1697105265863]"
2712,486,13,[],200,EleutherAI/gpt-neox-20b,128,1,5306.0,1.0,1,H100,1697105209261,1697105214567.0,120,14.0,20.0,"[12, 2742, 89, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 65]","[1697105209273, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567]"
2713,545,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265864,1697105267796.0,120,,,[17],[1697105265881]
2714,621,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247255,1697105250347.0,120,,,[256],[1697105247511]
2715,49,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252036.0,120,,,[42],[1697105250393]
2716,475,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105224662,1697105228773.0,120,,,"[9, 1581, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105224671, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2717,889,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243754.0,120,,,[106],[1697105242107]
2718,10,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105227064,1697105232144.0,120,,,"[5, 3446, 990, 76, 74, 74, 74]","[1697105227069, 1697105230515, 1697105231505, 1697105231581, 1697105231655, 1697105231729, 1697105231803]"
2719,41,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228774,1697105230475.0,120,,,[18],[1697105228792]
2720,317,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243757,1697105245501.0,120,,,[10],[1697105243767]
2721,401,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230477,1697105232146.0,120,,,"[5, 1023, 76, 75, 74, 73]","[1697105230482, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
2722,755,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232153,1697105234225.0,120,,,[162],[1697105232315]
2723,184,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234226,1697105236781.0,120,,,[12],[1697105234238]
2724,539,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236785,1697105240330.0,120,,,[293],[1697105237078]
2725,364,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232151,1697105234225.0,120,,,[140],[1697105232291]
2726,871,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241994.0,120,,,[154],[1697105240488]
2727,724,18,[],200,EleutherAI/gpt-neox-20b,128,1,1775.0,1.0,1,H100,1697105234227,1697105236002.0,120,11.0,1.0,"[68, 1707]","[1697105234295, 1697105236002]"
2728,647,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245504,1697105247243.0,120,,,[84],[1697105245588]
2729,440,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225145,1697105228773.0,120,,,"[8, 1099, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105225153, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2730,152,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236006,1697105238408.0,120,,,[31],[1697105236037]
2731,920,12,[],200,EleutherAI/gpt-neox-20b,128,1,2662.0,1.0,1,H100,1697105208898,1697105211560.0,120,96.0,4.0,"[4, 2412, 168, 77]","[1697105208902, 1697105211314, 1697105211482, 1697105211559]"
2732,300,24,[],200,EleutherAI/gpt-neox-20b,128,1,1553.0,1.0,1,H100,1697105242001,1697105243554.0,120,9.0,1.0,"[167, 1385]","[1697105242168, 1697105243553]"
2733,83,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248695.0,120,,,[55],[1697105247302]
2734,442,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248698,1697105250348.0,120,,,[95],[1697105248793]
2735,693,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230476.0,120,,,[96],[1697105228877]
2736,800,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252037.0,120,,,[118],[1697105250469]
2737,323,13,[],200,EleutherAI/gpt-neox-20b,128,1,5344.0,1.0,1,H100,1697105211560,1697105216904.0,120,84.0,20.0,"[9, 2261, 94, 90, 89, 68, 246, 85, 65, 75, 652, 85, 356, 91, 82, 511, 89, 67, 83, 246]","[1697105211569, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215826, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904]"
2738,535,13,[],200,EleutherAI/gpt-neox-20b,128,1,4378.0,1.0,1,H100,1697105202981,1697105207359.0,120,84.0,20.0,"[29, 1912, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84, 732, 89, 89, 86, 81, 79, 60, 61]","[1697105203010, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359]"
2739,225,36,[],200,EleutherAI/gpt-neox-20b,128,1,1640.0,1.0,1,H100,1697105252042,1697105253682.0,120,23.0,1.0,"[248, 1391]","[1697105252290, 1697105253681]"
2740,668,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253685,1697105256010.0,120,,,"[19, 1354]","[1697105253704, 1697105255058]"
2741,835,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230476.0,120,,,[237],[1697105229018]
2742,97,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258913.0,120,,,[98],[1697105256111]
2743,894,14,[],200,EleutherAI/gpt-neox-20b,128,1,2619.0,1.0,1,H100,1697105207360,1697105209979.0,120,14.0,1.0,"[20, 2598]","[1697105207380, 1697105209978]"
2744,457,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258916,1697105260462.0,120,,,[56],[1697105258972]
2745,327,15,[],200,EleutherAI/gpt-neox-20b,128,1,3089.0,1.0,1,H100,1697105209979,1697105213068.0,120,563.0,10.0,"[5, 2032, 88, 80, 80, 74, 72, 481, 88, 89]","[1697105209984, 1697105212016, 1697105212104, 1697105212184, 1697105212264, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068]"
2746,820,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260464,1697105262306.0,120,,,[28],[1697105260492]
2747,659,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105213071,1697105220994.0,120,,,"[11, 2212, 86, 355, 90, 84, 510, 89, 67, 83, 247, 84, 65, 386, 89, 87, 406, 87, 82, 256, 79, 368, 81, 59, 366, 89, 75, 259, 62, 234, 79, 229, 81, 198]","[1697105213082, 1697105215294, 1697105215380, 1697105215735, 1697105215825, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216905, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
2748,220,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262310,1697105264082.0,120,,,[25],[1697105262335]
2749,574,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265928.0,120,,,[43],[1697105264128]
2750,687,18,[],200,EleutherAI/gpt-neox-20b,128,1,4243.0,1.0,1,H100,1697105220996,1697105225239.0,120,96.0,20.0,"[48, 1623, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579]","[1697105221044, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239]"
2751,678,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105195393,1697105201998.0,120,,,"[8, 3288, 273, 410, 224, 231, 129, 150, 140, 81, 79, 220, 296, 80, 292, 160, 212]","[1697105195401, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
2752,595,40,[],200,EleutherAI/gpt-neox-20b,128,1,827.0,1.0,1,H100,1697105262244,1697105263071.0,120,8.0,1.0,"[45, 782]","[1697105262289, 1697105263071]"
2753,563,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264087,1697105267795.0,120,,,[204],[1697105264291]
2754,917,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[5],[1697105267803]
2755,677,13,[],200,EleutherAI/gpt-neox-20b,128,1,1957.0,1.0,1,H100,1697105213226,1697105215183.0,120,9.0,1.0,"[9, 1948]","[1697105213235, 1697105215183]"
2756,106,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105215184,1697105220994.0,120,,,"[5, 2833, 88, 81, 256, 79, 368, 81, 59, 366, 84, 80, 259, 62, 235, 78, 229, 81, 198]","[1697105215189, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219484, 1697105219564, 1697105219823, 1697105219885, 1697105220120, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
2757,342,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269599,1697105270303.0,120,,,[5],[1697105269604]
2758,702,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270309,1697105271973.0,120,,,[92],[1697105270401]
2759,101,42,[],200,EleutherAI/gpt-neox-20b,128,1,2437.0,1.0,1,H100,1697105271977,1697105274414.0,120,13.0,1.0,"[213, 2224]","[1697105272190, 1697105274414]"
2760,466,43,[],200,EleutherAI/gpt-neox-20b,128,1,2151.0,1.0,1,H100,1697105274415,1697105276566.0,120,457.0,20.0,"[5, 1524, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 33, 32, 32]","[1697105274420, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276502, 1697105276534, 1697105276566]"
2761,297,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105211484,1697105220994.0,120,,,"[32, 2314, 94, 90, 89, 68, 246, 85, 65, 75, 653, 84, 356, 91, 83, 510, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 82, 256, 79, 368, 81, 59, 366, 89, 75, 259, 62, 234, 79, 229, 81, 198]","[1697105211516, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215295, 1697105215379, 1697105215735, 1697105215826, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
2762,407,14,[],200,EleutherAI/gpt-neox-20b,128,1,2294.0,1.0,1,H100,1697105216420,1697105218714.0,120,16.0,1.0,"[8, 2286]","[1697105216428, 1697105218714]"
2763,767,15,[],200,EleutherAI/gpt-neox-20b,128,1,1628.0,1.0,1,H100,1697105218715,1697105220343.0,120,11.0,1.0,"[8, 1620]","[1697105218723, 1697105220343]"
2764,195,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105220344,1697105228774.0,120,,,"[13, 1608, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579, 82, 77, 75, 73, 706, 91, 84, 66, 84, 486, 91, 89, 85, 582, 94, 84, 84, 83]","[1697105220357, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225546, 1697105226252, 1697105226343, 1697105226427, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227910, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2765,636,9,[],200,EleutherAI/gpt-neox-20b,128,1,1774.0,1.0,1,H100,1697105201206,1697105202980.0,120,31.0,1.0,"[12, 1762]","[1697105201218, 1697105202980]"
2766,465,15,[],200,EleutherAI/gpt-neox-20b,128,1,1756.0,1.0,1,H100,1697105220998,1697105222754.0,120,364.0,3.0,"[94, 1575, 87]","[1697105221092, 1697105222667, 1697105222754]"
2767,685,17,[],200,EleutherAI/gpt-neox-20b,128,1,2258.0,1.0,1,H100,1697105218448,1697105220706.0,120,364.0,2.0,"[5, 2253]","[1697105218453, 1697105220706]"
2768,851,23,[],200,EleutherAI/gpt-neox-20b,128,1,938.0,1.0,1,H100,1697105240267,1697105241205.0,120,23.0,1.0,"[36, 902]","[1697105240303, 1697105241205]"
2769,276,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241207,1697105243753.0,120,,,[28],[1697105241235]
2770,213,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267187,1697105271972.0,120,,,"[12, 1779, 669, 704, 685]","[1697105267199, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
2771,905,16,[],200,EleutherAI/gpt-neox-20b,128,1,1404.0,1.0,1,H100,1697105224662,1697105226066.0,120,11.0,1.0,"[29, 1375]","[1697105224691, 1697105226066]"
2772,851,23,[],200,EleutherAI/gpt-neox-20b,128,1,1854.0,1.0,1,H100,1697105238412,1697105240266.0,120,23.0,1.0,"[187, 1667]","[1697105238599, 1697105240266]"
2773,200,18,[],200,EleutherAI/gpt-neox-20b,128,1,2767.0,1.0,1,H100,1697105220707,1697105223474.0,120,6.0,9.0,"[5, 1254, 701, 87, 84, 83, 81, 401, 71]","[1697105220712, 1697105221966, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474]"
2774,515,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232126,1697105233608.0,120,,,[26],[1697105232152]
2775,401,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225474,1697105228772.0,120,,,"[5, 2432, 93, 84, 84, 83]","[1697105225479, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2776,805,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[26],[1697105267824]
2777,874,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233610,1697105234918.0,120,,,[12],[1697105233622]
2778,565,19,[],200,EleutherAI/gpt-neox-20b,128,1,4780.0,1.0,1,H100,1697105223475,1697105228255.0,120,91.0,20.0,"[5, 1759, 82, 78, 74, 74, 705, 91, 85, 65, 84, 487, 90, 89, 85, 583, 93, 84, 84, 83]","[1697105223480, 1697105225239, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227064, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2779,609,8,[],200,EleutherAI/gpt-neox-20b,128,1,4078.0,1.0,1,H100,1697105202004,1697105206082.0,120,88.0,20.0,"[75, 1639, 88, 88, 87, 269, 87, 86, 84, 415, 93, 88, 88, 69, 87, 86, 389, 91, 85, 84]","[1697105202079, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
2780,12,9,[],200,EleutherAI/gpt-neox-20b,128,1,1784.0,1.0,1,H100,1697105206084,1697105207868.0,120,11.0,1.0,"[21, 1762]","[1697105206105, 1697105207867]"
2781,230,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[32],[1697105269632]
2782,371,10,[],200,EleutherAI/gpt-neox-20b,128,1,2110.0,1.0,1,H100,1697105207869,1697105209979.0,120,13.0,1.0,"[28, 2082]","[1697105207897, 1697105209979]"
2783,586,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270989,1697105271973.0,120,,,[21],[1697105271010]
2784,732,11,[],200,EleutherAI/gpt-neox-20b,128,1,4437.0,1.0,1,H100,1697105209980,1697105214417.0,120,345.0,12.0,"[12, 2899, 88, 89, 82, 75, 606, 93, 90, 89, 68, 246]","[1697105209992, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213831, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417]"
2785,620,11,[],200,EleutherAI/gpt-neox-20b,128,1,3935.0,1.0,1,H100,1697105185399,1697105189334.0,120,100.0,8.0,"[17, 3032, 94, 164, 81, 375, 87, 85]","[1697105185416, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334]"
2786,51,12,[],200,EleutherAI/gpt-neox-20b,128,1,8294.0,1.0,1,H100,1697105189335,1697105197629.0,120,364.0,36.0,"[5, 3064, 76, 286, 87, 83, 234, 82, 62, 306, 86, 189, 84, 63, 82, 265, 64, 84, 199, 80, 79, 260, 326, 87, 116, 83, 175, 418, 282, 184, 264, 85, 62, 151, 159, 82]","[1697105189340, 1697105192404, 1697105192480, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194042, 1697105194124, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194895, 1697105195155, 1697105195481, 1697105195568, 1697105195684, 1697105195767, 1697105195942, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197388, 1697105197547, 1697105197629]"
2787,157,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105214418,1697105220994.0,120,,,"[8, 3014, 89, 87, 406, 88, 81, 256, 79, 368, 81, 59, 366, 89, 75, 260, 61, 235, 78, 229, 81, 198]","[1697105214426, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219824, 1697105219885, 1697105220120, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
2788,394,26,[],200,EleutherAI/gpt-neox-20b,128,1,1834.0,1.0,1,H100,1697105234922,1697105236756.0,120,11.0,1.0,"[81, 1753]","[1697105235003, 1697105236756]"
2789,748,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236757,1697105238409.0,120,,,[12],[1697105236769]
2790,758,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230476.0,120,,,[40],[1697105228821]
2791,178,28,[],200,EleutherAI/gpt-neox-20b,128,1,1854.0,1.0,1,H100,1697105238412,1697105240266.0,120,11.0,1.0,"[199, 1655]","[1697105238611, 1697105240266]"
2792,163,14,[],200,EleutherAI/gpt-neox-20b,128,1,2208.0,1.0,1,H100,1697105206084,1697105208292.0,120,67.0,6.0,"[37, 1856, 86, 83, 82, 64]","[1697105206121, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292]"
2793,531,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240267,1697105241994.0,120,,,[24],[1697105240291]
2794,893,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243753.0,120,,,[70],[1697105242071]
2795,294,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243757,1697105245501.0,120,,,[6],[1697105243763]
2796,488,13,[],200,EleutherAI/gpt-neox-20b,128,1,1575.0,1.0,1,H100,1697105220998,1697105222573.0,120,6.0,1.0,"[18, 1557]","[1697105221016, 1697105222573]"
2797,651,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245505,1697105247243.0,120,,,[175],[1697105245680]
2798,916,19,[],200,EleutherAI/gpt-neox-20b,128,1,1455.0,1.0,1,H100,1697105226253,1697105227708.0,120,8.0,1.0,"[9, 1446]","[1697105226262, 1697105227708]"
2799,80,33,[],200,EleutherAI/gpt-neox-20b,128,1,2426.0,1.0,1,H100,1697105247255,1697105249681.0,120,13.0,1.0,"[264, 2162]","[1697105247519, 1697105249681]"
2800,346,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105227709,1697105232144.0,120,,,"[17, 2789, 990, 76, 75, 73, 74]","[1697105227726, 1697105230515, 1697105231505, 1697105231581, 1697105231656, 1697105231729, 1697105231803]"
2801,440,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105249682,1697105252037.0,120,,,[24],[1697105249706]
2802,137,7,[],200,EleutherAI/gpt-neox-20b,128,1,4080.0,1.0,1,H100,1697105202002,1697105206082.0,120,86.0,20.0,"[21, 1695, 88, 88, 87, 269, 87, 87, 83, 415, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84]","[1697105202023, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
2803,842,14,[],200,EleutherAI/gpt-neox-20b,128,1,3919.0,1.0,1,H100,1697105222574,1697105226493.0,120,161.0,16.0,"[4, 1679, 90, 70, 88, 87, 68, 579, 82, 77, 75, 73, 707, 90, 85, 65]","[1697105222578, 1697105224257, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225546, 1697105226253, 1697105226343, 1697105226428, 1697105226493]"
2804,797,35,[],200,EleutherAI/gpt-neox-20b,128,1,1640.0,1.0,1,H100,1697105252042,1697105253682.0,120,26.0,1.0,"[76, 1564]","[1697105252118, 1697105253682]"
2805,199,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253686,1697105255027.0,120,,,[83],[1697105253769]
2806,675,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232149,1697105233609.0,120,,,[21],[1697105232170]
2807,556,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[65],[1697105255095]
2808,100,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233610,1697105234919.0,120,,,[32],[1697105233642]
2809,913,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105258913.0,120,,,[77],[1697105257195]
2810,331,14,[],200,EleutherAI/gpt-neox-20b,128,1,2032.0,1.0,1,H100,1697105213151,1697105215183.0,120,26.0,1.0,"[4, 2028]","[1697105213155, 1697105215183]"
2811,343,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258916,1697105260462.0,120,,,[69],[1697105258985]
2812,755,11,[],200,EleutherAI/gpt-neox-20b,128,1,6132.0,1.0,1,H100,1697105211484,1697105217616.0,120,286.0,25.0,"[20, 2326, 94, 90, 89, 68, 246, 85, 64, 76, 653, 84, 356, 91, 83, 510, 89, 67, 83, 246, 85, 65, 386, 89, 87]","[1697105211504, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642, 1697105215295, 1697105215379, 1697105215735, 1697105215826, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616]"
2813,670,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105232146.0,120,,,[62],[1697105230540]
2814,462,23,[],200,EleutherAI/gpt-neox-20b,128,1,1834.0,1.0,1,H100,1697105234922,1697105236756.0,120,52.0,1.0,"[13, 1821]","[1697105234935, 1697105236756]"
2815,510,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238411,1697105240330.0,120,,,[72],[1697105238483]
2816,71,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232149,1697105233608.0,120,,,[13],[1697105232162]
2817,432,21,[],200,EleutherAI/gpt-neox-20b,128,1,1272.0,1.0,1,H100,1697105233610,1697105234882.0,120,13.0,1.0,"[32, 1240]","[1697105233642, 1697105234882]"
2818,701,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260464,1697105262306.0,120,,,[44],[1697105260508]
2819,101,41,[],200,EleutherAI/gpt-neox-20b,128,1,1680.0,1.0,1,H100,1697105262310,1697105263990.0,120,13.0,1.0,"[13, 1667]","[1697105262323, 1697105263990]"
2820,513,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105217617,1697105220996.0,120,,,"[9, 2494, 78, 229, 82, 197]","[1697105217626, 1697105220120, 1697105220198, 1697105220427, 1697105220509, 1697105220706]"
2821,840,21,[],200,EleutherAI/gpt-neox-20b,128,1,1596.0,1.0,1,H100,1697105240334,1697105241930.0,120,17.0,1.0,"[57, 1539]","[1697105240391, 1697105241930]"
2822,786,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234883,1697105236781.0,120,,,[17],[1697105234900]
2823,460,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263991,1697105265927.0,120,,,[4],[1697105263995]
2824,268,22,[],200,EleutherAI/gpt-neox-20b,128,1,759.0,1.0,1,H100,1697105241932,1697105242691.0,120,19.0,1.0,"[24, 735]","[1697105241956, 1697105242691]"
2825,626,23,[],200,EleutherAI/gpt-neox-20b,128,1,1785.0,1.0,1,H100,1697105242692,1697105244477.0,120,10.0,1.0,"[12, 1773]","[1697105242704, 1697105244477]"
2826,216,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105238408.0,120,,,[106],[1697105236890]
2827,794,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228780,1697105230476.0,120,,,[105],[1697105228885]
2828,56,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105244478,1697105247242.0,120,,,[9],[1697105244487]
2829,820,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236757,1697105238408.0,120,,,[4],[1697105236761]
2830,414,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248695.0,120,,,[59],[1697105247306]
2831,746,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248697,1697105250348.0,120,,,[35],[1697105248732]
2832,253,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238412,1697105240331.0,120,,,[187],[1697105238599]
2833,222,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230479,1697105234918.0,120,,,"[222, 2355, 600, 617]","[1697105230701, 1697105233056, 1697105233656, 1697105234273]"
2834,904,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250350,1697105252036.0,120,,,[51],[1697105250401]
2835,578,26,[],200,EleutherAI/gpt-neox-20b,128,1,2323.0,1.0,1,H100,1697105240367,1697105242690.0,120,31.0,1.0,"[251, 2072]","[1697105240618, 1697105242690]"
2836,173,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250349,1697105252037.0,120,,,[56],[1697105250405]
2837,305,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252039,1697105253711.0,120,,,[151],[1697105252190]
2838,672,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234921,1697105236781.0,120,,,[10],[1697105234931]
2839,105,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105240330.0,120,,,[198],[1697105236982]
2840,7,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242691,1697105245502.0,120,,,[5],[1697105242696]
2841,531,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253712.0,120,,,[69],[1697105252110]
2842,878,15,[],200,EleutherAI/gpt-neox-20b,128,1,5255.0,1.0,1,H100,1697105220998,1697105226253.0,120,83.0,20.0,"[174, 2231, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 580, 81, 78, 74, 74, 706]","[1697105221172, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225240, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226253]"
2843,702,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225145,1697105228773.0,120,,,"[21, 1897, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105225166, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2844,889,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[255],[1697105253971]
2845,132,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228782,1697105230476.0,120,,,[228],[1697105229010]
2846,483,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105232145.0,120,,,"[36, 992, 75, 75, 74, 73]","[1697105230514, 1697105231506, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
2847,840,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232151,1697105234225.0,120,,,[120],[1697105232271]
2848,318,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258913.0,120,,,[173],[1697105256186]
2849,271,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234226,1697105236781.0,120,,,[8],[1697105234234]
2850,646,31,[],200,EleutherAI/gpt-neox-20b,128,1,2510.0,1.0,1,H100,1697105258921,1697105261431.0,120,14.0,1.0,"[264, 2245]","[1697105259185, 1697105261430]"
2851,77,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105261432,1697105264082.0,120,,,[20],[1697105261452]
2852,719,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105240330.0,120,,,[190],[1697105236974]
2853,438,33,[],200,EleutherAI/gpt-neox-20b,128,1,1777.0,1.0,1,H100,1697105264086,1697105265863.0,120,9.0,1.0,"[131, 1646]","[1697105264217, 1697105265863]"
2854,792,34,[],200,EleutherAI/gpt-neox-20b,128,1,1322.0,1.0,1,H100,1697105265864,1697105267186.0,120,11.0,1.0,"[29, 1293]","[1697105265893, 1697105267186]"
2855,309,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267187,1697105271972.0,120,,,"[16, 1775, 669, 704, 685]","[1697105267203, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
2856,462,22,[],200,EleutherAI/gpt-neox-20b,128,1,2357.0,1.0,1,H100,1697105240333,1697105242690.0,120,52.0,1.0,"[271, 2086]","[1697105240604, 1697105242690]"
2857,570,24,[],200,EleutherAI/gpt-neox-20b,128,1,1854.0,1.0,1,H100,1697105238412,1697105240266.0,120,18.0,1.0,"[260, 1594]","[1697105238672, 1697105240266]"
2858,152,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240332,1697105241994.0,120,,,[36],[1697105240368]
2859,903,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240267,1697105241994.0,120,,,[40],[1697105240307]
2860,333,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243753.0,120,,,[78],[1697105242079]
2861,691,27,[],200,EleutherAI/gpt-neox-20b,128,1,1670.0,1.0,1,H100,1697105243757,1697105245427.0,120,47.0,1.0,"[135, 1535]","[1697105243892, 1697105245427]"
2862,125,28,[],200,EleutherAI/gpt-neox-20b,128,1,768.0,1.0,1,H100,1697105245428,1697105246196.0,120,13.0,1.0,"[29, 739]","[1697105245457, 1697105246196]"
2863,817,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242691,1697105245502.0,120,,,[9],[1697105242700]
2864,663,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271976,1697105273586.0,120,,,[126],[1697105272102]
2865,97,37,[],200,EleutherAI/gpt-neox-20b,128,1,2977.0,1.0,1,H100,1697105273589,1697105276566.0,120,6.0,20.0,"[214, 2141, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 33, 32, 32]","[1697105273803, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276502, 1697105276534, 1697105276566]"
2866,479,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105246197,1697105248696.0,120,,,[29],[1697105246226]
2867,353,15,[],200,EleutherAI/gpt-neox-20b,128,1,2661.0,1.0,1,H100,1697105208898,1697105211559.0,120,52.0,4.0,"[4, 2412, 168, 77]","[1697105208902, 1697105211314, 1697105211482, 1697105211559]"
2868,242,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245505,1697105247243.0,120,,,[179],[1697105245684]
2869,714,16,[],200,EleutherAI/gpt-neox-20b,128,1,5344.0,1.0,1,H100,1697105211560,1697105216904.0,120,83.0,20.0,"[5, 2265, 94, 90, 89, 68, 246, 85, 65, 75, 653, 84, 356, 91, 83, 510, 89, 67, 83, 246]","[1697105211565, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215295, 1697105215379, 1697105215735, 1697105215826, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904]"
2870,573,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247248,1697105248695.0,120,,,[143],[1697105247391]
2871,397,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248696.0,120,,,[35],[1697105247282]
2872,800,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105258913.0,120,,,[73],[1697105257191]
2873,752,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105252036.0,120,,,[186],[1697105248885]
2874,656,16,[],200,EleutherAI/gpt-neox-20b,128,1,2320.0,1.0,1,H100,1697105218023,1697105220343.0,120,26.0,1.0,"[5, 2315]","[1697105218028, 1697105220343]"
2875,200,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258916,1697105260462.0,120,,,[28],[1697105258944]
2876,1,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105250347.0,120,,,[13],[1697105248712]
2877,725,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238411,1697105240330.0,120,,,[92],[1697105238503]
2878,366,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252036.0,120,,,[38],[1697105250389]
2879,156,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241993.0,120,,,[81],[1697105240415]
2880,510,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243754.0,120,,,[14],[1697105242015]
2881,186,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253712.0,120,,,[20],[1697105252061]
2882,726,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252039,1697105253711.0,120,,,[139],[1697105252178]
2883,125,29,[],200,EleutherAI/gpt-neox-20b,128,1,2229.0,1.0,1,H100,1697105253716,1697105255945.0,120,13.0,1.0,"[298, 1930]","[1697105254014, 1697105255944]"
2884,863,21,[],200,EleutherAI/gpt-neox-20b,128,1,2438.0,1.0,1,H100,1697105243758,1697105246196.0,120,10.0,1.0,"[254, 2184]","[1697105244012, 1697105246196]"
2885,264,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105246197,1697105248696.0,120,,,[13],[1697105246210]
2886,630,33,[],200,EleutherAI/gpt-neox-20b,128,1,2228.0,1.0,1,H100,1697105253716,1697105255944.0,120,6.0,1.0,"[276, 1952]","[1697105253992, 1697105255944]"
2887,556,37,[],200,EleutherAI/gpt-neox-20b,128,1,1779.0,1.0,1,H100,1697105260464,1697105262243.0,120,9.0,1.0,"[24, 1755]","[1697105260488, 1697105262243]"
2888,63,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255949,1697105257115.0,120,,,[36],[1697105255985]
2889,422,35,[],200,EleutherAI/gpt-neox-20b,128,1,2653.0,1.0,1,H100,1697105257119,1697105259772.0,120,26.0,1.0,"[253, 2400]","[1697105257372, 1697105259772]"
2890,909,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262244,1697105264083.0,120,,,[4],[1697105262248]
2891,88,17,[],200,EleutherAI/gpt-neox-20b,128,1,4241.0,1.0,1,H100,1697105220998,1697105225239.0,120,58.0,20.0,"[82, 1587, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579]","[1697105221080, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239]"
2892,459,12,[],200,EleutherAI/gpt-neox-20b,128,1,3723.0,1.0,1,H100,1697105208292,1697105212015.0,120,58.0,5.0,"[5, 3017, 168, 77, 456]","[1697105208297, 1697105211314, 1697105211482, 1697105211559, 1697105212015]"
2893,339,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264086,1697105265928.0,120,,,[196],[1697105264282]
2894,776,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105259773,1697105262306.0,120,,,[4],[1697105259777]
2895,177,37,[],200,EleutherAI/gpt-neox-20b,128,1,1676.0,1.0,1,H100,1697105262314,1697105263990.0,120,14.0,1.0,"[274, 1402]","[1697105262588, 1697105263990]"
2896,531,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263991,1697105265927.0,120,,,[25],[1697105264016]
2897,700,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265935,1697105271973.0,120,,,"[239, 2804, 669, 704, 685]","[1697105266174, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
2898,892,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267796.0,120,,,[42],[1697105265973]
2899,322,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[42],[1697105267840]
2900,683,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[56],[1697105269656]
2901,788,13,[],200,EleutherAI/gpt-neox-20b,128,1,1625.0,1.0,1,H100,1697105212016,1697105213641.0,120,31.0,1.0,"[5, 1620]","[1697105212021, 1697105213641]"
2902,83,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270989,1697105271973.0,120,,,[13],[1697105271002]
2903,479,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255948,1697105257115.0,120,,,[21],[1697105255969]
2904,439,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271978,1697105275207.0,120,,,[232],[1697105272210]
2905,834,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105260463.0,120,,,[174],[1697105257292]
2906,442,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225240,1697105228774.0,120,,,"[25, 2646, 93, 84, 84, 83]","[1697105225265, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2907,263,32,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105260467,1697105262243.0,120,15.0,1.0,"[226, 1550]","[1697105260693, 1697105262243]"
2908,208,14,[],200,EleutherAI/gpt-neox-20b,128,1,5758.0,1.0,1,H100,1697105213642,1697105219400.0,120,96.0,20.0,"[8, 2769, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 82, 257, 78, 368, 81, 59, 366]","[1697105213650, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218448, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400]"
2909,624,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262245,1697105264082.0,120,,,[56],[1697105262301]
2910,764,16,[],200,EleutherAI/gpt-neox-20b,128,1,1989.0,1.0,1,H100,1697105210805,1697105212794.0,120,39.0,1.0,"[5, 1984]","[1697105210810, 1697105212794]"
2911,29,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265928.0,120,,,[35],[1697105264120]
2912,194,17,[],200,EleutherAI/gpt-neox-20b,128,1,4821.0,1.0,1,H100,1697105212795,1697105217616.0,120,335.0,16.0,"[5, 2494, 85, 356, 90, 84, 510, 89, 66, 85, 246, 84, 66, 385, 89, 87]","[1697105212800, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215909, 1697105216419, 1697105216508, 1697105216574, 1697105216659, 1697105216905, 1697105216989, 1697105217055, 1697105217440, 1697105217529, 1697105217616]"
2913,387,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265933,1697105271973.0,120,,,"[140, 2904, 669, 705, 685]","[1697105266073, 1697105268977, 1697105269646, 1697105270351, 1697105271036]"
2914,822,16,[],200,EleutherAI/gpt-neox-20b,128,1,5496.0,1.0,1,H100,1697105222759,1697105228255.0,120,88.0,20.0,"[8, 2472, 82, 77, 75, 74, 706, 90, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105222767, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225547, 1697105226253, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
2915,922,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253712.0,120,,,[65],[1697105252106]
2916,613,9,[],200,EleutherAI/gpt-neox-20b,128,1,5095.0,1.0,1,H100,1697105219565,1697105224660.0,120,90.0,20.0,"[9, 2391, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105219574, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
2917,326,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[307],[1697105254023]
2918,698,9,[],200,EleutherAI/gpt-neox-20b,128,1,3526.0,1.0,1,H100,1697105207360,1697105210886.0,120,182.0,6.0,"[4, 2769, 87, 82, 502, 82]","[1697105207364, 1697105210133, 1697105210220, 1697105210302, 1697105210804, 1697105210886]"
2919,193,15,[],200,EleutherAI/gpt-neox-20b,128,1,4377.0,1.0,1,H100,1697105202982,1697105207359.0,120,79.0,20.0,"[40, 1900, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84, 732, 89, 89, 86, 81, 79, 60, 61]","[1697105203022, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359]"
2920,542,40,[],200,EleutherAI/gpt-neox-20b,128,1,1579.0,1.0,1,H100,1697105271976,1697105273555.0,120,11.0,1.0,"[130, 1449]","[1697105272106, 1697105273555]"
2921,903,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273556,1697105275208.0,120,,,[5],[1697105273561]
2922,220,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271977,1697105273584.0,120,,,[141],[1697105272118]
2923,580,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273588,1697105275208.0,120,,,[110],[1697105273698]
2924,684,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258915.0,120,,,[65],[1697105256078]
2925,250,24,[],200,EleutherAI/gpt-neox-20b,128,1,1663.0,1.0,1,H100,1697105240267,1697105241930.0,120,31.0,1.0,"[65, 1598]","[1697105240332, 1697105241930]"
2926,732,14,[],200,EleutherAI/gpt-neox-20b,128,1,3612.0,1.0,1,H100,1697105210805,1697105214417.0,120,345.0,12.0,"[5, 2081, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246]","[1697105210810, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417]"
2927,612,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241931,1697105243754.0,120,,,[5],[1697105241936]
2928,340,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228257,1697105232145.0,120,,,"[8, 2251, 989, 76, 75, 74, 73]","[1697105228265, 1697105230516, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
2929,37,26,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105243758,1697105245427.0,120,20.0,1.0,"[239, 1430]","[1697105243997, 1697105245427]"
2930,395,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245428,1697105247243.0,120,,,[37],[1697105245465]
2931,698,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233609.0,120,,,[64],[1697105232214]
2932,123,19,[],200,EleutherAI/gpt-neox-20b,128,1,1272.0,1.0,1,H100,1697105233610,1697105234882.0,120,14.0,1.0,"[64, 1208]","[1697105233674, 1697105234882]"
2933,486,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234884,1697105236781.0,120,,,[32],[1697105234916]
2934,754,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247248,1697105248696.0,120,,,[150],[1697105247398]
2935,143,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105216576,1697105220995.0,120,,,"[4, 2820, 89, 75, 259, 62, 234, 79, 229, 81, 198]","[1697105216580, 1697105219400, 1697105219489, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
2936,146,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270308,1697105271972.0,120,,,[48],[1697105270356]
2937,506,36,[],200,EleutherAI/gpt-neox-20b,128,1,1579.0,1.0,1,H100,1697105271976,1697105273555.0,120,16.0,1.0,"[10, 1569]","[1697105271986, 1697105273555]"
2938,831,37,[],200,EleutherAI/gpt-neox-20b,128,1,1576.0,1.0,1,H100,1697105273556,1697105275132.0,120,11.0,1.0,"[29, 1547]","[1697105273585, 1697105275132]"
2939,0,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105214568,1697105220994.0,120,,,"[12, 2860, 89, 87, 406, 88, 81, 256, 79, 368, 81, 59, 366, 89, 75, 260, 61, 235, 78, 229, 81, 198]","[1697105214580, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219824, 1697105219885, 1697105220120, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
2940,682,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105215184,1697105220994.0,120,,,"[9, 2829, 88, 81, 256, 79, 368, 81, 59, 366, 89, 75, 259, 62, 235, 78, 229, 81, 198]","[1697105215193, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219823, 1697105219885, 1697105220120, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
2941,821,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265932,1697105267796.0,120,,,[16],[1697105265948]
2942,248,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[30],[1697105267828]
2943,692,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[28],[1697105269628]
2944,487,14,[],200,EleutherAI/gpt-neox-20b,128,1,3509.0,1.0,1,H100,1697105220996,1697105224505.0,120,123.0,17.0,"[36, 1635, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 352, 90, 70, 88]","[1697105221032, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224257, 1697105224347, 1697105224417, 1697105224505]"
2945,117,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270989,1697105273585.0,120,,,[33],[1697105271022]
2946,658,34,[],200,EleutherAI/gpt-neox-20b,128,1,2228.0,1.0,1,H100,1697105253716,1697105255944.0,120,11.0,1.0,"[272, 1956]","[1697105253988, 1697105255944]"
2947,431,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238412,1697105240331.0,120,,,[171],[1697105238583]
2948,682,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105216906,1697105220995.0,120,,,"[16, 2902, 62, 233, 79, 229, 81, 198]","[1697105216922, 1697105219824, 1697105219886, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
2949,84,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255949,1697105257115.0,120,,,[34],[1697105255983]
2950,774,8,[],200,EleutherAI/gpt-neox-20b,128,1,2665.0,1.0,1,H100,1697105192405,1697105195070.0,120,8.0,1.0,"[21, 2644]","[1697105192426, 1697105195070]"
2951,795,23,[],200,EleutherAI/gpt-neox-20b,128,1,1596.0,1.0,1,H100,1697105240334,1697105241930.0,120,12.0,1.0,"[174, 1422]","[1697105240508, 1697105241930]"
2952,4,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265935,1697105271972.0,120,,,"[263, 2780, 669, 704, 685]","[1697105266198, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
2953,225,24,[],200,EleutherAI/gpt-neox-20b,128,1,759.0,1.0,1,H100,1697105241932,1697105242691.0,120,23.0,1.0,"[28, 731]","[1697105241960, 1697105242691]"
2954,358,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271975,1697105273584.0,120,,,[31],[1697105272006]
2955,717,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273587,1697105275208.0,120,,,[31],[1697105273618]
2956,554,25,[],200,EleutherAI/gpt-neox-20b,128,1,1785.0,1.0,1,H100,1697105242692,1697105244477.0,120,26.0,1.0,"[20, 1765]","[1697105242712, 1697105244477]"
2957,200,9,[],200,EleutherAI/gpt-neox-20b,128,1,2962.0,1.0,1,H100,1697105195071,1697105198033.0,120,6.0,9.0,"[9, 2010, 85, 62, 152, 158, 82, 77, 327]","[1697105195080, 1697105197090, 1697105197175, 1697105197237, 1697105197389, 1697105197547, 1697105197629, 1697105197706, 1697105198033]"
2958,443,36,[],200,EleutherAI/gpt-neox-20b,128,1,1732.0,1.0,1,H100,1697105257118,1697105258850.0,120,19.0,1.0,"[13, 1719]","[1697105257131, 1697105258850]"
2959,908,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105244478,1697105247242.0,120,,,[9],[1697105244487]
2960,335,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248695.0,120,,,[51],[1697105247298]
2961,207,19,[],200,EleutherAI/gpt-neox-20b,128,1,1714.0,1.0,1,H100,1697105225240,1697105226954.0,120,10.0,1.0,"[29, 1685]","[1697105225269, 1697105226954]"
2962,566,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226955,1697105228774.0,120,,,[28],[1697105226983]
2963,805,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258851,1697105260463.0,120,,,[17],[1697105258868]
2964,924,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230476.0,120,,,[113],[1697105228894]
2965,357,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105232146.0,120,,,"[28, 1000, 75, 75, 74, 73]","[1697105230506, 1697105231506, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
2966,206,38,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105260467,1697105262243.0,120,16.0,1.0,"[234, 1542]","[1697105260701, 1697105262243]"
2967,567,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262244,1697105264083.0,120,,,[21],[1697105262265]
2968,692,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248698,1697105250348.0,120,,,[91],[1697105248789]
2969,921,40,[],200,EleutherAI/gpt-neox-20b,128,1,3099.0,1.0,1,H100,1697105264087,1697105267186.0,120,31.0,1.0,"[288, 2811]","[1697105264375, 1697105267186]"
2970,351,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267187,1697105271972.0,120,,,"[4, 1787, 669, 704, 685]","[1697105267191, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
2971,300,15,[],200,EleutherAI/gpt-neox-20b,128,1,1507.0,1.0,1,H100,1697105227244,1697105228751.0,120,9.0,1.0,"[5, 1502]","[1697105227249, 1697105228751]"
2972,656,16,[],200,EleutherAI/gpt-neox-20b,128,1,900.0,1.0,1,H100,1697105228752,1697105229652.0,120,26.0,1.0,"[16, 884]","[1697105228768, 1697105229652]"
2973,124,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252038.0,120,,,[222],[1697105250573]
2974,59,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105229653,1697105232145.0,120,,,"[16, 1836, 76, 75, 74, 73]","[1697105229669, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
2975,705,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271976,1697105273585.0,120,,,[46],[1697105272022]
2976,722,10,[],200,EleutherAI/gpt-neox-20b,128,1,3714.0,1.0,1,H100,1697105196833,1697105200547.0,120,39.0,1.0,"[10, 3703]","[1697105196843, 1697105200546]"
2977,108,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273587,1697105275208.0,120,,,[91],[1697105273678]
2978,155,11,[],200,EleutherAI/gpt-neox-20b,128,1,5535.0,1.0,1,H100,1697105200547,1697105206082.0,120,90.0,20.0,"[5, 3166, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84]","[1697105200552, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
2979,483,12,[],200,EleutherAI/gpt-neox-20b,128,1,5399.0,1.0,1,H100,1697105206084,1697105211483.0,120,84.0,20.0,"[17, 1876, 86, 83, 82, 64, 434, 87, 84, 79, 77, 385, 77, 619, 85, 83, 502, 82, 429, 167]","[1697105206101, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210134, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211315, 1697105211482]"
2980,284,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105261432,1697105264082.0,120,,,[12],[1697105261444]
2981,416,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232154,1697105234225.0,120,,,[237],[1697105232391]
2982,779,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234227,1697105236781.0,120,,,[43],[1697105234270]
2983,832,27,[],200,EleutherAI/gpt-neox-20b,128,1,2485.0,1.0,1,H100,1697105248699,1697105251184.0,120,15.0,1.0,"[182, 2303]","[1697105248881, 1697105251184]"
2984,261,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105251185,1697105253710.0,120,,,[5],[1697105251190]
2985,68,10,[],200,EleutherAI/gpt-neox-20b,128,1,1755.0,1.0,1,H100,1697105202982,1697105204737.0,120,12.0,1.0,"[32, 1723]","[1697105203014, 1697105204737]"
2986,204,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105238409.0,120,,,[122],[1697105236906]
2987,625,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248698,1697105250347.0,120,,,[10],[1697105248708]
2988,564,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238412,1697105240331.0,120,,,[179],[1697105238591]
2989,590,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105255027.0,120,,,[96],[1697105253810]
2990,645,12,[],200,EleutherAI/gpt-neox-20b,128,1,5068.0,1.0,1,H100,1697105202010,1697105207078.0,120,86.0,20.0,"[185, 2055, 87, 87, 83, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84, 732, 89, 89, 86]","[1697105202195, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206814, 1697105206903, 1697105206992, 1697105207078]"
2991,56,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250350,1697105252036.0,120,,,[42],[1697105250392]
2992,80,22,[],200,EleutherAI/gpt-neox-20b,128,1,1597.0,1.0,1,H100,1697105240334,1697105241931.0,120,13.0,1.0,"[249, 1347]","[1697105240583, 1697105241930]"
2993,437,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241932,1697105243754.0,120,,,[36],[1697105241968]
2994,737,7,[],200,EleutherAI/gpt-neox-20b,128,1,3687.0,1.0,1,H100,1697105195685,1697105199372.0,120,216.0,2.0,"[5, 3581, 101]","[1697105195690, 1697105199271, 1697105199372]"
2995,796,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243758,1697105247242.0,120,,,[247],[1697105244005]
2996,224,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248696.0,120,,,[9],[1697105247256]
2997,20,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255029,1697105256010.0,120,,,[26],[1697105255055]
2998,582,26,[],200,EleutherAI/gpt-neox-20b,128,1,2484.0,1.0,1,H100,1697105248700,1697105251184.0,120,19.0,1.0,"[274, 2210]","[1697105248974, 1697105251184]"
2999,377,31,[],200,EleutherAI/gpt-neox-20b,128,1,2017.0,1.0,1,H100,1697105256013,1697105258030.0,120,13.0,1.0,"[88, 1929]","[1697105256101, 1697105258030]"
3000,868,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228257,1697105232145.0,120,,,"[24, 2234, 991, 75, 75, 74, 73]","[1697105228281, 1697105230515, 1697105231506, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
3001,154,29,[],200,EleutherAI/gpt-neox-20b,128,1,2485.0,1.0,1,H100,1697105248699,1697105251184.0,120,13.0,1.0,"[198, 2287]","[1697105248897, 1697105251184]"
3002,736,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258032,1697105260463.0,120,,,[27],[1697105258059]
3003,913,18,[],200,EleutherAI/gpt-neox-20b,128,1,5259.0,1.0,1,H100,1697105219401,1697105224660.0,120,88.0,20.0,"[8, 2556, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105219409, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
3004,60,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228774,1697105230475.0,120,,,[18],[1697105228792]
3005,912,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105251186,1697105253711.0,120,,,[32],[1697105251218]
3006,165,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260465,1697105262306.0,120,,,[127],[1697105260592]
3007,421,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230477,1697105232146.0,120,,,"[17, 1011, 76, 75, 74, 73]","[1697105230494, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
3008,513,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105251186,1697105253711.0,120,,,[32],[1697105251218]
3009,497,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262314,1697105264082.0,120,,,[262],[1697105262576]
3010,871,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105255028.0,120,,,[177],[1697105253891]
3011,853,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265928.0,120,,,[39],[1697105264124]
3012,341,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105256010.0,120,,,[197],[1697105253911]
3013,165,15,[],200,EleutherAI/gpt-neox-20b,128,1,5467.0,1.0,1,H100,1697105214418,1697105219885.0,120,83.0,20.0,"[8, 2479, 84, 66, 385, 89, 87, 406, 88, 81, 256, 79, 368, 81, 59, 366, 89, 75, 260, 61]","[1697105214426, 1697105216905, 1697105216989, 1697105217055, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219824, 1697105219885]"
3014,702,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258913.0,120,,,[161],[1697105256174]
3015,129,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258927,1697105262306.0,120,,,[279],[1697105259206]
3016,458,31,[],200,EleutherAI/gpt-neox-20b,128,1,1678.0,1.0,1,H100,1697105262312,1697105263990.0,120,11.0,1.0,"[179, 1499]","[1697105262491, 1697105263990]"
3017,281,36,[],200,EleutherAI/gpt-neox-20b,128,1,2981.0,1.0,1,H100,1697105265934,1697105268915.0,120,23.0,1.0,"[160, 2821]","[1697105266094, 1697105268915]"
3018,817,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263991,1697105265927.0,120,,,[21],[1697105264012]
3019,635,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268917,1697105270302.0,120,,,[28],[1697105268945]
3020,245,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105271973.0,120,,,"[142, 2904, 669, 705, 685]","[1697105266073, 1697105268977, 1697105269646, 1697105270351, 1697105271036]"
3021,66,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270309,1697105271973.0,120,,,[64],[1697105270373]
3022,296,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[154],[1697105255184]
3023,602,34,[],200,EleutherAI/gpt-neox-20b,128,1,2436.0,1.0,1,H100,1697105271978,1697105274414.0,120,15.0,1.0,"[237, 2199]","[1697105272215, 1697105274414]"
3024,33,35,[],200,EleutherAI/gpt-neox-20b,128,1,1719.0,1.0,1,H100,1697105274415,1697105276134.0,120,140.0,7.0,"[9, 1520, 41, 41, 34, 33, 41]","[1697105274424, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134]"
3025,397,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271977,1697105273584.0,120,,,[137],[1697105272114]
3026,658,33,[],200,EleutherAI/gpt-neox-20b,128,1,1733.0,1.0,1,H100,1697105257117,1697105258850.0,120,11.0,1.0,"[58, 1675]","[1697105257175, 1697105258850]"
3027,14,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271977,1697105273584.0,120,,,[201],[1697105272178]
3028,375,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273588,1697105275208.0,120,,,[114],[1697105273702]
3029,58,34,[],200,EleutherAI/gpt-neox-20b,128,1,921.0,1.0,1,H100,1697105258851,1697105259772.0,120,15.0,1.0,"[29, 892]","[1697105258880, 1697105259772]"
3030,341,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105224662,1697105228773.0,120,,,"[9, 1581, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105224671, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
3031,419,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105259773,1697105262306.0,120,,,[20],[1697105259793]
3032,775,36,[],200,EleutherAI/gpt-neox-20b,128,1,1679.0,1.0,1,H100,1697105262311,1697105263990.0,120,17.0,1.0,"[92, 1587]","[1697105262403, 1697105263990]"
3033,759,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273588,1697105275208.0,120,,,[94],[1697105273682]
3034,522,15,[],200,EleutherAI/gpt-neox-20b,128,1,2316.0,1.0,1,H100,1697105208293,1697105210609.0,120,20.0,1.0,"[4, 2312]","[1697105208297, 1697105210609]"
3035,880,16,[],200,EleutherAI/gpt-neox-20b,128,1,2281.0,1.0,1,H100,1697105210610,1697105212891.0,120,84.0,2.0,"[4, 2277]","[1697105210614, 1697105212891]"
3036,320,12,[],200,EleutherAI/gpt-neox-20b,128,1,7505.0,1.0,1,H100,1697105202010,1697105209515.0,120,109.0,36.0,"[173, 2067, 87, 87, 83, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84, 731, 90, 89, 86, 81, 79, 60, 61, 618, 86, 82, 83, 63, 435, 87, 84, 79, 77, 385, 77]","[1697105202183, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515]"
3037,811,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234923,1697105238408.0,120,,,[249],[1697105235172]
3038,241,22,[],200,EleutherAI/gpt-neox-20b,128,1,1855.0,1.0,1,H100,1697105238411,1697105240266.0,120,19.0,1.0,"[76, 1778]","[1697105238487, 1697105240265]"
3039,686,23,[],200,EleutherAI/gpt-neox-20b,128,1,938.0,1.0,1,H100,1697105240267,1697105241205.0,120,31.0,1.0,"[48, 890]","[1697105240315, 1697105241205]"
3040,429,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105234224.0,120,,,[73],[1697105232223]
3041,310,17,[],200,EleutherAI/gpt-neox-20b,128,1,2290.0,1.0,1,H100,1697105212893,1697105215183.0,120,26.0,1.0,"[8, 2282]","[1697105212901, 1697105215183]"
3042,789,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234226,1697105234919.0,120,,,[12],[1697105234238]
3043,668,18,[],200,EleutherAI/gpt-neox-20b,128,1,3342.0,1.0,1,H100,1697105215184,1697105218526.0,120,109.0,6.0,"[5, 2833, 88, 81, 256, 79]","[1697105215189, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526]"
3044,111,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241206,1697105243753.0,120,,,[17],[1697105241223]
3045,467,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243756,1697105245502.0,120,,,[43],[1697105243799]
3046,248,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262312,1697105264083.0,120,,,[99],[1697105262411]
3047,220,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236781.0,120,,,[162],[1697105235084]
3048,824,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245505,1697105247243.0,120,,,[183],[1697105245688]
3049,577,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264087,1697105265928.0,120,,,[211],[1697105264298]
3050,255,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247255,1697105250347.0,120,,,[260],[1697105247515]
3051,671,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230475.0,120,,,[32],[1697105228813]
3052,587,28,[],200,EleutherAI/gpt-neox-20b,128,1,1656.0,1.0,1,H100,1697105250355,1697105252011.0,120,13.0,1.0,"[234, 1422]","[1697105250589, 1697105252011]"
3053,7,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265935,1697105271973.0,120,,,"[247, 2796, 669, 704, 685]","[1697105266182, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
3054,662,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243555,1697105245503.0,120,,,[20],[1697105243575]
3055,122,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105232146.0,120,,,[115],[1697105230593]
3056,791,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105219887,1697105228773.0,120,,,"[12, 2066, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579, 81, 78, 75, 73, 706, 91, 84, 66, 84, 486, 91, 89, 85, 582, 94, 84, 84, 83]","[1697105219899, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225320, 1697105225398, 1697105225473, 1697105225546, 1697105226252, 1697105226343, 1697105226427, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227910, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
3057,87,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105248695.0,120,,,[264],[1697105245770]
3058,487,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232153,1697105234225.0,120,,,[222],[1697105232375]
3059,846,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234226,1697105236781.0,120,,,[20],[1697105234246]
3060,642,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225240,1697105228774.0,120,,,"[17, 1807, 91, 88, 85, 583, 93, 84, 84, 83]","[1697105225257, 1697105227064, 1697105227155, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
3061,546,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105238408.0,120,,,[25],[1697105236809]
3062,42,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228783,1697105230476.0,120,,,[215],[1697105228998]
3063,396,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105234918.0,120,,,"[207, 2371, 600, 617]","[1697105230685, 1697105233056, 1697105233656, 1697105234273]"
3064,758,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234921,1697105236781.0,120,,,[6],[1697105234927]
3065,905,25,[],200,EleutherAI/gpt-neox-20b,128,1,1854.0,1.0,1,H100,1697105238411,1697105240265.0,120,11.0,1.0,"[19, 1835]","[1697105238430, 1697105240265]"
3066,188,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236785,1697105240330.0,120,,,[218],[1697105237003]
3067,623,14,[],200,EleutherAI/gpt-neox-20b,128,1,2860.0,1.0,1,H100,1697105207360,1697105210220.0,120,140.0,3.0,"[4, 2769, 86]","[1697105207364, 1697105210133, 1697105210219]"
3068,771,15,[],200,EleutherAI/gpt-neox-20b,128,1,5511.0,1.0,1,H100,1697105212105,1697105217616.0,120,47.0,20.0,"[9, 2303, 85, 65, 75, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246, 85, 65, 386, 89, 87]","[1697105212114, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616]"
3069,357,15,[],200,EleutherAI/gpt-neox-20b,128,1,6330.0,1.0,1,H100,1697105220998,1697105227328.0,120,52.0,33.0,"[98, 1571, 87, 85, 82, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579, 82, 77, 75, 73, 706, 91, 85, 65, 84, 486, 91, 89, 85]","[1697105221096, 1697105222667, 1697105222754, 1697105222839, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225546, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328]"
3070,24,15,[],200,EleutherAI/gpt-neox-20b,128,1,3794.0,1.0,1,H100,1697105210220,1697105214014.0,120,79.0,9.0,"[5, 2666, 88, 89, 82, 75, 606, 93, 90]","[1697105210225, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213831, 1697105213924, 1697105214014]"
3071,558,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105198033,1697105201998.0,120,,,"[5, 3256, 160, 213]","[1697105198038, 1697105201294, 1697105201454, 1697105201667]"
3072,919,11,[],200,EleutherAI/gpt-neox-20b,128,1,1624.0,1.0,1,H100,1697105202002,1697105203626.0,120,14.0,1.0,"[37, 1586]","[1697105202039, 1697105203625]"
3073,922,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105252036.0,120,,,[106],[1697105248805]
3074,386,16,[],200,EleutherAI/gpt-neox-20b,128,1,2889.0,1.0,1,H100,1697105214015,1697105216904.0,120,140.0,6.0,"[4, 2400, 89, 67, 83, 246]","[1697105214019, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904]"
3075,349,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252040,1697105253711.0,120,,,[171],[1697105252211]
3076,711,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105255028.0,120,,,[173],[1697105253887]
3077,711,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232153,1697105234225.0,120,,,[154],[1697105232307]
3078,198,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105217617,1697105220996.0,120,,,"[13, 2490, 78, 229, 82, 197]","[1697105217630, 1697105220120, 1697105220198, 1697105220427, 1697105220509, 1697105220706]"
3079,749,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105216905,1697105220995.0,120,,,"[9, 2910, 62, 233, 79, 229, 81, 198]","[1697105216914, 1697105219824, 1697105219886, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
3080,139,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[85],[1697105255115]
3081,470,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105258913.0,120,,,[97],[1697105257215]
3082,529,17,[],200,EleutherAI/gpt-neox-20b,128,1,1574.0,1.0,1,H100,1697105220999,1697105222573.0,120,10.0,1.0,"[77, 1497]","[1697105221076, 1697105222573]"
3083,827,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258917,1697105260463.0,120,,,[100],[1697105259017]
3084,110,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234227,1697105236780.0,120,,,[64],[1697105234291]
3085,886,18,[],200,EleutherAI/gpt-neox-20b,128,1,2570.0,1.0,1,H100,1697105222574,1697105225144.0,120,17.0,1.0,"[20, 2550]","[1697105222594, 1697105225144]"
3086,319,19,[],200,EleutherAI/gpt-neox-20b,128,1,1809.0,1.0,1,H100,1697105225145,1697105226954.0,120,31.0,1.0,"[33, 1776]","[1697105225178, 1697105226954]"
3087,177,18,[],200,EleutherAI/gpt-neox-20b,128,1,2311.0,1.0,1,H100,1697105220999,1697105223310.0,120,14.0,1.0,"[194, 2117]","[1697105221193, 1697105223310]"
3088,530,19,[],200,EleutherAI/gpt-neox-20b,128,1,1833.0,1.0,1,H100,1697105223311,1697105225144.0,120,26.0,1.0,"[28, 1805]","[1697105223339, 1697105225144]"
3089,155,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228257,1697105232145.0,120,,,"[12, 2246, 990, 76, 75, 74, 73]","[1697105228269, 1697105230515, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
3090,466,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236783,1697105238408.0,120,,,[19],[1697105236802]
3091,675,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226954,1697105228773.0,120,,,[5],[1697105226959]
3092,257,36,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105260467,1697105262243.0,120,14.0,1.0,"[214, 1562]","[1697105260681, 1697105262243]"
3093,74,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230475.0,120,,,[133],[1697105228914]
3094,428,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230477,1697105232146.0,120,,,"[21, 808, 199, 76, 75, 74, 73]","[1697105230498, 1697105231306, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
3095,356,17,[],200,EleutherAI/gpt-neox-20b,128,1,3068.0,1.0,1,H100,1697105215826,1697105218894.0,120,874.0,2.0,"[5, 3063]","[1697105215831, 1697105218894]"
3096,827,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238411,1697105240330.0,120,,,[68],[1697105238479]
3097,615,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262244,1697105264083.0,120,,,[25],[1697105262269]
3098,256,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241993.0,120,,,[141],[1697105240475]
3099,595,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233609.0,120,,,[65],[1697105232215]
3100,788,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232153,1697105234225.0,120,,,[158],[1697105232311]
3101,23,22,[],200,EleutherAI/gpt-neox-20b,128,1,1271.0,1.0,1,H100,1697105233611,1697105234882.0,120,26.0,1.0,"[75, 1196]","[1697105233686, 1697105234882]"
3102,587,28,[],200,EleutherAI/gpt-neox-20b,128,1,1554.0,1.0,1,H100,1697105242000,1697105243554.0,120,13.0,1.0,"[31, 1522]","[1697105242031, 1697105243553]"
3103,219,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234226,1697105236781.0,120,,,[16],[1697105234242]
3104,688,18,[],200,EleutherAI/gpt-neox-20b,128,1,3859.0,1.0,1,H100,1697105218895,1697105222754.0,120,345.0,4.0,"[5, 3065, 702, 87]","[1697105218900, 1697105221965, 1697105222667, 1697105222754]"
3105,578,25,[],200,EleutherAI/gpt-neox-20b,128,1,2554.0,1.0,1,H100,1697105236784,1697105239338.0,120,31.0,1.0,"[194, 2360]","[1697105236978, 1697105239338]"
3106,911,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105239340,1697105241995.0,120,,,[14],[1697105239354]
3107,43,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264087,1697105267795.0,120,,,[216],[1697105264303]
3108,335,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243753.0,120,,,[74],[1697105242075]
3109,373,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[90],[1697105267888]
3110,747,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105227244,1697105232144.0,120,,,"[9, 3262, 990, 76, 74, 74, 74]","[1697105227253, 1697105230515, 1697105231505, 1697105231581, 1697105231655, 1697105231729, 1697105231803]"
3111,15,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243555,1697105245502.0,120,,,[8],[1697105243563]
3112,731,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269599,1697105270988.0,120,,,[9],[1697105269608]
3113,695,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243756,1697105245502.0,120,,,[39],[1697105243795]
3114,156,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270989,1697105271973.0,120,,,[9],[1697105270998]
3115,177,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233609.0,120,,,[32],[1697105232182]
3116,535,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233610,1697105234919.0,120,,,[40],[1697105233650]
3117,519,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271977,1697105273584.0,120,,,[197],[1697105272174]
3118,865,22,[],200,EleutherAI/gpt-neox-20b,128,1,1834.0,1.0,1,H100,1697105234922,1697105236756.0,120,9.0,1.0,"[170, 1664]","[1697105235092, 1697105236756]"
3119,877,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273588,1697105275208.0,120,,,[118],[1697105273706]
3120,616,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255032,1697105257114.0,120,,,[172],[1697105255204]
3121,300,23,[],200,EleutherAI/gpt-neox-20b,128,1,1628.0,1.0,1,H100,1697105236757,1697105238385.0,120,9.0,1.0,"[28, 1599]","[1697105236785, 1697105238384]"
3122,120,29,[],200,EleutherAI/gpt-neox-20b,128,1,1664.0,1.0,1,H100,1697105245505,1697105247169.0,120,17.0,1.0,"[108, 1555]","[1697105245613, 1697105247168]"
3123,478,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247170,1697105248696.0,120,,,[36],[1697105247206]
3124,928,31,[],200,EleutherAI/gpt-neox-20b,128,1,1622.0,1.0,1,H100,1697105248700,1697105250322.0,120,20.0,1.0,"[33, 1589]","[1697105248733, 1697105250322]"
3125,359,32,[],200,EleutherAI/gpt-neox-20b,128,1,862.0,1.0,1,H100,1697105250323,1697105251185.0,120,10.0,1.0,"[16, 845]","[1697105250339, 1697105251184]"
3126,719,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105251186,1697105253711.0,120,,,[24],[1697105251210]
3127,547,16,[],200,EleutherAI/gpt-neox-20b,128,1,2619.0,1.0,1,H100,1697105207360,1697105209979.0,120,12.0,1.0,"[24, 2595]","[1697105207384, 1697105209979]"
3128,127,10,[],200,EleutherAI/gpt-neox-20b,128,1,2262.0,1.0,1,H100,1697105210888,1697105213150.0,120,100.0,5.0,"[6, 1997, 88, 89, 82]","[1697105210894, 1697105212891, 1697105212979, 1697105213068, 1697105213150]"
3129,457,11,[],200,EleutherAI/gpt-neox-20b,128,1,2584.0,1.0,1,H100,1697105213151,1697105215735.0,120,874.0,2.0,"[8, 2576]","[1697105213159, 1697105215735]"
3130,144,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105255027.0,120,,,[159],[1697105253873]
3131,814,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105215736,1697105220994.0,120,,,"[5, 2706, 79, 368, 81, 59, 366, 87, 77, 259, 62, 234, 79, 229, 81, 198]","[1697105215741, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219487, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
3132,497,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255029,1697105256010.0,120,,,[14],[1697105255043]
3133,338,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226068,1697105228772.0,120,,,[9],[1697105226077]
3134,909,17,[],200,EleutherAI/gpt-neox-20b,128,1,4587.0,1.0,1,H100,1697105209980,1697105214567.0,120,86.0,20.0,"[12, 2024, 89, 80, 79, 74, 72, 481, 88, 89, 82, 75, 605, 94, 90, 90, 68, 245, 85, 65]","[1697105209992, 1697105212016, 1697105212105, 1697105212185, 1697105212264, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214104, 1697105214172, 1697105214417, 1697105214502, 1697105214567]"
3135,828,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256011,1697105258907.0,120,,,[15],[1697105256026]
3136,295,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105234225.0,120,,,[69],[1697105232219]
3137,663,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230475.0,120,,,[125],[1697105228906]
3138,842,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105238408.0,120,,,[34],[1697105236818]
3139,93,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230477,1697105232146.0,120,,,"[17, 1011, 76, 75, 74, 73]","[1697105230494, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
3140,246,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238412,1697105240331.0,120,,,[264],[1697105238676]
3141,651,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234226,1697105236781.0,120,,,[33],[1697105234259]
3142,191,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230479,1697105234918.0,120,,,"[230, 2347, 600, 617]","[1697105230709, 1697105233056, 1697105233656, 1697105234273]"
3143,446,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232153,1697105234225.0,120,,,[226],[1697105232379]
3144,257,37,[],200,EleutherAI/gpt-neox-20b,128,1,1522.0,1.0,1,H100,1697105258916,1697105260438.0,120,14.0,1.0,"[65, 1457]","[1697105258981, 1697105260438]"
3145,809,21,[],200,EleutherAI/gpt-neox-20b,128,1,1775.0,1.0,1,H100,1697105234227,1697105236002.0,120,16.0,1.0,"[60, 1715]","[1697105234287, 1697105236002]"
3146,76,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105240329.0,120,,,[186],[1697105236970]
3147,622,38,[],200,EleutherAI/gpt-neox-20b,128,1,1804.0,1.0,1,H100,1697105260439,1697105262243.0,120,20.0,1.0,"[33, 1771]","[1697105260472, 1697105262243]"
3148,579,17,[],200,EleutherAI/gpt-neox-20b,128,1,2467.0,1.0,1,H100,1697105225241,1697105227708.0,120,19.0,1.0,"[32, 2435]","[1697105225273, 1697105227708]"
3149,52,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262244,1697105264083.0,120,,,[9],[1697105262253]
3150,7,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105227709,1697105232144.0,120,,,"[9, 2797, 990, 76, 75, 73, 74]","[1697105227718, 1697105230515, 1697105231505, 1697105231581, 1697105231656, 1697105231729, 1697105231803]"
3151,380,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264087,1697105265928.0,120,,,[207],[1697105264294]
3152,238,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236006,1697105238409.0,120,,,[30],[1697105236036]
3153,730,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265933,1697105271973.0,120,,,"[144, 2901, 668, 705, 685]","[1697105266077, 1697105268978, 1697105269646, 1697105270351, 1697105271036]"
3154,570,23,[],200,EleutherAI/gpt-neox-20b,128,1,1854.0,1.0,1,H100,1697105238412,1697105240266.0,120,18.0,1.0,"[199, 1655]","[1697105238611, 1697105240266]"
3155,1,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240267,1697105241994.0,120,,,[44],[1697105240311]
3156,601,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241994.0,120,,,[233],[1697105240567]
3157,355,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242000,1697105243755.0,120,,,[31],[1697105242031]
3158,434,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240332,1697105241994.0,120,,,[259],[1697105240591]
3159,708,26,[],200,EleutherAI/gpt-neox-20b,128,1,2438.0,1.0,1,H100,1697105243758,1697105246196.0,120,140.0,1.0,"[259, 2179]","[1697105244017, 1697105246196]"
3160,287,9,[],200,EleutherAI/gpt-neox-20b,128,1,2097.0,1.0,1,H100,1697105178975,1697105181072.0,120,10.0,1.0,"[4, 2093]","[1697105178979, 1697105181072]"
3161,160,42,[],200,EleutherAI/gpt-neox-20b,128,1,2436.0,1.0,1,H100,1697105271978,1697105274414.0,120,13.0,1.0,"[216, 2220]","[1697105272194, 1697105274414]"
3162,617,10,[],200,EleutherAI/gpt-neox-20b,128,1,5024.0,1.0,1,H100,1697105181073,1697105186097.0,120,87.0,20.0,"[5, 2139, 87, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363, 74, 537, 88]","[1697105181078, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398, 1697105185472, 1697105186009, 1697105186097]"
3163,369,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233608.0,120,,,[48],[1697105232198]
3164,30,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242004,1697105243755.0,120,,,[212],[1697105242216]
3165,696,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233610,1697105234919.0,120,,,[24],[1697105233634]
3166,139,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105246197,1697105248696.0,120,,,[21],[1697105246218]
3167,924,20,[],200,EleutherAI/gpt-neox-20b,128,1,1395.0,1.0,1,H100,1697105228257,1697105229652.0,120,9.0,1.0,"[4, 1391]","[1697105228261, 1697105229652]"
3168,587,28,[],200,EleutherAI/gpt-neox-20b,128,1,2485.0,1.0,1,H100,1697105248699,1697105251184.0,120,13.0,1.0,"[170, 2315]","[1697105248869, 1697105251184]"
3169,19,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105251185,1697105253711.0,120,,,[21],[1697105251206]
3170,49,11,[],200,EleutherAI/gpt-neox-20b,128,1,3151.0,1.0,1,H100,1697105186098,1697105189249.0,120,109.0,3.0,"[4, 3061, 86]","[1697105186102, 1697105189163, 1697105189249]"
3171,403,12,[],200,EleutherAI/gpt-neox-20b,128,1,3154.0,1.0,1,H100,1697105189250,1697105192404.0,120,874.0,2.0,"[4, 3150]","[1697105189254, 1697105192404]"
3172,378,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105255027.0,120,,,[99],[1697105253813]
3173,352,21,[],200,EleutherAI/gpt-neox-20b,128,1,1928.0,1.0,1,H100,1697105229653,1697105231581.0,120,11.0,3.0,"[32, 1621, 199, 76]","[1697105229685, 1697105231306, 1697105231505, 1697105231581]"
3174,384,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243758,1697105247242.0,120,,,[267],[1697105244025]
3175,406,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253712.0,120,,,"[32, 1608]","[1697105252073, 1697105253681]"
3176,736,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255032,1697105257114.0,120,,,[171],[1697105255203]
3177,765,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[296],[1697105254012]
3178,763,13,[],200,EleutherAI/gpt-neox-20b,128,1,2664.0,1.0,1,H100,1697105192406,1697105195070.0,120,20.0,1.0,"[24, 2640]","[1697105192430, 1697105195070]"
3179,165,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258917.0,120,,,[69],[1697105256082]
3180,134,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258907.0,120,,,[10],[1697105257127]
3181,524,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258926,1697105262306.0,120,,,[260],[1697105259186]
3182,703,22,[],200,EleutherAI/gpt-neox-20b,128,1,1413.0,1.0,1,H100,1697105231582,1697105232995.0,120,12.0,1.0,"[5, 1408]","[1697105231587, 1697105232995]"
3183,187,14,[],200,EleutherAI/gpt-neox-20b,128,1,4756.0,1.0,1,H100,1697105195071,1697105199827.0,120,161.0,6.0,"[5, 3613, 273, 410, 224, 231]","[1697105195076, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827]"
3184,104,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232996,1697105234920.0,120,,,[12],[1697105233008]
3185,488,33,[],200,EleutherAI/gpt-neox-20b,128,1,1523.0,1.0,1,H100,1697105258915,1697105260438.0,120,6.0,1.0,"[26, 1496]","[1697105258941, 1697105260437]"
3186,882,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262310,1697105264083.0,120,,,[77],[1697105262387]
3187,307,37,[],200,EleutherAI/gpt-neox-20b,128,1,1777.0,1.0,1,H100,1697105264087,1697105265864.0,120,26.0,1.0,"[220, 1556]","[1697105264307, 1697105265863]"
3188,203,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263991,1697105265927.0,120,,,[13],[1697105264004]
3189,845,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260439,1697105262307.0,120,,,[29],[1697105260468]
3190,408,13,[],200,EleutherAI/gpt-neox-20b,128,1,2917.0,1.0,1,H100,1697105197630,1697105200547.0,120,16.0,1.0,"[4, 2912]","[1697105197634, 1697105200546]"
3191,276,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262314,1697105265927.0,120,,,[282],[1697105262596]
3192,766,14,[],200,EleutherAI/gpt-neox-20b,128,1,2432.0,1.0,1,H100,1697105200548,1697105202980.0,120,11.0,1.0,"[12, 2420]","[1697105200560, 1697105202980]"
3193,557,38,[],200,EleutherAI/gpt-neox-20b,128,1,2981.0,1.0,1,H100,1697105265934,1697105268915.0,120,31.0,1.0,"[164, 2817]","[1697105266098, 1697105268915]"
3194,75,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268916,1697105270303.0,120,,,[9],[1697105268925]
3195,640,36,[],200,EleutherAI/gpt-neox-20b,128,1,1841.0,1.0,1,H100,1697105265931,1697105267772.0,120,15.0,1.0,"[54, 1787]","[1697105265985, 1697105267772]"
3196,196,15,[],200,EleutherAI/gpt-neox-20b,128,1,1179.0,1.0,1,H100,1697105202981,1697105204160.0,120,13.0,1.0,"[21, 1158]","[1697105203002, 1697105204160]"
3197,524,16,[],200,EleutherAI/gpt-neox-20b,128,1,7854.0,1.0,1,H100,1697105204161,1697105212015.0,120,100.0,30.0,"[12, 2640, 90, 89, 86, 81, 79, 60, 61, 618, 86, 83, 82, 64, 434, 87, 84, 79, 78, 384, 77, 618, 86, 83, 502, 82, 428, 168, 77, 456]","[1697105204173, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209054, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482, 1697105211559, 1697105212015]"
3198,39,37,[],200,EleutherAI/gpt-neox-20b,128,1,1142.0,1.0,1,H100,1697105267773,1697105268915.0,120,8.0,1.0,"[5, 1137]","[1697105267778, 1697105268915]"
3199,519,15,[],200,EleutherAI/gpt-neox-20b,128,1,11654.0,1.0,1,H100,1697105199828,1697105211482.0,120,58.0,47.0,"[4, 3886, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84, 731, 90, 89, 86, 80, 80, 60, 60, 618, 87, 82, 83, 63, 434, 88, 84, 79, 77, 385, 77, 618, 86, 83, 502, 81, 429, 168]","[1697105199832, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207358, 1697105207976, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208725, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210885, 1697105211314, 1697105211482]"
3200,436,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270309,1697105271973.0,120,,,[76],[1697105270385]
3201,878,16,[],200,EleutherAI/gpt-neox-20b,128,1,5421.0,1.0,1,H100,1697105211483,1697105216904.0,120,83.0,20.0,"[13, 2334, 94, 90, 89, 68, 246, 85, 64, 76, 653, 84, 356, 90, 84, 510, 89, 67, 83, 246]","[1697105211496, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642, 1697105215295, 1697105215379, 1697105215735, 1697105215825, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904]"
3202,398,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268916,1697105270302.0,120,,,[13],[1697105268929]
3203,749,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270303,1697105271973.0,120,,,[9],[1697105270312]
3204,795,41,[],200,EleutherAI/gpt-neox-20b,128,1,1578.0,1.0,1,H100,1697105271977,1697105273555.0,120,12.0,1.0,"[133, 1445]","[1697105272110, 1697105273555]"
3205,462,24,[],200,EleutherAI/gpt-neox-20b,128,1,1833.0,1.0,1,H100,1697105234923,1697105236756.0,120,52.0,1.0,"[64, 1769]","[1697105234987, 1697105236756]"
3206,307,17,[],200,EleutherAI/gpt-neox-20b,128,1,2835.0,1.0,1,H100,1697105216906,1697105219741.0,120,26.0,1.0,"[16, 2819]","[1697105216922, 1697105219741]"
3207,665,18,[],200,EleutherAI/gpt-neox-20b,128,1,4918.0,1.0,1,H100,1697105219742,1697105224660.0,120,90.0,20.0,"[4, 2219, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105219746, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
3208,227,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273556,1697105275207.0,120,,,[17],[1697105273573]
3209,821,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236757,1697105238408.0,120,,,[29],[1697105236786]
3210,179,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271978,1697105275207.0,120,,,[233],[1697105272211]
3211,494,8,[],200,EleutherAI/gpt-neox-20b,128,1,2892.0,1.0,1,H100,1697105206084,1697105208976.0,120,6.0,10.0,"[33, 1860, 86, 83, 82, 64, 434, 87, 84, 79]","[1697105206117, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976]"
3212,67,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105218529,1697105228773.0,120,,,"[7, 3429, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 84, 82, 351, 91, 70, 88, 87, 68, 579, 81, 78, 75, 73, 706, 91, 84, 66, 84, 486, 91, 89, 85, 582, 94, 84, 84, 83]","[1697105218536, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223823, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225320, 1697105225398, 1697105225473, 1697105225546, 1697105226252, 1697105226343, 1697105226427, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227910, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
3213,502,17,[],200,EleutherAI/gpt-neox-20b,128,1,2312.0,1.0,1,H100,1697105220998,1697105223310.0,120,19.0,1.0,"[178, 2134]","[1697105221176, 1697105223310]"
3214,827,18,[],200,EleutherAI/gpt-neox-20b,128,1,4944.0,1.0,1,H100,1697105223311,1697105228255.0,120,96.0,20.0,"[12, 1916, 82, 77, 75, 74, 705, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105223323, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225547, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
3215,165,16,[],200,EleutherAI/gpt-neox-20b,128,1,4241.0,1.0,1,H100,1697105220998,1697105225239.0,120,83.0,20.0,"[86, 1583, 87, 85, 82, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579]","[1697105221084, 1697105222667, 1697105222754, 1697105222839, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239]"
3216,111,16,[],200,EleutherAI/gpt-neox-20b,128,1,1923.0,1.0,1,H100,1697105220998,1697105222921.0,120,79.0,5.0,"[90, 1579, 87, 84, 83]","[1697105221088, 1697105222667, 1697105222754, 1697105222838, 1697105222921]"
3217,469,17,[],200,EleutherAI/gpt-neox-20b,128,1,2222.0,1.0,1,H100,1697105222922,1697105225144.0,120,17.0,1.0,"[8, 2214]","[1697105222930, 1697105225144]"
3218,834,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225145,1697105228773.0,120,,,"[5, 1102, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105225150, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
3219,372,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271978,1697105275207.0,120,,,[224],[1697105272202]
3220,235,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228783,1697105230475.0,120,,,[202],[1697105228985]
3221,593,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230477,1697105234919.0,120,,,"[112, 2466, 601, 617]","[1697105230589, 1697105233055, 1697105233656, 1697105234273]"
3222,18,21,[],200,EleutherAI/gpt-neox-20b,128,1,2973.0,1.0,1,H100,1697105234922,1697105237895.0,120,15.0,1.0,"[194, 2779]","[1697105235116, 1697105237895]"
3223,373,22,[],200,EleutherAI/gpt-neox-20b,128,1,1443.0,1.0,1,H100,1697105237896,1697105239339.0,120,15.0,1.0,"[25, 1418]","[1697105237921, 1697105239339]"
3224,510,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242000,1697105243754.0,120,,,[27],[1697105242027]
3225,864,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243758,1697105245502.0,120,,,[18],[1697105243776]
3226,183,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105217617,1697105220996.0,120,,,"[5, 2498, 78, 229, 82, 197]","[1697105217622, 1697105220120, 1697105220198, 1697105220427, 1697105220509, 1697105220706]"
3227,291,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245505,1697105247243.0,120,,,[171],[1697105245676]
3228,731,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105239340,1697105241993.0,120,,,[41],[1697105239381]
3229,619,31,[],200,EleutherAI/gpt-neox-20b,128,1,2427.0,1.0,1,H100,1697105247254,1697105249681.0,120,10.0,1.0,"[237, 2189]","[1697105247491, 1697105249680]"
3230,623,13,[],200,EleutherAI/gpt-neox-20b,128,1,1681.0,1.0,1,H100,1697105224662,1697105226343.0,120,140.0,3.0,"[21, 1569, 91]","[1697105224683, 1697105226252, 1697105226343]"
3231,51,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105249682,1697105252037.0,120,,,[16],[1697105249698]
3232,512,13,[],200,EleutherAI/gpt-neox-20b,128,1,2312.0,1.0,1,H100,1697105220998,1697105223310.0,120,11.0,1.0,"[183, 2129]","[1697105221181, 1697105223310]"
3233,26,14,[],200,EleutherAI/gpt-neox-20b,128,1,2407.0,1.0,1,H100,1697105226344,1697105228751.0,120,18.0,1.0,"[9, 2398]","[1697105226353, 1697105228751]"
3234,872,14,[],200,EleutherAI/gpt-neox-20b,128,1,4944.0,1.0,1,H100,1697105223311,1697105228255.0,120,91.0,20.0,"[24, 1904, 82, 78, 74, 74, 705, 91, 85, 65, 84, 487, 90, 89, 85, 583, 93, 84, 84, 83]","[1697105223335, 1697105225239, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227064, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
3235,380,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228752,1697105232145.0,120,,,"[8, 1756, 990, 75, 75, 74, 73]","[1697105228760, 1697105230516, 1697105231506, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
3236,250,24,[],200,EleutherAI/gpt-neox-20b,128,1,1553.0,1.0,1,H100,1697105242001,1697105243554.0,120,31.0,1.0,"[78, 1475]","[1697105242079, 1697105243554]"
3237,740,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233609.0,120,,,[56],[1697105232206]
3238,411,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253712.0,120,,,[28],[1697105252069]
3239,168,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233612,1697105236781.0,120,,,[78],[1697105233690]
3240,519,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225240,1697105228773.0,120,,,"[21, 1803, 91, 88, 85, 583, 93, 84, 84, 83]","[1697105225261, 1697105227064, 1697105227155, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
3241,549,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240333,1697105241994.0,120,,,[46],[1697105240379]
3242,772,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256011.0,120,,,[359],[1697105254075]
3243,197,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258913.0,120,,,[102],[1697105256115]
3244,613,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243555,1697105245503.0,120,,,[24],[1697105243579]
3245,114,15,[],200,EleutherAI/gpt-neox-20b,128,1,5254.0,1.0,1,H100,1697105220998,1697105226252.0,120,88.0,20.0,"[114, 2291, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 580, 81, 78, 74, 73, 706]","[1697105221112, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225240, 1697105225321, 1697105225399, 1697105225473, 1697105225546, 1697105226252]"
3246,41,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105247243.0,120,,,[190],[1697105245696]
3247,401,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247248,1697105248696.0,120,,,[139],[1697105247387]
3248,179,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253715,1697105256010.0,120,,,[199],[1697105253914]
3249,455,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252042,1697105253711.0,120,,,[168],[1697105252210]
3250,24,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263072,1697105265926.0,120,,,[25],[1697105263097]
3251,380,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267796.0,120,,,[42],[1697105265973]
3252,540,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258913.0,120,,,[94],[1697105256107]
3253,903,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258919,1697105260463.0,120,,,[150],[1697105259069]
3254,815,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[251],[1697105253967]
3255,332,33,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105260467,1697105262243.0,120,39.0,1.0,"[206, 1570]","[1697105260673, 1697105262243]"
3256,734,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[34],[1697105267832]
3257,778,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262244,1697105264082.0,120,,,[37],[1697105262281]
3258,249,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[28],[1697105269628]
3259,476,12,[],200,EleutherAI/gpt-neox-20b,128,1,10125.0,1.0,1,H100,1697105209439,1697105219564.0,120,6.0,50.0,"[28, 1848, 167, 77, 456, 89, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 64, 76, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 81, 257, 79, 368, 81, 59, 366, 84, 80]","[1697105209467, 1697105211315, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218190, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219484, 1697105219564]"
3260,203,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265928.0,120,,,[31],[1697105264116]
3261,640,38,[],200,EleutherAI/gpt-neox-20b,128,1,1777.0,1.0,1,H100,1697105264086,1697105265863.0,120,15.0,1.0,"[106, 1671]","[1697105264192, 1697105265863]"
3262,430,11,[],200,EleutherAI/gpt-neox-20b,128,1,1976.0,1.0,1,H100,1697105204738,1697105206714.0,120,15.0,1.0,"[8, 1968]","[1697105204746, 1697105206714]"
3263,308,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226254,1697105228773.0,120,,,[12],[1697105226266]
3264,556,36,[],200,EleutherAI/gpt-neox-20b,128,1,2979.0,1.0,1,H100,1697105265937,1697105268916.0,120,9.0,1.0,"[281, 2697]","[1697105266218, 1697105268915]"
3265,916,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268917,1697105270302.0,120,,,[36],[1697105268953]
3266,240,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256012,1697105258907.0,120,,,[29],[1697105256041]
3267,348,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270308,1697105271972.0,120,,,[60],[1697105270368]
3268,680,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271976,1697105273585.0,120,,,[118],[1697105272094]
3269,759,12,[],200,EleutherAI/gpt-neox-20b,128,1,5549.0,1.0,1,H100,1697105206715,1697105212264.0,120,92.0,20.0,"[21, 1990, 87, 84, 79, 78, 384, 77, 618, 86, 83, 502, 82, 428, 169, 76, 456, 89, 80, 79]","[1697105206736, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209054, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211483, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263]"
3270,111,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273589,1697105275208.0,120,,,[186],[1697105273775]
3271,599,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258915,1697105260463.0,120,,,[5],[1697105258920]
3272,25,34,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105260467,1697105262243.0,120,12.0,1.0,"[222, 1554]","[1697105260689, 1697105262243]"
3273,68,39,[],200,EleutherAI/gpt-neox-20b,128,1,1321.0,1.0,1,H100,1697105265865,1697105267186.0,120,12.0,1.0,"[38, 1283]","[1697105265903, 1697105267186]"
3274,399,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267187,1697105271972.0,120,,,"[20, 1771, 669, 704, 685]","[1697105267207, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
3275,355,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262244,1697105264083.0,120,,,[33],[1697105262277]
3276,374,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105247243.0,120,,,[199],[1697105245705]
3277,117,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258920,1697105260463.0,120,,,[161],[1697105259081]
3278,765,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230475.0,120,,,[28],[1697105228809]
3279,731,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247248,1697105248696.0,120,,,[130],[1697105247378]
3280,471,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260467,1697105262307.0,120,,,[206],[1697105260673]
3281,184,13,[],200,EleutherAI/gpt-neox-20b,128,1,5352.0,1.0,1,H100,1697105212264,1697105217616.0,120,87.0,20.0,"[5, 2148, 85, 65, 75, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246, 85, 65, 386, 89, 87]","[1697105212269, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616]"
3282,830,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262314,1697105264082.0,120,,,[270],[1697105262584]
3283,230,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265928.0,120,,,[14],[1697105264099]
3284,587,39,[],200,EleutherAI/gpt-neox-20b,128,1,2980.0,1.0,1,H100,1697105265936,1697105268916.0,120,13.0,1.0,"[266, 2713]","[1697105266202, 1697105268915]"
3285,18,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268917,1697105270302.0,120,,,[32],[1697105268949]
3286,375,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270304,1697105271972.0,120,,,[40],[1697105270344]
3287,732,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271976,1697105273585.0,120,,,[46],[1697105272022]
3288,160,32,[],200,EleutherAI/gpt-neox-20b,128,1,1623.0,1.0,1,H100,1697105248699,1697105250322.0,120,13.0,1.0,"[22, 1601]","[1697105248721, 1697105250322]"
3289,250,43,[],200,EleutherAI/gpt-neox-20b,128,1,1543.0,1.0,1,H100,1697105273589,1697105275132.0,120,31.0,1.0,"[202, 1341]","[1697105273791, 1697105275132]"
3290,41,10,[],200,EleutherAI/gpt-neox-20b,128,1,9474.0,1.0,1,H100,1697105202008,1697105211482.0,120,39.0,43.0,"[171, 2071, 87, 87, 83, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84, 731, 90, 89, 86, 80, 80, 60, 61, 618, 86, 82, 83, 63, 435, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 81, 429, 168]","[1697105202179, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208291, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210885, 1697105211314, 1697105211482]"
3291,544,14,[],200,EleutherAI/gpt-neox-20b,128,1,2420.0,1.0,1,H100,1697105217617,1697105220037.0,120,26.0,1.0,"[21, 2399]","[1697105217638, 1697105220037]"
3292,490,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250323,1697105252037.0,120,,,[4],[1697105250327]
3293,848,34,[],200,EleutherAI/gpt-neox-20b,128,1,1640.0,1.0,1,H100,1697105252042,1697105253682.0,120,47.0,1.0,"[63, 1577]","[1697105252105, 1697105253682]"
3294,192,16,[],200,EleutherAI/gpt-neox-20b,128,1,5317.0,1.0,1,H100,1697105214568,1697105219885.0,120,93.0,20.0,"[4, 2333, 84, 66, 385, 89, 87, 406, 88, 81, 256, 79, 368, 81, 59, 366, 89, 76, 259, 61]","[1697105214572, 1697105216905, 1697105216989, 1697105217055, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219565, 1697105219824, 1697105219885]"
3295,897,15,[],200,EleutherAI/gpt-neox-20b,128,1,1865.0,1.0,1,H100,1697105220038,1697105221903.0,120,9.0,1.0,"[16, 1849]","[1697105220054, 1697105221903]"
3296,328,16,[],200,EleutherAI/gpt-neox-20b,128,1,1836.0,1.0,1,H100,1697105221904,1697105223740.0,120,109.0,6.0,"[4, 1495, 71, 92, 87, 87]","[1697105221908, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223740]"
3297,660,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105223741,1697105228773.0,120,,,"[4, 1494, 82, 78, 74, 74, 705, 91, 85, 65, 84, 487, 90, 89, 85, 583, 93, 84, 84, 83]","[1697105223745, 1697105225239, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227064, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
3298,144,8,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105199373,1697105201999.0,120,,,[5],[1697105199378]
3299,502,9,[],200,EleutherAI/gpt-neox-20b,128,1,1616.0,1.0,1,H100,1697105202010,1697105203626.0,120,19.0,1.0,"[169, 1447]","[1697105202179, 1697105203626]"
3300,860,10,[],200,EleutherAI/gpt-neox-20b,128,1,5811.0,1.0,1,H100,1697105203627,1697105209438.0,120,85.0,20.0,"[28, 3158, 90, 89, 86, 80, 80, 60, 61, 618, 86, 83, 82, 64, 434, 87, 84, 79, 77, 385]","[1697105203655, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438]"
3301,273,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253688,1697105255028.0,120,,,[117],[1697105253805]
3302,522,15,[],200,EleutherAI/gpt-neox-20b,128,1,1577.0,1.0,1,H100,1697105220996,1697105222573.0,120,20.0,1.0,"[24, 1553]","[1697105221020, 1697105222573]"
3303,903,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105270302.0,120,,,[171],[1697105267972]
3304,124,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236782.0,120,,,[69],[1697105234991]
3305,880,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243753.0,120,,,[38],[1697105242039]
3306,779,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232151,1697105234225.0,120,,,[128],[1697105232279]
3307,744,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247246,1697105248696.0,120,,,[32],[1697105247278]
3308,324,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270308,1697105271972.0,120,,,[28],[1697105270336]
3309,209,21,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105234226,1697105236002.0,120,20.0,1.0,"[57, 1719]","[1697105234283, 1697105236002]"
3310,567,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236003,1697105238408.0,120,,,[21],[1697105236024]
3311,147,27,[],200,EleutherAI/gpt-neox-20b,128,1,2485.0,1.0,1,H100,1697105248699,1697105251184.0,120,182.0,1.0,"[186, 2299]","[1697105248885, 1697105251184]"
3312,897,23,[],200,EleutherAI/gpt-neox-20b,128,1,1855.0,1.0,1,H100,1697105238411,1697105240266.0,120,9.0,1.0,"[96, 1759]","[1697105238507, 1697105240266]"
3313,326,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240267,1697105241994.0,120,,,[32],[1697105240299]
3314,876,16,[],200,EleutherAI/gpt-neox-20b,128,1,1588.0,1.0,1,H100,1697105222574,1697105224162.0,120,11.0,1.0,"[12, 1576]","[1697105222586, 1697105224162]"
3315,683,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271975,1697105273585.0,120,,,[39],[1697105272014]
3316,687,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242000,1697105243755.0,120,,,[15],[1697105242015]
3317,304,17,[],200,EleutherAI/gpt-neox-20b,128,1,4092.0,1.0,1,H100,1697105224163,1697105228255.0,120,86.0,20.0,"[8, 1068, 82, 78, 74, 74, 705, 91, 85, 65, 84, 487, 90, 89, 85, 583, 93, 84, 84, 83]","[1697105224171, 1697105225239, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227064, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
3318,113,26,[],200,EleutherAI/gpt-neox-20b,128,1,2437.0,1.0,1,H100,1697105243759,1697105246196.0,120,13.0,1.0,"[314, 2123]","[1697105244073, 1697105246196]"
3319,670,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265864,1697105267796.0,120,,,[25],[1697105265889]
3320,558,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105246197,1697105248696.0,120,,,[25],[1697105246222]
3321,177,20,[],200,EleutherAI/gpt-neox-20b,128,1,1686.0,1.0,1,H100,1697105227065,1697105228751.0,120,14.0,1.0,"[4, 1682]","[1697105227069, 1697105228751]"
3322,112,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273587,1697105275208.0,120,,,[39],[1697105273626]
3323,74,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105234919.0,120,,,"[123, 2455, 600, 617]","[1697105230601, 1697105233056, 1697105233656, 1697105234273]"
3324,538,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228752,1697105232145.0,120,,,"[4, 1760, 990, 75, 75, 74, 73]","[1697105228756, 1697105230516, 1697105231506, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
3325,506,28,[],200,EleutherAI/gpt-neox-20b,128,1,1379.0,1.0,1,H100,1697105251186,1697105252565.0,120,16.0,1.0,"[36, 1343]","[1697105251222, 1697105252565]"
3326,852,9,[],200,EleutherAI/gpt-neox-20b,128,1,5590.0,1.0,1,H100,1697105208977,1697105214567.0,120,100.0,20.0,"[4, 3034, 89, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 69, 245, 85, 65]","[1697105208981, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214172, 1697105214417, 1697105214502, 1697105214567]"
3327,18,29,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105252012,1697105253681.0,120,15.0,1.0,"[29, 1640]","[1697105252041, 1697105253681]"
3328,912,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105252036.0,120,,,[110],[1697105248809]
3329,867,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252566,1697105256010.0,120,,,"[8, 2484]","[1697105252574, 1697105255058]"
3330,378,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253687,1697105255028.0,120,,,[91],[1697105253778]
3331,447,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105250347.0,120,,,[9],[1697105248708]
3332,732,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[69],[1697105255099]
3333,292,30,[],200,EleutherAI/gpt-neox-20b,128,1,2017.0,1.0,1,H100,1697105256013,1697105258030.0,120,286.0,1.0,"[37, 1979]","[1697105256050, 1697105258029]"
3334,775,28,[],200,EleutherAI/gpt-neox-20b,128,1,1662.0,1.0,1,H100,1697105250349,1697105252011.0,120,17.0,1.0,"[60, 1602]","[1697105250409, 1697105252011]"
3335,866,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232149,1697105233609.0,120,,,[17],[1697105232166]
3336,622,31,[],200,EleutherAI/gpt-neox-20b,128,1,1741.0,1.0,1,H100,1697105258031,1697105259772.0,120,20.0,1.0,"[20, 1721]","[1697105258051, 1697105259772]"
3337,47,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105259773,1697105262306.0,120,,,[20],[1697105259793]
3338,346,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252040,1697105253711.0,120,,,[174],[1697105252214]
3339,405,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262310,1697105264082.0,120,,,[65],[1697105262375]
3340,703,30,[],200,EleutherAI/gpt-neox-20b,128,1,2228.0,1.0,1,H100,1697105253716,1697105255944.0,120,12.0,1.0,"[214, 2014]","[1697105253930, 1697105255944]"
3341,136,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255947,1697105257115.0,120,,,[14],[1697105255961]
3342,157,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105260463.0,120,,,[166],[1697105257284]
3343,466,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105260463.0,120,,,[178],[1697105257296]
3344,204,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252012,1697105253711.0,120,,,[9],[1697105252021]
3345,563,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[300],[1697105254016]
3346,820,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260468,1697105262307.0,120,,,[245],[1697105260713]
3347,921,31,[],200,EleutherAI/gpt-neox-20b,128,1,2017.0,1.0,1,H100,1697105256013,1697105258030.0,120,31.0,1.0,"[25, 1991]","[1697105256038, 1697105258029]"
3348,767,34,[],200,EleutherAI/gpt-neox-20b,128,1,1777.0,1.0,1,H100,1697105264086,1697105265863.0,120,11.0,1.0,"[193, 1584]","[1697105264279, 1697105265863]"
3349,346,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258030,1697105260462.0,120,,,[5],[1697105258035]
3350,795,33,[],200,EleutherAI/gpt-neox-20b,128,1,1778.0,1.0,1,H100,1697105260465,1697105262243.0,120,12.0,1.0,"[19, 1759]","[1697105260484, 1697105262243]"
3351,224,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262244,1697105264083.0,120,,,[8],[1697105262252]
3352,585,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264087,1697105267795.0,120,,,[296],[1697105264383]
3353,12,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[10],[1697105267808]
3354,341,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269599,1697105270988.0,120,,,[17],[1697105269616]
3355,250,34,[],200,EleutherAI/gpt-neox-20b,128,1,1677.0,1.0,1,H100,1697105262313,1697105263990.0,120,31.0,1.0,"[191, 1486]","[1697105262504, 1697105263990]"
3356,700,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270989,1697105271973.0,120,,,[25],[1697105271014]
3357,125,39,[],200,EleutherAI/gpt-neox-20b,128,1,2435.0,1.0,1,H100,1697105271979,1697105274414.0,120,13.0,1.0,"[292, 2143]","[1697105272271, 1697105274414]"
3358,252,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228257,1697105232145.0,120,,,"[12, 2246, 990, 76, 75, 74, 73]","[1697105228269, 1697105230515, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
3359,604,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263991,1697105265927.0,120,,,[21],[1697105264012]
3360,36,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267796.0,120,,,[58],[1697105265989]
3361,612,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232149,1697105233608.0,120,,,[9],[1697105232158]
3362,487,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260467,1697105262307.0,120,,,[141],[1697105260608]
3363,486,40,[],200,EleutherAI/gpt-neox-20b,128,1,2150.0,1.0,1,H100,1697105274416,1697105276566.0,120,14.0,20.0,"[36, 1492, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 33, 32, 32]","[1697105274452, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276502, 1697105276534, 1697105276566]"
3364,849,34,[],200,EleutherAI/gpt-neox-20b,128,1,1675.0,1.0,1,H100,1697105262315,1697105263990.0,120,10.0,1.0,"[289, 1386]","[1697105262604, 1697105263990]"
3365,526,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105238409.0,120,,,[102],[1697105236886]
3366,323,12,[],200,EleutherAI/gpt-neox-20b,128,1,5186.0,1.0,1,H100,1697105203627,1697105208813.0,120,84.0,20.0,"[16, 2179, 91, 85, 84, 731, 91, 88, 86, 81, 79, 60, 61, 618, 86, 83, 82, 64, 434, 87]","[1697105203643, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206904, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813]"
3367,366,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267799,1697105269599.0,120,,,[77],[1697105267876]
3368,727,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[77],[1697105269677]
3369,330,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240266,1697105241993.0,120,,,[9],[1697105240275]
3370,156,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270989,1697105273585.0,120,,,[29],[1697105271018]
3371,689,27,[],200,EleutherAI/gpt-neox-20b,128,1,1553.0,1.0,1,H100,1697105242001,1697105243554.0,120,15.0,1.0,"[46, 1507]","[1697105242047, 1697105243554]"
3372,526,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258919,1697105260463.0,120,,,[154],[1697105259073]
3373,122,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243555,1697105245502.0,120,,,[12],[1697105243567]
3374,512,40,[],200,EleutherAI/gpt-neox-20b,128,1,2309.0,1.0,1,H100,1697105273589,1697105275898.0,120,11.0,1.0,"[217, 2092]","[1697105273806, 1697105275898]"
3375,453,29,[],200,EleutherAI/gpt-neox-20b,128,1,1662.0,1.0,1,H100,1697105245506,1697105247168.0,120,26.0,1.0,"[34, 1628]","[1697105245540, 1697105247168]"
3376,586,11,[],200,EleutherAI/gpt-neox-20b,128,1,4475.0,1.0,1,H100,1697105190681,1697105195156.0,120,85.0,20.0,"[5, 2080, 87, 83, 234, 82, 62, 306, 86, 189, 84, 64, 81, 265, 63, 85, 199, 80, 79, 261]","[1697105190686, 1697105192766, 1697105192853, 1697105192936, 1697105193170, 1697105193252, 1697105193314, 1697105193620, 1697105193706, 1697105193895, 1697105193979, 1697105194043, 1697105194124, 1697105194389, 1697105194452, 1697105194537, 1697105194736, 1697105194816, 1697105194895, 1697105195156]"
3377,145,17,[],200,EleutherAI/gpt-neox-20b,128,1,3522.0,1.0,1,H100,1697105216905,1697105220427.0,120,161.0,9.0,"[5, 2490, 89, 75, 260, 62, 233, 79, 229]","[1697105216910, 1697105219400, 1697105219489, 1697105219564, 1697105219824, 1697105219886, 1697105220119, 1697105220198, 1697105220427]"
3378,812,30,[],200,EleutherAI/gpt-neox-20b,128,1,839.0,1.0,1,H100,1697105247170,1697105248009.0,120,16.0,1.0,"[24, 815]","[1697105247194, 1697105248009]"
3379,716,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264087,1697105265928.0,120,,,[17],[1697105264104]
3380,238,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248010,1697105250348.0,120,,,[17],[1697105248027]
3381,797,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228784,1697105230476.0,120,,,[286],[1697105229070]
3382,629,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243759,1697105245502.0,120,,,[137],[1697105243896]
3383,226,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105232146.0,120,,,"[49, 1598]","[1697105230527, 1697105232125]"
3384,60,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105247242.0,120,,,[17],[1697105245523]
3385,421,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247250,1697105250347.0,120,,,[165],[1697105247415]
3386,750,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250350,1697105252037.0,120,,,[67],[1697105250417]
3387,184,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253713.0,120,,,[68],[1697105252109]
3388,538,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[284],[1697105254000]
3389,636,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[68],[1697105255098]
3390,897,31,[],200,EleutherAI/gpt-neox-20b,128,1,2016.0,1.0,1,H100,1697105256013,1697105258029.0,120,9.0,1.0,"[21, 1995]","[1697105256034, 1697105258029]"
3391,326,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258030,1697105260462.0,120,,,[5],[1697105258035]
3392,65,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105258913.0,120,,,[154],[1697105257272]
3393,512,38,[],200,EleutherAI/gpt-neox-20b,128,1,1520.0,1.0,1,H100,1697105258918,1697105260438.0,120,11.0,1.0,"[55, 1465]","[1697105258973, 1697105260438]"
3394,518,43,[],200,EleutherAI/gpt-neox-20b,128,1,1482.0,1.0,1,H100,1697105274416,1697105275898.0,120,23.0,1.0,"[28, 1454]","[1697105274444, 1697105275898]"
3395,653,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260465,1697105262306.0,120,,,[51],[1697105260516]
3396,81,13,[],200,EleutherAI/gpt-neox-20b,128,1,5026.0,1.0,1,H100,1697105207079,1697105212105.0,120,732.0,13.0,"[5, 2354, 77, 618, 86, 83, 502, 82, 429, 168, 76, 457, 88]","[1697105207084, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211315, 1697105211483, 1697105211559, 1697105212016, 1697105212104]"
3397,84,34,[],200,EleutherAI/gpt-neox-20b,128,1,1678.0,1.0,1,H100,1697105262312,1697105263990.0,120,26.0,1.0,"[164, 1514]","[1697105262476, 1697105263990]"
3398,868,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260439,1697105262307.0,120,,,[25],[1697105260464]
3399,441,35,[],200,EleutherAI/gpt-neox-20b,128,1,1013.0,1.0,1,H100,1697105263991,1697105265004.0,120,6.0,1.0,"[17, 996]","[1697105264008, 1697105265004]"
3400,297,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262313,1697105264082.0,120,,,[186],[1697105262499]
3401,656,41,[],200,EleutherAI/gpt-neox-20b,128,1,1778.0,1.0,1,H100,1697105264085,1697105265863.0,120,26.0,1.0,"[83, 1695]","[1697105264168, 1697105265863]"
3402,81,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265864,1697105267796.0,120,,,[5],[1697105265869]
3403,413,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267799,1697105269598.0,120,,,[109],[1697105267908]
3404,773,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[68],[1697105269668]
3405,57,6,[],200,EleutherAI/gpt-neox-20b,128,1,2145.0,1.0,1,H100,1697105202015,1697105204160.0,120,13.0,1.0,"[256, 1889]","[1697105202271, 1697105204160]"
3406,205,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270989,1697105271973.0,120,,,[8],[1697105270997]
3407,419,7,[],200,EleutherAI/gpt-neox-20b,128,1,5277.0,1.0,1,H100,1697105204161,1697105209438.0,120,88.0,20.0,"[12, 2640, 90, 89, 86, 81, 79, 60, 61, 618, 86, 83, 82, 64, 434, 87, 84, 79, 78, 384]","[1697105204173, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209054, 1697105209438]"
3408,558,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271978,1697105275207.0,120,,,[301],[1697105272279]
3409,799,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265006,1697105267795.0,120,,,[13],[1697105265019]
3410,229,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267799,1697105269598.0,120,,,[93],[1697105267892]
3411,674,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[93],[1697105269693]
3412,554,24,[],200,EleutherAI/gpt-neox-20b,128,1,1834.0,1.0,1,H100,1697105234922,1697105236756.0,120,26.0,1.0,"[13, 1821]","[1697105234935, 1697105236756]"
3413,106,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270989,1697105273584.0,120,,,[25],[1697105271014]
3414,882,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236757,1697105238409.0,120,,,[4],[1697105236761]
3415,462,40,[],200,EleutherAI/gpt-neox-20b,128,1,1545.0,1.0,1,H100,1697105273587,1697105275132.0,120,52.0,1.0,"[82, 1463]","[1697105273669, 1697105275132]"
3416,307,26,[],200,EleutherAI/gpt-neox-20b,128,1,1854.0,1.0,1,H100,1697105238412,1697105240266.0,120,26.0,1.0,"[195, 1658]","[1697105238607, 1697105240265]"
3417,495,16,[],200,EleutherAI/gpt-neox-20b,128,1,2016.0,1.0,1,H100,1697105219887,1697105221903.0,120,13.0,1.0,"[8, 2008]","[1697105219895, 1697105221903]"
3418,440,14,[],200,EleutherAI/gpt-neox-20b,128,1,5511.0,1.0,1,H100,1697105212105,1697105217616.0,120,84.0,20.0,"[17, 2295, 85, 65, 75, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246, 85, 65, 386, 89, 87]","[1697105212122, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616]"
3419,483,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236785,1697105240330.0,120,,,[217],[1697105237002]
3420,749,8,[],200,EleutherAI/gpt-neox-20b,128,1,5128.0,1.0,1,H100,1697105209439,1697105214567.0,120,47.0,20.0,"[12, 2564, 89, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 69, 245, 85, 65]","[1697105209451, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214172, 1697105214417, 1697105214502, 1697105214567]"
3421,546,6,[],200,EleutherAI/gpt-neox-20b,128,1,4855.0,1.0,1,H100,1697105180544,1697105185399.0,120,93.0,20.0,"[20, 2286, 89, 88, 190, 87, 78, 372, 86, 85, 78, 384, 83, 79, 78, 59, 215, 77, 57, 363]","[1697105180564, 1697105182850, 1697105182939, 1697105183027, 1697105183217, 1697105183304, 1697105183382, 1697105183754, 1697105183840, 1697105183925, 1697105184003, 1697105184387, 1697105184470, 1697105184549, 1697105184627, 1697105184686, 1697105184901, 1697105184978, 1697105185035, 1697105185398]"
3422,849,17,[],200,EleutherAI/gpt-neox-20b,128,1,2257.0,1.0,1,H100,1697105221905,1697105224162.0,120,10.0,1.0,"[36, 2221]","[1697105221941, 1697105224162]"
3423,838,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240333,1697105243753.0,120,,,[274],[1697105240607]
3424,278,18,[],200,EleutherAI/gpt-neox-20b,128,1,981.0,1.0,1,H100,1697105224163,1697105225144.0,120,13.0,1.0,"[12, 969]","[1697105224175, 1697105225144]"
3425,270,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243757,1697105245502.0,120,,,[110],[1697105243867]
3426,716,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105248695.0,120,,,[274],[1697105245780]
3427,633,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225145,1697105228773.0,120,,,"[13, 1094, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105225158, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
3428,798,15,[],200,EleutherAI/gpt-neox-20b,128,1,3089.0,1.0,1,H100,1697105217617,1697105220706.0,120,79.0,6.0,"[17, 2486, 78, 229, 82, 197]","[1697105217634, 1697105220120, 1697105220198, 1697105220427, 1697105220509, 1697105220706]"
3429,181,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105214568,1697105220994.0,120,,,"[16, 2856, 89, 87, 406, 88, 81, 256, 79, 368, 81, 59, 366, 89, 75, 260, 61, 235, 78, 229, 81, 198]","[1697105214584, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219824, 1697105219885, 1697105220120, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
3430,65,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228782,1697105232145.0,120,,,"[296, 2428, 75, 75, 74, 73]","[1697105229078, 1697105231506, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
3431,199,16,[],200,EleutherAI/gpt-neox-20b,128,1,1196.0,1.0,1,H100,1697105220707,1697105221903.0,120,13.0,1.0,"[5, 1191]","[1697105220712, 1697105221903]"
3432,561,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105218110,1697105220996.0,120,,,"[5, 2312, 82, 197]","[1697105218115, 1697105220427, 1697105220509, 1697105220706]"
3433,550,17,[],200,EleutherAI/gpt-neox-20b,128,1,5339.0,1.0,1,H100,1697105221904,1697105227243.0,120,91.0,20.0,"[21, 2332, 90, 70, 88, 87, 68, 579, 82, 78, 74, 74, 706, 90, 85, 65, 84, 486, 91, 89]","[1697105221925, 1697105224257, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226253, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243]"
3434,512,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233609.0,120,,,[32],[1697105232182]
3435,872,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233610,1697105234919.0,120,,,[64],[1697105233674]
3436,297,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234925,1697105238408.0,120,,,[187],[1697105235112]
3437,915,19,[],200,EleutherAI/gpt-neox-20b,128,1,2312.0,1.0,1,H100,1697105220998,1697105223310.0,120,182.0,1.0,"[190, 2122]","[1697105221188, 1697105223310]"
3438,340,20,[],200,EleutherAI/gpt-neox-20b,128,1,4944.0,1.0,1,H100,1697105223311,1697105228255.0,120,85.0,20.0,"[20, 1908, 82, 78, 74, 74, 705, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105223331, 1697105225239, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
3439,657,24,[],200,EleutherAI/gpt-neox-20b,128,1,1855.0,1.0,1,H100,1697105238411,1697105240266.0,120,10.0,1.0,"[64, 1791]","[1697105238475, 1697105240266]"
3440,434,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236780.0,120,,,[162],[1697105235084]
3441,85,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240267,1697105241994.0,120,,,[65],[1697105240332]
3442,791,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105238409.0,120,,,[126],[1697105236910]
3443,220,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238412,1697105240330.0,120,,,[103],[1697105238515]
3444,300,23,[],200,EleutherAI/gpt-neox-20b,128,1,1272.0,1.0,1,H100,1697105233610,1697105234882.0,120,9.0,1.0,"[68, 1204]","[1697105233678, 1697105234882]"
3445,579,25,[],200,EleutherAI/gpt-neox-20b,128,1,1596.0,1.0,1,H100,1697105240334,1697105241930.0,120,19.0,1.0,"[169, 1427]","[1697105240503, 1697105241930]"
3446,906,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105227244,1697105228774.0,120,,,[5],[1697105227249]
3447,337,19,[],200,EleutherAI/gpt-neox-20b,128,1,2522.0,1.0,1,H100,1697105228784,1697105231306.0,120,12.0,1.0,"[298, 2224]","[1697105229082, 1697105231306]"
3448,702,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105231307,1697105234919.0,120,,,"[9, 1740, 600, 617]","[1697105231316, 1697105233056, 1697105233656, 1697105234273]"
3449,654,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234883,1697105236781.0,120,,,[9],[1697105234892]
3450,217,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236780.0,120,,,[149],[1697105235071]
3451,84,25,[],200,EleutherAI/gpt-neox-20b,128,1,1601.0,1.0,1,H100,1697105236784,1697105238385.0,120,26.0,1.0,"[134, 1467]","[1697105236918, 1697105238385]"
3452,907,26,[],200,EleutherAI/gpt-neox-20b,128,1,760.0,1.0,1,H100,1697105241931,1697105242691.0,120,10.0,1.0,"[21, 739]","[1697105241952, 1697105242691]"
3453,438,26,[],200,EleutherAI/gpt-neox-20b,128,1,1879.0,1.0,1,H100,1697105238386,1697105240265.0,120,9.0,1.0,"[32, 1847]","[1697105238418, 1697105240265]"
3454,234,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230479,1697105234920.0,120,,,"[190, 2325, 62, 600, 617]","[1697105230669, 1697105232994, 1697105233056, 1697105233656, 1697105234273]"
3455,577,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236783,1697105238408.0,120,,,[90],[1697105236873]
3456,886,27,[],200,EleutherAI/gpt-neox-20b,128,1,939.0,1.0,1,H100,1697105240266,1697105241205.0,120,17.0,1.0,"[5, 934]","[1697105240271, 1697105241205]"
3457,2,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238411,1697105240330.0,120,,,[92],[1697105238503]
3458,336,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242691,1697105245502.0,120,,,[5],[1697105242696]
3459,819,15,[],200,EleutherAI/gpt-neox-20b,128,1,638.0,1.0,1,H100,1697105224506,1697105225144.0,120,13.0,1.0,"[4, 634]","[1697105224510, 1697105225144]"
3460,40,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233610,1697105234918.0,120,,,[16],[1697105233626]
3461,405,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236780.0,120,,,[145],[1697105235067]
3462,250,16,[],200,EleutherAI/gpt-neox-20b,128,1,1808.0,1.0,1,H100,1697105225146,1697105226954.0,120,31.0,1.0,"[48, 1759]","[1697105225194, 1697105226953]"
3463,317,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241206,1697105243753.0,120,,,[13],[1697105241219]
3464,592,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234923,1697105238408.0,120,,,[253],[1697105235176]
3465,674,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243758,1697105245501.0,120,,,[230],[1697105243988]
3466,851,23,[],200,EleutherAI/gpt-neox-20b,128,1,1601.0,1.0,1,H100,1697105236784,1697105238385.0,120,23.0,1.0,"[94, 1507]","[1697105236878, 1697105238385]"
3467,103,30,[],200,EleutherAI/gpt-neox-20b,128,1,1663.0,1.0,1,H100,1697105245505,1697105247168.0,120,15.0,1.0,"[104, 1559]","[1697105245609, 1697105247168]"
3468,22,22,[],200,EleutherAI/gpt-neox-20b,128,1,1854.0,1.0,1,H100,1697105238411,1697105240265.0,120,16.0,1.0,"[60, 1794]","[1697105238471, 1697105240265]"
3469,604,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226954,1697105228773.0,120,,,[9],[1697105226963]
3470,380,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240267,1697105241994.0,120,,,[32],[1697105240299]
3471,33,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228782,1697105230476.0,120,,,[108],[1697105228890]
3472,66,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225548,1697105228772.0,120,,,"[4, 2359, 93, 84, 84, 83]","[1697105225552, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
3473,387,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230479,1697105234918.0,120,,,"[218, 2359, 600, 617]","[1697105230697, 1697105233056, 1697105233656, 1697105234273]"
3474,835,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236781.0,120,,,[29],[1697105234951]
3475,739,24,[],200,EleutherAI/gpt-neox-20b,128,1,1554.0,1.0,1,H100,1697105242000,1697105243554.0,120,216.0,1.0,"[119, 1434]","[1697105242119, 1697105243553]"
3476,255,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243555,1697105245501.0,120,,,[49],[1697105243604]
3477,266,21,[],200,EleutherAI/gpt-neox-20b,128,1,1600.0,1.0,1,H100,1697105236785,1697105238385.0,120,9.0,1.0,"[84, 1516]","[1697105236869, 1697105238385]"
3478,612,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245504,1697105247243.0,120,,,[79],[1697105245583]
3479,627,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238386,1697105240331.0,120,,,[8],[1697105238394]
3480,42,27,[],200,EleutherAI/gpt-neox-20b,128,1,1389.0,1.0,1,H100,1697105247248,1697105248637.0,120,10.0,1.0,"[135, 1253]","[1697105247383, 1697105248636]"
3481,463,31,[],200,EleutherAI/gpt-neox-20b,128,1,839.0,1.0,1,H100,1697105247170,1697105248009.0,120,39.0,1.0,"[24, 815]","[1697105247194, 1697105248009]"
3482,400,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248637,1697105250347.0,120,,,[13],[1697105248650]
3483,757,29,[],200,EleutherAI/gpt-neox-20b,128,1,1660.0,1.0,1,H100,1697105250351,1697105252011.0,120,20.0,1.0,"[26, 1634]","[1697105250377, 1697105252011]"
3484,790,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248010,1697105250348.0,120,,,[21],[1697105248031]
3485,159,30,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105252012,1697105253681.0,120,31.0,1.0,"[33, 1636]","[1697105252045, 1697105253681]"
3486,459,13,[],200,EleutherAI/gpt-neox-20b,128,1,2825.0,1.0,1,H100,1697105209439,1697105212264.0,120,58.0,5.0,"[4, 2572, 89, 80, 79]","[1697105209443, 1697105212015, 1697105212104, 1697105212184, 1697105212263]"
3487,56,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241994.0,120,,,[157],[1697105240491]
3488,383,23,[],200,EleutherAI/gpt-neox-20b,128,1,1119.0,1.0,1,H100,1697105234883,1697105236002.0,120,15.0,1.0,"[29, 1090]","[1697105234912, 1697105236002]"
3489,382,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242000,1697105243754.0,120,,,[19],[1697105242019]
3490,520,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253688,1697105255028.0,120,,,[113],[1697105253801]
3491,474,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105224662,1697105228773.0,120,,,"[37, 1554, 90, 85, 65, 84, 486, 91, 89, 85, 582, 94, 84, 84, 83]","[1697105224699, 1697105226253, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227910, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
3492,219,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252037.0,120,,,[122],[1697105250473]
3493,876,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[162],[1697105255192]
3494,579,34,[],200,EleutherAI/gpt-neox-20b,128,1,1639.0,1.0,1,H100,1697105252042,1697105253681.0,120,19.0,1.0,"[229, 1410]","[1697105252271, 1697105253681]"
3495,56,17,[],200,EleutherAI/gpt-neox-20b,128,1,4316.0,1.0,1,H100,1697105220344,1697105224660.0,120,86.0,20.0,"[5, 1616, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105220349, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
3496,7,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253687,1697105255028.0,120,,,[87],[1697105253774]
3497,337,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[77],[1697105255107]
3498,695,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105258913.0,120,,,[89],[1697105257207]
3499,658,24,[],200,EleutherAI/gpt-neox-20b,128,1,1879.0,1.0,1,H100,1697105238386,1697105240265.0,120,11.0,1.0,"[25, 1854]","[1697105238411, 1697105240265]"
3500,831,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230476.0,120,,,[105],[1697105228886]
3501,88,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240266,1697105241993.0,120,,,[5],[1697105240271]
3502,711,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236003,1697105238408.0,120,,,[15],[1697105236018]
3503,234,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230479,1697105234918.0,120,,,"[222, 2293, 62, 600, 617]","[1697105230701, 1697105232994, 1697105233056, 1697105233656, 1697105234273]"
3504,139,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238411,1697105240330.0,120,,,[80],[1697105238491]
3505,124,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258917,1697105260462.0,120,,,[60],[1697105258977]
3506,598,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236782.0,120,,,[53],[1697105234975]
3507,483,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260464,1697105262306.0,120,,,[32],[1697105260496]
3508,26,22,[],200,EleutherAI/gpt-neox-20b,128,1,2554.0,1.0,1,H100,1697105236785,1697105239339.0,120,18.0,1.0,"[297, 2257]","[1697105237082, 1697105239339]"
3509,380,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105239340,1697105241993.0,120,,,[45],[1697105239385]
3510,840,40,[],200,EleutherAI/gpt-neox-20b,128,1,1680.0,1.0,1,H100,1697105262310,1697105263990.0,120,17.0,1.0,"[77, 1603]","[1697105262387, 1697105263990]"
3511,739,24,[],200,EleutherAI/gpt-neox-20b,128,1,1540.0,1.0,1,H100,1697105242014,1697105243554.0,120,216.0,1.0,"[270, 1270]","[1697105242284, 1697105243554]"
3512,438,26,[],200,EleutherAI/gpt-neox-20b,128,1,1554.0,1.0,1,H100,1697105242000,1697105243554.0,120,9.0,1.0,"[23, 1530]","[1697105242023, 1697105243553]"
3513,135,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243555,1697105245502.0,120,,,[28],[1697105243583]
3514,450,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228257,1697105232145.0,120,,,"[25, 2234, 990, 75, 75, 74, 73]","[1697105228282, 1697105230516, 1697105231506, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
3515,415,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105224662,1697105228773.0,120,,,"[41, 1549, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105224703, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
3516,496,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105248695.0,120,,,[202],[1697105245708]
3517,855,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248698,1697105250348.0,120,,,[91],[1697105248789]
3518,767,27,[],200,EleutherAI/gpt-neox-20b,128,1,922.0,1.0,1,H100,1697105243555,1697105244477.0,120,11.0,1.0,"[36, 886]","[1697105243591, 1697105244477]"
3519,288,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252038.0,120,,,[166],[1697105250517]
3520,734,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252042,1697105253712.0,120,,,[277],[1697105252319]
3521,159,30,[],200,EleutherAI/gpt-neox-20b,128,1,2228.0,1.0,1,H100,1697105253716,1697105255944.0,120,31.0,1.0,"[268, 1960]","[1697105253984, 1697105255944]"
3522,517,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255948,1697105257115.0,120,,,[27],[1697105255975]
3523,873,32,[],200,EleutherAI/gpt-neox-20b,128,1,1734.0,1.0,1,H100,1697105257116,1697105258850.0,120,6.0,1.0,"[19, 1715]","[1697105257135, 1697105258850]"
3524,197,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105244478,1697105247242.0,120,,,[5],[1697105244483]
3525,304,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258851,1697105260463.0,120,,,[17],[1697105258868]
3526,633,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260468,1697105262307.0,120,,,[301],[1697105260769]
3527,67,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262322,1697105265927.0,120,,,[294],[1697105262616]
3528,559,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247246,1697105248696.0,120,,,[36],[1697105247282]
3529,780,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230475.0,120,,,[137],[1697105228918]
3530,208,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230477,1697105232146.0,120,,,"[5, 1023, 76, 75, 74, 73]","[1697105230482, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
3531,806,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232151,1697105234225.0,120,,,[120],[1697105232271]
3532,231,19,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105234226,1697105236002.0,120,13.0,1.0,"[32, 1744]","[1697105234258, 1697105236002]"
3533,561,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236003,1697105238408.0,120,,,[15],[1697105236018]
3534,539,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233608.0,120,,,[36],[1697105232186]
3535,198,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105232146.0,120,,,[106],[1697105230584]
3536,528,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232153,1697105234225.0,120,,,[154],[1697105232307]
3537,888,20,[],200,EleutherAI/gpt-neox-20b,128,1,1775.0,1.0,1,H100,1697105234227,1697105236002.0,120,19.0,1.0,"[72, 1703]","[1697105234299, 1697105236002]"
3538,314,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236003,1697105238408.0,120,,,[15],[1697105236018]
3539,83,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105231307,1697105234919.0,120,,,"[13, 1736, 600, 617]","[1697105231320, 1697105233056, 1697105233656, 1697105234273]"
3540,673,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238411,1697105240330.0,120,,,[100],[1697105238511]
3541,101,23,[],200,EleutherAI/gpt-neox-20b,128,1,1596.0,1.0,1,H100,1697105240334,1697105241930.0,120,13.0,1.0,"[65, 1531]","[1697105240399, 1697105241930]"
3542,544,24,[],200,EleutherAI/gpt-neox-20b,128,1,759.0,1.0,1,H100,1697105241932,1697105242691.0,120,26.0,1.0,"[40, 719]","[1697105241972, 1697105242691]"
3543,444,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236782.0,120,,,[85],[1697105235007]
3544,906,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242692,1697105245502.0,120,,,[20],[1697105242712]
3545,802,17,[],200,EleutherAI/gpt-neox-20b,128,1,1599.0,1.0,1,H100,1697105236786,1697105238385.0,120,9.0,1.0,"[120, 1479]","[1697105236906, 1697105238385]"
3546,651,15,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105220998,1697105222667.0,120,457.0,2.0,"[82, 1587]","[1697105221080, 1697105222667]"
3547,334,26,[],200,EleutherAI/gpt-neox-20b,128,1,1662.0,1.0,1,H100,1697105245506,1697105247168.0,120,15.0,1.0,"[33, 1629]","[1697105245539, 1697105247168]"
3548,759,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228257,1697105232145.0,120,,,"[8, 2250, 990, 76, 75, 74, 73]","[1697105228265, 1697105230515, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
3549,242,13,[],200,EleutherAI/gpt-neox-20b,128,1,3258.0,1.0,1,H100,1697105220998,1697105224256.0,120,345.0,9.0,"[102, 2303, 71, 92, 87, 86, 85, 81, 351]","[1697105221100, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256]"
3550,694,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247170,1697105248696.0,120,,,[28],[1697105247198]
3551,316,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243756,1697105245502.0,120,,,[32],[1697105243788]
3552,121,28,[],200,EleutherAI/gpt-neox-20b,128,1,2484.0,1.0,1,H100,1697105248700,1697105251184.0,120,13.0,1.0,"[201, 2283]","[1697105248901, 1697105251184]"
3553,602,14,[],200,EleutherAI/gpt-neox-20b,128,1,887.0,1.0,1,H100,1697105224257,1697105225144.0,120,15.0,1.0,"[5, 882]","[1697105224262, 1697105225144]"
3554,675,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245505,1697105247243.0,120,,,[163],[1697105245668]
3555,184,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233609.0,120,,,[52],[1697105232202]
3556,540,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233610,1697105234919.0,120,,,[36],[1697105233646]
3557,104,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247248,1697105248696.0,120,,,[151],[1697105247399]
3558,868,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236782.0,120,,,[85],[1697105235007]
3559,272,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226494,1697105228773.0,120,,,[4],[1697105226498]
3560,30,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225145,1697105228773.0,120,,,"[21, 1897, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105225166, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
3561,299,24,[],200,EleutherAI/gpt-neox-20b,128,1,2554.0,1.0,1,H100,1697105236785,1697105239339.0,120,14.0,1.0,"[290, 2264]","[1697105237075, 1697105239339]"
3562,877,7,[],200,EleutherAI/gpt-neox-20b,128,1,6283.0,1.0,1,H100,1697105185400,1697105191683.0,120,85.0,20.0,"[24, 3024, 94, 164, 81, 375, 87, 85, 481, 90, 272, 165, 250, 88, 251, 66, 87, 66, 367, 166]","[1697105185424, 1697105188448, 1697105188542, 1697105188706, 1697105188787, 1697105189162, 1697105189249, 1697105189334, 1697105189815, 1697105189905, 1697105190177, 1697105190342, 1697105190592, 1697105190680, 1697105190931, 1697105190997, 1697105191084, 1697105191150, 1697105191517, 1697105191683]"
3563,633,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230476.0,120,,,[96],[1697105228877]
3564,66,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105234919.0,120,,,"[131, 2447, 600, 617]","[1697105230609, 1697105233056, 1697105233656, 1697105234273]"
3565,663,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105239340,1697105241995.0,120,,,[33],[1697105239373]
3566,363,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228780,1697105230475.0,120,,,[21],[1697105228801]
3567,719,17,[],200,EleutherAI/gpt-neox-20b,128,1,1327.0,1.0,1,H100,1697105230477,1697105231804.0,120,182.0,6.0,"[21, 1007, 76, 75, 74, 73]","[1697105230498, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
3568,147,18,[],200,EleutherAI/gpt-neox-20b,128,1,1191.0,1.0,1,H100,1697105231804,1697105232995.0,120,182.0,1.0,"[9, 1182]","[1697105231813, 1697105232995]"
3569,91,26,[],200,EleutherAI/gpt-neox-20b,128,1,1553.0,1.0,1,H100,1697105242001,1697105243554.0,120,23.0,1.0,"[110, 1443]","[1697105242111, 1697105243554]"
3570,535,10,[],200,EleutherAI/gpt-neox-20b,128,1,4242.0,1.0,1,H100,1697105220998,1697105225240.0,120,84.0,20.0,"[94, 1575, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579]","[1697105221092, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239]"
3571,422,27,[],200,EleutherAI/gpt-neox-20b,128,1,921.0,1.0,1,H100,1697105243556,1697105244477.0,120,26.0,1.0,"[52, 869]","[1697105243608, 1697105244477]"
3572,512,18,[],200,EleutherAI/gpt-neox-20b,128,1,2972.0,1.0,1,H100,1697105234923,1697105237895.0,120,11.0,1.0,"[253, 2719]","[1697105235176, 1697105237895]"
3573,865,19,[],200,EleutherAI/gpt-neox-20b,128,1,1443.0,1.0,1,H100,1697105237896,1697105239339.0,120,9.0,1.0,"[17, 1425]","[1697105237913, 1697105239338]"
3574,290,20,[],200,EleutherAI/gpt-neox-20b,128,1,1865.0,1.0,1,H100,1697105239340,1697105241205.0,120,14.0,1.0,"[29, 1836]","[1697105239369, 1697105241205]"
3575,776,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105244478,1697105247242.0,120,,,[13],[1697105244491]
3576,501,19,[],200,EleutherAI/gpt-neox-20b,128,1,1886.0,1.0,1,H100,1697105232996,1697105234882.0,120,19.0,1.0,"[12, 1874]","[1697105233008, 1697105234882]"
3577,863,20,[],200,EleutherAI/gpt-neox-20b,128,1,1119.0,1.0,1,H100,1697105234883,1697105236002.0,120,10.0,1.0,"[21, 1098]","[1697105234904, 1697105236002]"
3578,201,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248696.0,120,,,[26],[1697105247273]
3579,263,21,[],200,EleutherAI/gpt-neox-20b,128,1,1889.0,1.0,1,H100,1697105236006,1697105237895.0,120,15.0,1.0,"[22, 1867]","[1697105236028, 1697105237895]"
3580,200,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265864,1697105267796.0,120,,,[9],[1697105265873]
3581,245,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105238409.0,120,,,[126],[1697105236910]
3582,879,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243754.0,120,,,[106],[1697105242107]
3583,305,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243758,1697105247242.0,120,,,[234],[1697105243992]
3584,560,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248700,1697105252036.0,120,,,[210],[1697105248910]
3585,921,31,[],200,EleutherAI/gpt-neox-20b,128,1,1640.0,1.0,1,H100,1697105252042,1697105253682.0,120,31.0,1.0,"[281, 1359]","[1697105252323, 1697105253682]"
3586,646,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105269598.0,120,,,[179],[1697105267980]
3587,622,22,[],200,EleutherAI/gpt-neox-20b,128,1,1443.0,1.0,1,H100,1697105237896,1697105239339.0,120,20.0,1.0,"[17, 1426]","[1697105237913, 1697105239339]"
3588,601,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238412,1697105240331.0,120,,,[167],[1697105238579]
3589,26,24,[],200,EleutherAI/gpt-neox-20b,128,1,1596.0,1.0,1,H100,1697105240334,1697105241930.0,120,18.0,1.0,"[246, 1350]","[1697105240580, 1697105241930]"
3590,71,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[80],[1697105269680]
3591,55,23,[],200,EleutherAI/gpt-neox-20b,128,1,1865.0,1.0,1,H100,1697105239340,1697105241205.0,120,12.0,1.0,"[37, 1828]","[1697105239377, 1697105241205]"
3592,409,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241206,1697105243753.0,120,,,[21],[1697105241227]
3593,384,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241932,1697105243754.0,120,,,[16],[1697105241948]
3594,584,8,[],200,EleutherAI/gpt-neox-20b,128,1,1977.0,1.0,1,H100,1697105201003,1697105202980.0,120,10.0,1.0,"[5, 1972]","[1697105201008, 1697105202980]"
3595,659,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247251,1697105250347.0,120,,,[228],[1697105247479]
3596,699,21,[],200,EleutherAI/gpt-neox-20b,128,1,1395.0,1.0,1,H100,1697105228257,1697105229652.0,120,39.0,1.0,"[32, 1363]","[1697105228289, 1697105229652]"
3597,12,9,[],200,EleutherAI/gpt-neox-20b,128,1,1756.0,1.0,1,H100,1697105202981,1697105204737.0,120,11.0,1.0,"[21, 1735]","[1697105203002, 1697105204737]"
3598,855,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243758,1697105245502.0,120,,,[231],[1697105243989]
3599,100,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105229653,1697105232146.0,120,,,"[24, 1828, 76, 75, 74, 73]","[1697105229677, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
3600,371,10,[],200,EleutherAI/gpt-neox-20b,128,1,1976.0,1.0,1,H100,1697105204738,1697105206714.0,120,13.0,1.0,"[12, 1964]","[1697105204750, 1697105206714]"
3601,280,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245504,1697105247243.0,120,,,[96],[1697105245600]
3602,743,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243756,1697105245502.0,120,,,[51],[1697105243807]
3603,638,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247250,1697105250347.0,120,,,[237],[1697105247487]
3604,895,11,[],200,EleutherAI/gpt-neox-20b,128,1,2467.0,1.0,1,H100,1697105225241,1697105227708.0,120,15.0,1.0,"[32, 2435]","[1697105225273, 1697105227708]"
3605,319,12,[],200,EleutherAI/gpt-neox-20b,128,1,1942.0,1.0,1,H100,1697105227710,1697105229652.0,120,31.0,1.0,"[20, 1921]","[1697105227730, 1697105229651]"
3606,71,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250350,1697105252036.0,120,,,[38],[1697105250388]
3607,729,11,[],200,EleutherAI/gpt-neox-20b,128,1,2011.0,1.0,1,H100,1697105206715,1697105208726.0,120,874.0,2.0,"[17, 1994]","[1697105206732, 1697105208726]"
3608,857,20,[],200,EleutherAI/gpt-neox-20b,128,1,1809.0,1.0,1,H100,1697105225145,1697105226954.0,120,18.0,1.0,"[37, 1772]","[1697105225182, 1697105226954]"
3609,150,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245505,1697105247242.0,120,,,[10],[1697105245515]
3610,286,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226955,1697105228774.0,120,,,[32],[1697105226987]
3611,647,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228782,1697105230475.0,120,,,[187],[1697105228969]
3612,156,12,[],200,EleutherAI/gpt-neox-20b,128,1,5445.0,1.0,1,H100,1697105208727,1697105214172.0,120,86.0,20.0,"[4, 2583, 168, 77, 456, 89, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68]","[1697105208731, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171]"
3613,432,29,[],200,EleutherAI/gpt-neox-20b,128,1,1641.0,1.0,1,H100,1697105252041,1697105253682.0,120,13.0,1.0,"[40, 1600]","[1697105252081, 1697105253681]"
3614,279,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238385,1697105240331.0,120,,,[5],[1697105238390]
3615,763,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253685,1697105255027.0,120,,,[28],[1697105253713]
3616,77,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105232146.0,120,,,[94],[1697105230572]
3617,630,25,[],200,EleutherAI/gpt-neox-20b,128,1,1596.0,1.0,1,H100,1697105240334,1697105241930.0,120,6.0,1.0,"[141, 1455]","[1697105240475, 1697105241930]"
3618,410,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232153,1697105234225.0,120,,,[166],[1697105232319]
3619,716,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105227329,1697105228774.0,120,,,[5],[1697105227334]
3620,145,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228783,1697105230476.0,120,,,[223],[1697105229006]
3621,755,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105252036.0,120,,,[182],[1697105248881]
3622,121,19,[],200,EleutherAI/gpt-neox-20b,128,1,2387.0,1.0,1,H100,1697105222757,1697105225144.0,120,13.0,1.0,"[7, 2380]","[1697105222764, 1697105225144]"
3623,502,18,[],200,EleutherAI/gpt-neox-20b,128,1,2517.0,1.0,1,H100,1697105230478,1697105232995.0,120,19.0,1.0,"[199, 2318]","[1697105230677, 1697105232995]"
3624,737,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243757,1697105245501.0,120,,,"[7, 1662]","[1697105243764, 1697105245426]"
3625,188,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255029,1697105257114.0,120,,,[37],[1697105255066]
3626,792,14,[],200,EleutherAI/gpt-neox-20b,128,1,529.0,1.0,1,H100,1697105212265,1697105212794.0,120,11.0,1.0,"[12, 517]","[1697105212277, 1697105212794]"
3627,166,26,[],200,EleutherAI/gpt-neox-20b,128,1,1664.0,1.0,1,H100,1697105245504,1697105247168.0,120,14.0,1.0,"[100, 1564]","[1697105245604, 1697105247168]"
3628,480,20,[],200,EleutherAI/gpt-neox-20b,128,1,1809.0,1.0,1,H100,1697105225145,1697105226954.0,120,26.0,1.0,"[45, 1764]","[1697105225190, 1697105226954]"
3629,151,29,[],200,EleutherAI/gpt-neox-20b,128,1,1641.0,1.0,1,H100,1697105252041,1697105253682.0,120,39.0,1.0,"[36, 1604]","[1697105252077, 1697105253681]"
3630,220,15,[],200,EleutherAI/gpt-neox-20b,128,1,2499.0,1.0,1,H100,1697105212795,1697105215294.0,120,67.0,2.0,"[5, 2494]","[1697105212800, 1697105215294]"
3631,527,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247169,1697105248696.0,120,,,[17],[1697105247186]
3632,889,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105252036.0,120,,,[210],[1697105248909]
3633,510,30,[],200,EleutherAI/gpt-neox-20b,128,1,1373.0,1.0,1,H100,1697105253685,1697105255058.0,120,79.0,2.0,"[16, 1357]","[1697105253701, 1697105255058]"
3634,574,16,[],200,EleutherAI/gpt-neox-20b,128,1,3152.0,1.0,1,H100,1697105215295,1697105218447.0,120,364.0,2.0,"[9, 3143]","[1697105215304, 1697105218447]"
3635,290,29,[],200,EleutherAI/gpt-neox-20b,128,1,1641.0,1.0,1,H100,1697105252041,1697105253682.0,120,14.0,1.0,"[73, 1568]","[1697105252114, 1697105253682]"
3636,648,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253685,1697105255027.0,120,,,[31],[1697105253716]
3637,541,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258907.0,120,,,[6],[1697105257123]
3638,901,33,[],200,EleutherAI/gpt-neox-20b,128,1,1522.0,1.0,1,H100,1697105258916,1697105260438.0,120,17.0,1.0,"[85, 1436]","[1697105259001, 1697105260437]"
3639,330,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260439,1697105262307.0,120,,,[8],[1697105260447]
3640,871,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255059,1697105257114.0,120,,,[148],[1697105255207]
3641,69,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255029,1697105257113.0,120,,,[30],[1697105255059]
3642,303,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105260463.0,120,,,[182],[1697105257300]
3643,428,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258907.0,120,,,"[22, 1711]","[1697105257139, 1697105258850]"
3644,786,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258914,1697105260463.0,120,,,[14],[1697105258928]
3645,833,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226955,1697105228774.0,120,,,[16],[1697105226971]
3646,192,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260467,1697105262307.0,120,,,[214],[1697105260681]
3647,258,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228783,1697105230476.0,120,,,[291],[1697105229074]
3648,552,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262314,1697105264082.0,120,,,[278],[1697105262592]
3649,704,23,[],200,EleutherAI/gpt-neox-20b,128,1,1647.0,1.0,1,H100,1697105230478,1697105232125.0,120,14.0,1.0,"[119, 1528]","[1697105230597, 1697105232125]"
3650,633,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260467,1697105262307.0,120,,,[230],[1697105260697]
3651,133,24,[],200,EleutherAI/gpt-neox-20b,128,1,869.0,1.0,1,H100,1697105232126,1697105232995.0,120,15.0,1.0,"[9, 860]","[1697105232135, 1697105232995]"
3652,909,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265927.0,120,,,[51],[1697105264136]
3653,498,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232996,1697105234225.0,120,,,[16],[1697105233012]
3654,665,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262314,1697105264082.0,120,,,[198],[1697105262512]
3655,58,34,[],200,EleutherAI/gpt-neox-20b,128,1,1677.0,1.0,1,H100,1697105262313,1697105263990.0,120,15.0,1.0,"[183, 1494]","[1697105262496, 1697105263990]"
3656,95,36,[],200,EleutherAI/gpt-neox-20b,128,1,1779.0,1.0,1,H100,1697105264085,1697105265864.0,120,12.0,1.0,"[103, 1675]","[1697105264188, 1697105265863]"
3657,339,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267796.0,120,,,[62],[1697105265993]
3658,858,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234227,1697105236780.0,120,,,[72],[1697105234299]
3659,690,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105270302.0,120,,,[188],[1697105267989]
3660,1,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105218448,1697105220995.0,120,,,[17],[1697105218465]
3661,206,39,[],200,EleutherAI/gpt-neox-20b,128,1,1637.0,1.0,1,H100,1697105270308,1697105271945.0,120,16.0,1.0,"[32, 1605]","[1697105270340, 1697105271945]"
3662,565,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271946,1697105273585.0,120,,,[17],[1697105271963]
3663,926,41,[],200,EleutherAI/gpt-neox-20b,128,1,3264.0,1.0,1,H100,1697105273589,1697105276853.0,120,563.0,30.0,"[213, 2142, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 33, 32, 32, 33, 29, 28, 28, 28, 32, 27, 27, 27, 28]","[1697105273802, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276502, 1697105276534, 1697105276566, 1697105276599, 1697105276628, 1697105276656, 1697105276684, 1697105276712, 1697105276744, 1697105276771, 1697105276798, 1697105276825, 1697105276853]"
3664,505,18,[],200,EleutherAI/gpt-neox-20b,128,1,5915.0,1.0,1,H100,1697105220428,1697105226343.0,120,100.0,27.0,"[6, 1532, 701, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579, 82, 77, 75, 73, 706, 91]","[1697105220434, 1697105221966, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225546, 1697105226252, 1697105226343]"
3665,300,31,[],200,EleutherAI/gpt-neox-20b,128,1,2980.0,1.0,1,H100,1697105265935,1697105268915.0,120,9.0,1.0,"[179, 2801]","[1697105266114, 1697105268915]"
3666,145,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265934,1697105271973.0,120,,,"[164, 2880, 669, 704, 685]","[1697105266098, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
3667,508,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271978,1697105275207.0,120,,,[241],[1697105272219]
3668,584,7,[],200,EleutherAI/gpt-neox-20b,128,1,1624.0,1.0,1,H100,1697105202002,1697105203626.0,120,10.0,1.0,"[37, 1587]","[1697105202039, 1697105203626]"
3669,699,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228780,1697105230475.0,120,,,[25],[1697105228805]
3670,629,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268918,1697105270302.0,120,,,[35],[1697105268953]
3671,257,26,[],200,EleutherAI/gpt-neox-20b,128,1,1855.0,1.0,1,H100,1697105238411,1697105240266.0,120,14.0,1.0,"[76, 1778]","[1697105238487, 1697105240265]"
3672,13,8,[],200,EleutherAI/gpt-neox-20b,128,1,5811.0,1.0,1,H100,1697105203627,1697105209438.0,120,90.0,20.0,"[32, 3154, 90, 89, 86, 80, 80, 60, 61, 618, 86, 83, 82, 64, 434, 87, 84, 79, 77, 385]","[1697105203659, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438]"
3673,203,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238386,1697105240331.0,120,,,[16],[1697105238402]
3674,100,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105232146.0,120,,,[110],[1697105230588]
3675,148,26,[],200,EleutherAI/gpt-neox-20b,128,1,2485.0,1.0,1,H100,1697105248699,1697105251184.0,120,16.0,1.0,"[98, 2387]","[1697105248797, 1697105251184]"
3676,502,27,[],200,EleutherAI/gpt-neox-20b,128,1,1379.0,1.0,1,H100,1697105251185,1697105252564.0,120,19.0,1.0,"[9, 1370]","[1697105251194, 1697105252564]"
3677,861,28,[],200,EleutherAI/gpt-neox-20b,128,1,1506.0,1.0,1,H100,1697105252565,1697105254071.0,120,10.0,1.0,"[5, 1501]","[1697105252570, 1697105254071]"
3678,286,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105254072,1697105256009.0,120,,,[8],[1697105254080]
3679,617,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256011,1697105258907.0,120,,,[11],[1697105256022]
3680,585,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240267,1697105241994.0,120,,,[52],[1697105240319]
3681,49,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258916,1697105260462.0,120,,,[73],[1697105258989]
3682,410,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260464,1697105262306.0,120,,,[36],[1697105260500]
3683,458,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232153,1697105234225.0,120,,,[226],[1697105232379]
3684,769,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262310,1697105264083.0,120,,,[81],[1697105262391]
3685,819,23,[],200,EleutherAI/gpt-neox-20b,128,1,1775.0,1.0,1,H100,1697105234227,1697105236002.0,120,13.0,1.0,"[60, 1715]","[1697105234287, 1697105236002]"
3686,164,34,[],200,EleutherAI/gpt-neox-20b,128,1,3099.0,1.0,1,H100,1697105264087,1697105267186.0,120,15.0,1.0,"[228, 2871]","[1697105264315, 1697105267186]"
3687,519,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267187,1697105271972.0,120,,,"[4, 1787, 669, 704, 685]","[1697105267191, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
3688,15,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243754.0,120,,,[114],[1697105242115]
3689,55,33,[],200,EleutherAI/gpt-neox-20b,128,1,1636.0,1.0,1,H100,1697105270309,1697105271945.0,120,12.0,1.0,"[88, 1548]","[1697105270397, 1697105271945]"
3690,366,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243758,1697105245501.0,120,,,[154],[1697105243912]
3691,409,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271946,1697105273585.0,120,,,[13],[1697105271959]
3692,245,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236005,1697105238408.0,120,,,[23],[1697105236028]
3693,723,30,[],200,EleutherAI/gpt-neox-20b,128,1,1664.0,1.0,1,H100,1697105245504,1697105247168.0,120,14.0,1.0,"[84, 1580]","[1697105245588, 1697105247168]"
3694,550,17,[],200,EleutherAI/gpt-neox-20b,128,1,4774.0,1.0,1,H100,1697105219886,1697105224660.0,120,91.0,20.0,"[5, 2074, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105219891, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
3695,878,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271976,1697105273585.0,120,,,[114],[1697105272090]
3696,767,35,[],200,EleutherAI/gpt-neox-20b,128,1,2308.0,1.0,1,H100,1697105273590,1697105275898.0,120,11.0,1.0,"[284, 2024]","[1697105273874, 1697105275898]"
3697,307,37,[],200,EleutherAI/gpt-neox-20b,128,1,2309.0,1.0,1,H100,1697105273589,1697105275898.0,120,26.0,1.0,"[210, 2099]","[1697105273799, 1697105275898]"
3698,574,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238410,1697105240330.0,120,,,[12],[1697105238422]
3699,154,31,[],200,EleutherAI/gpt-neox-20b,128,1,839.0,1.0,1,H100,1697105247170,1697105248009.0,120,13.0,1.0,"[32, 807]","[1697105247202, 1697105248009]"
3700,4,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240332,1697105243753.0,120,,,[263],[1697105240595]
3701,486,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248011,1697105250348.0,120,,,[28],[1697105248039]
3702,362,27,[],200,EleutherAI/gpt-neox-20b,128,1,1670.0,1.0,1,H100,1697105243757,1697105245427.0,120,14.0,1.0,"[118, 1552]","[1697105243875, 1697105245427]"
3703,849,33,[],200,EleutherAI/gpt-neox-20b,128,1,1660.0,1.0,1,H100,1697105250351,1697105252011.0,120,10.0,1.0,"[130, 1530]","[1697105250481, 1697105252011]"
3704,450,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105251186,1697105253710.0,120,,,[12],[1697105251198]
3705,278,34,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105252013,1697105253682.0,120,13.0,1.0,"[40, 1628]","[1697105252053, 1697105253681]"
3706,719,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245428,1697105247242.0,120,,,[25],[1697105245453]
3707,150,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248695.0,120,,,[55],[1697105247302]
3708,454,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105250347.0,120,,,[14],[1697105248713]
3709,784,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250350,1697105252036.0,120,,,[31],[1697105250381]
3710,631,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253686,1697105255027.0,120,,,[44],[1697105253730]
3711,57,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255029,1697105257114.0,120,,,[45],[1697105255074]
3712,213,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253712.0,120,,,[16],[1697105252057]
3713,809,30,[],200,EleutherAI/gpt-neox-20b,128,1,2228.0,1.0,1,H100,1697105253716,1697105255944.0,120,16.0,1.0,"[206, 2022]","[1697105253922, 1697105255944]"
3714,480,47,[],200,EleutherAI/gpt-neox-20b,128,1,1543.0,1.0,1,H100,1697105273589,1697105275132.0,120,26.0,1.0,"[181, 1362]","[1697105273770, 1697105275132]"
3715,574,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253715,1697105255028.0,120,,,[179],[1697105253894]
3716,8,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[161],[1697105255191]
3717,909,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105224662,1697105228773.0,120,,,"[33, 1557, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105224695, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
3718,502,37,[],200,EleutherAI/gpt-neox-20b,128,1,1733.0,1.0,1,H100,1697105257117,1697105258850.0,120,19.0,1.0,"[62, 1671]","[1697105257179, 1697105258850]"
3719,598,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248698,1697105250347.0,120,,,[6],[1697105248704]
3720,864,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258851,1697105260463.0,120,,,[5],[1697105258856]
3721,414,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242000,1697105243754.0,120,,,[172],[1697105242172]
3722,294,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260466,1697105262306.0,120,,,[126],[1697105260592]
3723,23,31,[],200,EleutherAI/gpt-neox-20b,128,1,1660.0,1.0,1,H100,1697105250351,1697105252011.0,120,26.0,1.0,"[66, 1594]","[1697105250417, 1697105252011]"
3724,238,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255945,1697105257114.0,120,,,[6],[1697105255951]
3725,382,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252012,1697105253711.0,120,,,[17],[1697105252029]
3726,597,32,[],200,EleutherAI/gpt-neox-20b,128,1,2654.0,1.0,1,H100,1697105257118,1697105259772.0,120,39.0,1.0,"[198, 2456]","[1697105257316, 1697105259772]"
3727,773,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243758,1697105245501.0,120,,,[150],[1697105243908]
3728,308,17,[],200,EleutherAI/gpt-neox-20b,128,1,4242.0,1.0,1,H100,1697105220998,1697105225240.0,120,87.0,20.0,"[98, 1571, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579]","[1697105221096, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239]"
3729,655,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262312,1697105264083.0,120,,,[171],[1697105262483]
3730,926,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105259773,1697105262306.0,120,,,[4],[1697105259777]
3731,80,41,[],200,EleutherAI/gpt-neox-20b,128,1,1777.0,1.0,1,H100,1697105264086,1697105265863.0,120,13.0,1.0,"[127, 1650]","[1697105264213, 1697105265863]"
3732,351,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262309,1697105264082.0,120,,,[6],[1697105262315]
3733,410,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265864,1697105267796.0,120,,,[13],[1697105265877]
3734,342,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230475.0,120,,,[32],[1697105228813]
3735,714,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265928.0,120,,,[39],[1697105264124]
3736,671,18,[],200,EleutherAI/gpt-neox-20b,128,1,2467.0,1.0,1,H100,1697105225241,1697105227708.0,120,12.0,1.0,"[40, 2427]","[1697105225281, 1697105227708]"
3737,142,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265935,1697105271972.0,120,,,"[259, 2784, 669, 704, 685]","[1697105266194, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
3738,676,20,[],200,EleutherAI/gpt-neox-20b,128,1,1647.0,1.0,1,H100,1697105230478,1697105232125.0,120,19.0,1.0,"[90, 1557]","[1697105230568, 1697105232125]"
3739,104,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232126,1697105234919.0,120,,,"[13, 917, 600, 617]","[1697105232139, 1697105233056, 1697105233656, 1697105234273]"
3740,503,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271975,1697105273584.0,120,,,[27],[1697105272002]
3741,458,22,[],200,EleutherAI/gpt-neox-20b,128,1,2973.0,1.0,1,H100,1697105234922,1697105237895.0,120,11.0,1.0,"[246, 2727]","[1697105235168, 1697105237895]"
3742,768,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267799,1697105269598.0,120,,,[101],[1697105267900]
3743,830,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273588,1697105275208.0,120,,,[102],[1697105273690]
3744,818,23,[],200,EleutherAI/gpt-neox-20b,128,1,1443.0,1.0,1,H100,1697105237896,1697105239339.0,120,13.0,1.0,"[20, 1423]","[1697105237916, 1697105239339]"
3745,242,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105239340,1697105241995.0,120,,,[15],[1697105239355]
3746,70,19,[],200,EleutherAI/gpt-neox-20b,128,1,1942.0,1.0,1,H100,1697105227710,1697105229652.0,120,39.0,1.0,"[24, 1917]","[1697105227734, 1697105229651]"
3747,194,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[52],[1697105269652]
3748,555,45,[],200,EleutherAI/gpt-neox-20b,128,1,1758.0,1.0,1,H100,1697105270990,1697105272748.0,120,11.0,1.0,"[52, 1706]","[1697105271042, 1697105272748]"
3749,323,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253687,1697105255028.0,120,,,[99],[1697105253786]
3750,884,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105272749,1697105275207.0,120,,,[5],[1697105272754]
3751,424,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105229653,1697105232145.0,120,,,"[8, 1844, 76, 75, 74, 73]","[1697105229661, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
3752,574,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242002,1697105243753.0,120,,,[85],[1697105242087]
3753,4,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243757,1697105245502.0,120,,,[122],[1697105243879]
3754,425,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270989,1697105273585.0,120,,,[45],[1697105271034]
3755,784,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273587,1697105275208.0,120,,,[35],[1697105273622]
3756,683,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[149],[1697105255179]
3757,779,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233609.0,120,,,[16],[1697105232166]
3758,279,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263991,1697105265928.0,120,,,[53],[1697105264044]
3759,366,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105247242.0,120,,,[25],[1697105245531]
3760,488,15,[],200,EleutherAI/gpt-neox-20b,128,1,1575.0,1.0,1,H100,1697105220998,1697105222573.0,120,6.0,1.0,"[14, 1561]","[1697105221012, 1697105222573]"
3761,640,36,[],200,EleutherAI/gpt-neox-20b,128,1,2980.0,1.0,1,H100,1697105265935,1697105268915.0,120,15.0,1.0,"[251, 2729]","[1697105266186, 1697105268915]"
3762,208,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233610,1697105234919.0,120,,,[28],[1697105233638]
3763,720,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248695.0,120,,,[43],[1697105247290]
3764,881,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260467,1697105262307.0,120,,,[201],[1697105260668]
3765,462,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232153,1697105234225.0,120,,,[234],[1697105232387]
3766,395,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228775,1697105230475.0,120,,,[11],[1697105228786]
3767,754,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230477,1697105232146.0,120,,,"[13, 1015, 76, 75, 74, 73]","[1697105230490, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
3768,824,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234227,1697105236782.0,120,,,[48],[1697105234275]
3769,498,26,[],200,EleutherAI/gpt-neox-20b,128,1,1596.0,1.0,1,H100,1697105240334,1697105241930.0,120,9.0,1.0,"[73, 1523]","[1697105240407, 1697105241930]"
3770,311,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262312,1697105264083.0,120,,,[172],[1697105262484]
3771,531,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228782,1697105230475.0,120,,,[207],[1697105228989]
3772,852,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241932,1697105243754.0,120,,,[20],[1697105241952]
3773,474,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226253,1697105228773.0,120,,,[5],[1697105226258]
3774,287,28,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105243758,1697105245427.0,120,10.0,1.0,"[227, 1442]","[1697105243985, 1697105245427]"
3775,846,13,[],200,EleutherAI/gpt-neox-20b,128,1,1742.0,1.0,1,H100,1697105211483,1697105213225.0,120,140.0,6.0,"[5, 1403, 88, 89, 82, 75]","[1697105211488, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225]"
3776,890,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105232146.0,120,,,[98],[1697105230576]
3777,318,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232153,1697105234225.0,120,,,[214],[1697105232367]
3778,239,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263991,1697105265927.0,120,,,[29],[1697105264020]
3779,828,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228782,1697105230475.0,120,,,[204],[1697105228986]
3780,359,18,[],200,EleutherAI/gpt-neox-20b,128,1,2312.0,1.0,1,H100,1697105220998,1697105223310.0,120,10.0,1.0,"[187, 2125]","[1697105221185, 1697105223310]"
3781,227,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105234919.0,120,,,"[115, 2463, 600, 617]","[1697105230593, 1697105233056, 1697105233656, 1697105234273]"
3782,674,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234227,1697105236780.0,120,,,[68],[1697105234295]
3783,271,14,[],200,EleutherAI/gpt-neox-20b,128,1,5668.0,1.0,1,H100,1697105213226,1697105218894.0,120,87.0,20.0,"[17, 2492, 91, 83, 510, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 88, 81, 257, 78, 368]","[1697105213243, 1697105215735, 1697105215826, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218110, 1697105218191, 1697105218448, 1697105218526, 1697105218894]"
3784,99,21,[],200,EleutherAI/gpt-neox-20b,128,1,1601.0,1.0,1,H100,1697105236784,1697105238385.0,120,10.0,1.0,"[30, 1571]","[1697105236814, 1697105238385]"
3785,428,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238386,1697105240331.0,120,,,"[4, 949]","[1697105238390, 1697105239339]"
3786,187,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232152,1697105234225.0,120,,,[151],[1697105232303]
3787,787,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241993.0,120,,,[145],[1697105240479]
3788,542,22,[],200,EleutherAI/gpt-neox-20b,128,1,1775.0,1.0,1,H100,1697105234227,1697105236002.0,120,11.0,1.0,"[76, 1699]","[1697105234303, 1697105236002]"
3789,223,24,[],200,EleutherAI/gpt-neox-20b,128,1,1553.0,1.0,1,H100,1697105242001,1697105243554.0,120,16.0,1.0,"[223, 1330]","[1697105242224, 1697105243554]"
3790,871,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236006,1697105238408.0,120,,,[26],[1697105236032]
3791,691,19,[],200,EleutherAI/gpt-neox-20b,128,1,1833.0,1.0,1,H100,1697105223311,1697105225144.0,120,47.0,1.0,"[21, 1812]","[1697105223332, 1697105225144]"
3792,580,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243555,1697105245502.0,120,,,[28],[1697105243583]
3793,922,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105252036.0,120,,,[198],[1697105248897]
3794,583,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236780.0,120,,,[157],[1697105235079]
3795,296,24,[],200,EleutherAI/gpt-neox-20b,128,1,1853.0,1.0,1,H100,1697105238412,1697105240265.0,120,6.0,1.0,"[167, 1686]","[1697105238579, 1697105240265]"
3796,15,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236783,1697105238408.0,120,,,[87],[1697105236870]
3797,22,12,[],200,EleutherAI/gpt-neox-20b,128,1,2790.0,1.0,1,H100,1697105195157,1697105197947.0,120,16.0,1.0,"[16, 2774]","[1697105195173, 1697105197947]"
3798,599,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265933,1697105267796.0,120,,,[84],[1697105266017]
3799,468,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105197948,1697105201998.0,120,,,"[8, 2879, 87, 80, 292, 160, 212]","[1697105197956, 1697105200835, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
3800,372,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238412,1697105240330.0,120,,,[83],[1697105238495]
3801,24,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267797,1697105269598.0,120,,,[83],[1697105267880]
3802,919,21,[],200,EleutherAI/gpt-neox-20b,128,1,1854.0,1.0,1,H100,1697105238411,1697105240265.0,120,14.0,1.0,"[27, 1827]","[1697105238438, 1697105240265]"
3803,706,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241995.0,120,,,[77],[1697105240411]
3804,131,23,[],200,EleutherAI/gpt-neox-20b,128,1,1553.0,1.0,1,H100,1697105242001,1697105243554.0,120,8.0,1.0,"[178, 1375]","[1697105242179, 1697105243554]"
3805,491,24,[],200,EleutherAI/gpt-neox-20b,128,1,922.0,1.0,1,H100,1697105243555,1697105244477.0,120,14.0,1.0,"[24, 898]","[1697105243579, 1697105244477]"
3806,355,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240267,1697105241993.0,120,,,[16],[1697105240283]
3807,848,25,[],200,EleutherAI/gpt-neox-20b,128,1,1718.0,1.0,1,H100,1697105244478,1697105246196.0,120,47.0,1.0,"[21, 1697]","[1697105244499, 1697105246196]"
3808,826,14,[],200,EleutherAI/gpt-neox-20b,128,1,4080.0,1.0,1,H100,1697105202002,1697105206082.0,120,87.0,20.0,"[33, 1683, 88, 88, 87, 269, 87, 86, 84, 415, 93, 88, 89, 68, 87, 86, 389, 91, 85, 84]","[1697105202035, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205015, 1697105205103, 1697105205192, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082]"
3809,568,15,[],200,EleutherAI/gpt-neox-20b,128,1,2502.0,1.0,1,H100,1697105219401,1697105221903.0,120,11.0,1.0,"[12, 2490]","[1697105219413, 1697105221903]"
3810,277,26,[],200,EleutherAI/gpt-neox-20b,128,1,1811.0,1.0,1,H100,1697105246198,1697105248009.0,120,18.0,1.0,"[40, 1771]","[1697105246238, 1697105248009]"
3811,925,16,[],200,EleutherAI/gpt-neox-20b,128,1,4349.0,1.0,1,H100,1697105221904,1697105226253.0,120,87.0,20.0,"[12, 1487, 71, 92, 87, 87, 84, 82, 350, 91, 70, 88, 87, 68, 579, 82, 78, 74, 74, 706]","[1697105221916, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223740, 1697105223824, 1697105223906, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226253]"
3812,56,16,[],200,EleutherAI/gpt-neox-20b,128,1,5587.0,1.0,1,H100,1697105222668,1697105228255.0,120,86.0,20.0,"[4, 2567, 82, 77, 75, 74, 706, 90, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105222672, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225547, 1697105226253, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
3813,667,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240267,1697105241994.0,120,,,[24],[1697105240291]
3814,675,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232151,1697105234225.0,120,,,[148],[1697105232299]
3815,70,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105270302.0,120,,,[196],[1697105267997]
3816,339,18,[],200,EleutherAI/gpt-neox-20b,128,1,5859.0,1.0,1,H100,1697105214568,1697105220427.0,120,87.0,20.0,"[16, 2857, 88, 87, 406, 88, 81, 256, 79, 368, 81, 59, 366, 89, 75, 260, 61, 235, 78, 229]","[1697105214584, 1697105217441, 1697105217529, 1697105217616, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219824, 1697105219885, 1697105220120, 1697105220198, 1697105220427]"
3817,430,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270307,1697105270988.0,120,,,[14],[1697105270321]
3818,92,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243754.0,120,,,[175],[1697105242176]
3819,786,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270990,1697105273585.0,120,,,[92],[1697105271082]
3820,453,29,[],200,EleutherAI/gpt-neox-20b,128,1,1670.0,1.0,1,H100,1697105243757,1697105245427.0,120,26.0,1.0,"[135, 1535]","[1697105243892, 1697105245427]"
3821,783,30,[],200,EleutherAI/gpt-neox-20b,128,1,768.0,1.0,1,H100,1697105245428,1697105246196.0,120,286.0,1.0,"[46, 722]","[1697105245474, 1697105246196]"
3822,214,42,[],200,EleutherAI/gpt-neox-20b,128,1,2976.0,1.0,1,H100,1697105273590,1697105276566.0,120,52.0,20.0,"[225, 2129, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 33, 32, 32]","[1697105273815, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276502, 1697105276534, 1697105276566]"
3823,215,31,[],200,EleutherAI/gpt-neox-20b,128,1,1812.0,1.0,1,H100,1697105246197,1697105248009.0,120,12.0,1.0,"[33, 1779]","[1697105246230, 1697105248009]"
3824,202,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245505,1697105247243.0,120,,,[176],[1697105245681]
3825,574,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248010,1697105250348.0,120,,,[9],[1697105248019]
3826,556,29,[],200,EleutherAI/gpt-neox-20b,128,1,1388.0,1.0,1,H100,1697105247248,1697105248636.0,120,9.0,1.0,"[142, 1246]","[1697105247390, 1697105248636]"
3827,928,33,[],200,EleutherAI/gpt-neox-20b,128,1,1660.0,1.0,1,H100,1697105250351,1697105252011.0,120,20.0,1.0,"[150, 1510]","[1697105250501, 1697105252011]"
3828,918,30,[],200,EleutherAI/gpt-neox-20b,128,1,1043.0,1.0,1,H100,1697105248638,1697105249681.0,120,23.0,1.0,"[24, 1019]","[1697105248662, 1697105249681]"
3829,357,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252012,1697105253711.0,120,,,[9],[1697105252021]
3830,318,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105249682,1697105252037.0,120,,,[4],[1697105249686]
3831,800,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253715,1697105255027.0,120,,,[164],[1697105253879]
3832,677,32,[],200,EleutherAI/gpt-neox-20b,128,1,1640.0,1.0,1,H100,1697105252042,1697105253682.0,120,9.0,1.0,"[233, 1406]","[1697105252275, 1697105253681]"
3833,232,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105256010.0,120,,,[16],[1697105255046]
3834,589,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256011,1697105258907.0,120,,,[18],[1697105256029]
3835,106,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253685,1697105256010.0,120,,,"[12, 1361]","[1697105253697, 1697105255058]"
3836,853,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228783,1697105230475.0,120,,,[211],[1697105228994]
3837,22,38,[],200,EleutherAI/gpt-neox-20b,128,1,1518.0,1.0,1,H100,1697105258920,1697105260438.0,120,16.0,1.0,"[169, 1349]","[1697105259089, 1697105260438]"
3838,377,39,[],200,EleutherAI/gpt-neox-20b,128,1,1804.0,1.0,1,H100,1697105260439,1697105262243.0,120,13.0,1.0,"[37, 1767]","[1697105260476, 1697105262243]"
3839,426,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228782,1697105230476.0,120,,,[288],[1697105229070]
3840,707,40,[],200,EleutherAI/gpt-neox-20b,128,1,827.0,1.0,1,H100,1697105262244,1697105263071.0,120,8.0,1.0,"[49, 778]","[1697105262293, 1697105263071]"
3841,282,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230479,1697105234918.0,120,,,"[214, 2363, 600, 617]","[1697105230693, 1697105233056, 1697105233656, 1697105234273]"
3842,463,34,[],200,EleutherAI/gpt-neox-20b,128,1,2017.0,1.0,1,H100,1697105256013,1697105258030.0,120,39.0,1.0,"[84, 1933]","[1697105256097, 1697105258030]"
3843,794,35,[],200,EleutherAI/gpt-neox-20b,128,1,1741.0,1.0,1,H100,1697105258031,1697105259772.0,120,11.0,1.0,"[12, 1729]","[1697105258043, 1697105259772]"
3844,643,20,[],200,EleutherAI/gpt-neox-20b,128,1,1834.0,1.0,1,H100,1697105234922,1697105236756.0,120,18.0,1.0,"[49, 1785]","[1697105234971, 1697105236756]"
3845,74,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236757,1697105238409.0,120,,,[20],[1697105236777]
3846,515,22,[],200,EleutherAI/gpt-neox-20b,128,1,1852.0,1.0,1,H100,1697105238414,1697105240266.0,120,11.0,1.0,"[262, 1590]","[1697105238676, 1697105240266]"
3847,869,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240267,1697105241994.0,120,,,[49],[1697105240316]
3848,298,24,[],200,EleutherAI/gpt-neox-20b,128,1,1554.0,1.0,1,H100,1697105242000,1697105243554.0,120,17.0,1.0,"[83, 1471]","[1697105242083, 1697105243554]"
3849,136,41,[],200,EleutherAI/gpt-neox-20b,128,1,1932.0,1.0,1,H100,1697105263072,1697105265004.0,120,31.0,1.0,"[25, 1907]","[1697105263097, 1697105265004]"
3850,659,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243557,1697105245501.0,120,,,[54],[1697105243611]
3851,493,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265006,1697105267795.0,120,,,[9],[1697105265015]
3852,784,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105232146.0,120,,,[106],[1697105230584]
3853,853,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[22],[1697105267820]
3854,212,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232153,1697105234225.0,120,,,[222],[1697105232375]
3855,92,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245504,1697105247243.0,120,,,[75],[1697105245579]
3856,219,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105259773,1697105262306.0,120,,,[12],[1697105259785]
3857,252,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[40],[1697105269640]
3858,422,27,[],200,EleutherAI/gpt-neox-20b,128,1,2427.0,1.0,1,H100,1697105247254,1697105249681.0,120,26.0,1.0,"[241, 2186]","[1697105247495, 1697105249681]"
3859,580,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262314,1697105265927.0,120,,,[282],[1697105262596]
3860,780,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105249682,1697105252037.0,120,,,[21],[1697105249703]
3861,543,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234228,1697105236781.0,120,,,[75],[1697105234303]
3862,357,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241995.0,120,,,[57],[1697105240391]
3863,715,25,[],200,EleutherAI/gpt-neox-20b,128,1,1544.0,1.0,1,H100,1697105242010,1697105243554.0,120,20.0,1.0,"[266, 1278]","[1697105242276, 1697105243554]"
3864,118,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243555,1697105245501.0,120,,,[45],[1697105243600]
3865,207,29,[],200,EleutherAI/gpt-neox-20b,128,1,1641.0,1.0,1,H100,1697105252041,1697105253682.0,120,10.0,1.0,"[56, 1585]","[1697105252097, 1697105253682]"
3866,560,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253688,1697105255028.0,120,,,[106],[1697105253794]
3867,10,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267795.0,120,,,[13],[1697105265944]
3868,918,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257115.0,120,,,[141],[1697105255171]
3869,371,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267799,1697105269598.0,120,,,[17],[1697105267816]
3870,481,27,[],200,EleutherAI/gpt-neox-20b,128,1,1664.0,1.0,1,H100,1697105245504,1697105247168.0,120,10.0,1.0,"[92, 1572]","[1697105245596, 1697105247168]"
3871,814,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269599,1697105270988.0,120,,,[13],[1697105269612]
3872,23,13,[],200,EleutherAI/gpt-neox-20b,128,1,2222.0,1.0,1,H100,1697105212105,1697105214327.0,120,26.0,1.0,"[13, 2209]","[1697105212118, 1697105214327]"
3873,838,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247169,1697105248696.0,120,,,[21],[1697105247190]
3874,467,14,[],200,EleutherAI/gpt-neox-20b,128,1,5557.0,1.0,1,H100,1697105214328,1697105219885.0,120,93.0,20.0,"[8, 2568, 85, 66, 385, 89, 87, 406, 88, 81, 256, 79, 368, 81, 59, 366, 89, 75, 259, 62]","[1697105214336, 1697105216904, 1697105216989, 1697105217055, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219823, 1697105219885]"
3875,263,29,[],200,EleutherAI/gpt-neox-20b,128,1,2485.0,1.0,1,H100,1697105248699,1697105251184.0,120,15.0,1.0,"[194, 2291]","[1697105248893, 1697105251184]"
3876,323,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105260462.0,120,,,[194],[1697105257312]
3877,623,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105251186,1697105253711.0,120,,,[28],[1697105251214]
3878,19,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105256010.0,120,,,[201],[1697105253915]
3879,60,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241932,1697105243754.0,120,,,[32],[1697105241964]
3880,684,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260464,1697105262306.0,120,,,[104],[1697105260568]
3881,112,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262309,1697105264082.0,120,,,[17],[1697105262326]
3882,103,13,[],200,EleutherAI/gpt-neox-20b,128,1,1622.0,1.0,1,H100,1697105202004,1697105203626.0,120,15.0,1.0,"[99, 1523]","[1697105202103, 1697105203626]"
3883,457,14,[],200,EleutherAI/gpt-neox-20b,128,1,2196.0,1.0,1,H100,1697105203627,1697105205823.0,120,874.0,2.0,"[8, 2187]","[1697105203635, 1697105205822]"
3884,242,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270989,1697105271973.0,120,,,[5],[1697105270994]
3885,418,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243758,1697105245501.0,120,,,[17],[1697105243775]
3886,304,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258916.0,120,,,[54],[1697105257171]
3887,748,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245505,1697105247242.0,120,,,[6],[1697105245511]
3888,597,42,[],200,EleutherAI/gpt-neox-20b,128,1,2436.0,1.0,1,H100,1697105271978,1697105274414.0,120,39.0,1.0,"[225, 2211]","[1697105272203, 1697105274414]"
3889,27,43,[],200,EleutherAI/gpt-neox-20b,128,1,2952.0,1.0,1,H100,1697105274416,1697105277368.0,120,15.0,50.0,"[24, 1504, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 33, 32, 32, 33, 29, 28, 28, 28, 32, 27, 27, 27, 28, 30, 26, 26, 29, 26, 26, 28, 25, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 24, 26]","[1697105274440, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276502, 1697105276534, 1697105276566, 1697105276599, 1697105276628, 1697105276656, 1697105276684, 1697105276712, 1697105276744, 1697105276771, 1697105276798, 1697105276825, 1697105276853, 1697105276883, 1697105276909, 1697105276935, 1697105276964, 1697105276990, 1697105277016, 1697105277044, 1697105277069, 1697105277093, 1697105277118, 1697105277143, 1697105277168, 1697105277193, 1697105277218, 1697105277243, 1697105277268, 1697105277293, 1697105277318, 1697105277342, 1697105277368]"
3890,817,15,[],200,EleutherAI/gpt-neox-20b,128,1,5658.0,1.0,1,H100,1697105205824,1697105211482.0,120,86.0,20.0,"[8, 2145, 86, 82, 83, 64, 434, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 82, 428, 168]","[1697105205832, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482]"
3891,471,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265929.0,120,,,[47],[1697105264132]
3892,658,34,[],200,EleutherAI/gpt-neox-20b,128,1,2505.0,1.0,1,H100,1697105258925,1697105261430.0,120,11.0,1.0,"[253, 2252]","[1697105259178, 1697105261430]"
3893,63,35,[],200,EleutherAI/gpt-neox-20b,128,1,1639.0,1.0,1,H100,1697105261432,1697105263071.0,120,39.0,1.0,"[28, 1611]","[1697105261460, 1697105263071]"
3894,184,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248695.0,120,,,[43],[1697105247290]
3895,420,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263072,1697105265927.0,120,,,[12],[1697105263084]
3896,541,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248698,1697105250348.0,120,,,[83],[1697105248781]
3897,666,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230476.0,120,,,[101],[1697105228882]
3898,91,18,[],200,EleutherAI/gpt-neox-20b,128,1,1647.0,1.0,1,H100,1697105230478,1697105232125.0,120,23.0,1.0,"[94, 1553]","[1697105230572, 1697105232125]"
3899,421,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267795.0,120,,,[12],[1697105265943]
3900,534,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232126,1697105234919.0,120,,,"[13, 917, 600, 617]","[1697105232139, 1697105233056, 1697105233656, 1697105234273]"
3901,252,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236785,1697105240330.0,120,,,[222],[1697105237007]
3902,822,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265934,1697105271974.0,120,,,"[236, 2808, 669, 704, 685]","[1697105266170, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
3903,578,26,[],200,EleutherAI/gpt-neox-20b,128,1,1596.0,1.0,1,H100,1697105240334,1697105241930.0,120,31.0,1.0,"[61, 1535]","[1697105240395, 1697105241930]"
3904,780,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[13],[1697105267811]
3905,3,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241932,1697105243754.0,120,,,[28],[1697105241960]
3906,209,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270302.0,120,,,[24],[1697105269624]
3907,361,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243758,1697105247242.0,120,,,[246],[1697105244004]
3908,720,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247246,1697105248696.0,120,,,[32],[1697105247278]
3909,156,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105252036.0,120,,,[190],[1697105248889]
3910,417,25,[],200,EleutherAI/gpt-neox-20b,128,1,1640.0,1.0,1,H100,1697105252041,1697105253681.0,120,17.0,1.0,"[20, 1620]","[1697105252061, 1697105253681]"
3911,746,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253687,1697105255028.0,120,,,[90],[1697105253777]
3912,223,37,[],200,EleutherAI/gpt-neox-20b,128,1,2436.0,1.0,1,H100,1697105271978,1697105274414.0,120,16.0,1.0,"[297, 2139]","[1697105272275, 1697105274414]"
3913,581,38,[],200,EleutherAI/gpt-neox-20b,128,1,2150.0,1.0,1,H100,1697105274416,1697105276566.0,120,47.0,20.0,"[20, 1508, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 33, 32, 32]","[1697105274436, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276502, 1697105276534, 1697105276566]"
3914,173,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255029,1697105257114.0,120,,,[38],[1697105255067]
3915,526,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258913.0,120,,,[30],[1697105257147]
3916,602,31,[],200,EleutherAI/gpt-neox-20b,128,1,1641.0,1.0,1,H100,1697105252041,1697105253682.0,120,15.0,1.0,"[242, 1398]","[1697105252283, 1697105253681]"
3917,31,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253686,1697105255027.0,120,,,[47],[1697105253733]
3918,890,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236781.0,120,,,[166],[1697105235088]
3919,884,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258917,1697105260463.0,120,,,[88],[1697105259005]
3920,385,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255029,1697105257114.0,120,,,[41],[1697105255070]
3921,323,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105238408.0,120,,,[97],[1697105236881]
3922,387,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269599,1697105270302.0,120,,,[13],[1697105269612]
3923,740,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258907.0,120,,,[10],[1697105257127]
3924,686,22,[],200,EleutherAI/gpt-neox-20b,128,1,1853.0,1.0,1,H100,1697105238412,1697105240265.0,120,31.0,1.0,"[171, 1682]","[1697105238583, 1697105240265]"
3925,85,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240266,1697105241993.0,120,,,[9],[1697105240275]
3926,317,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260465,1697105262306.0,120,,,[23],[1697105260488]
3927,893,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233609,1697105234918.0,120,,,[9],[1697105233618]
3928,766,31,[],200,EleutherAI/gpt-neox-20b,128,1,1680.0,1.0,1,H100,1697105262310,1697105263990.0,120,11.0,1.0,"[61, 1619]","[1697105262371, 1697105263990]"
3929,196,32,[],200,EleutherAI/gpt-neox-20b,128,1,1013.0,1.0,1,H100,1697105263991,1697105265004.0,120,13.0,1.0,"[17, 996]","[1697105264008, 1697105265004]"
3930,554,33,[],200,EleutherAI/gpt-neox-20b,128,1,2180.0,1.0,1,H100,1697105265006,1697105267186.0,120,26.0,1.0,"[13, 2167]","[1697105265019, 1697105267186]"
3931,318,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234921,1697105236781.0,120,,,[6],[1697105234927]
3932,745,45,[],200,EleutherAI/gpt-neox-20b,128,1,1636.0,1.0,1,H100,1697105270309,1697105271945.0,120,17.0,1.0,"[76, 1560]","[1697105270385, 1697105271945]"
3933,264,46,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271946,1697105273586.0,120,,,[5],[1697105271951]
3934,623,47,[],200,EleutherAI/gpt-neox-20b,128,1,2396.0,1.0,1,H100,1697105273589,1697105275985.0,120,140.0,3.0,"[205, 2150, 41]","[1697105273794, 1697105275944, 1697105275985]"
3935,904,34,[],200,EleutherAI/gpt-neox-20b,128,1,1791.0,1.0,1,H100,1697105267187,1697105268978.0,120,563.0,2.0,"[21, 1770]","[1697105267208, 1697105268978]"
3936,335,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268979,1697105270302.0,120,,,[5],[1697105268984]
3937,445,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243753.0,120,,,[34],[1697105242035]
3938,799,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243757,1697105245502.0,120,,,[59],[1697105243816]
3939,663,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270309,1697105271973.0,120,,,[80],[1697105270389]
3940,224,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105247243.0,120,,,[179],[1697105245685]
3941,859,19,[],200,EleutherAI/gpt-neox-20b,128,1,1364.0,1.0,1,H100,1697105226344,1697105227708.0,120,23.0,1.0,"[5, 1359]","[1697105226349, 1697105227708]"
3942,724,27,[],200,EleutherAI/gpt-neox-20b,128,1,1671.0,1.0,1,H100,1697105248010,1697105249681.0,120,11.0,1.0,"[25, 1646]","[1697105248035, 1697105249681]"
3943,260,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105227710,1697105232144.0,120,,,"[20, 2785, 990, 76, 75, 73, 74]","[1697105227730, 1697105230515, 1697105231505, 1697105231581, 1697105231656, 1697105231729, 1697105231803]"
3944,98,37,[],200,EleutherAI/gpt-neox-20b,128,1,1578.0,1.0,1,H100,1697105271977,1697105273555.0,120,14.0,1.0,"[205, 1373]","[1697105272182, 1697105273555]"
3945,457,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273556,1697105275207.0,120,,,[13],[1697105273569]
3946,152,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105249682,1697105252037.0,120,,,[16],[1697105249698]
3947,509,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252042,1697105253712.0,120,,,[269],[1697105252311]
3948,868,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[259],[1697105253975]
3949,297,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258925.0,120,,,[76],[1697105256089]
3950,614,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233609.0,120,,,[57],[1697105232207]
3951,47,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233610,1697105234919.0,120,,,[28],[1697105233638]
3952,91,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230476.0,120,,,[92],[1697105228873]
3953,406,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236782.0,120,,,"[57, 1777]","[1697105234979, 1697105236756]"
3954,882,17,[],200,EleutherAI/gpt-neox-20b,128,1,3278.0,1.0,1,H100,1697105212016,1697105215294.0,120,345.0,11.0,"[5, 1810, 93, 90, 89, 68, 246, 85, 65, 75, 652]","[1697105212021, 1697105213831, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294]"
3955,851,24,[],200,EleutherAI/gpt-neox-20b,128,1,2553.0,1.0,1,H100,1697105236786,1697105239339.0,120,23.0,1.0,"[233, 2319]","[1697105237019, 1697105239338]"
3956,451,19,[],200,EleutherAI/gpt-neox-20b,128,1,1648.0,1.0,1,H100,1697105230477,1697105232125.0,120,286.0,1.0,"[91, 1557]","[1697105230568, 1697105232125]"
3957,805,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232126,1697105234919.0,120,,,"[17, 913, 601, 616]","[1697105232143, 1697105233056, 1697105233657, 1697105234273]"
3958,285,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105239340,1697105241995.0,120,,,[25],[1697105239365]
3959,638,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242000,1697105243754.0,120,,,[11],[1697105242011]
3960,67,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243761,1697105247242.0,120,,,[271],[1697105244032]
3961,422,28,[],200,EleutherAI/gpt-neox-20b,128,1,1389.0,1.0,1,H100,1697105247247,1697105248636.0,120,26.0,1.0,"[10, 1379]","[1697105247257, 1697105248636]"
3962,754,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248637,1697105250348.0,120,,,[5],[1697105248642]
3963,95,19,[],200,EleutherAI/gpt-neox-20b,128,1,1404.0,1.0,1,H100,1697105224662,1697105226066.0,120,12.0,1.0,"[45, 1358]","[1697105224707, 1697105226065]"
3964,233,21,[],200,EleutherAI/gpt-neox-20b,128,1,1834.0,1.0,1,H100,1697105234922,1697105236756.0,120,6.0,1.0,"[182, 1652]","[1697105235104, 1697105236756]"
3965,671,19,[],200,EleutherAI/gpt-neox-20b,128,1,1475.0,1.0,1,H100,1697105220428,1697105221903.0,120,12.0,1.0,"[10, 1465]","[1697105220438, 1697105221903]"
3966,560,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236757,1697105238408.0,120,,,[37],[1697105236794]
3967,100,20,[],200,EleutherAI/gpt-neox-20b,128,1,4439.0,1.0,1,H100,1697105221904,1697105226343.0,120,732.0,14.0,"[17, 2336, 90, 70, 88, 87, 68, 579, 82, 78, 74, 74, 705, 91]","[1697105221921, 1697105224257, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226252, 1697105226343]"
3968,922,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238411,1697105240330.0,120,,,[11],[1697105238422]
3969,540,20,[],200,EleutherAI/gpt-neox-20b,128,1,2104.0,1.0,1,H100,1697105226068,1697105228172.0,120,140.0,5.0,"[8, 1835, 93, 84, 84]","[1697105226076, 1697105227911, 1697105228004, 1697105228088, 1697105228172]"
3970,649,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241206,1697105243753.0,120,,,[5],[1697105241211]
3971,337,35,[],200,EleutherAI/gpt-neox-20b,128,1,1732.0,1.0,1,H100,1697105257118,1697105258850.0,120,12.0,1.0,"[162, 1570]","[1697105257280, 1697105258850]"
3972,667,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228257,1697105232144.0,120,,,"[29, 2230, 990, 75, 75, 74, 73]","[1697105228286, 1697105230516, 1697105231506, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
3973,352,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241993.0,120,,,"[133, 1463]","[1697105240467, 1697105241930]"
3974,691,36,[],200,EleutherAI/gpt-neox-20b,128,1,921.0,1.0,1,H100,1697105258851,1697105259772.0,120,47.0,1.0,"[29, 892]","[1697105258880, 1697105259772]"
3975,79,22,[],200,EleutherAI/gpt-neox-20b,128,1,1671.0,1.0,1,H100,1697105243756,1697105245427.0,120,12.0,1.0,"[40, 1631]","[1697105243796, 1697105245427]"
3976,414,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245428,1697105247242.0,120,,,[9],[1697105245437]
3977,121,37,[],200,EleutherAI/gpt-neox-20b,128,1,1658.0,1.0,1,H100,1697105259773,1697105261431.0,120,13.0,1.0,"[24, 1633]","[1697105259797, 1697105261430]"
3978,774,24,[],200,EleutherAI/gpt-neox-20b,128,1,1387.0,1.0,1,H100,1697105247249,1697105248636.0,120,8.0,1.0,"[133, 1254]","[1697105247382, 1697105248636]"
3979,709,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242010,1697105245502.0,120,,,[270],[1697105242280]
3980,183,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252037.0,120,,,[154],[1697105250505]
3981,542,31,[],200,EleutherAI/gpt-neox-20b,128,1,1640.0,1.0,1,H100,1697105252042,1697105253682.0,120,11.0,1.0,"[265, 1375]","[1697105252307, 1697105253682]"
3982,900,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253686,1697105255027.0,120,,,[38],[1697105253724]
3983,331,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255029,1697105257114.0,120,,,[54],[1697105255083]
3984,137,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245505,1697105247243.0,120,,,[167],[1697105245672]
3985,658,34,[],200,EleutherAI/gpt-neox-20b,128,1,1732.0,1.0,1,H100,1697105257118,1697105258850.0,120,11.0,1.0,"[166, 1566]","[1697105257284, 1697105258850]"
3986,87,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258851,1697105260463.0,120,,,[25],[1697105258876]
3987,446,36,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105260467,1697105262243.0,120,26.0,1.0,"[218, 1558]","[1697105260685, 1697105262243]"
3988,202,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248638,1697105250347.0,120,,,[20],[1697105248658]
3989,584,27,[],200,EleutherAI/gpt-neox-20b,128,1,2430.0,1.0,1,H100,1697105247250,1697105249680.0,120,10.0,1.0,"[161, 2269]","[1697105247411, 1697105249680]"
3990,455,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226344,1697105228773.0,120,,,[5],[1697105226349]
3991,108,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258913.0,120,,,[38],[1697105257155]
3992,804,37,[],200,EleutherAI/gpt-neox-20b,128,1,827.0,1.0,1,H100,1697105262244,1697105263071.0,120,20.0,1.0,"[41, 786]","[1697105262285, 1697105263071]"
3993,820,16,[],200,EleutherAI/gpt-neox-20b,128,1,2747.0,1.0,1,H100,1697105222574,1697105225321.0,120,161.0,9.0,"[8, 1675, 90, 70, 88, 87, 68, 579, 82]","[1697105222582, 1697105224257, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321]"
3994,467,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258917,1697105260462.0,120,,,[68],[1697105258985]
3995,649,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105229653,1697105232145.0,120,,,"[12, 1840, 76, 75, 74, 73]","[1697105229665, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
3996,695,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245505,1697105247242.0,120,,,[14],[1697105245519]
3997,229,38,[],200,EleutherAI/gpt-neox-20b,128,1,1931.0,1.0,1,H100,1697105263073,1697105265004.0,120,15.0,1.0,"[28, 1903]","[1697105263101, 1697105265004]"
3998,216,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228774,1697105230475.0,120,,,[22],[1697105228796]
3999,809,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230475.0,120,,,[192],[1697105228973]
4000,239,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105232146.0,120,,,[48],[1697105230526]
4001,660,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230477,1697105232146.0,120,,,"[13, 1015, 76, 75, 74, 73]","[1697105230490, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
4002,571,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232152,1697105234225.0,120,,,[143],[1697105232295]
4003,506,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233608.0,120,,,[44],[1697105232194]
4004,863,21,[],200,EleutherAI/gpt-neox-20b,128,1,1272.0,1.0,1,H100,1697105233610,1697105234882.0,120,10.0,1.0,"[44, 1228]","[1697105233654, 1697105234882]"
4005,264,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234883,1697105236781.0,120,,,[13],[1697105234896]
4006,629,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236787,1697105240330.0,120,,,[299],[1697105237086]
4007,57,24,[],200,EleutherAI/gpt-neox-20b,128,1,1596.0,1.0,1,H100,1697105240334,1697105241930.0,120,13.0,1.0,"[237, 1359]","[1697105240571, 1697105241930]"
4008,508,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248696.0,120,,,[6],[1697105247253]
4009,417,25,[],200,EleutherAI/gpt-neox-20b,128,1,759.0,1.0,1,H100,1697105241932,1697105242691.0,120,17.0,1.0,"[36, 723]","[1697105241968, 1697105242691]"
4010,771,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242692,1697105245502.0,120,,,[16],[1697105242708]
4011,284,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105248695.0,120,,,[262],[1697105245768]
4012,642,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248697,1697105250348.0,120,,,[31],[1697105248728]
4013,74,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252036.0,120,,,[50],[1697105250401]
4014,437,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252039,1697105253711.0,120,,,[143],[1697105252182]
4015,563,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265006,1697105267796.0,120,,,[21],[1697105265027]
4016,765,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105255027.0,120,,,[155],[1697105253869]
4017,107,5,[],200,EleutherAI/gpt-neox-20b,128,1,1862.0,1.0,1,H100,1697105193620,1697105195482.0,120,216.0,2.0,"[5, 1857]","[1697105193625, 1697105195482]"
4018,866,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105252036.0,120,,,[190],[1697105248889]
4019,440,6,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105195483,1697105201998.0,120,,,"[4, 3202, 273, 410, 224, 231, 129, 150, 140, 81, 79, 220, 296, 80, 292, 160, 212]","[1697105195487, 1697105198689, 1697105198962, 1697105199372, 1697105199596, 1697105199827, 1697105199956, 1697105200106, 1697105200246, 1697105200327, 1697105200406, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
4020,921,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105270302.0,120,,,[207],[1697105268008]
4021,288,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253712.0,120,,,[229],[1697105252270]
4022,353,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270308,1697105271972.0,120,,,[40],[1697105270348]
4023,708,42,[],200,EleutherAI/gpt-neox-20b,128,1,1579.0,1.0,1,H100,1697105271976,1697105273555.0,120,140.0,1.0,"[18, 1561]","[1697105271994, 1697105273555]"
4024,224,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273556,1697105275207.0,120,,,[10],[1697105273566]
4025,190,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[61],[1697105255091]
4026,380,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258913.0,120,,,[165],[1697105256178]
4027,739,33,[],200,EleutherAI/gpt-neox-20b,128,1,1522.0,1.0,1,H100,1697105258916,1697105260438.0,120,216.0,1.0,"[24, 1497]","[1697105258940, 1697105260437]"
4028,764,25,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105234226,1697105236002.0,120,39.0,1.0,"[49, 1727]","[1697105234275, 1697105236002]"
4029,194,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236003,1697105238408.0,120,,,[21],[1697105236024]
4030,171,34,[],200,EleutherAI/gpt-neox-20b,128,1,1804.0,1.0,1,H100,1697105260439,1697105262243.0,120,6.0,1.0,"[29, 1775]","[1697105260468, 1697105262243]"
4031,549,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258921.0,120,,,[62],[1697105257179]
4032,782,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265935,1697105271973.0,120,,,"[247, 2796, 669, 704, 685]","[1697105266182, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
4033,904,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258926,1697105262306.0,120,,,[256],[1697105259182]
4034,488,13,[],200,EleutherAI/gpt-neox-20b,128,1,2061.0,1.0,1,H100,1697105214173,1697105216234.0,120,6.0,1.0,"[4, 2057]","[1697105214177, 1697105216234]"
4035,798,7,[],200,EleutherAI/gpt-neox-20b,128,1,2248.0,1.0,1,H100,1697105202002,1697105204250.0,120,79.0,6.0,"[21, 1695, 88, 88, 87, 269]","[1697105202023, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250]"
4036,336,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262310,1697105264083.0,120,,,[85],[1697105262395]
4037,846,14,[],200,EleutherAI/gpt-neox-20b,128,1,3254.0,1.0,1,H100,1697105216235,1697105219489.0,120,140.0,6.0,"[5, 2654, 81, 60, 365, 89]","[1697105216240, 1697105218894, 1697105218975, 1697105219035, 1697105219400, 1697105219489]"
4038,612,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270989,1697105273585.0,120,,,[33],[1697105271022]
4039,257,27,[],200,EleutherAI/gpt-neox-20b,128,1,1601.0,1.0,1,H100,1697105236784,1697105238385.0,120,14.0,1.0,"[110, 1491]","[1697105236894, 1697105238385]"
4040,825,15,[],200,EleutherAI/gpt-neox-20b,128,1,4774.0,1.0,1,H100,1697105219886,1697105224660.0,120,96.0,20.0,"[5, 2074, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68]","[1697105219891, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660]"
4041,212,38,[],200,EleutherAI/gpt-neox-20b,128,1,2436.0,1.0,1,H100,1697105271978,1697105274414.0,120,31.0,1.0,"[249, 2187]","[1697105272227, 1697105274414]"
4042,537,39,[],200,EleutherAI/gpt-neox-20b,128,1,2151.0,1.0,1,H100,1697105274415,1697105276566.0,120,83.0,20.0,"[21, 1508, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 33, 32, 32]","[1697105274436, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276502, 1697105276534, 1697105276566]"
4043,666,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264087,1697105267795.0,120,,,[284],[1697105264371]
4044,95,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267799,1697105269598.0,120,,,[13],[1697105267812]
4045,457,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269599,1697105270988.0,120,,,[9],[1697105269608]
4046,97,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105247243.0,120,,,[270],[1697105245776]
4047,655,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240267,1697105241993.0,120,,,[12],[1697105240279]
4048,763,41,[],200,EleutherAI/gpt-neox-20b,128,1,1578.0,1.0,1,H100,1697105271977,1697105273555.0,120,20.0,1.0,"[133, 1445]","[1697105272110, 1697105273555]"
4049,255,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105224662,1697105228773.0,120,,,"[5, 1585, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105224667, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
4050,192,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273556,1697105275207.0,120,,,[11],[1697105273567]
4051,87,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243753.0,120,,,[90],[1697105242091]
4052,276,15,[],200,EleutherAI/gpt-neox-20b,128,1,4333.0,1.0,1,H100,1697105219491,1697105223824.0,120,732.0,13.0,"[9, 2465, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85]","[1697105219500, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824]"
4053,448,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243757,1697105245503.0,120,,,[127],[1697105243884]
4054,895,28,[],200,EleutherAI/gpt-neox-20b,128,1,1663.0,1.0,1,H100,1697105245505,1697105247168.0,120,15.0,1.0,"[103, 1560]","[1697105245608, 1697105247168]"
4055,320,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247169,1697105248696.0,120,,,[13],[1697105247182]
4056,674,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248700,1697105252037.0,120,,,[270],[1697105248970]
4057,43,10,[],200,EleutherAI/gpt-neox-20b,128,1,2492.0,1.0,1,H100,1697105224662,1697105227154.0,120,732.0,8.0,"[21, 1569, 91, 85, 65, 84, 486, 91]","[1697105224683, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154]"
4058,400,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105227155,1697105228774.0,120,,,[5],[1697105227160]
4059,758,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230476.0,120,,,[117],[1697105228898]
4060,104,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253710.0,120,,,[129],[1697105252170]
4061,159,13,[],200,EleutherAI/gpt-neox-20b,128,1,828.0,1.0,1,H100,1697105230478,1697105231306.0,120,31.0,1.0,"[24, 804]","[1697105230502, 1697105231306]"
4062,791,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105211484,1697105220994.0,120,,,"[28, 2318, 94, 90, 89, 68, 246, 85, 64, 76, 653, 84, 356, 91, 83, 510, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 82, 256, 79, 368, 81, 59, 366, 84, 80, 259, 62, 234, 79, 229, 81, 198]","[1697105211512, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642, 1697105215295, 1697105215379, 1697105215735, 1697105215826, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219484, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
4063,513,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105231307,1697105234919.0,120,,,"[17, 1732, 600, 617]","[1697105231324, 1697105233056, 1697105233656, 1697105234273]"
4064,332,14,[],200,EleutherAI/gpt-neox-20b,128,1,2543.0,1.0,1,H100,1697105215295,1697105217838.0,120,39.0,1.0,"[5, 2538]","[1697105215300, 1697105217838]"
4065,685,15,[],200,EleutherAI/gpt-neox-20b,128,1,2281.0,1.0,1,H100,1697105217839,1697105220120.0,120,364.0,2.0,"[4, 2277]","[1697105217843, 1697105220120]"
4066,115,16,[],200,EleutherAI/gpt-neox-20b,128,1,1782.0,1.0,1,H100,1697105220121,1697105221903.0,120,13.0,1.0,"[8, 1774]","[1697105220129, 1697105221903]"
4067,561,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241994.0,120,,,[241],[1697105240575]
4068,918,20,[],200,EleutherAI/gpt-neox-20b,128,1,1554.0,1.0,1,H100,1697105242000,1697105243554.0,120,23.0,1.0,"[27, 1526]","[1697105242027, 1697105243553]"
4069,348,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243555,1697105245502.0,120,,,[8],[1697105243563]
4070,281,11,[],200,EleutherAI/gpt-neox-20b,128,1,2484.0,1.0,1,H100,1697105209439,1697105211923.0,120,23.0,1.0,"[28, 2456]","[1697105209467, 1697105211923]"
4071,706,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245505,1697105247242.0,120,,,[6],[1697105245511]
4072,641,12,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105211924,1697105220994.0,120,,,"[5, 1901, 94, 90, 89, 68, 246, 85, 65, 75, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 82, 256, 79, 368, 81, 59, 366, 87, 77, 259, 62, 234, 79, 228, 82, 198]","[1697105211929, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219487, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220426, 1697105220508, 1697105220706]"
4073,107,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248695.0,120,,,[59],[1697105247306]
4074,464,24,[],200,EleutherAI/gpt-neox-20b,128,1,1623.0,1.0,1,H100,1697105248699,1697105250322.0,120,12.0,1.0,"[17, 1606]","[1697105248716, 1697105250322]"
4075,819,25,[],200,EleutherAI/gpt-neox-20b,128,1,862.0,1.0,1,H100,1697105250323,1697105251185.0,120,13.0,1.0,"[8, 853]","[1697105250331, 1697105251184]"
4076,210,10,[],200,EleutherAI/gpt-neox-20b,128,1,3580.0,1.0,1,H100,1697105194453,1697105198033.0,120,140.0,2.0,"[5, 3575]","[1697105194458, 1697105198033]"
4077,253,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105251186,1697105253711.0,120,,,[16],[1697105251202]
4078,610,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105255027.0,120,,,[107],[1697105253821]
4079,130,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[150],[1697105255180]
4080,484,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258914.0,120,,,[38],[1697105257155]
4081,842,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258921,1697105262306.0,120,,,[193],[1697105259114]
4082,567,11,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105198034,1697105201998.0,120,,,"[4, 3256, 160, 213]","[1697105198038, 1697105201294, 1697105201454, 1697105201667]"
4083,267,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262310,1697105264082.0,120,,,[69],[1697105262379]
4084,736,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[282],[1697105253998]
4085,170,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258914.0,120,,,[57],[1697105256070]
4086,282,10,[],200,EleutherAI/gpt-neox-20b,128,1,5318.0,1.0,1,H100,1697105214568,1697105219886.0,120,87.0,20.0,"[8, 2329, 84, 66, 385, 89, 87, 406, 88, 81, 256, 79, 368, 81, 59, 366, 89, 75, 260, 61]","[1697105214576, 1697105216905, 1697105216989, 1697105217055, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219489, 1697105219564, 1697105219824, 1697105219885]"
4087,498,35,[],200,EleutherAI/gpt-neox-20b,128,1,2510.0,1.0,1,H100,1697105258920,1697105261430.0,120,9.0,1.0,"[189, 2321]","[1697105259109, 1697105261430]"
4088,606,45,[],200,EleutherAI/gpt-neox-20b,128,1,1758.0,1.0,1,H100,1697105270990,1697105272748.0,120,9.0,1.0,"[56, 1702]","[1697105271046, 1697105272748]"
4089,627,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264086,1697105265928.0,120,,,[182],[1697105264268]
4090,30,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265934,1697105271974.0,120,,,"[244, 2800, 669, 704, 685]","[1697105266178, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
4091,474,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105261432,1697105264083.0,120,,,[16],[1697105261448]
4092,859,36,[],200,EleutherAI/gpt-neox-20b,128,1,1639.0,1.0,1,H100,1697105261432,1697105263071.0,120,23.0,1.0,"[12, 1627]","[1697105261444, 1697105263071]"
4093,290,37,[],200,EleutherAI/gpt-neox-20b,128,1,1932.0,1.0,1,H100,1697105263072,1697105265004.0,120,14.0,1.0,"[17, 1915]","[1697105263089, 1697105265004]"
4094,389,34,[],200,EleutherAI/gpt-neox-20b,128,1,1577.0,1.0,1,H100,1697105271978,1697105273555.0,120,8.0,1.0,"[301, 1276]","[1697105272279, 1697105273555]"
4095,834,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264086,1697105265928.0,120,,,[188],[1697105264274]
4096,237,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265936,1697105271972.0,120,,,"[270, 2772, 669, 704, 685]","[1697105266206, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
4097,644,38,[],200,EleutherAI/gpt-neox-20b,128,1,2180.0,1.0,1,H100,1697105265006,1697105267186.0,120,19.0,1.0,"[21, 2159]","[1697105265027, 1697105267186]"
4098,69,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267187,1697105271972.0,120,,,"[8, 1783, 669, 704, 685]","[1697105267195, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
4099,598,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271975,1697105273584.0,120,,,[7],[1697105271982]
4100,29,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273588,1697105275208.0,120,,,[106],[1697105273694]
4101,923,12,[],200,EleutherAI/gpt-neox-20b,128,1,2243.0,1.0,1,H100,1697105202007,1697105204250.0,120,140.0,6.0,"[160, 1551, 88, 88, 87, 269]","[1697105202167, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250]"
4102,304,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228257,1697105232145.0,120,,,"[20, 2239, 990, 75, 75, 74, 73]","[1697105228277, 1697105230516, 1697105231506, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
4103,124,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248695.0,120,,,[71],[1697105247318]
4104,82,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233609.0,120,,,[20],[1697105232170]
4105,672,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264087,1697105265928.0,120,,,[25],[1697105264112]
4106,901,31,[],200,EleutherAI/gpt-neox-20b,128,1,1660.0,1.0,1,H100,1697105250351,1697105252011.0,120,17.0,1.0,"[226, 1434]","[1697105250577, 1697105252011]"
4107,322,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252012,1697105253712.0,120,,,[25],[1697105252037]
4108,437,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253712.0,120,,,[52],[1697105252093]
4109,832,19,[],200,EleutherAI/gpt-neox-20b,128,1,1886.0,1.0,1,H100,1697105232996,1697105234882.0,120,15.0,1.0,"[24, 1862]","[1697105233020, 1697105234882]"
4110,791,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[294],[1697105254010]
4111,253,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225321,1697105228772.0,120,,,"[5, 2585, 93, 84, 84, 83]","[1697105225326, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
4112,217,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258913.0,120,,,[90],[1697105256103]
4113,265,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234883,1697105236781.0,120,,,[5],[1697105234888]
4114,612,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228778,1697105230475.0,120,,,[19],[1697105228797]
4115,72,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265932,1697105271973.0,120,,,"[137, 2908, 669, 705, 685]","[1697105266069, 1697105268977, 1697105269646, 1697105270351, 1697105271036]"
4116,439,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233610,1697105234919.0,120,,,[36],[1697105233646]
4117,36,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105232145.0,120,,,"[32, 996, 75, 75, 74, 73]","[1697105230510, 1697105231506, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
4118,803,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230475.0,120,,,[40],[1697105228821]
4119,202,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105234920.0,120,,,"[191, 2387, 600, 617]","[1697105230669, 1697105233056, 1697105233656, 1697105234273]"
4120,612,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228779,1697105230475.0,120,,,[26],[1697105228805]
4121,435,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271978,1697105275207.0,120,,,[293],[1697105272271]
4122,592,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252037.0,120,,,[134],[1697105250485]
4123,575,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258920,1697105262306.0,120,,,[253],[1697105259173]
4124,367,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233608.0,120,,,[36],[1697105232186]
4125,8,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262310,1697105264082.0,120,,,[61],[1697105262371]
4126,338,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265928.0,120,,,[99],[1697105264184]
4127,875,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236782.0,120,,,"[73, 1761]","[1697105234995, 1697105236756]"
4128,699,37,[],200,EleutherAI/gpt-neox-20b,128,1,2980.0,1.0,1,H100,1697105265935,1697105268915.0,120,39.0,1.0,"[251, 2729]","[1697105266186, 1697105268915]"
4129,562,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234925,1697105238408.0,120,,,[259],[1697105235184]
4130,629,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258928,1697105262306.0,120,,,[270],[1697105259198]
4131,721,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233609,1697105234920.0,120,,,[5],[1697105233614]
4132,911,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238411,1697105240330.0,120,,,[60],[1697105238471]
4133,340,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240333,1697105241994.0,120,,,[42],[1697105240375]
4134,699,21,[],200,EleutherAI/gpt-neox-20b,128,1,1553.0,1.0,1,H100,1697105242001,1697105243554.0,120,39.0,1.0,"[182, 1370]","[1697105242183, 1697105243553]"
4135,634,16,[],200,EleutherAI/gpt-neox-20b,128,1,1319.0,1.0,1,H100,1697105223825,1697105225144.0,120,13.0,1.0,"[5, 1314]","[1697105223830, 1697105225144]"
4136,149,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234923,1697105238408.0,120,,,[245],[1697105235168]
4137,512,23,[],200,EleutherAI/gpt-neox-20b,128,1,1854.0,1.0,1,H100,1697105238411,1697105240265.0,120,11.0,1.0,"[15, 1839]","[1697105238426, 1697105240265]"
4138,873,24,[],200,EleutherAI/gpt-neox-20b,128,1,938.0,1.0,1,H100,1697105240267,1697105241205.0,120,6.0,1.0,"[44, 894]","[1697105240311, 1697105241205]"
4139,305,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236785,1697105240330.0,120,,,[206],[1697105236991]
4140,102,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243555,1697105245502.0,120,,,[20],[1697105243575]
4141,62,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225145,1697105228773.0,120,,,"[17, 1090, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105225162, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
4142,666,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240333,1697105241995.0,120,,,[50],[1697105240383]
4143,67,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242016,1697105245502.0,120,,,[272],[1697105242288]
4144,464,23,[],200,EleutherAI/gpt-neox-20b,128,1,1662.0,1.0,1,H100,1697105245506,1697105247168.0,120,12.0,1.0,"[212, 1450]","[1697105245718, 1697105247168]"
4145,823,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247169,1697105248696.0,120,,,[17],[1697105247186]
4146,437,6,[],200,EleutherAI/gpt-neox-20b,128,1,5972.0,1.0,1,H100,1697105202005,1697105207977.0,120,91.0,29.0,"[106, 1607, 88, 88, 87, 269, 87, 87, 83, 415, 92, 89, 88, 69, 87, 86, 389, 91, 85, 84, 731, 90, 89, 86, 80, 80, 60, 61, 618]","[1697105202111, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204424, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206813, 1697105206903, 1697105206992, 1697105207078, 1697105207158, 1697105207238, 1697105207298, 1697105207359, 1697105207977]"
4147,248,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105252036.0,120,,,[174],[1697105248873]
4148,421,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245504,1697105247242.0,120,,,[28],[1697105245532]
4149,775,20,[],200,EleutherAI/gpt-neox-20b,128,1,2430.0,1.0,1,H100,1697105247250,1697105249680.0,120,17.0,1.0,"[165, 2265]","[1697105247415, 1697105249680]"
4150,205,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105249681,1697105252037.0,120,,,[5],[1697105249686]
4151,566,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252042,1697105253712.0,120,,,[261],[1697105252303]
4152,924,13,[],200,EleutherAI/gpt-neox-20b,128,1,2338.0,1.0,1,H100,1697105219565,1697105221903.0,120,9.0,1.0,"[5, 2333]","[1697105219570, 1697105221903]"
4153,392,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228784,1697105230476.0,120,,,[291],[1697105229075]
4154,357,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105221904,1697105228772.0,120,,,"[24, 2329, 90, 70, 88, 87, 68, 579, 82, 78, 74, 74, 706, 90, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105221928, 1697105224257, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226253, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
4155,86,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[264],[1697105253980]
4156,750,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105234918.0,120,,,"[207, 2371, 600, 617]","[1697105230685, 1697105233056, 1697105233656, 1697105234273]"
4157,899,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228173,1697105232145.0,120,,,"[4, 2339, 989, 76, 75, 74, 73]","[1697105228177, 1697105230516, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
4158,469,17,[],200,EleutherAI/gpt-neox-20b,128,1,2258.0,1.0,1,H100,1697105221904,1697105224162.0,120,17.0,1.0,"[25, 2233]","[1697105221929, 1697105224162]"
4159,445,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258914.0,120,,,[32],[1697105256045]
4160,803,25,[],200,EleutherAI/gpt-neox-20b,128,1,2505.0,1.0,1,H100,1697105258925,1697105261430.0,120,20.0,1.0,"[180, 2325]","[1697105259105, 1697105261430]"
4161,224,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105261431,1697105264082.0,120,,,[5],[1697105261436]
4162,821,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260464,1697105262306.0,120,,,[36],[1697105260500]
4163,327,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233609.0,120,,,[28],[1697105232178]
4164,64,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268916,1697105270302.0,120,,,[13],[1697105268929]
4165,685,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233610,1697105234919.0,120,,,[56],[1697105233666]
4166,583,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265928.0,120,,,[91],[1697105264176]
4167,831,18,[],200,EleutherAI/gpt-neox-20b,128,1,981.0,1.0,1,H100,1697105224163,1697105225144.0,120,11.0,1.0,"[12, 969]","[1697105224175, 1697105225144]"
4168,232,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225145,1697105228773.0,120,,,"[25, 1893, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105225170, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
4169,39,46,[],200,EleutherAI/gpt-neox-20b,128,1,1664.0,1.0,1,H100,1697105272750,1697105274414.0,120,8.0,1.0,"[20, 1644]","[1697105272770, 1697105274414]"
4170,86,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236782.0,120,,,[77],[1697105234999]
4171,911,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265934,1697105271973.0,120,,,"[168, 2876, 669, 704, 685]","[1697105266102, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
4172,12,28,[],200,EleutherAI/gpt-neox-20b,128,1,1503.0,1.0,1,H100,1697105249682,1697105251185.0,120,11.0,1.0,"[20, 1482]","[1697105249702, 1697105251184]"
4173,345,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271978,1697105275207.0,120,,,[229],[1697105272207]
4174,370,29,[],200,EleutherAI/gpt-neox-20b,128,1,1379.0,1.0,1,H100,1697105251186,1697105252565.0,120,31.0,1.0,"[36, 1343]","[1697105251222, 1697105252565]"
4175,444,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236785,1697105240330.0,120,,,[230],[1697105237015]
4176,397,47,[],200,EleutherAI/gpt-neox-20b,128,1,1529.0,1.0,1,H100,1697105274415,1697105275944.0,120,67.0,2.0,"[13, 1516]","[1697105274428, 1697105275944]"
4177,801,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240333,1697105241995.0,120,,,[54],[1697105240387]
4178,730,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252566,1697105256010.0,120,,,"[8, 2484]","[1697105252574, 1697105255058]"
4179,395,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270306,1697105271972.0,120,,,[26],[1697105270332]
4180,232,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243753.0,120,,,[82],[1697105242083]
4181,748,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271975,1697105273584.0,120,,,[35],[1697105272010]
4182,129,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256016,1697105258913.0,120,,,[182],[1697105256198]
4183,483,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258917,1697105260462.0,120,,,[76],[1697105258993]
4184,593,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228783,1697105230475.0,120,,,[199],[1697105228982]
4185,659,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232154,1697105234225.0,120,,,[229],[1697105232383]
4186,24,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105232145.0,120,,,"[32, 996, 75, 75, 74, 73]","[1697105230510, 1697105231506, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
4187,378,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232147,1697105233608.0,120,,,[8],[1697105232155]
4188,94,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232151,1697105234225.0,120,,,[136],[1697105232287]
4189,593,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243757,1697105245502.0,120,,,[130],[1697105243887]
4190,731,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233609,1697105234918.0,120,,,[13],[1697105233622]
4191,455,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234226,1697105236781.0,120,,,[28],[1697105234254]
4192,501,35,[],200,EleutherAI/gpt-neox-20b,128,1,827.0,1.0,1,H100,1697105262244,1697105263071.0,120,19.0,1.0,"[13, 814]","[1697105262257, 1697105263071]"
4193,920,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105247243.0,120,,,[183],[1697105245689]
4194,44,46,[],200,EleutherAI/gpt-neox-20b,128,1,1543.0,1.0,1,H100,1697105273589,1697105275132.0,120,12.0,1.0,"[197, 1346]","[1697105273786, 1697105275132]"
4195,175,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234226,1697105236781.0,120,,,[40],[1697105234266]
4196,348,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247250,1697105250347.0,120,,,[233],[1697105247483]
4197,701,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250354,1697105252038.0,120,,,[227],[1697105250581]
4198,136,32,[],200,EleutherAI/gpt-neox-20b,128,1,1640.0,1.0,1,H100,1697105252042,1697105253682.0,120,31.0,1.0,"[256, 1384]","[1697105252298, 1697105253682]"
4199,493,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253685,1697105256010.0,120,,,"[11, 1362]","[1697105253696, 1697105255058]"
4200,448,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247248,1697105250347.0,120,,,[155],[1697105247403]
4201,528,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236785,1697105240330.0,120,,,[209],[1697105236994]
4202,826,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258915.0,120,,,[64],[1697105256077]
4203,891,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240333,1697105241994.0,120,,,[263],[1697105240596]
4204,855,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263072,1697105265927.0,120,,,[21],[1697105263093]
4205,807,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250350,1697105252038.0,120,,,[11],[1697105250361]
4206,320,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243755.0,120,,,[210],[1697105242211]
4207,681,21,[],200,EleutherAI/gpt-neox-20b,128,1,2438.0,1.0,1,H100,1697105243758,1697105246196.0,120,23.0,1.0,"[311, 2127]","[1697105244069, 1697105246196]"
4208,132,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236782.0,120,,,[53],[1697105234975]
4209,82,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105246197,1697105248696.0,120,,,[17],[1697105246214]
4210,493,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105240330.0,120,,,[198],[1697105236982]
4211,40,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105258912.0,120,,,[86],[1697105257204]
4212,236,29,[],200,EleutherAI/gpt-neox-20b,128,1,1638.0,1.0,1,H100,1697105252044,1697105253682.0,120,8.0,1.0,"[275, 1363]","[1697105252319, 1697105253682]"
4213,256,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258925,1697105262306.0,120,,,[245],[1697105259170]
4214,597,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253686,1697105255028.0,120,,,[87],[1697105253773]
4215,854,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240333,1697105241994.0,120,,,[38],[1697105240371]
4216,370,39,[],200,EleutherAI/gpt-neox-20b,128,1,1521.0,1.0,1,H100,1697105258916,1697105260437.0,120,31.0,1.0,"[20, 1501]","[1697105258936, 1697105260437]"
4217,437,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105252036.0,120,,,[110],[1697105248809]
4218,284,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267796.0,120,,,[62],[1697105265993]
4219,121,20,[],200,EleutherAI/gpt-neox-20b,128,1,1809.0,1.0,1,H100,1697105225145,1697105226954.0,120,13.0,1.0,"[29, 1779]","[1697105225174, 1697105226953]"
4220,483,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226955,1697105228773.0,120,,,[8],[1697105226963]
4221,610,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262310,1697105264083.0,120,,,[85],[1697105262395]
4222,285,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243754.0,120,,,[187],[1697105242188]
4223,35,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264087,1697105265928.0,120,,,[192],[1697105264279]
4224,229,8,[],200,EleutherAI/gpt-neox-20b,128,1,2463.0,1.0,1,H100,1697105204251,1697105206714.0,120,15.0,1.0,"[13, 2450]","[1697105204264, 1697105206714]"
4225,2,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[60],[1697105255090]
4226,791,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252039,1697105253711.0,120,,,[135],[1697105252174]
4227,837,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228783,1697105230475.0,120,,,[215],[1697105228998]
4228,393,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265937,1697105271972.0,120,,,"[269, 2772, 669, 704, 685]","[1697105266206, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
4229,266,23,[],200,EleutherAI/gpt-neox-20b,128,1,2516.0,1.0,1,H100,1697105230479,1697105232995.0,120,9.0,1.0,"[214, 2301]","[1697105230693, 1697105232994]"
4230,708,24,[],200,EleutherAI/gpt-neox-20b,128,1,1886.0,1.0,1,H100,1697105232996,1697105234882.0,120,140.0,1.0,"[16, 1870]","[1697105233012, 1697105234882]"
4231,640,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105270302.0,120,,,[200],[1697105268001]
4232,138,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234883,1697105236781.0,120,,,[5],[1697105234888]
4233,4,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234226,1697105236781.0,120,,,[37],[1697105234263]
4234,582,9,[],200,EleutherAI/gpt-neox-20b,128,1,1827.0,1.0,1,H100,1697105206715,1697105208542.0,120,19.0,1.0,"[25, 1801]","[1697105206740, 1697105208541]"
4235,842,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271975,1697105273584.0,120,,,[6],[1697105271981]
4236,363,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236785,1697105240330.0,120,,,[298],[1697105237083]
4237,221,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105255027.0,120,,,[111],[1697105253825]
4238,720,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240367,1697105243753.0,120,,,[245],[1697105240612]
4239,582,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255029,1697105257113.0,120,,,[34],[1697105255063]
4240,72,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270308,1697105271972.0,120,,,[44],[1697105270352]
4241,912,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258907.0,120,,,[22],[1697105257139]
4242,516,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271976,1697105273585.0,120,,,[126],[1697105272102]
4243,272,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273588,1697105275208.0,120,,,[110],[1697105273698]
4244,7,10,[],200,EleutherAI/gpt-neox-20b,128,1,4349.0,1.0,1,H100,1697105208542,1697105212891.0,120,345.0,11.0,"[9, 2763, 168, 77, 456, 89, 80, 79, 75, 72, 481]","[1697105208551, 1697105211314, 1697105211482, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891]"
4245,876,41,[],200,EleutherAI/gpt-neox-20b,128,1,2309.0,1.0,1,H100,1697105273589,1697105275898.0,120,11.0,1.0,"[221, 2088]","[1697105273810, 1697105275898]"
4246,142,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243757,1697105245502.0,120,,,[111],[1697105243868]
4247,472,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105247243.0,120,,,[191],[1697105245697]
4248,829,30,[],200,EleutherAI/gpt-neox-20b,128,1,2430.0,1.0,1,H100,1697105247251,1697105249681.0,120,20.0,1.0,"[220, 2210]","[1697105247471, 1697105249681]"
4249,265,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105249682,1697105252037.0,120,,,[37],[1697105249719]
4250,625,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252039,1697105253711.0,120,,,[147],[1697105252186]
4251,140,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105255028.0,120,,,[192],[1697105253906]
4252,499,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236783,1697105238408.0,120,,,[94],[1697105236877]
4253,500,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257115.0,120,,,[145],[1697105255175]
4254,857,27,[],200,EleutherAI/gpt-neox-20b,128,1,1854.0,1.0,1,H100,1697105238411,1697105240265.0,120,18.0,1.0,"[160, 1694]","[1697105238571, 1697105240265]"
4255,650,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105255028.0,120,,,[211],[1697105253927]
4256,453,11,[],200,EleutherAI/gpt-neox-20b,128,1,1435.0,1.0,1,H100,1697105212892,1697105214327.0,120,26.0,1.0,"[9, 1426]","[1697105212901, 1697105214327]"
4257,80,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[49],[1697105255079]
4258,814,12,[],200,EleutherAI/gpt-neox-20b,128,1,5557.0,1.0,1,H100,1697105214328,1697105219885.0,120,89.0,20.0,"[8, 2568, 85, 66, 385, 89, 87, 406, 88, 81, 256, 79, 368, 81, 59, 366, 84, 80, 259, 62]","[1697105214336, 1697105216904, 1697105216989, 1697105217055, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218110, 1697105218191, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219484, 1697105219564, 1697105219823, 1697105219885]"
4259,262,28,[],200,EleutherAI/gpt-neox-20b,128,1,938.0,1.0,1,H100,1697105240267,1697105241205.0,120,39.0,1.0,"[36, 902]","[1697105240303, 1697105241205]"
4260,615,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245428,1697105247242.0,120,,,[12],[1697105245440]
4261,47,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247251,1697105250347.0,120,,,[224],[1697105247475]
4262,850,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105260462.0,120,,,[250],[1697105257368]
4263,279,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260465,1697105262306.0,120,,,[107],[1697105260572]
4264,407,31,[],200,EleutherAI/gpt-neox-20b,128,1,1660.0,1.0,1,H100,1697105250351,1697105252011.0,120,16.0,1.0,"[17, 1643]","[1697105250368, 1697105252011]"
4265,638,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262311,1697105264083.0,120,,,[96],[1697105262407]
4266,169,35,[],200,EleutherAI/gpt-neox-20b,128,1,1523.0,1.0,1,H100,1697105258915,1697105260438.0,120,10.0,1.0,"[52, 1471]","[1697105258967, 1697105260438]"
4267,616,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241208,1697105243754.0,120,,,[31],[1697105241239]
4268,44,38,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105264087,1697105265863.0,120,12.0,1.0,"[224, 1552]","[1697105264311, 1697105265863]"
4269,501,36,[],200,EleutherAI/gpt-neox-20b,128,1,992.0,1.0,1,H100,1697105260439,1697105261431.0,120,19.0,1.0,"[16, 976]","[1697105260455, 1697105261431]"
4270,760,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252012,1697105253711.0,120,,,[21],[1697105252033]
4271,864,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105261432,1697105264083.0,120,,,[24],[1697105261456]
4272,44,30,[],200,EleutherAI/gpt-neox-20b,128,1,1670.0,1.0,1,H100,1697105243757,1697105245427.0,120,12.0,1.0,"[11, 1659]","[1697105243768, 1697105245427]"
4273,293,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264086,1697105265928.0,120,,,[196],[1697105264282]
4274,583,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248695.0,120,,,[67],[1697105247314]
4275,185,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253715,1697105255028.0,120,,,[183],[1697105253898]
4276,714,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242000,1697105243755.0,120,,,[7],[1697105242007]
4277,462,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105255028.0,120,,,[88],[1697105253802]
4278,796,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[73],[1697105255103]
4279,401,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265865,1697105267795.0,120,,,[34],[1697105265899]
4280,227,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105260463.0,120,,,[158],[1697105257276]
4281,761,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[86],[1697105267884]
4282,915,28,[],200,EleutherAI/gpt-neox-20b,128,1,1624.0,1.0,1,H100,1697105248698,1697105250322.0,120,182.0,1.0,"[95, 1529]","[1697105248793, 1697105250322]"
4283,347,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250323,1697105252037.0,120,,,[12],[1697105250335]
4284,706,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252042,1697105253711.0,120,,,[164],[1697105252206]
4285,113,24,[],200,EleutherAI/gpt-neox-20b,128,1,2438.0,1.0,1,H100,1697105243758,1697105246196.0,120,13.0,1.0,"[270, 2168]","[1697105244028, 1697105246196]"
4286,131,31,[],200,EleutherAI/gpt-neox-20b,128,1,2229.0,1.0,1,H100,1697105253716,1697105255945.0,120,8.0,1.0,"[303, 1926]","[1697105254019, 1697105255945]"
4287,491,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255949,1697105257115.0,120,,,[38],[1697105255987]
4288,186,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269599,1697105270988.0,120,,,[17],[1697105269616]
4289,585,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260467,1697105262307.0,120,,,[226],[1697105260693]
4290,816,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105260463.0,120,,,[170],[1697105257288]
4291,124,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268916,1697105270302.0,120,,,[5],[1697105268921]
4292,647,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265935,1697105271974.0,120,,,"[239, 2804, 669, 704, 685]","[1697105266174, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
4293,542,42,[],200,EleutherAI/gpt-neox-20b,128,1,1758.0,1.0,1,H100,1697105270990,1697105272748.0,120,11.0,1.0,"[80, 1678]","[1697105271070, 1697105272748]"
4294,515,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257115.0,120,,,[89],[1697105255119]
4295,464,25,[],200,EleutherAI/gpt-neox-20b,128,1,1811.0,1.0,1,H100,1697105246198,1697105248009.0,120,12.0,1.0,"[36, 1775]","[1697105246234, 1697105248009]"
4296,877,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105258913.0,120,,,[154],[1697105257272]
4297,309,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258921,1697105262305.0,120,,,[172],[1697105259093]
4298,366,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105247242.0,120,,,[61],[1697105245567]
4299,56,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262310,1697105264083.0,120,,,[89],[1697105262399]
4300,77,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271978,1697105275207.0,120,,,[305],[1697105272283]
4301,668,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262310,1697105264082.0,120,,,[17],[1697105262327]
4302,389,25,[],200,EleutherAI/gpt-neox-20b,128,1,1485.0,1.0,1,H100,1697105241206,1697105242691.0,120,8.0,1.0,"[25, 1460]","[1697105241231, 1697105242691]"
4303,823,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248010,1697105250348.0,120,,,[9],[1697105248019]
4304,871,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105272749,1697105275208.0,120,,,[13],[1697105272762]
4305,252,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250349,1697105252037.0,120,,,[64],[1697105250413]
4306,105,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234227,1697105236782.0,120,,,[52],[1697105234279]
4307,414,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265928.0,120,,,[23],[1697105264108]
4308,613,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252042,1697105253711.0,120,,,[177],[1697105252219]
4309,134,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253715,1697105255028.0,120,,,[188],[1697105253903]
4310,773,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265934,1697105271973.0,120,,,"[172, 2872, 669, 704, 685]","[1697105266106, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
4311,607,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253712.0,120,,,[32],[1697105252073]
4312,492,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257113.0,120,,,[146],[1697105255176]
4313,897,24,[],200,EleutherAI/gpt-neox-20b,128,1,1601.0,1.0,1,H100,1697105236784,1697105238385.0,120,9.0,1.0,"[102, 1499]","[1697105236886, 1697105238385]"
4314,119,27,[],200,EleutherAI/gpt-neox-20b,128,1,2228.0,1.0,1,H100,1697105253716,1697105255944.0,120,31.0,1.0,"[262, 1966]","[1697105253978, 1697105255944]"
4315,150,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248698,1697105250348.0,120,,,[79],[1697105248777]
4316,479,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252037.0,120,,,[130],[1697105250481]
4317,480,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255949,1697105257115.0,120,,,[30],[1697105255979]
4318,834,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252042,1697105253712.0,120,,,[265],[1697105252307]
4319,266,32,[],200,EleutherAI/gpt-neox-20b,128,1,2228.0,1.0,1,H100,1697105253716,1697105255944.0,120,9.0,1.0,"[218, 2010]","[1697105253934, 1697105255944]"
4320,331,25,[],200,EleutherAI/gpt-neox-20b,128,1,953.0,1.0,1,H100,1697105238386,1697105239339.0,120,26.0,1.0,"[16, 937]","[1697105238402, 1697105239339]"
4321,688,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105239340,1697105241995.0,120,,,[21],[1697105239361]
4322,120,27,[],200,EleutherAI/gpt-neox-20b,128,1,1547.0,1.0,1,H100,1697105242007,1697105243554.0,120,17.0,1.0,"[265, 1282]","[1697105242272, 1697105243554]"
4323,623,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255945,1697105257114.0,120,,,[11],[1697105255956]
4324,446,28,[],200,EleutherAI/gpt-neox-20b,128,1,922.0,1.0,1,H100,1697105243555,1697105244477.0,120,26.0,1.0,"[48, 874]","[1697105243603, 1697105244477]"
4325,839,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105258913.0,120,,,[194],[1697105257312]
4326,804,29,[],200,EleutherAI/gpt-neox-20b,128,1,1718.0,1.0,1,H100,1697105244478,1697105246196.0,120,20.0,1.0,"[17, 1701]","[1697105244495, 1697105246196]"
4327,272,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258917,1697105262306.0,120,,,[260],[1697105259177]
4328,145,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105258913.0,120,,,[82],[1697105257200]
4329,229,30,[],200,EleutherAI/gpt-neox-20b,128,1,1811.0,1.0,1,H100,1697105246198,1697105248009.0,120,15.0,1.0,"[40, 1771]","[1697105246238, 1697105248009]"
4330,589,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248010,1697105250348.0,120,,,[21],[1697105248031]
4331,498,35,[],200,EleutherAI/gpt-neox-20b,128,1,1521.0,1.0,1,H100,1697105258917,1697105260438.0,120,9.0,1.0,"[92, 1429]","[1697105259009, 1697105260438]"
4332,341,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262313,1697105264082.0,120,,,[195],[1697105262508]
4333,21,32,[],200,EleutherAI/gpt-neox-20b,128,1,1660.0,1.0,1,H100,1697105250351,1697105252011.0,120,15.0,1.0,"[134, 1526]","[1697105250485, 1697105252011]"
4334,469,33,[],200,EleutherAI/gpt-neox-20b,128,1,1668.0,1.0,1,H100,1697105252013,1697105253681.0,120,17.0,1.0,"[36, 1632]","[1697105252049, 1697105253681]"
4335,856,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260439,1697105262307.0,120,,,[37],[1697105260476]
4336,287,37,[],200,EleutherAI/gpt-neox-20b,128,1,1678.0,1.0,1,H100,1697105262312,1697105263990.0,120,10.0,1.0,"[103, 1575]","[1697105262415, 1697105263990]"
4337,348,13,[],200,EleutherAI/gpt-neox-20b,128,1,5187.0,1.0,1,H100,1697105204251,1697105209438.0,120,91.0,20.0,"[5, 2558, 89, 89, 86, 81, 79, 60, 61, 618, 86, 83, 82, 63, 435, 87, 84, 79, 78, 384]","[1697105204256, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208291, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209054, 1697105209438]"
4338,569,23,[],200,EleutherAI/gpt-neox-20b,128,1,1834.0,1.0,1,H100,1697105234922,1697105236756.0,120,16.0,1.0,"[73, 1761]","[1697105234995, 1697105236756]"
4339,828,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253687,1697105255028.0,120,,,[94],[1697105253781]
4340,547,27,[],200,EleutherAI/gpt-neox-20b,128,1,1854.0,1.0,1,H100,1697105238412,1697105240266.0,120,12.0,1.0,"[163, 1690]","[1697105238575, 1697105240265]"
4341,700,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265928.0,120,,,[6],[1697105264091]
4342,257,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[64],[1697105255094]
4343,612,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105258913.0,120,,,[81],[1697105257199]
4344,37,37,[],200,EleutherAI/gpt-neox-20b,128,1,2505.0,1.0,1,H100,1697105258925,1697105261430.0,120,20.0,1.0,"[249, 2256]","[1697105259174, 1697105261430]"
4345,365,38,[],200,EleutherAI/gpt-neox-20b,128,1,1639.0,1.0,1,H100,1697105261432,1697105263071.0,120,23.0,1.0,"[16, 1623]","[1697105261448, 1697105263071]"
4346,644,38,[],200,EleutherAI/gpt-neox-20b,128,1,1013.0,1.0,1,H100,1697105263992,1697105265005.0,120,19.0,1.0,"[52, 960]","[1697105264044, 1697105265004]"
4347,729,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263072,1697105265927.0,120,,,[8],[1697105263080]
4348,161,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267795.0,120,,,[6],[1697105265937]
4349,907,28,[],200,EleutherAI/gpt-neox-20b,128,1,938.0,1.0,1,H100,1697105240267,1697105241205.0,120,10.0,1.0,"[61, 877]","[1697105240328, 1697105241205]"
4350,46,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265006,1697105267795.0,120,,,[5],[1697105265011]
4351,129,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265937,1697105271972.0,120,,,"[274, 2767, 669, 704, 685]","[1697105266211, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
4352,681,13,[],200,EleutherAI/gpt-neox-20b,128,1,2313.0,1.0,1,H100,1697105208815,1697105211128.0,120,23.0,1.0,"[12, 2301]","[1697105208827, 1697105211128]"
4353,519,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[30],[1697105267828]
4354,111,14,[],200,EleutherAI/gpt-neox-20b,128,1,2021.0,1.0,1,H100,1697105211129,1697105213150.0,120,79.0,5.0,"[5, 1757, 88, 89, 82]","[1697105211134, 1697105212891, 1697105212979, 1697105213068, 1697105213150]"
4355,647,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253715,1697105255027.0,120,,,[160],[1697105253875]
4356,426,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241206,1697105243753.0,120,,,[21],[1697105241227]
4357,486,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271976,1697105273585.0,120,,,[122],[1697105272098]
4358,849,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269601,1697105270988.0,120,,,[88],[1697105269689]
4359,453,37,[],200,EleutherAI/gpt-neox-20b,128,1,1321.0,1.0,1,H100,1697105265865,1697105267186.0,120,26.0,1.0,"[38, 1283]","[1697105265903, 1697105267186]"
4360,845,41,[],200,EleutherAI/gpt-neox-20b,128,1,3779.0,1.0,1,H100,1697105273589,1697105277368.0,120,244.0,50.0,"[201, 2154, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 33, 32, 32, 33, 29, 28, 28, 28, 32, 27, 27, 27, 27, 31, 26, 26, 29, 26, 26, 28, 25, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25]","[1697105273790, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276502, 1697105276534, 1697105276566, 1697105276599, 1697105276628, 1697105276656, 1697105276684, 1697105276712, 1697105276744, 1697105276771, 1697105276798, 1697105276825, 1697105276852, 1697105276883, 1697105276909, 1697105276935, 1697105276964, 1697105276990, 1697105277016, 1697105277044, 1697105277069, 1697105277093, 1697105277118, 1697105277143, 1697105277168, 1697105277193, 1697105277218, 1697105277243, 1697105277268, 1697105277293, 1697105277318, 1697105277343, 1697105277368]"
4361,163,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[48],[1697105255078]
4362,803,38,[],200,EleutherAI/gpt-neox-20b,128,1,1727.0,1.0,1,H100,1697105267188,1697105268915.0,120,20.0,1.0,"[24, 1703]","[1697105267212, 1697105268915]"
4363,233,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268917,1697105270302.0,120,,,[16],[1697105268933]
4364,465,15,[],200,EleutherAI/gpt-neox-20b,128,1,2675.0,1.0,1,H100,1697105213151,1697105215826.0,120,364.0,3.0,"[8, 2576, 91]","[1697105213159, 1697105215735, 1697105215826]"
4365,730,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243756,1697105245502.0,120,,,[56],[1697105243812]
4366,151,29,[],200,EleutherAI/gpt-neox-20b,128,1,1663.0,1.0,1,H100,1697105245505,1697105247168.0,120,39.0,1.0,"[10, 1653]","[1697105245515, 1697105247168]"
4367,820,16,[],200,EleutherAI/gpt-neox-20b,128,1,3738.0,1.0,1,H100,1697105215827,1697105219565.0,120,161.0,9.0,"[8, 2612, 79, 368, 81, 59, 366, 88, 76]","[1697105215835, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219488, 1697105219564]"
4368,562,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270305,1697105271973.0,120,,,[16],[1697105270321]
4369,510,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247169,1697105248696.0,120,,,[5],[1697105247174]
4370,524,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258915.0,120,,,[50],[1697105257167]
4371,868,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105252036.0,120,,,[178],[1697105248877]
4372,301,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253712.0,120,,,[40],[1697105252081]
4373,634,33,[],200,EleutherAI/gpt-neox-20b,128,1,2229.0,1.0,1,H100,1697105253716,1697105255945.0,120,13.0,1.0,"[278, 1950]","[1697105253994, 1697105255944]"
4374,921,41,[],200,EleutherAI/gpt-neox-20b,128,1,2436.0,1.0,1,H100,1697105271978,1697105274414.0,120,31.0,1.0,"[228, 2208]","[1697105272206, 1697105274414]"
4375,619,21,[],200,EleutherAI/gpt-neox-20b,128,1,1601.0,1.0,1,H100,1697105236784,1697105238385.0,120,10.0,1.0,"[106, 1495]","[1697105236890, 1697105238385]"
4376,216,16,[],200,EleutherAI/gpt-neox-20b,128,1,4426.0,1.0,1,H100,1697105211483,1697105215909.0,120,91.0,20.0,"[5, 1403, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 64, 76, 653, 84, 356, 90, 84]","[1697105211488, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642, 1697105215295, 1697105215379, 1697105215735, 1697105215825, 1697105215909]"
4377,62,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255948,1697105257114.0,120,,,[17],[1697105255965]
4378,49,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238386,1697105240331.0,120,,,[12],[1697105238398]
4379,403,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241994.0,120,,,[166],[1697105240500]
4380,736,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242015,1697105245502.0,120,,,[277],[1697105242292]
4381,357,42,[],200,EleutherAI/gpt-neox-20b,128,1,2520.0,1.0,1,H100,1697105274415,1697105276935.0,120,52.0,33.0,"[5, 1524, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 32, 33, 32, 33, 29, 28, 28, 28, 32, 27, 27, 27, 27, 31, 26, 26]","[1697105274420, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276501, 1697105276534, 1697105276566, 1697105276599, 1697105276628, 1697105276656, 1697105276684, 1697105276712, 1697105276744, 1697105276771, 1697105276798, 1697105276825, 1697105276852, 1697105276883, 1697105276909, 1697105276935]"
4382,422,35,[],200,EleutherAI/gpt-neox-20b,128,1,2654.0,1.0,1,H100,1697105257118,1697105259772.0,120,26.0,1.0,"[250, 2404]","[1697105257368, 1697105259772]"
4383,772,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105259773,1697105262306.0,120,,,[8],[1697105259781]
4384,201,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262310,1697105264082.0,120,,,[73],[1697105262383]
4385,165,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105248695.0,120,,,[210],[1697105245716]
4386,531,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264086,1697105265928.0,120,,,[119],[1697105264205]
4387,895,39,[],200,EleutherAI/gpt-neox-20b,128,1,2980.0,1.0,1,H100,1697105265936,1697105268916.0,120,15.0,1.0,"[274, 2705]","[1697105266210, 1697105268915]"
4388,325,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268917,1697105270302.0,120,,,[24],[1697105268941]
4389,526,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248697,1697105250348.0,120,,,[32],[1697105248729]
4390,683,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270303,1697105271973.0,120,,,[18],[1697105270321]
4391,886,27,[],200,EleutherAI/gpt-neox-20b,128,1,1660.0,1.0,1,H100,1697105250351,1697105252011.0,120,17.0,1.0,"[138, 1522]","[1697105250489, 1697105252011]"
4392,108,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271978,1697105273585.0,120,,,[96],[1697105272074]
4393,282,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252012,1697105253711.0,120,,,[21],[1697105252033]
4394,39,18,[],200,EleutherAI/gpt-neox-20b,128,1,1647.0,1.0,1,H100,1697105230478,1697105232125.0,120,8.0,1.0,"[89, 1558]","[1697105230567, 1697105232125]"
4395,435,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273590,1697105275208.0,120,,,[100],[1697105273690]
4396,22,33,[],200,EleutherAI/gpt-neox-20b,128,1,1640.0,1.0,1,H100,1697105252042,1697105253682.0,120,16.0,1.0,"[273, 1367]","[1697105252315, 1697105253682]"
4397,643,18,[],200,EleutherAI/gpt-neox-20b,128,1,2420.0,1.0,1,H100,1697105217617,1697105220037.0,120,18.0,1.0,"[9, 2410]","[1697105217626, 1697105220036]"
4398,67,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105220039,1697105228773.0,120,,,"[19, 1907, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579, 82, 77, 75, 73, 706, 91, 84, 66, 84, 486, 91, 89, 85, 582, 94, 84, 84, 83]","[1697105220058, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225546, 1697105226252, 1697105226343, 1697105226427, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227910, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
4399,351,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253685,1697105256010.0,120,,,"[25, 1348]","[1697105253710, 1697105255058]"
4400,11,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262311,1697105264083.0,120,,,[92],[1697105262403]
4401,371,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232126,1697105233608.0,120,,,[21],[1697105232147]
4402,247,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105219888,1697105228773.0,120,,,"[15, 2062, 702, 87, 85, 82, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579, 81, 78, 75, 73, 706, 91, 84, 66, 84, 486, 91, 89, 85, 582, 94, 84, 84, 83]","[1697105219903, 1697105221965, 1697105222667, 1697105222754, 1697105222839, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225320, 1697105225398, 1697105225473, 1697105225546, 1697105226252, 1697105226343, 1697105226427, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227910, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
4403,729,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233609,1697105234920.0,120,,,[5],[1697105233614]
4404,365,37,[],200,EleutherAI/gpt-neox-20b,128,1,3099.0,1.0,1,H100,1697105264087,1697105267186.0,120,23.0,1.0,"[228, 2871]","[1697105264315, 1697105267186]"
4405,357,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105226254,1697105228773.0,120,,,[16],[1697105226270]
4406,808,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228782,1697105230476.0,120,,,[212],[1697105228994]
4407,236,19,[],200,EleutherAI/gpt-neox-20b,128,1,1646.0,1.0,1,H100,1697105230479,1697105232125.0,120,8.0,1.0,"[97, 1549]","[1697105230576, 1697105232125]"
4408,414,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228257,1697105232145.0,120,,,"[4, 2255, 989, 76, 75, 74, 73]","[1697105228261, 1697105230516, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
4409,591,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232126,1697105234919.0,120,,,"[17, 913, 601, 616]","[1697105232143, 1697105233056, 1697105233657, 1697105234273]"
4410,21,21,[],200,EleutherAI/gpt-neox-20b,128,1,2970.0,1.0,1,H100,1697105234925,1697105237895.0,120,15.0,1.0,"[255, 2715]","[1697105235180, 1697105237895]"
4411,374,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105237896,1697105240331.0,120,,,[9],[1697105237905]
4412,716,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258913.0,120,,,[181],[1697105256194]
4413,704,23,[],200,EleutherAI/gpt-neox-20b,128,1,1596.0,1.0,1,H100,1697105240334,1697105241930.0,120,14.0,1.0,"[178, 1418]","[1697105240512, 1697105241930]"
4414,137,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241932,1697105243754.0,120,,,[16],[1697105241948]
4415,498,25,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105243758,1697105245427.0,120,9.0,1.0,"[14, 1655]","[1697105243772, 1697105245427]"
4416,857,26,[],200,EleutherAI/gpt-neox-20b,128,1,768.0,1.0,1,H100,1697105245428,1697105246196.0,120,18.0,1.0,"[17, 751]","[1697105245445, 1697105246196]"
4417,775,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232149,1697105233609.0,120,,,[54],[1697105232203]
4418,282,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105246197,1697105248696.0,120,,,[13],[1697105246210]
4419,611,28,[],200,EleutherAI/gpt-neox-20b,128,1,2485.0,1.0,1,H100,1697105248699,1697105251184.0,120,14.0,1.0,"[114, 2371]","[1697105248813, 1697105251184]"
4420,38,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105251185,1697105253710.0,120,,,[13],[1697105251198]
4421,146,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258918,1697105260462.0,120,,,[79],[1697105258997]
4422,398,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105255028.0,120,,,[84],[1697105253798]
4423,757,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257115.0,120,,,[90],[1697105255120]
4424,503,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260465,1697105262306.0,120,,,[111],[1697105260576]
4425,17,38,[],200,EleutherAI/gpt-neox-20b,128,1,1677.0,1.0,1,H100,1697105262313,1697105263990.0,120,23.0,1.0,"[259, 1418]","[1697105262572, 1697105263990]"
4426,370,39,[],200,EleutherAI/gpt-neox-20b,128,1,1013.0,1.0,1,H100,1697105263992,1697105265005.0,120,31.0,1.0,"[48, 965]","[1697105264040, 1697105265005]"
4427,160,32,[],200,EleutherAI/gpt-neox-20b,128,1,1732.0,1.0,1,H100,1697105257118,1697105258850.0,120,13.0,1.0,"[198, 1534]","[1697105257316, 1697105258850]"
4428,206,19,[],200,EleutherAI/gpt-neox-20b,128,1,1272.0,1.0,1,H100,1697105233610,1697105234882.0,120,16.0,1.0,"[48, 1224]","[1697105233658, 1697105234882]"
4429,514,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258851,1697105260463.0,120,,,[21],[1697105258872]
4430,728,40,[],200,EleutherAI/gpt-neox-20b,128,1,2180.0,1.0,1,H100,1697105265006,1697105267186.0,120,20.0,1.0,"[29, 2151]","[1697105265035, 1697105267186]"
4431,874,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260467,1697105262307.0,120,,,[250],[1697105260717]
4432,531,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234883,1697105236781.0,120,,,[25],[1697105234908]
4433,557,26,[],200,EleutherAI/gpt-neox-20b,128,1,1660.0,1.0,1,H100,1697105250351,1697105252011.0,120,31.0,1.0,"[29, 1631]","[1697105250380, 1697105252011]"
4434,159,41,[],200,EleutherAI/gpt-neox-20b,128,1,1728.0,1.0,1,H100,1697105267188,1697105268916.0,120,31.0,1.0,"[27, 1700]","[1697105267215, 1697105268915]"
4435,303,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262314,1697105264082.0,120,,,[257],[1697105262571]
4436,523,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268917,1697105270302.0,120,,,[32],[1697105268949]
4437,911,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252012,1697105253711.0,120,,,[5],[1697105252017]
4438,890,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236785,1697105240330.0,120,,,[294],[1697105237079]
4439,680,13,[],200,EleutherAI/gpt-neox-20b,128,1,3634.0,1.0,1,H100,1697105209516,1697105213150.0,120,123.0,11.0,"[4, 2496, 88, 80, 79, 75, 72, 481, 88, 89, 82]","[1697105209520, 1697105212016, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150]"
4440,311,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253715,1697105255028.0,120,,,[170],[1697105253885]
4441,314,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241995.0,120,,,[65],[1697105240399]
4442,660,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265928.0,120,,,[10],[1697105264095]
4443,670,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105256009.0,120,,,[12],[1697105255042]
4444,178,37,[],200,EleutherAI/gpt-neox-20b,128,1,1838.0,1.0,1,H100,1697105265934,1697105267772.0,120,11.0,1.0,"[147, 1691]","[1697105266081, 1697105267772]"
4445,675,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242004,1697105243755.0,120,,,[204],[1697105242208]
4446,106,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243758,1697105247242.0,120,,,[262],[1697105244020]
4447,554,25,[],200,EleutherAI/gpt-neox-20b,128,1,1389.0,1.0,1,H100,1697105247247,1697105248636.0,120,26.0,1.0,"[21, 1368]","[1697105247268, 1697105248636]"
4448,535,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267773,1697105271973.0,120,,,"[5, 1200, 669, 704, 685]","[1697105267778, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
4449,106,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256011,1697105258907.0,120,,,[6],[1697105256017]
4450,606,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228782,1697105230475.0,120,,,[188],[1697105228970]
4451,464,31,[],200,EleutherAI/gpt-neox-20b,128,1,2509.0,1.0,1,H100,1697105258921,1697105261430.0,120,12.0,1.0,"[260, 2249]","[1697105259181, 1697105261430]"
4452,31,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230477,1697105232146.0,120,,,"[9, 1019, 76, 75, 74, 73]","[1697105230486, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
4453,398,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271976,1697105273585.0,120,,,[114],[1697105272090]
4454,417,35,[],200,EleutherAI/gpt-neox-20b,128,1,1013.0,1.0,1,H100,1697105263991,1697105265004.0,120,17.0,1.0,"[41, 972]","[1697105264032, 1697105265004]"
4455,794,32,[],200,EleutherAI/gpt-neox-20b,128,1,1639.0,1.0,1,H100,1697105261432,1697105263071.0,120,11.0,1.0,"[20, 1619]","[1697105261452, 1697105263071]"
4456,219,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263072,1697105265927.0,120,,,[4],[1697105263076]
4457,574,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267796.0,120,,,[54],[1697105265985]
4458,811,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270989,1697105273585.0,120,,,[45],[1697105271034]
4459,3,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105270302.0,120,,,[171],[1697105267972]
4460,364,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270312,1697105271973.0,120,,,[97],[1697105270409]
4461,772,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265006,1697105267796.0,120,,,[25],[1697105265031]
4462,760,41,[],200,EleutherAI/gpt-neox-20b,128,1,4097.0,1.0,1,H100,1697105273589,1697105277686.0,120,335.0,64.0,"[222, 2133, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 33, 32, 32, 33, 29, 28, 28, 28, 32, 27, 27, 27, 27, 31, 26, 26, 29, 26, 26, 28, 25, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 24, 26, 23, 23, 23, 24, 24, 21, 22, 22, 22, 22, 22, 23, 22]","[1697105273811, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276502, 1697105276534, 1697105276566, 1697105276599, 1697105276628, 1697105276656, 1697105276684, 1697105276712, 1697105276744, 1697105276771, 1697105276798, 1697105276825, 1697105276852, 1697105276883, 1697105276909, 1697105276935, 1697105276964, 1697105276990, 1697105277016, 1697105277044, 1697105277069, 1697105277093, 1697105277118, 1697105277143, 1697105277168, 1697105277193, 1697105277218, 1697105277243, 1697105277268, 1697105277293, 1697105277318, 1697105277343, 1697105277367, 1697105277393, 1697105277416, 1697105277439, 1697105277462, 1697105277486, 1697105277510, 1697105277531, 1697105277553, 1697105277575, 1697105277597, 1697105277619, 1697105277641, 1697105277664, 1697105277686]"
4463,912,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248637,1697105250348.0,120,,,[13],[1697105248650]
4464,204,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[26],[1697105267824]
4465,339,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252037.0,120,,,[154],[1697105250505]
4466,534,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[20],[1697105269620]
4467,892,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270989,1697105273584.0,120,,,[29],[1697105271018]
4468,678,14,[],200,EleutherAI/gpt-neox-20b,128,1,4978.0,1.0,1,H100,1697105209439,1697105214417.0,120,244.0,18.0,"[20, 2557, 88, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 69, 245]","[1697105209459, 1697105212016, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214172, 1697105214417]"
4469,693,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252042,1697105253712.0,120,,,[273],[1697105252315]
4470,320,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273587,1697105275208.0,120,,,[83],[1697105273670]
4471,814,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271977,1697105273584.0,120,,,[137],[1697105272114]
4472,123,29,[],200,EleutherAI/gpt-neox-20b,128,1,2229.0,1.0,1,H100,1697105253716,1697105255945.0,120,14.0,1.0,"[304, 1925]","[1697105254020, 1697105255945]"
4473,616,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238387,1697105240331.0,120,,,[31],[1697105238418]
4474,37,29,[],200,EleutherAI/gpt-neox-20b,128,1,1597.0,1.0,1,H100,1697105240334,1697105241931.0,120,20.0,1.0,"[253, 1343]","[1697105240587, 1697105241930]"
4475,628,15,[],200,EleutherAI/gpt-neox-20b,128,1,4670.0,1.0,1,H100,1697105218896,1697105223566.0,120,732.0,10.0,"[12, 3057, 702, 87, 84, 83, 81, 401, 71, 92]","[1697105218908, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566]"
4476,240,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273588,1697105275208.0,120,,,[122],[1697105273710]
4477,55,16,[],200,EleutherAI/gpt-neox-20b,128,1,1577.0,1.0,1,H100,1697105223567,1697105225144.0,120,12.0,1.0,"[5, 1572]","[1697105223572, 1697105225144]"
4478,455,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255948,1697105257115.0,120,,,[29],[1697105255977]
4479,816,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105258913.0,120,,,[158],[1697105257276]
4480,395,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241932,1697105243754.0,120,,,[24],[1697105241956]
4481,246,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258921,1697105262305.0,120,,,[180],[1697105259101]
4482,754,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243757,1697105245503.0,120,,,[139],[1697105243896]
4483,359,32,[],200,EleutherAI/gpt-neox-20b,128,1,1732.0,1.0,1,H100,1697105257118,1697105258850.0,120,10.0,1.0,"[174, 1558]","[1697105257292, 1697105258850]"
4484,270,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270990,1697105273585.0,120,,,[100],[1697105271090]
4485,110,15,[],200,EleutherAI/gpt-neox-20b,128,1,2637.0,1.0,1,H100,1697105214418,1697105217055.0,120,96.0,4.0,"[4, 2482, 85, 66]","[1697105214422, 1697105216904, 1697105216989, 1697105217055]"
4486,629,44,[],200,EleutherAI/gpt-neox-20b,128,1,10443.0,1.0,1,H100,1697105273592,1697105284035.0,120,457.0,381.0,"[290, 2062, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 32, 33, 32, 33, 29, 28, 28, 28, 32, 27, 27, 27, 27, 31, 26, 26, 29, 26, 26, 28, 25, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 24, 25, 26, 23, 23, 24, 23, 24, 21, 22, 22, 22, 22, 22, 23, 22, 22, 20, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 19, 20, 20, 19, 20, 20, 20, 19, 20, 20, 20, 19, 20, 20, 20, 19, 20, 20, 19, 20, 20, 20, 19, 20, 20, 20, 19, 20, 20, 19, 20, 20, 20, 19, 20, 20, 20, 19, 20, 20, 19, 20, 20, 20, 19, 20, 20, 20, 19, 20, 20, 19, 20, 20, 20, 19, 20, 20, 20, 19, 20, 20, 20, 19, 20, 20, 20, 20, 19, 20, 20, 20, 19, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 19, 20, 20, 20, 20, 19, 20, 20, 20, 20, 19, 20, 20, 20, 20, 19, 20, 20, 20, 20, 19, 20, 20, 20, 20, 19, 20, 20, 20, 20, 19, 20, 20, 20, 20, 19, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20]","[1697105273882, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276501, 1697105276534, 1697105276566, 1697105276599, 1697105276628, 1697105276656, 1697105276684, 1697105276712, 1697105276744, 1697105276771, 1697105276798, 1697105276825, 1697105276852, 1697105276883, 1697105276909, 1697105276935, 1697105276964, 1697105276990, 1697105277016, 1697105277044, 1697105277069, 1697105277093, 1697105277118, 1697105277143, 1697105277168, 1697105277193, 1697105277218, 1697105277243, 1697105277268, 1697105277293, 1697105277318, 1697105277342, 1697105277367, 1697105277393, 1697105277416, 1697105277439, 1697105277463, 1697105277486, 1697105277510, 1697105277531, 1697105277553, 1697105277575, 1697105277597, 1697105277619, 1697105277641, 1697105277664, 1697105277686, 1697105277708, 1697105277728, 1697105277749, 1697105277770, 1697105277791, 1697105277812, 1697105277833, 1697105277853, 1697105277874, 1697105277895, 1697105277916, 1697105277937, 1697105277957, 1697105277978, 1697105277999, 1697105278020, 1697105278041, 1697105278062, 1697105278083, 1697105278103, 1697105278124, 1697105278145, 1697105278166, 1697105278187, 1697105278208, 1697105278229, 1697105278250, 1697105278270, 1697105278291, 1697105278312, 1697105278333, 1697105278354, 1697105278375, 1697105278396, 1697105278417, 1697105278437, 1697105278458, 1697105278479, 1697105278500, 1697105278521, 1697105278542, 1697105278563, 1697105278584, 1697105278605, 1697105278625, 1697105278646, 1697105278667, 1697105278688, 1697105278709, 1697105278730, 1697105278751, 1697105278772, 1697105278793, 1697105278814, 1697105278835, 1697105278856, 1697105278876, 1697105278895, 1697105278915, 1697105278935, 1697105278954, 1697105278974, 1697105278994, 1697105279014, 1697105279033, 1697105279053, 1697105279073, 1697105279093, 1697105279112, 1697105279132, 1697105279152, 1697105279172, 1697105279191, 1697105279211, 1697105279231, 1697105279250, 1697105279270, 1697105279290, 1697105279310, 1697105279329, 1697105279349, 1697105279369, 1697105279389, 1697105279408, 1697105279428, 1697105279448, 1697105279467, 1697105279487, 1697105279507, 1697105279527, 1697105279546, 1697105279566, 1697105279586, 1697105279606, 1697105279625, 1697105279645, 1697105279665, 1697105279684, 1697105279704, 1697105279724, 1697105279744, 1697105279763, 1697105279783, 1697105279803, 1697105279823, 1697105279842, 1697105279862, 1697105279882, 1697105279901, 1697105279921, 1697105279941, 1697105279961, 1697105279980, 1697105280000, 1697105280020, 1697105280040, 1697105280059, 1697105280079, 1697105280099, 1697105280119, 1697105280138, 1697105280158, 1697105280178, 1697105280198, 1697105280218, 1697105280237, 1697105280257, 1697105280277, 1697105280297, 1697105280316, 1697105280336, 1697105280356, 1697105280376, 1697105280396, 1697105280416, 1697105280435, 1697105280455, 1697105280475, 1697105280495, 1697105280515, 1697105280534, 1697105280554, 1697105280574, 1697105280594, 1697105280614, 1697105280633, 1697105280653, 1697105280673, 1697105280693, 1697105280713, 1697105280732, 1697105280752, 1697105280772, 1697105280792, 1697105280812, 1697105280831, 1697105280851, 1697105280871, 1697105280891, 1697105280911, 1697105280930, 1697105280950, 1697105280970, 1697105280990, 1697105281010, 1697105281029, 1697105281049, 1697105281069, 1697105281089, 1697105281109, 1697105281128, 1697105281148, 1697105281168, 1697105281188, 1697105281208, 1697105281227, 1697105281247, 1697105281267, 1697105281287, 1697105281307, 1697105281326, 1697105281346, 1697105281366, 1697105281386, 1697105281406, 1697105281426, 1697105281446, 1697105281466, 1697105281485, 1697105281505, 1697105281525, 1697105281545, 1697105281565, 1697105281585, 1697105281605, 1697105281625, 1697105281644, 1697105281664, 1697105281684, 1697105281704, 1697105281724, 1697105281744, 1697105281764, 1697105281783, 1697105281803, 1697105281823, 1697105281843, 1697105281863, 1697105281883, 1697105281903, 1697105281923, 1697105281943, 1697105281962, 1697105281982, 1697105282002, 1697105282022, 1697105282042, 1697105282062, 1697105282082, 1697105282102, 1697105282122, 1697105282141, 1697105282161, 1697105282181, 1697105282201, 1697105282221, 1697105282241, 1697105282261, 1697105282281, 1697105282301, 1697105282320, 1697105282340, 1697105282360, 1697105282380, 1697105282400, 1697105282420, 1697105282440, 1697105282460, 1697105282480, 1697105282499, 1697105282519, 1697105282539, 1697105282559, 1697105282579, 1697105282599, 1697105282619, 1697105282639, 1697105282659, 1697105282678, 1697105282698, 1697105282718, 1697105282738, 1697105282758, 1697105282778, 1697105282798, 1697105282818, 1697105282838, 1697105282858, 1697105282878, 1697105282898, 1697105282918, 1697105282938, 1697105282958, 1697105282978, 1697105282997, 1697105283017, 1697105283037, 1697105283057, 1697105283077, 1697105283097, 1697105283117, 1697105283137, 1697105283157, 1697105283177, 1697105283197, 1697105283217, 1697105283237, 1697105283257, 1697105283277, 1697105283297, 1697105283317, 1697105283337, 1697105283356, 1697105283376, 1697105283396, 1697105283416, 1697105283436, 1697105283456, 1697105283476, 1697105283496, 1697105283516, 1697105283536, 1697105283556, 1697105283576, 1697105283596, 1697105283616, 1697105283636, 1697105283656, 1697105283676, 1697105283696, 1697105283716, 1697105283736, 1697105283755, 1697105283775, 1697105283795, 1697105283815, 1697105283835, 1697105283855, 1697105283875, 1697105283895, 1697105283915, 1697105283935, 1697105283955, 1697105283975, 1697105283995, 1697105284015, 1697105284035]"
4487,471,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105217056,1697105220995.0,120,,,"[4, 2764, 62, 233, 79, 229, 82, 197]","[1697105217060, 1697105219824, 1697105219886, 1697105220119, 1697105220198, 1697105220427, 1697105220509, 1697105220706]"
4488,713,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258851,1697105260463.0,120,,,[25],[1697105258876]
4489,161,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105247242.0,120,,,[29],[1697105245535]
4490,604,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262310,1697105264082.0,120,,,[11],[1697105262321]
4491,519,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247250,1697105250347.0,120,,,[225],[1697105247475]
4492,878,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250350,1697105252036.0,120,,,[16],[1697105250366]
4493,831,17,[],200,EleutherAI/gpt-neox-20b,128,1,2312.0,1.0,1,H100,1697105220998,1697105223310.0,120,11.0,1.0,"[182, 2130]","[1697105221180, 1697105223310]"
4494,346,18,[],200,EleutherAI/gpt-neox-20b,128,1,4944.0,1.0,1,H100,1697105223311,1697105228255.0,120,85.0,20.0,"[12, 1916, 82, 77, 75, 74, 705, 91, 84, 66, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105223323, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225547, 1697105226252, 1697105226343, 1697105226427, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
4495,636,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253715,1697105255028.0,120,,,[192],[1697105253907]
4496,303,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253711.0,120,,,[177],[1697105252218]
4497,66,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[165],[1697105255195]
4498,424,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258925.0,120,,,[66],[1697105257183]
4499,788,32,[],200,EleutherAI/gpt-neox-20b,128,1,2505.0,1.0,1,H100,1697105258926,1697105261431.0,120,31.0,1.0,"[272, 2233]","[1697105259198, 1697105261431]"
4500,720,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248694.0,120,,,[39],[1697105247286]
4501,659,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[280],[1697105253996]
4502,153,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248698,1697105250348.0,120,,,[75],[1697105248773]
4503,305,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105261432,1697105264083.0,120,,,[28],[1697105261460]
4504,663,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264087,1697105265928.0,120,,,[199],[1697105264286]
4505,89,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265937,1697105271972.0,120,,,"[285, 2756, 669, 704, 685]","[1697105266222, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
4506,697,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228257,1697105232145.0,120,,,"[16, 2242, 990, 76, 75, 74, 73]","[1697105228273, 1697105230515, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
4507,444,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271975,1697105273585.0,120,,,[39],[1697105272014]
4508,363,9,[],200,EleutherAI/gpt-neox-20b,128,1,5856.0,1.0,1,H100,1697105209439,1697105215295.0,120,286.0,22.0,"[8, 2568, 89, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 65, 75, 652]","[1697105209447, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294]"
4509,159,21,[],200,EleutherAI/gpt-neox-20b,128,1,2972.0,1.0,1,H100,1697105234923,1697105237895.0,120,31.0,1.0,"[257, 2715]","[1697105235180, 1697105237895]"
4510,483,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252038.0,120,,,[218],[1697105250569]
4511,801,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273587,1697105275208.0,120,,,[87],[1697105273674]
4512,180,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234921,1697105236781.0,120,,,[22],[1697105234943]
4513,517,22,[],200,EleutherAI/gpt-neox-20b,128,1,1442.0,1.0,1,H100,1697105237897,1697105239339.0,120,15.0,1.0,"[23, 1419]","[1697105237920, 1697105239339]"
4514,874,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105239340,1697105241993.0,120,,,[41],[1697105239381]
4515,276,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105245502.0,120,,,[271],[1697105242272]
4516,198,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271978,1697105273585.0,120,,,[100],[1697105272078]
4517,633,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245504,1697105247243.0,120,,,[100],[1697105245604]
4518,63,26,[],200,EleutherAI/gpt-neox-20b,128,1,2426.0,1.0,1,H100,1697105247255,1697105249681.0,120,39.0,1.0,"[248, 2178]","[1697105247503, 1697105249681]"
4519,844,32,[],200,EleutherAI/gpt-neox-20b,128,1,1640.0,1.0,1,H100,1697105252042,1697105253682.0,120,10.0,1.0,"[282, 1358]","[1697105252324, 1697105253682]"
4520,529,37,[],200,EleutherAI/gpt-neox-20b,128,1,1543.0,1.0,1,H100,1697105273589,1697105275132.0,120,10.0,1.0,"[129, 1414]","[1697105273718, 1697105275132]"
4521,273,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253687,1697105255028.0,120,,,[103],[1697105253790]
4522,846,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260464,1697105262306.0,120,,,[40],[1697105260504]
4523,181,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273587,1697105275207.0,120,,,[14],[1697105273601]
4524,71,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232149,1697105233609.0,120,,,[29],[1697105232178]
4525,429,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233610,1697105234919.0,120,,,[60],[1697105233670]
4526,109,14,[],200,EleutherAI/gpt-neox-20b,128,1,5297.0,1.0,1,H100,1697105213151,1697105218448.0,120,90.0,20.0,"[4, 2140, 85, 355, 90, 84, 510, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 88, 81, 257]","[1697105213155, 1697105215295, 1697105215380, 1697105215735, 1697105215825, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218110, 1697105218191, 1697105218448]"
4527,636,11,[],200,EleutherAI/gpt-neox-20b,128,1,2016.0,1.0,1,H100,1697105219887,1697105221903.0,120,31.0,1.0,"[12, 2004]","[1697105219899, 1697105221903]"
4528,783,21,[],200,EleutherAI/gpt-neox-20b,128,1,2970.0,1.0,1,H100,1697105234925,1697105237895.0,120,286.0,1.0,"[259, 2711]","[1697105235184, 1697105237895]"
4529,86,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236757,1697105238408.0,120,,,[25],[1697105236782]
4530,798,7,[],200,EleutherAI/gpt-neox-20b,128,1,3581.0,1.0,1,H100,1697105207978,1697105211559.0,120,79.0,6.0,"[4, 2822, 83, 427, 168, 77]","[1697105207982, 1697105210804, 1697105210887, 1697105211314, 1697105211482, 1697105211559]"
4531,208,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105237896,1697105240331.0,120,,,[13],[1697105237909]
4532,229,8,[],200,EleutherAI/gpt-neox-20b,128,1,1233.0,1.0,1,H100,1697105211561,1697105212794.0,120,15.0,1.0,"[8, 1225]","[1697105211569, 1697105212794]"
4533,568,23,[],200,EleutherAI/gpt-neox-20b,128,1,1596.0,1.0,1,H100,1697105240334,1697105241930.0,120,11.0,1.0,"[162, 1434]","[1697105240496, 1697105241930]"
4534,896,24,[],200,EleutherAI/gpt-neox-20b,128,1,760.0,1.0,1,H100,1697105241931,1697105242691.0,120,15.0,1.0,"[13, 747]","[1697105241944, 1697105242691]"
4535,628,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257115.0,120,,,[142],[1697105255172]
4536,332,25,[],200,EleutherAI/gpt-neox-20b,128,1,1785.0,1.0,1,H100,1697105242692,1697105244477.0,120,39.0,1.0,"[24, 1761]","[1697105242716, 1697105244477]"
4537,586,9,[],200,EleutherAI/gpt-neox-20b,128,1,5652.0,1.0,1,H100,1697105212795,1697105218447.0,120,85.0,20.0,"[13, 2486, 86, 355, 90, 84, 510, 89, 67, 83, 247, 84, 65, 386, 89, 87, 406, 87, 82, 256]","[1697105212808, 1697105215294, 1697105215380, 1697105215735, 1697105215825, 1697105215909, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216905, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218447]"
4538,691,26,[],200,EleutherAI/gpt-neox-20b,128,1,1718.0,1.0,1,H100,1697105244478,1697105246196.0,120,47.0,1.0,"[17, 1701]","[1697105244495, 1697105246196]"
4539,53,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105260462.0,120,,,[258],[1697105257376]
4540,120,27,[],200,EleutherAI/gpt-neox-20b,128,1,1811.0,1.0,1,H100,1697105246198,1697105248009.0,120,17.0,1.0,"[36, 1775]","[1697105246234, 1697105248009]"
4541,499,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260464,1697105262306.0,120,,,[48],[1697105260512]
4542,503,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225145,1697105228773.0,120,,,"[17, 1091, 90, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105225162, 1697105226253, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
4543,470,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248010,1697105250348.0,120,,,[13],[1697105248023]
4544,916,29,[],200,EleutherAI/gpt-neox-20b,128,1,1660.0,1.0,1,H100,1697105250351,1697105252011.0,120,8.0,1.0,"[142, 1518]","[1697105250493, 1697105252011]"
4545,158,12,[],200,EleutherAI/gpt-neox-20b,128,1,5339.0,1.0,1,H100,1697105221904,1697105227243.0,120,85.0,20.0,"[20, 2333, 90, 70, 88, 87, 68, 579, 82, 78, 74, 74, 706, 90, 85, 65, 84, 486, 91, 89]","[1697105221924, 1697105224257, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226253, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243]"
4546,345,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252012,1697105253711.0,120,,,[17],[1697105252029]
4547,783,30,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105243758,1697105245427.0,120,286.0,1.0,"[146, 1523]","[1697105243904, 1697105245427]"
4548,218,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245428,1697105247242.0,120,,,[12],[1697105245440]
4549,470,15,[],200,EleutherAI/gpt-neox-20b,128,1,2258.0,1.0,1,H100,1697105218448,1697105220706.0,120,39.0,2.0,"[13, 2245]","[1697105218461, 1697105220706]"
4550,704,31,[],200,EleutherAI/gpt-neox-20b,128,1,2229.0,1.0,1,H100,1697105253716,1697105255945.0,120,14.0,1.0,"[286, 1942]","[1697105254002, 1697105255944]"
4551,797,16,[],200,EleutherAI/gpt-neox-20b,128,1,1196.0,1.0,1,H100,1697105220707,1697105221903.0,120,26.0,1.0,"[9, 1187]","[1697105220716, 1697105221903]"
4552,140,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255948,1697105257114.0,120,,,[23],[1697105255971]
4553,861,37,[],200,EleutherAI/gpt-neox-20b,128,1,1676.0,1.0,1,H100,1697105262314,1697105263990.0,120,10.0,1.0,"[286, 1390]","[1697105262600, 1697105263990]"
4554,572,32,[],200,EleutherAI/gpt-neox-20b,128,1,2426.0,1.0,1,H100,1697105247255,1697105249681.0,120,16.0,1.0,"[244, 2182]","[1697105247499, 1697105249681]"
4555,887,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258925,1697105262306.0,120,,,[193],[1697105259118]
4556,469,33,[],200,EleutherAI/gpt-neox-20b,128,1,1732.0,1.0,1,H100,1697105257118,1697105258850.0,120,17.0,1.0,"[170, 1562]","[1697105257288, 1697105258850]"
4557,225,17,[],200,EleutherAI/gpt-neox-20b,128,1,2258.0,1.0,1,H100,1697105221904,1697105224162.0,120,23.0,1.0,"[28, 2230]","[1697105221932, 1697105224162]"
4558,316,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262310,1697105264082.0,120,,,[29],[1697105262339]
4559,293,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263991,1697105265928.0,120,,,[49],[1697105264040]
4560,670,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264086,1697105265928.0,120,,,[110],[1697105264196]
4561,828,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258851,1697105260463.0,120,,,[9],[1697105258860]
4562,579,18,[],200,EleutherAI/gpt-neox-20b,128,1,981.0,1.0,1,H100,1697105224163,1697105225144.0,120,19.0,1.0,"[16, 965]","[1697105224179, 1697105225144]"
4563,652,39,[],200,EleutherAI/gpt-neox-20b,128,1,2980.0,1.0,1,H100,1697105265935,1697105268915.0,120,14.0,1.0,"[255, 2725]","[1697105266190, 1697105268915]"
4564,12,19,[],200,EleutherAI/gpt-neox-20b,128,1,1808.0,1.0,1,H100,1697105225146,1697105226954.0,120,11.0,1.0,"[40, 1768]","[1697105225186, 1697105226954]"
4565,863,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228782,1697105230476.0,120,,,[119],[1697105228901]
4566,253,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260467,1697105262307.0,120,,,[133],[1697105260600]
4567,344,28,[],200,EleutherAI/gpt-neox-20b,128,1,1520.0,1.0,1,H100,1697105258917,1697105260437.0,120,13.0,1.0,"[84, 1436]","[1697105259001, 1697105260437]"
4568,701,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260439,1697105262307.0,120,,,[12],[1697105260451]
4569,606,36,[],200,EleutherAI/gpt-neox-20b,128,1,1678.0,1.0,1,H100,1697105262312,1697105263990.0,120,9.0,1.0,"[163, 1515]","[1697105262475, 1697105263990]"
4570,67,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265939,1697105271972.0,120,,,"[276, 2763, 669, 704, 685]","[1697105266215, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
4571,129,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262317,1697105265927.0,120,,,[307],[1697105262624]
4572,58,37,[],200,EleutherAI/gpt-neox-20b,128,1,2017.0,1.0,1,H100,1697105256013,1697105258030.0,120,15.0,1.0,"[82, 1935]","[1697105256095, 1697105258030]"
4573,43,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238411,1697105240330.0,120,,,[100],[1697105238511]
4574,421,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105249682,1697105252037.0,120,,,[37],[1697105249719]
4575,751,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273556,1697105275207.0,120,,,[25],[1697105273581]
4576,774,28,[],200,EleutherAI/gpt-neox-20b,128,1,1640.0,1.0,1,H100,1697105252042,1697105253682.0,120,8.0,1.0,"[253, 1387]","[1697105252295, 1697105253682]"
4577,180,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253686,1697105255027.0,120,,,[48],[1697105253734]
4578,274,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262310,1697105264082.0,120,,,[21],[1697105262331]
4579,400,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241994.0,120,,,[153],[1697105240487]
4580,537,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[56],[1697105255086]
4581,538,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105240330.0,120,,,[186],[1697105236970]
4582,184,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265927.0,120,,,[87],[1697105264172]
4583,891,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240332,1697105241994.0,120,,,[256],[1697105240588]
4584,763,21,[],200,EleutherAI/gpt-neox-20b,128,1,1553.0,1.0,1,H100,1697105242001,1697105243554.0,120,20.0,1.0,"[98, 1455]","[1697105242099, 1697105243554]"
4585,413,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242003,1697105243754.0,120,,,[212],[1697105242215]
4586,448,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238411,1697105240330.0,120,,,[24],[1697105238435]
4587,770,24,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105243758,1697105245427.0,120,13.0,1.0,"[218, 1451]","[1697105243976, 1697105245427]"
4588,537,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270309,1697105271972.0,120,,,[63],[1697105270372]
4589,202,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245429,1697105247242.0,120,,,[49],[1697105245478]
4590,731,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260438,1697105262307.0,120,,,[5],[1697105260443]
4591,454,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248697,1697105250348.0,120,,,[44],[1697105248741]
4592,442,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258913.0,120,,,[34],[1697105257151]
4593,812,31,[],200,EleutherAI/gpt-neox-20b,128,1,1660.0,1.0,1,H100,1697105250351,1697105252011.0,120,16.0,1.0,"[61, 1599]","[1697105250412, 1697105252011]"
4594,803,16,[],200,EleutherAI/gpt-neox-20b,128,1,1834.0,1.0,1,H100,1697105234922,1697105236756.0,120,20.0,1.0,"[178, 1656]","[1697105235100, 1697105236756]"
4595,240,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252012,1697105253711.0,120,,,[13],[1697105252025]
4596,805,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258920,1697105260463.0,120,,,[157],[1697105259077]
4597,205,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260467,1697105262307.0,120,,,[210],[1697105260677]
4598,227,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236757,1697105238408.0,120,,,[36],[1697105236793]
4599,599,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253715,1697105256011.0,120,,,[208],[1697105253923]
4600,25,34,[],200,EleutherAI/gpt-neox-20b,128,1,1778.0,1.0,1,H100,1697105264085,1697105265863.0,120,12.0,1.0,"[95, 1683]","[1697105264180, 1697105265863]"
4601,28,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258907.0,120,,,[24],[1697105256037]
4602,473,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258917,1697105260462.0,120,,,[72],[1697105258989]
4603,832,36,[],200,EleutherAI/gpt-neox-20b,128,1,1778.0,1.0,1,H100,1697105260465,1697105262243.0,120,15.0,1.0,"[55, 1723]","[1697105260520, 1697105262243]"
4604,257,37,[],200,EleutherAI/gpt-neox-20b,128,1,826.0,1.0,1,H100,1697105262245,1697105263071.0,120,14.0,1.0,"[52, 774]","[1697105262297, 1697105263071]"
4605,355,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265864,1697105267796.0,120,,,[21],[1697105265885]
4606,749,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242692,1697105245502.0,120,,,[12],[1697105242704]
4607,620,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263072,1697105265927.0,120,,,[8],[1697105263080]
4608,467,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105238408.0,120,,,[38],[1697105236822]
4609,419,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258031,1697105260462.0,120,,,[8],[1697105258039]
4610,782,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260465,1697105262306.0,120,,,[111],[1697105260576]
4611,127,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233608.0,120,,,[40],[1697105232190]
4612,485,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233609,1697105234918.0,120,,,[17],[1697105233626]
4613,850,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258913.0,120,,,[26],[1697105257143]
4614,210,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262314,1697105265927.0,120,,,[298],[1697105262612]
4615,565,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265932,1697105267796.0,120,,,[65],[1697105265997]
4616,400,11,[],200,EleutherAI/gpt-neox-20b,128,1,2347.0,1.0,1,H100,1697105211483,1697105213830.0,120,123.0,7.0,"[9, 1399, 88, 89, 82, 75, 605]","[1697105211492, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830]"
4617,272,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258919,1697105260462.0,120,,,[74],[1697105258993]
4618,626,31,[],200,EleutherAI/gpt-neox-20b,128,1,1680.0,1.0,1,H100,1697105262310,1697105263990.0,120,10.0,1.0,"[81, 1599]","[1697105262391, 1697105263990]"
4619,82,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105270302.0,120,,,[203],[1697105268004]
4620,436,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270308,1697105271973.0,120,,,[85],[1697105270393]
4621,426,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230476.0,120,,,[88],[1697105228869]
4622,797,44,[],200,EleutherAI/gpt-neox-20b,128,1,2436.0,1.0,1,H100,1697105271978,1697105274414.0,120,26.0,1.0,"[297, 2139]","[1697105272275, 1697105274414]"
4623,629,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260468,1697105262307.0,120,,,[140],[1697105260608]
4624,753,12,[],200,EleutherAI/gpt-neox-20b,128,1,5569.0,1.0,1,H100,1697105213831,1697105219400.0,120,83.0,20.0,"[5, 2583, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 82, 257, 78, 368, 81, 59, 366]","[1697105213836, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218191, 1697105218448, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400]"
4625,243,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273588,1697105275208.0,120,,,[98],[1697105273686]
4626,227,45,[],200,EleutherAI/gpt-neox-20b,128,1,2297.0,1.0,1,H100,1697105274416,1697105276713.0,120,364.0,25.0,"[24, 1504, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 33, 32, 32, 33, 29, 28, 28, 28]","[1697105274440, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276502, 1697105276534, 1697105276566, 1697105276599, 1697105276628, 1697105276656, 1697105276684, 1697105276712]"
4627,27,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263991,1697105265927.0,120,,,[29],[1697105264020]
4628,385,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267795.0,120,,,[12],[1697105265943]
4629,892,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271976,1697105273585.0,120,,,[118],[1697105272094]
4630,186,13,[],200,EleutherAI/gpt-neox-20b,128,1,5920.0,1.0,1,H100,1697105219401,1697105225321.0,120,123.0,22.0,"[4, 2560, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579, 81]","[1697105219405, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225320]"
4631,813,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105238409.0,120,,,[118],[1697105236902]
4632,743,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[6],[1697105267804]
4633,215,20,[],200,EleutherAI/gpt-neox-20b,128,1,1854.0,1.0,1,H100,1697105238412,1697105240266.0,120,12.0,1.0,"[256, 1598]","[1697105238668, 1697105240266]"
4634,565,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240267,1697105241994.0,120,,,[57],[1697105240324]
4635,924,22,[],200,EleutherAI/gpt-neox-20b,128,1,1553.0,1.0,1,H100,1697105242001,1697105243554.0,120,9.0,1.0,"[199, 1354]","[1697105242200, 1697105243554]"
4636,322,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273589,1697105275208.0,120,,,[193],[1697105273782]
4637,172,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[40],[1697105269640]
4638,897,40,[],200,EleutherAI/gpt-neox-20b,128,1,1578.0,1.0,1,H100,1697105271977,1697105273555.0,120,9.0,1.0,"[193, 1385]","[1697105272170, 1697105273555]"
4639,0,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105249682,1697105252038.0,120,,,[41],[1697105249723]
4640,501,36,[],200,EleutherAI/gpt-neox-20b,128,1,1759.0,1.0,1,H100,1697105270990,1697105272749.0,120,19.0,1.0,"[80, 1678]","[1697105271070, 1697105272748]"
4641,864,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105272750,1697105275208.0,120,,,[20],[1697105272770]
4642,558,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248695.0,120,,,[51],[1697105247298]
4643,162,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262312,1697105264082.0,120,,,[176],[1697105262488]
4644,325,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273556,1697105275207.0,120,,,[29],[1697105273585]
4645,523,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265928.0,120,,,[27],[1697105264112]
4646,331,34,[],200,EleutherAI/gpt-neox-20b,128,1,1640.0,1.0,1,H100,1697105252042,1697105253682.0,120,26.0,1.0,"[252, 1388]","[1697105252294, 1697105253682]"
4647,687,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253685,1697105256010.0,120,,,"[23, 1350]","[1697105253708, 1697105255058]"
4648,291,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230479,1697105234918.0,120,,,"[202, 2375, 600, 617]","[1697105230681, 1697105233056, 1697105233656, 1697105234273]"
4649,649,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234921,1697105236782.0,120,,,[22],[1697105234943]
4650,877,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265934,1697105271973.0,120,,,"[156, 2888, 669, 704, 685]","[1697105266090, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
4651,556,18,[],200,EleutherAI/gpt-neox-20b,128,1,1854.0,1.0,1,H100,1697105238411,1697105240265.0,120,9.0,1.0,"[31, 1823]","[1697105238442, 1697105240265]"
4652,7,10,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105218448,1697105220995.0,120,,,"[9, 2249]","[1697105218457, 1697105220706]"
4653,37,37,[],200,EleutherAI/gpt-neox-20b,128,1,1013.0,1.0,1,H100,1697105263991,1697105265004.0,120,20.0,1.0,"[25, 988]","[1697105264016, 1697105265004]"
4654,79,21,[],200,EleutherAI/gpt-neox-20b,128,1,2554.0,1.0,1,H100,1697105236785,1697105239339.0,120,12.0,1.0,"[285, 2269]","[1697105237070, 1697105239339]"
4655,337,11,[],200,EleutherAI/gpt-neox-20b,128,1,1575.0,1.0,1,H100,1697105220998,1697105222573.0,120,12.0,1.0,"[110, 1465]","[1697105221108, 1697105222573]"
4656,915,19,[],200,EleutherAI/gpt-neox-20b,128,1,938.0,1.0,1,H100,1697105240267,1697105241205.0,120,182.0,1.0,"[20, 918]","[1697105240287, 1697105241205]"
4657,676,24,[],200,EleutherAI/gpt-neox-20b,128,1,2554.0,1.0,1,H100,1697105236784,1697105239338.0,120,19.0,1.0,"[203, 2351]","[1697105236987, 1697105239338]"
4658,118,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258913.0,120,,,[80],[1697105256093]
4659,108,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105239340,1697105241994.0,120,,,[5],[1697105239345]
4660,695,12,[],200,EleutherAI/gpt-neox-20b,128,1,5681.0,1.0,1,H100,1697105222574,1697105228255.0,120,92.0,20.0,"[12, 2653, 82, 77, 75, 73, 707, 90, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105222586, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225546, 1697105226253, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
4661,408,22,[],200,EleutherAI/gpt-neox-20b,128,1,1865.0,1.0,1,H100,1697105239340,1697105241205.0,120,16.0,1.0,"[37, 1828]","[1697105239377, 1697105241205]"
4662,769,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241206,1697105243753.0,120,,,[9],[1697105241215]
4663,559,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243754.0,120,,,[202],[1697105242203]
4664,195,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243756,1697105245502.0,120,,,[48],[1697105243804]
4665,916,27,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105243758,1697105245427.0,120,8.0,1.0,"[211, 1458]","[1697105243969, 1697105245427]"
4666,475,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258919,1697105260463.0,120,,,[94],[1697105259013]
4667,553,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245505,1697105247243.0,120,,,[168],[1697105245673]
4668,341,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245428,1697105247243.0,120,,,[41],[1697105245469]
4669,579,17,[],200,EleutherAI/gpt-neox-20b,128,1,2804.0,1.0,1,H100,1697105215910,1697105218714.0,120,19.0,1.0,"[21, 2783]","[1697105215931, 1697105218714]"
4670,694,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267187,1697105271972.0,120,,,"[24, 1767, 669, 704, 685]","[1697105267211, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
4671,833,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260465,1697105262306.0,120,,,[115],[1697105260580]
4672,235,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262312,1697105264083.0,120,,,[160],[1697105262472]
4673,125,39,[],200,EleutherAI/gpt-neox-20b,128,1,1578.0,1.0,1,H100,1697105271977,1697105273555.0,120,13.0,1.0,"[193, 1385]","[1697105272170, 1697105273555]"
4674,701,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247250,1697105250347.0,120,,,[237],[1697105247487]
4675,592,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264087,1697105267795.0,120,,,[284],[1697105264371]
4676,399,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245428,1697105247242.0,120,,,[4],[1697105245432]
4677,760,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247249,1697105250347.0,120,,,[154],[1697105247403]
4678,489,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273556,1697105275207.0,120,,,[13],[1697105273569]
4679,162,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250350,1697105252036.0,120,,,[12],[1697105250362]
4680,713,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105270302.0,120,,,[167],[1697105267968]
4681,145,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270303,1697105270988.0,120,,,[5],[1697105270308]
4682,508,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270990,1697105273585.0,120,,,[88],[1697105271078]
4683,836,39,[],200,EleutherAI/gpt-neox-20b,128,1,1544.0,1.0,1,H100,1697105273588,1697105275132.0,120,11.0,1.0,"[126, 1418]","[1697105273714, 1697105275132]"
4684,24,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[86],[1697105267884]
4685,380,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[48],[1697105269648]
4686,312,18,[],200,EleutherAI/gpt-neox-20b,128,1,2542.0,1.0,1,H100,1697105215296,1697105217838.0,120,23.0,1.0,"[8, 2534]","[1697105215304, 1697105217838]"
4687,708,43,[],200,EleutherAI/gpt-neox-20b,128,1,1759.0,1.0,1,H100,1697105270990,1697105272749.0,120,140.0,1.0,"[92, 1666]","[1697105271082, 1697105272748]"
4688,133,44,[],200,EleutherAI/gpt-neox-20b,128,1,1664.0,1.0,1,H100,1697105272750,1697105274414.0,120,15.0,1.0,"[24, 1640]","[1697105272774, 1697105274414]"
4689,852,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270305,1697105271973.0,120,,,[19],[1697105270324]
4690,496,45,[],200,EleutherAI/gpt-neox-20b,128,1,1856.0,1.0,1,H100,1697105274415,1697105276271.0,120,335.0,11.0,"[13, 1516, 41, 41, 34, 33, 41, 39, 33, 33, 32]","[1697105274428, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271]"
4691,633,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265927.0,120,,,[87],[1697105264172]
4692,282,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271977,1697105273584.0,120,,,[209],[1697105272186]
4693,33,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265934,1697105271973.0,120,,,"[152, 2892, 668, 705, 685]","[1697105266086, 1697105268978, 1697105269646, 1697105270351, 1697105271036]"
4694,632,45,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273587,1697105275208.0,120,,,[26],[1697105273613]
4695,390,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271978,1697105275207.0,120,,,[249],[1697105272227]
4696,540,39,[],200,EleutherAI/gpt-neox-20b,128,1,5101.0,1.0,1,H100,1697105265935,1697105271036.0,120,140.0,5.0,"[171, 2872, 669, 704, 685]","[1697105266106, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
4697,670,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105217839,1697105220996.0,120,,,"[4, 2584, 82, 197]","[1697105217843, 1697105220427, 1697105220509, 1697105220706]"
4698,893,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271037,1697105273585.0,120,,,[53],[1697105271090]
4699,95,20,[],200,EleutherAI/gpt-neox-20b,128,1,2309.0,1.0,1,H100,1697105221001,1697105223310.0,120,12.0,1.0,"[199, 2110]","[1697105221200, 1697105223310]"
4700,353,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243555,1697105245503.0,120,,,[16],[1697105243571]
4701,632,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225321,1697105228772.0,120,,,"[5, 2585, 93, 84, 84, 83]","[1697105225326, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
4702,278,44,[],200,EleutherAI/gpt-neox-20b,128,1,2436.0,1.0,1,H100,1697105271978,1697105274414.0,120,13.0,1.0,"[245, 2191]","[1697105272223, 1697105274414]"
4703,429,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105223311,1697105228772.0,120,,,"[17, 1911, 82, 78, 74, 74, 705, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105223328, 1697105225239, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
4704,370,20,[],200,EleutherAI/gpt-neox-20b,128,1,1796.0,1.0,1,H100,1697105226955,1697105228751.0,120,31.0,1.0,"[28, 1768]","[1697105226983, 1697105228751]"
4705,717,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105248695.0,120,,,[268],[1697105245774]
4706,64,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228779,1697105230475.0,120,,,[18],[1697105228797]
4707,118,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248697,1697105250348.0,120,,,[40],[1697105248737]
4708,419,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105232146.0,120,,,[53],[1697105230531]
4709,636,45,[],200,EleutherAI/gpt-neox-20b,128,1,1482.0,1.0,1,H100,1697105274416,1697105275898.0,120,31.0,1.0,"[32, 1450]","[1697105274448, 1697105275898]"
4710,248,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260467,1697105262307.0,120,,,[137],[1697105260604]
4711,607,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262312,1697105264083.0,120,,,[155],[1697105262467]
4712,38,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264087,1697105265928.0,120,,,[208],[1697105264295]
4713,393,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265932,1697105267796.0,120,,,[69],[1697105266001]
4714,839,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267799,1697105269598.0,120,,,[109],[1697105267908]
4715,129,13,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228258,1697105232145.0,120,,,"[36, 2222, 990, 75, 75, 74, 73]","[1697105228294, 1697105230516, 1697105231506, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
4716,268,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[81],[1697105269681]
4717,626,40,[],200,EleutherAI/gpt-neox-20b,128,1,956.0,1.0,1,H100,1697105270989,1697105271945.0,120,10.0,1.0,"[41, 915]","[1697105271030, 1697105271945]"
4718,56,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271946,1697105273584.0,120,,,[21],[1697105271967]
4719,385,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273588,1697105275208.0,120,,,[98],[1697105273686]
4720,490,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233608.0,120,,,[41],[1697105232191]
4721,6,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233609,1697105234918.0,120,,,[9],[1697105233618]
4722,366,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236782.0,120,,,[49],[1697105234971]
4723,716,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236785,1697105240330.0,120,,,[210],[1697105236995]
4724,558,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262314,1697105264082.0,120,,,[274],[1697105262588]
4725,126,30,[],200,EleutherAI/gpt-neox-20b,128,1,1657.0,1.0,1,H100,1697105250354,1697105252011.0,120,19.0,1.0,"[224, 1433]","[1697105250578, 1697105252011]"
4726,483,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267796.0,120,,,[46],[1697105265977]
4727,144,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240333,1697105243753.0,120,,,[266],[1697105240599]
4728,918,39,[],200,EleutherAI/gpt-neox-20b,128,1,1778.0,1.0,1,H100,1697105264086,1697105265864.0,120,23.0,1.0,"[114, 1664]","[1697105264200, 1697105265864]"
4729,520,34,[],200,EleutherAI/gpt-neox-20b,128,1,1641.0,1.0,1,H100,1697105252041,1697105253682.0,120,11.0,1.0,"[44, 1596]","[1697105252085, 1697105253681]"
4730,503,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243757,1697105245502.0,120,,,[58],[1697105243815]
4731,811,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105270302.0,120,,,[167],[1697105267968]
4732,839,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245505,1697105247243.0,120,,,[172],[1697105245677]
4733,269,21,[],200,EleutherAI/gpt-neox-20b,128,1,2427.0,1.0,1,H100,1697105247254,1697105249681.0,120,11.0,1.0,"[249, 2178]","[1697105247503, 1697105249681]"
4734,241,33,[],200,EleutherAI/gpt-neox-20b,128,1,1642.0,1.0,1,H100,1697105270303,1697105271945.0,120,19.0,1.0,"[21, 1621]","[1697105270324, 1697105271945]"
4735,723,10,[],200,EleutherAI/gpt-neox-20b,128,1,2037.0,1.0,1,H100,1697105215296,1697105217333.0,120,14.0,1.0,"[12, 2025]","[1697105215308, 1697105217333]"
4736,606,34,[],200,EleutherAI/gpt-neox-20b,128,1,803.0,1.0,1,H100,1697105271946,1697105272749.0,120,9.0,1.0,"[21, 781]","[1697105271967, 1697105272748]"
4737,627,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105249682,1697105252037.0,120,,,[28],[1697105249710]
4738,36,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105272750,1697105275208.0,120,,,[16],[1697105272766]
4739,151,11,[],200,EleutherAI/gpt-neox-20b,128,1,2703.0,1.0,1,H100,1697105217334,1697105220037.0,120,39.0,1.0,"[5, 2698]","[1697105217339, 1697105220037]"
4740,52,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252039,1697105253711.0,120,,,[155],[1697105252194]
4741,484,12,[],200,EleutherAI/gpt-neox-20b,128,1,7966.0,1.0,1,H100,1697105220038,1697105228004.0,120,86.0,36.0,"[12, 1915, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579, 82, 77, 75, 73, 706, 91, 84, 66, 84, 486, 91, 89, 85, 582, 94]","[1697105220050, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225546, 1697105226252, 1697105226343, 1697105226427, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227910, 1697105228004]"
4742,821,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238411,1697105240330.0,120,,,[64],[1697105238475]
4743,408,24,[],200,EleutherAI/gpt-neox-20b,128,1,2227.0,1.0,1,H100,1697105253717,1697105255944.0,120,16.0,1.0,"[351, 1876]","[1697105254068, 1697105255944]"
4744,736,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255952,1697105257115.0,120,,,[37],[1697105255989]
4745,168,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257121,1697105260462.0,120,,,[255],[1697105257376]
4746,531,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260465,1697105262306.0,120,,,[119],[1697105260584]
4747,781,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105234918.0,120,,,"[211, 2367, 600, 617]","[1697105230689, 1697105233056, 1697105233656, 1697105234273]"
4748,888,28,[],200,EleutherAI/gpt-neox-20b,128,1,1676.0,1.0,1,H100,1697105262314,1697105263990.0,120,19.0,1.0,"[286, 1390]","[1697105262600, 1697105263990]"
4749,211,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234923,1697105238407.0,120,,,[185],[1697105235108]
4750,543,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238413,1697105240331.0,120,,,[271],[1697105238684]
4751,900,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241994.0,120,,,[238],[1697105240572]
4752,746,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271977,1697105275207.0,120,,,[218],[1697105272195]
4753,335,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242000,1697105243754.0,120,,,[220],[1697105242220]
4754,313,29,[],200,EleutherAI/gpt-neox-20b,128,1,1013.0,1.0,1,H100,1697105263992,1697105265005.0,120,20.0,1.0,"[44, 969]","[1697105264036, 1697105265005]"
4755,899,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105258907.0,120,,,[17],[1697105257135]
4756,329,32,[],200,EleutherAI/gpt-neox-20b,128,1,1521.0,1.0,1,H100,1697105258917,1697105260438.0,120,15.0,1.0,"[92, 1429]","[1697105259009, 1697105260438]"
4757,769,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260439,1697105262307.0,120,,,[8],[1697105260447]
4758,194,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262311,1697105264082.0,120,,,[68],[1697105262379]
4759,553,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265928.0,120,,,[107],[1697105264192]
4760,915,36,[],200,EleutherAI/gpt-neox-20b,128,1,2980.0,1.0,1,H100,1697105265935,1697105268915.0,120,182.0,1.0,"[267, 2713]","[1697105266202, 1697105268915]"
4761,345,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268917,1697105270302.0,120,,,[24],[1697105268941]
4762,886,27,[],200,EleutherAI/gpt-neox-20b,128,1,1625.0,1.0,1,H100,1697105248697,1697105250322.0,120,17.0,1.0,"[28, 1597]","[1697105248725, 1697105250322]"
4763,689,26,[],200,EleutherAI/gpt-neox-20b,128,1,2438.0,1.0,1,H100,1697105243758,1697105246196.0,120,15.0,1.0,"[251, 2187]","[1697105244009, 1697105246196]"
4764,117,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105246197,1697105248695.0,120,,,[5],[1697105246202]
4765,678,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270308,1697105271972.0,120,,,[36],[1697105270344]
4766,106,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271976,1697105273585.0,120,,,[94],[1697105272070]
4767,311,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250323,1697105252037.0,120,,,[8],[1697105250331]
4768,462,40,[],200,EleutherAI/gpt-neox-20b,128,1,1543.0,1.0,1,H100,1697105273589,1697105275132.0,120,52.0,1.0,"[185, 1358]","[1697105273774, 1697105275132]"
4769,671,29,[],200,EleutherAI/gpt-neox-20b,128,1,1639.0,1.0,1,H100,1697105252042,1697105253681.0,120,12.0,1.0,"[181, 1458]","[1697105252223, 1697105253681]"
4770,103,30,[],200,EleutherAI/gpt-neox-20b,128,1,386.0,1.0,1,H100,1697105253685,1697105254071.0,120,15.0,1.0,"[15, 371]","[1697105253700, 1697105254071]"
4771,462,31,[],200,EleutherAI/gpt-neox-20b,128,1,1872.0,1.0,1,H100,1697105254072,1697105255944.0,120,52.0,1.0,"[11, 1861]","[1697105254083, 1697105255944]"
4772,140,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260467,1697105262307.0,120,,,[210],[1697105260677]
4773,476,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252038.0,120,,,[162],[1697105250513]
4774,830,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253712.0,120,,,[77],[1697105252118]
4775,497,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262312,1697105264083.0,120,,,[167],[1697105262479]
4776,794,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255949,1697105257115.0,120,,,[32],[1697105255981]
4777,829,36,[],200,EleutherAI/gpt-neox-20b,128,1,3099.0,1.0,1,H100,1697105264087,1697105267186.0,120,20.0,1.0,"[292, 2807]","[1697105264379, 1697105267186]"
4778,219,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105260462.0,120,,,[190],[1697105257308]
4779,778,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232152,1697105234225.0,120,,,[143],[1697105232295]
4780,907,26,[],200,EleutherAI/gpt-neox-20b,128,1,2425.0,1.0,1,H100,1697105247256,1697105249681.0,120,10.0,1.0,"[255, 2170]","[1697105247511, 1697105249681]"
4781,578,34,[],200,EleutherAI/gpt-neox-20b,128,1,1778.0,1.0,1,H100,1697105260465,1697105262243.0,120,31.0,1.0,"[115, 1663]","[1697105260580, 1697105262243]"
4782,260,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267187,1697105271972.0,120,,,"[16, 1775, 669, 704, 685]","[1697105267203, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
4783,311,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105249682,1697105252037.0,120,,,[25],[1697105249707]
4784,207,18,[],200,EleutherAI/gpt-neox-20b,128,1,1775.0,1.0,1,H100,1697105234227,1697105236002.0,120,10.0,1.0,"[44, 1731]","[1697105234271, 1697105236002]"
4785,533,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236003,1697105238408.0,120,,,[18],[1697105236021]
4786,88,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252037.0,120,,,[54],[1697105250405]
4787,894,20,[],200,EleutherAI/gpt-neox-20b,128,1,1854.0,1.0,1,H100,1697105238412,1697105240266.0,120,14.0,1.0,"[175, 1678]","[1697105238587, 1697105240265]"
4788,449,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252039,1697105253711.0,120,,,[159],[1697105252198]
4789,782,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[292],[1697105254008]
4790,322,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240267,1697105241994.0,120,,,[40],[1697105240307]
4791,685,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243754.0,120,,,[170],[1697105242171]
4792,846,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236782.0,120,,,[9],[1697105234931]
4793,250,23,[],200,EleutherAI/gpt-neox-20b,128,1,2552.0,1.0,1,H100,1697105236786,1697105239338.0,120,31.0,1.0,"[301, 2251]","[1697105237087, 1697105239338]"
4794,608,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105239339,1697105241994.0,120,,,[6],[1697105239345]
4795,342,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265864,1697105267796.0,120,,,[25],[1697105265889]
4796,212,30,[],200,EleutherAI/gpt-neox-20b,128,1,2017.0,1.0,1,H100,1697105256013,1697105258030.0,120,31.0,1.0,"[156, 1861]","[1697105256169, 1697105258030]"
4797,703,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267800,1697105269599.0,120,,,[184],[1697105267984]
4798,110,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243758,1697105245502.0,120,,,[223],[1697105243981]
4799,786,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230476.0,120,,,[92],[1697105228873]
4800,569,31,[],200,EleutherAI/gpt-neox-20b,128,1,1741.0,1.0,1,H100,1697105258031,1697105259772.0,120,16.0,1.0,"[16, 1725]","[1697105258047, 1697105259772]"
4801,156,13,[],200,EleutherAI/gpt-neox-20b,128,1,4241.0,1.0,1,H100,1697105220998,1697105225239.0,120,86.0,20.0,"[74, 1595, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579]","[1697105221072, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239]"
4802,920,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105259773,1697105262306.0,120,,,[8],[1697105259781]
4803,221,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269601,1697105271973.0,120,,,[99],[1697105269700]
4804,439,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245504,1697105247243.0,120,,,[88],[1697105245592]
4805,216,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105234919.0,120,,,"[139, 2439, 600, 617]","[1697105230617, 1697105233056, 1697105233656, 1697105234273]"
4806,38,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243753.0,120,,,[42],[1697105242043]
4807,389,26,[],200,EleutherAI/gpt-neox-20b,128,1,1671.0,1.0,1,H100,1697105243756,1697105245427.0,120,8.0,1.0,"[35, 1636]","[1697105243791, 1697105245427]"
4808,644,30,[],200,EleutherAI/gpt-neox-20b,128,1,2179.0,1.0,1,H100,1697105265007,1697105267186.0,120,19.0,1.0,"[36, 2143]","[1697105265043, 1697105267186]"
4809,69,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267187,1697105271972.0,120,,,"[8, 1783, 669, 704, 685]","[1697105267195, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
4810,361,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232152,1697105234225.0,120,,,[135],[1697105232287]
4811,715,17,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105234226,1697105236002.0,120,20.0,1.0,"[36, 1740]","[1697105234262, 1697105236002]"
4812,147,18,[],200,EleutherAI/gpt-neox-20b,128,1,1892.0,1.0,1,H100,1697105236003,1697105237895.0,120,182.0,1.0,"[15, 1877]","[1697105236018, 1697105237895]"
4813,506,19,[],200,EleutherAI/gpt-neox-20b,128,1,1442.0,1.0,1,H100,1697105237897,1697105239339.0,120,16.0,1.0,"[28, 1414]","[1697105237925, 1697105239339]"
4814,582,43,[],200,EleutherAI/gpt-neox-20b,128,1,1577.0,1.0,1,H100,1697105271978,1697105273555.0,120,19.0,1.0,"[104, 1473]","[1697105272082, 1697105273555]"
4815,574,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105238408.0,120,,,[170],[1697105235092]
4816,838,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105239340,1697105241995.0,120,,,[33],[1697105239373]
4817,428,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271976,1697105273585.0,120,,,"[94, 1485]","[1697105272070, 1697105273555]"
4818,263,21,[],200,EleutherAI/gpt-neox-20b,128,1,1547.0,1.0,1,H100,1697105242007,1697105243554.0,120,15.0,1.0,"[184, 1363]","[1697105242191, 1697105243554]"
4819,89,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238411,1697105240330.0,120,,,[80],[1697105238491]
4820,443,28,[],200,EleutherAI/gpt-neox-20b,128,1,2485.0,1.0,1,H100,1697105248699,1697105251184.0,120,19.0,1.0,"[98, 2387]","[1697105248797, 1697105251184]"
4821,804,29,[],200,EleutherAI/gpt-neox-20b,128,1,1379.0,1.0,1,H100,1697105251185,1697105252564.0,120,20.0,1.0,"[5, 1374]","[1697105251190, 1697105252564]"
4822,235,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252566,1697105256010.0,120,,,"[12, 2480]","[1697105252578, 1697105255058]"
4823,789,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273588,1697105275208.0,120,,,[126],[1697105273714]
4824,593,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258913.0,120,,,[61],[1697105256074]
4825,449,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240333,1697105241995.0,120,,,[50],[1697105240383]
4826,702,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228752,1697105232145.0,120,,,"[8, 1756, 990, 75, 75, 74, 73]","[1697105228760, 1697105230516, 1697105231506, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
4827,21,32,[],200,EleutherAI/gpt-neox-20b,128,1,1520.0,1.0,1,H100,1697105258918,1697105260438.0,120,15.0,1.0,"[79, 1440]","[1697105258997, 1697105260437]"
4828,133,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105234225.0,120,,,[69],[1697105232219]
4829,369,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265006,1697105267796.0,120,,,[25],[1697105265031]
4830,487,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234225,1697105236781.0,120,,,[5],[1697105234230]
4831,256,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105255028.0,120,,,[179],[1697105253895]
4832,351,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260438,1697105262307.0,120,,,[5],[1697105260443]
4833,614,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[157],[1697105255187]
4834,732,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267797,1697105269598.0,120,,,[71],[1697105267868]
4835,709,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262314,1697105265926.0,120,,,[266],[1697105262580]
4836,137,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267796.0,120,,,[38],[1697105265969]
4837,623,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243555,1697105245502.0,120,,,[16],[1697105243571]
4838,496,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[34],[1697105267832]
4839,161,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[72],[1697105269672]
4840,424,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271975,1697105273585.0,120,,,[43],[1697105272018]
4841,786,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273589,1697105275208.0,120,,,[189],[1697105273778]
4842,18,30,[],200,EleutherAI/gpt-neox-20b,128,1,1732.0,1.0,1,H100,1697105257118,1697105258850.0,120,15.0,1.0,"[69, 1663]","[1697105257187, 1697105258850]"
4843,169,27,[],200,EleutherAI/gpt-neox-20b,128,1,1663.0,1.0,1,H100,1697105245505,1697105247168.0,120,10.0,1.0,"[187, 1476]","[1697105245692, 1697105247168]"
4844,188,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243555,1697105245501.0,120,,,[41],[1697105243596]
4845,377,31,[],200,EleutherAI/gpt-neox-20b,128,1,921.0,1.0,1,H100,1697105258851,1697105259772.0,120,13.0,1.0,"[33, 888]","[1697105258884, 1697105259772]"
4846,738,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105259773,1697105262306.0,120,,,[12],[1697105259785]
4847,546,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245504,1697105247243.0,120,,,[80],[1697105245584]
4848,168,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262316,1697105265927.0,120,,,[296],[1697105262612]
4849,522,34,[],200,EleutherAI/gpt-neox-20b,128,1,1841.0,1.0,1,H100,1697105265931,1697105267772.0,120,20.0,1.0,"[17, 1824]","[1697105265948, 1697105267772]"
4850,876,24,[],200,EleutherAI/gpt-neox-20b,128,1,2432.0,1.0,1,H100,1697105247248,1697105249680.0,120,11.0,1.0,"[159, 2273]","[1697105247407, 1697105249680]"
4851,305,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105249682,1697105252037.0,120,,,[12],[1697105249694]
4852,663,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252039,1697105253711.0,120,,,[143],[1697105252182]
4853,34,35,[],200,EleutherAI/gpt-neox-20b,128,1,1142.0,1.0,1,H100,1697105267774,1697105268916.0,120,12.0,1.0,"[12, 1130]","[1697105267786, 1697105268916]"
4854,807,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240333,1697105243753.0,120,,,[275],[1697105240608]
4855,393,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268917,1697105270302.0,120,,,[28],[1697105268945]
4856,232,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243757,1697105245502.0,120,,,[115],[1697105243872]
4857,746,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245428,1697105247242.0,120,,,[4],[1697105245432]
4858,590,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105247243.0,120,,,[187],[1697105245693]
4859,916,29,[],200,EleutherAI/gpt-neox-20b,128,1,1381.0,1.0,1,H100,1697105247255,1697105248636.0,120,8.0,1.0,"[260, 1121]","[1697105247515, 1697105248636]"
4860,715,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228781,1697105230475.0,120,,,[36],[1697105228817]
4861,52,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268917,1697105270302.0,120,,,[20],[1697105268937]
4862,140,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230478,1697105234919.0,120,,,"[127, 2451, 600, 617]","[1697105230605, 1697105233056, 1697105233656, 1697105234273]"
4863,754,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270308,1697105271973.0,120,,,[13],[1697105270321]
4864,348,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248637,1697105250347.0,120,,,[21],[1697105248658]
4865,706,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252036.0,120,,,[17],[1697105250368]
4866,12,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[92],[1697105269692]
4867,140,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253711.0,120,,,[186],[1697105252227]
4868,803,27,[],200,EleutherAI/gpt-neox-20b,128,1,1553.0,1.0,1,H100,1697105242001,1697105243554.0,120,20.0,1.0,"[198, 1355]","[1697105242199, 1697105243554]"
4869,494,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[258],[1697105253974]
4870,824,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258907.0,120,,,[20],[1697105256033]
4871,499,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236781.0,120,,,[182],[1697105235104]
4872,847,13,[],200,EleutherAI/gpt-neox-20b,128,1,1647.0,1.0,1,H100,1697105228005,1697105229652.0,120,10.0,1.0,"[8, 1639]","[1697105228013, 1697105229652]"
4873,183,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271978,1697105275207.0,120,,,[245],[1697105272223]
4874,275,14,[],200,EleutherAI/gpt-neox-20b,128,1,2003.0,1.0,1,H100,1697105229653,1697105231656.0,120,161.0,4.0,"[4, 1848, 76, 75]","[1697105229657, 1697105231505, 1697105231581, 1697105231656]"
4875,253,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258915,1697105260463.0,120,,,[17],[1697105258932]
4876,824,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105238408.0,120,,,[26],[1697105236810]
4877,634,15,[],200,EleutherAI/gpt-neox-20b,128,1,1338.0,1.0,1,H100,1697105231657,1697105232995.0,120,13.0,1.0,"[5, 1333]","[1697105231662, 1697105232995]"
4878,366,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270990,1697105273585.0,120,,,[96],[1697105271086]
4879,729,39,[],200,EleutherAI/gpt-neox-20b,128,1,2354.0,1.0,1,H100,1697105273590,1697105275944.0,120,874.0,2.0,"[288, 2066]","[1697105273878, 1697105275944]"
4880,56,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232996,1697105234919.0,120,,,[8],[1697105233004]
4881,621,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271976,1697105273585.0,120,,,[110],[1697105272086]
4882,670,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253711.0,120,,,[133],[1697105252174]
4883,610,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260467,1697105262307.0,120,,,[238],[1697105260705]
4884,235,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243555,1697105245501.0,120,,,[52],[1697105243607]
4885,40,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262311,1697105264083.0,120,,,[88],[1697105262399]
4886,846,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105238408.0,120,,,[33],[1697105236817]
4887,368,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264087,1697105265928.0,120,,,[21],[1697105264108]
4888,726,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265934,1697105271973.0,120,,,"[160, 2884, 668, 705, 685]","[1697105266094, 1697105268978, 1697105269646, 1697105270351, 1697105271036]"
4889,156,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271977,1697105273584.0,120,,,[205],[1697105272182]
4890,250,25,[],200,EleutherAI/gpt-neox-20b,128,1,1596.0,1.0,1,H100,1697105240334,1697105241930.0,120,31.0,1.0,"[73, 1523]","[1697105240407, 1697105241930]"
4891,575,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241931,1697105243754.0,120,,,[5],[1697105241936]
4892,514,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273587,1697105275207.0,120,,,[10],[1697105273597]
4893,718,9,[],200,EleutherAI/gpt-neox-20b,128,1,1623.0,1.0,1,H100,1697105202002,1697105203625.0,120,13.0,1.0,"[5, 1618]","[1697105202007, 1697105203625]"
4894,152,10,[],200,EleutherAI/gpt-neox-20b,128,1,5187.0,1.0,1,H100,1697105203626,1697105208813.0,120,87.0,20.0,"[9, 2187, 91, 85, 84, 732, 89, 89, 86, 81, 79, 60, 61, 618, 86, 82, 83, 64, 434, 87]","[1697105203635, 1697105205822, 1697105205913, 1697105205998, 1697105206082, 1697105206814, 1697105206903, 1697105206992, 1697105207078, 1697105207159, 1697105207238, 1697105207298, 1697105207359, 1697105207977, 1697105208063, 1697105208145, 1697105208228, 1697105208292, 1697105208726, 1697105208813]"
4895,458,31,[],200,EleutherAI/gpt-neox-20b,128,1,1668.0,1.0,1,H100,1697105252013,1697105253681.0,120,11.0,1.0,"[36, 1632]","[1697105252049, 1697105253681]"
4896,816,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253687,1697105255028.0,120,,,[95],[1697105253782]
4897,271,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238412,1697105240331.0,120,,,[183],[1697105238595]
4898,249,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[158],[1697105255188]
4899,603,34,[],200,EleutherAI/gpt-neox-20b,128,1,1733.0,1.0,1,H100,1697105257117,1697105258850.0,120,9.0,1.0,"[58, 1675]","[1697105257175, 1697105258850]"
4900,33,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258851,1697105260463.0,120,,,[13],[1697105258864]
4901,362,36,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105260467,1697105262243.0,120,14.0,1.0,"[234, 1542]","[1697105260701, 1697105262243]"
4902,718,37,[],200,EleutherAI/gpt-neox-20b,128,1,826.0,1.0,1,H100,1697105262245,1697105263071.0,120,13.0,1.0,"[52, 774]","[1697105262297, 1697105263071]"
4903,150,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263072,1697105265927.0,120,,,[17],[1697105263089]
4904,507,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267796.0,120,,,[78],[1697105266009]
4905,51,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105248695.0,120,,,[272],[1697105245778]
4906,7,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243758,1697105245501.0,120,,,[214],[1697105243972]
4907,841,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105270303.0,120,,,[208],[1697105268009]
4908,367,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245504,1697105247243.0,120,,,[76],[1697105245580]
4909,725,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248695.0,120,,,[123],[1697105247370]
4910,153,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105252036.0,120,,,[102],[1697105248801]
4911,266,41,[],200,EleutherAI/gpt-neox-20b,128,1,1636.0,1.0,1,H100,1697105270309,1697105271945.0,120,9.0,1.0,"[88, 1548]","[1697105270397, 1697105271945]"
4912,409,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248697,1697105250347.0,120,,,[7],[1697105248704]
4913,877,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253685,1697105256010.0,120,,,"[10, 1363]","[1697105253695, 1697105255058]"
4914,739,25,[],200,EleutherAI/gpt-neox-20b,128,1,1661.0,1.0,1,H100,1697105250350,1697105252011.0,120,216.0,1.0,"[23, 1638]","[1697105250373, 1697105252011]"
4915,168,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252014,1697105253712.0,120,,,[39],[1697105252053]
4916,308,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258916.0,120,,,[68],[1697105256081]
4917,484,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253711.0,120,,,[181],[1697105252222]
4918,665,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258926,1697105262306.0,120,,,[268],[1697105259194]
4919,481,11,[],200,EleutherAI/gpt-neox-20b,128,1,2314.0,1.0,1,H100,1697105208814,1697105211128.0,120,10.0,1.0,"[9, 2305]","[1697105208823, 1697105211128]"
4920,842,12,[],200,EleutherAI/gpt-neox-20b,128,1,4166.0,1.0,1,H100,1697105211129,1697105215295.0,120,161.0,16.0,"[5, 1757, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 65, 75, 652]","[1697105211134, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214567, 1697105214642, 1697105215294]"
4921,321,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273588,1697105275208.0,120,,,[118],[1697105273706]
4922,798,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247254,1697105250347.0,120,,,[217],[1697105247471]
4923,402,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270303,1697105271973.0,120,,,[6],[1697105270309]
4924,7,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273556,1697105275207.0,120,,,[21],[1697105273577]
4925,841,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253715,1697105256010.0,120,,,[204],[1697105253919]
4926,761,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271976,1697105273584.0,120,,,[14],[1697105271990]
4927,3,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262244,1697105264083.0,120,,,[21],[1697105262265]
4928,189,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273587,1697105275207.0,120,,,[6],[1697105273593]
4929,267,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258911.0,120,,,[169],[1697105256182]
4930,361,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264086,1697105265928.0,120,,,[13],[1697105264099]
4931,11,18,[],200,EleutherAI/gpt-neox-20b,128,1,5702.0,1.0,1,H100,1697105218715,1697105224417.0,120,732.0,17.0,"[4, 3246, 701, 88, 84, 83, 81, 401, 71, 92, 87, 86, 84, 82, 351, 91, 70]","[1697105218719, 1697105221965, 1697105222666, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223823, 1697105223905, 1697105224256, 1697105224347, 1697105224417]"
4932,247,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105206086,1697105220994.0,120,,,"[87, 1804, 86, 83, 82, 64, 434, 87, 84, 79, 78, 384, 77, 619, 85, 83, 502, 82, 429, 168, 76, 456, 89, 80, 79, 75, 72, 481, 88, 89, 82, 75, 605, 94, 90, 89, 68, 246, 85, 64, 76, 652, 85, 356, 90, 83, 511, 89, 67, 83, 246, 85, 65, 386, 89, 87, 406, 87, 81, 257, 79, 368, 81, 59, 366, 84, 80, 259, 62, 234, 79, 228, 82, 197]","[1697105206173, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209054, 1697105209438, 1697105209515, 1697105210134, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211315, 1697105211483, 1697105211559, 1697105212015, 1697105212104, 1697105212184, 1697105212263, 1697105212338, 1697105212410, 1697105212891, 1697105212979, 1697105213068, 1697105213150, 1697105213225, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642, 1697105215294, 1697105215379, 1697105215735, 1697105215825, 1697105215908, 1697105216419, 1697105216508, 1697105216575, 1697105216658, 1697105216904, 1697105216989, 1697105217054, 1697105217440, 1697105217529, 1697105217616, 1697105218022, 1697105218109, 1697105218190, 1697105218447, 1697105218526, 1697105218894, 1697105218975, 1697105219034, 1697105219400, 1697105219484, 1697105219564, 1697105219823, 1697105219885, 1697105220119, 1697105220198, 1697105220426, 1697105220508, 1697105220705]"
4933,515,41,[],200,EleutherAI/gpt-neox-20b,128,1,956.0,1.0,1,H100,1697105270989,1697105271945.0,120,11.0,1.0,"[37, 919]","[1697105271026, 1697105271945]"
4934,874,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271946,1697105273584.0,120,,,[29],[1697105271975]
4935,695,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265932,1697105267796.0,120,,,[81],[1697105266013]
4936,49,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267796.0,120,,,[46],[1697105265977]
4937,270,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273588,1697105275208.0,120,,,[106],[1697105273694]
4938,100,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105255027.0,120,,,[104],[1697105253818]
4939,380,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267799,1697105269598.0,120,,,[97],[1697105267896]
4940,461,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[153],[1697105255183]
4941,736,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269601,1697105271973.0,120,,,[96],[1697105269697]
4942,127,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105270302.0,120,,,[175],[1697105267976]
4943,164,42,[],200,EleutherAI/gpt-neox-20b,128,1,1580.0,1.0,1,H100,1697105271975,1697105273555.0,120,15.0,1.0,"[23, 1557]","[1697105271998, 1697105273555]"
4944,518,43,[],200,EleutherAI/gpt-neox-20b,128,1,1574.0,1.0,1,H100,1697105273558,1697105275132.0,120,23.0,1.0,"[35, 1539]","[1697105273593, 1697105275132]"
4945,486,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270308,1697105271972.0,120,,,[40],[1697105270348]
4946,844,40,[],200,EleutherAI/gpt-neox-20b,128,1,1579.0,1.0,1,H100,1697105271976,1697105273555.0,120,10.0,1.0,"[50, 1529]","[1697105272026, 1697105273555]"
4947,264,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273556,1697105275207.0,120,,,[25],[1697105273581]
4948,31,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262313,1697105264082.0,120,,,[179],[1697105262492]
4949,623,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271946,1697105273585.0,120,,,[9],[1697105271955]
4950,392,35,[],200,EleutherAI/gpt-neox-20b,128,1,1779.0,1.0,1,H100,1697105264085,1697105265864.0,120,20.0,1.0,"[111, 1667]","[1697105264196, 1697105265863]"
4951,53,43,[],200,EleutherAI/gpt-neox-20b,128,1,3897.0,1.0,1,H100,1697105273589,1697105277486.0,120,216.0,55.0,"[206, 2149, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 33, 32, 32, 33, 29, 28, 28, 28, 32, 27, 27, 27, 27, 31, 26, 26, 29, 26, 26, 28, 25, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 23, 23, 24, 23]","[1697105273795, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276502, 1697105276534, 1697105276566, 1697105276599, 1697105276628, 1697105276656, 1697105276684, 1697105276712, 1697105276744, 1697105276771, 1697105276798, 1697105276825, 1697105276852, 1697105276883, 1697105276909, 1697105276935, 1697105276964, 1697105276990, 1697105277016, 1697105277044, 1697105277069, 1697105277093, 1697105277118, 1697105277143, 1697105277168, 1697105277193, 1697105277218, 1697105277243, 1697105277268, 1697105277293, 1697105277318, 1697105277343, 1697105277368, 1697105277393, 1697105277416, 1697105277439, 1697105277463, 1697105277486]"
4952,68,38,[],200,EleutherAI/gpt-neox-20b,128,1,1681.0,1.0,1,H100,1697105262309,1697105263990.0,120,12.0,1.0,"[6, 1675]","[1697105262315, 1697105263990]"
4953,423,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263991,1697105265927.0,120,,,[4],[1697105263995]
4954,753,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265864,1697105267795.0,120,,,[35],[1697105265899]
4955,148,28,[],200,EleutherAI/gpt-neox-20b,128,1,1388.0,1.0,1,H100,1697105247248,1697105248636.0,120,16.0,1.0,"[126, 1262]","[1697105247374, 1697105248636]"
4956,781,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267796.0,120,,,[50],[1697105265981]
4957,206,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267799,1697105269598.0,120,,,[73],[1697105267872]
4958,569,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[84],[1697105269684]
4959,529,28,[],200,EleutherAI/gpt-neox-20b,128,1,840.0,1.0,1,H100,1697105247169,1697105248009.0,120,10.0,1.0,"[21, 819]","[1697105247190, 1697105248009]"
4960,85,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270990,1697105273585.0,120,,,[52],[1697105271042]
4961,886,29,[],200,EleutherAI/gpt-neox-20b,128,1,1671.0,1.0,1,H100,1697105248010,1697105249681.0,120,17.0,1.0,"[17, 1654]","[1697105248027, 1697105249681]"
4962,444,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273587,1697105275208.0,120,,,[95],[1697105273682]
4963,483,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270309,1697105271973.0,120,,,[68],[1697105270377]
4964,293,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105249682,1697105252037.0,120,,,[33],[1697105249715]
4965,255,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238412,1697105240331.0,120,,,[195],[1697105238607]
4966,616,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240370,1697105243753.0,120,,,[252],[1697105240622]
4967,653,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253712.0,120,,,[57],[1697105252098]
4968,594,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105247242.0,120,,,[21],[1697105245527]
4969,81,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105255028.0,120,,,[173],[1697105253889]
4970,435,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[57],[1697105255087]
4971,628,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258921,1697105262306.0,120,,,[181],[1697105259102]
4972,602,26,[],200,EleutherAI/gpt-neox-20b,128,1,1597.0,1.0,1,H100,1697105240334,1697105241931.0,120,15.0,1.0,"[245, 1351]","[1697105240579, 1697105241930]"
4973,33,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241931,1697105243754.0,120,,,[13],[1697105241944]
4974,927,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248696.0,120,,,[148],[1697105247395]
4975,352,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248699,1697105252036.0,120,,,"[206, 2279]","[1697105248905, 1697105251184]"
4976,191,15,[],200,EleutherAI/gpt-neox-20b,128,1,4242.0,1.0,1,H100,1697105220997,1697105225239.0,120,85.0,20.0,"[7, 1663, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579]","[1697105221004, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239]"
4977,394,28,[],200,EleutherAI/gpt-neox-20b,128,1,1669.0,1.0,1,H100,1697105243758,1697105245427.0,120,11.0,1.0,"[22, 1647]","[1697105243780, 1697105245427]"
4978,752,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245428,1697105247242.0,120,,,[16],[1697105245444]
4979,28,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262310,1697105264082.0,120,,,[11],[1697105262321]
4980,710,32,[],200,EleutherAI/gpt-neox-20b,128,1,1639.0,1.0,1,H100,1697105252042,1697105253681.0,120,14.0,1.0,"[156, 1483]","[1697105252198, 1697105253681]"
4981,305,8,[],200,EleutherAI/gpt-neox-20b,128,1,5704.0,1.0,1,H100,1697105191685,1697105197389.0,120,86.0,20.0,"[9, 2695, 64, 84, 199, 80, 79, 260, 327, 86, 116, 83, 176, 417, 282, 184, 264, 85, 62, 152]","[1697105191694, 1697105194389, 1697105194453, 1697105194537, 1697105194736, 1697105194816, 1697105194895, 1697105195155, 1697105195482, 1697105195568, 1697105195684, 1697105195767, 1697105195943, 1697105196360, 1697105196642, 1697105196826, 1697105197090, 1697105197175, 1697105197237, 1697105197389]"
4982,135,33,[],200,EleutherAI/gpt-neox-20b,128,1,1375.0,1.0,1,H100,1697105253683,1697105255058.0,120,52.0,2.0,"[5, 1370]","[1697105253688, 1697105255058]"
4983,183,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[21],[1697105267819]
4984,495,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255059,1697105257114.0,120,,,[149],[1697105255208]
4985,387,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265930.0,120,,,[43],[1697105264128]
4986,791,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105260462.0,120,,,[186],[1697105257304]
4987,827,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105260463.0,120,,,[178],[1697105257296]
4988,266,30,[],200,EleutherAI/gpt-neox-20b,128,1,1388.0,1.0,1,H100,1697105247248,1697105248636.0,120,9.0,1.0,"[131, 1257]","[1697105247379, 1697105248636]"
4989,190,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260464,1697105262306.0,120,,,[40],[1697105260504]
4990,745,37,[],200,EleutherAI/gpt-neox-20b,128,1,2981.0,1.0,1,H100,1697105265934,1697105268915.0,120,17.0,1.0,"[176, 2805]","[1697105266110, 1697105268915]"
4991,551,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262312,1697105264082.0,120,,,[175],[1697105262487]
4992,174,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268916,1697105270303.0,120,,,[5],[1697105268921]
4993,350,33,[],200,EleutherAI/gpt-neox-20b,128,1,1680.0,1.0,1,H100,1697105262310,1697105263990.0,120,216.0,1.0,"[29, 1651]","[1697105262339, 1697105263990]"
4994,259,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260467,1697105262307.0,120,,,[133],[1697105260600]
4995,533,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270308,1697105271972.0,120,,,[69],[1697105270377]
4996,914,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265928.0,120,,,[6],[1697105264091]
4997,52,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271976,1697105273584.0,120,,,[13],[1697105271989]
4998,618,37,[],200,EleutherAI/gpt-neox-20b,128,1,1674.0,1.0,1,H100,1697105262316,1697105263990.0,120,9.0,1.0,"[304, 1370]","[1697105262620, 1697105263990]"
4999,544,16,[],200,EleutherAI/gpt-neox-20b,128,1,1714.0,1.0,1,H100,1697105225240,1697105226954.0,120,26.0,1.0,"[17, 1697]","[1697105225257, 1697105226954]"
5000,343,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265937,1697105271972.0,120,,,"[277, 2764, 669, 704, 685]","[1697105266214, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
5001,538,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[20],[1697105269620]
5002,47,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263991,1697105265927.0,120,,,[37],[1697105264028]
5003,795,34,[],200,EleutherAI/gpt-neox-20b,128,1,1013.0,1.0,1,H100,1697105263991,1697105265004.0,120,12.0,1.0,"[33, 980]","[1697105264024, 1697105265004]"
5004,397,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265932,1697105267796.0,120,,,[73],[1697105266005]
5005,863,39,[],200,EleutherAI/gpt-neox-20b,128,1,1758.0,1.0,1,H100,1697105270990,1697105272748.0,120,10.0,1.0,"[56, 1702]","[1697105271046, 1697105272748]"
5006,407,41,[],200,EleutherAI/gpt-neox-20b,128,1,1545.0,1.0,1,H100,1697105273587,1697105275132.0,120,16.0,1.0,"[23, 1522]","[1697105273610, 1697105275132]"
5007,727,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105270302.0,120,,,[204],[1697105268005]
5008,515,13,[],200,EleutherAI/gpt-neox-20b,128,1,1507.0,1.0,1,H100,1697105227244,1697105228751.0,120,11.0,1.0,"[9, 1498]","[1697105227253, 1697105228751]"
5009,92,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105255027.0,120,,,[163],[1697105253877]
5010,876,14,[],200,EleutherAI/gpt-neox-20b,128,1,900.0,1.0,1,H100,1697105228752,1697105229652.0,120,11.0,1.0,"[12, 888]","[1697105228764, 1697105229652]"
5011,673,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271975,1697105273585.0,120,,,[43],[1697105272018]
5012,98,40,[],200,EleutherAI/gpt-neox-20b,128,1,1545.0,1.0,1,H100,1697105273587,1697105275132.0,120,14.0,1.0,"[87, 1458]","[1697105273674, 1697105275132]"
5013,302,15,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105229653,1697105232145.0,120,,,"[20, 1832, 76, 75, 74, 73]","[1697105229673, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
5014,51,39,[],200,EleutherAI/gpt-neox-20b,128,1,3427.0,1.0,1,H100,1697105273589,1697105277016.0,120,364.0,36.0,"[198, 2157, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 33, 32, 32, 33, 29, 28, 28, 28, 32, 27, 27, 27, 27, 31, 26, 26, 29, 26, 26]","[1697105273787, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276502, 1697105276534, 1697105276566, 1697105276599, 1697105276628, 1697105276656, 1697105276684, 1697105276712, 1697105276744, 1697105276771, 1697105276798, 1697105276825, 1697105276852, 1697105276883, 1697105276909, 1697105276935, 1697105276964, 1697105276990, 1697105277016]"
5015,631,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232151,1697105234225.0,120,,,[132],[1697105232283]
5016,56,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234227,1697105236782.0,120,,,[56],[1697105234283]
5017,415,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236785,1697105240330.0,120,,,[229],[1697105237014]
5018,156,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270305,1697105271972.0,120,,,[23],[1697105270328]
5019,776,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241995.0,120,,,[53],[1697105240387]
5020,209,20,[],200,EleutherAI/gpt-neox-20b,128,1,1539.0,1.0,1,H100,1697105242015,1697105243554.0,120,20.0,1.0,"[261, 1278]","[1697105242276, 1697105243554]"
5021,539,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243555,1697105245503.0,120,,,[33],[1697105243588]
5022,518,14,[],200,EleutherAI/gpt-neox-20b,128,1,2467.0,1.0,1,H100,1697105225241,1697105227708.0,120,23.0,1.0,"[28, 2439]","[1697105225269, 1697105227708]"
5023,519,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271975,1697105273584.0,120,,,[31],[1697105272006]
5024,45,21,[],200,EleutherAI/gpt-neox-20b,128,1,1671.0,1.0,1,H100,1697105243756,1697105245427.0,120,19.0,1.0,"[31, 1640]","[1697105243787, 1697105245427]"
5025,786,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",9999,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,,120,,,[34],[1697105257151]
5026,881,15,[],200,EleutherAI/gpt-neox-20b,128,1,4021.0,1.0,1,H100,1697105227709,1697105231730.0,120,58.0,6.0,"[5, 2801, 990, 76, 74, 74]","[1697105227714, 1697105230515, 1697105231505, 1697105231581, 1697105231655, 1697105231729]"
5027,880,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273587,1697105275207.0,120,,,[10],[1697105273597]
5028,378,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245428,1697105247242.0,120,,,[25],[1697105245453]
5029,732,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247246,1697105248696.0,120,,,[15],[1697105247261]
5030,160,24,[],200,EleutherAI/gpt-neox-20b,128,1,2485.0,1.0,1,H100,1697105248700,1697105251185.0,120,13.0,1.0,"[213, 2271]","[1697105248913, 1697105251184]"
5031,516,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105251186,1697105253711.0,120,,,[16],[1697105251202]
5032,226,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265006,1697105267795.0,120,,,"[5, 2175]","[1697105265011, 1697105267186]"
5033,878,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105256009.0,120,,,[212],[1697105253926]
5034,279,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256011,1697105258907.0,120,,,[14],[1697105256025]
5035,637,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258915,1697105260463.0,120,,,[14],[1697105258929]
5036,907,17,[],200,EleutherAI/gpt-neox-20b,128,1,1796.0,1.0,1,H100,1697105226955,1697105228751.0,120,10.0,1.0,"[20, 1776]","[1697105226975, 1697105228751]"
5037,65,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260467,1697105262307.0,120,,,[222],[1697105260689]
5038,336,18,[],200,EleutherAI/gpt-neox-20b,128,1,3051.0,1.0,1,H100,1697105228752,1697105231803.0,120,58.0,7.0,"[4, 1760, 990, 75, 75, 74, 73]","[1697105228756, 1697105230516, 1697105231506, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
5039,695,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105231804,1697105234919.0,120,,,"[5, 1247, 600, 617]","[1697105231809, 1697105233056, 1697105233656, 1697105234273]"
5040,221,17,[],200,EleutherAI/gpt-neox-20b,128,1,8439.0,1.0,1,H100,1697105219565,1697105228004.0,120,364.0,36.0,"[9, 2391, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579, 81, 78, 75, 73, 706, 91, 84, 66, 84, 486, 91, 89, 85, 582, 94]","[1697105219574, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225320, 1697105225398, 1697105225473, 1697105225546, 1697105226252, 1697105226343, 1697105226427, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227910, 1697105228004]"
5041,215,20,[],200,EleutherAI/gpt-neox-20b,128,1,1834.0,1.0,1,H100,1697105234922,1697105236756.0,120,12.0,1.0,"[186, 1648]","[1697105235108, 1697105236756]"
5042,590,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[94],[1697105267892]
5043,292,40,[],200,EleutherAI/gpt-neox-20b,128,1,1666.0,1.0,1,H100,1697105272749,1697105274415.0,120,286.0,1.0,"[5, 1660]","[1697105272754, 1697105274414]"
5044,568,21,[],200,EleutherAI/gpt-neox-20b,128,1,1628.0,1.0,1,H100,1697105236757,1697105238385.0,120,11.0,1.0,"[32, 1595]","[1697105236789, 1697105238384]"
5045,928,22,[],200,EleutherAI/gpt-neox-20b,128,1,1879.0,1.0,1,H100,1697105238386,1697105240265.0,120,20.0,1.0,"[25, 1854]","[1697105238411, 1697105240265]"
5046,353,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240266,1697105241993.0,120,,,[13],[1697105240279]
5047,653,41,[],200,EleutherAI/gpt-neox-20b,128,1,1678.0,1.0,1,H100,1697105274415,1697105276093.0,120,96.0,6.0,"[9, 1520, 41, 41, 34, 33]","[1697105274424, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093]"
5048,450,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257115.0,120,,,[82],[1697105255112]
5049,424,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262314,1697105265927.0,120,,,[278],[1697105262592]
5050,780,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105260462.0,120,,,[186],[1697105257304]
5051,18,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[24],[1697105269624]
5052,781,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267795.0,120,,,[6],[1697105265937]
5053,297,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267799,1697105269598.0,120,,,[16],[1697105267815]
5054,509,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248637,1697105250348.0,120,,,[9],[1697105248646]
5055,349,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270989,1697105271973.0,120,,,[21],[1697105271010]
5056,870,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252038.0,120,,,[218],[1697105250569]
5057,300,31,[],200,EleutherAI/gpt-neox-20b,128,1,1641.0,1.0,1,H100,1697105252040,1697105253681.0,120,9.0,1.0,"[162, 1479]","[1697105252202, 1697105253681]"
5058,654,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253687,1697105255028.0,120,,,[98],[1697105253785]
5059,656,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269601,1697105270988.0,120,,,[72],[1697105269673]
5060,85,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270989,1697105271973.0,120,,,[13],[1697105271002]
5061,51,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257115.0,120,,,[138],[1697105255168]
5062,714,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242000,1697105243753.0,120,,,[43],[1697105242043]
5063,115,25,[],200,EleutherAI/gpt-neox-20b,128,1,1670.0,1.0,1,H100,1697105243757,1697105245427.0,120,13.0,1.0,"[119, 1551]","[1697105243876, 1697105245427]"
5064,476,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245429,1697105247242.0,120,,,[56],[1697105245485]
5065,699,39,[],200,EleutherAI/gpt-neox-20b,128,1,2436.0,1.0,1,H100,1697105271978,1697105274414.0,120,39.0,1.0,"[241, 2195]","[1697105272219, 1697105274414]"
5066,835,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247247,1697105248695.0,120,,,[47],[1697105247294]
5067,261,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248698,1697105250348.0,120,,,[83],[1697105248781]
5068,615,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252038.0,120,,,[158],[1697105250509]
5069,16,30,[],200,EleutherAI/gpt-neox-20b,128,1,1638.0,1.0,1,H100,1697105252044,1697105253682.0,120,9.0,1.0,"[267, 1371]","[1697105252311, 1697105253682]"
5070,373,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253686,1697105255027.0,120,,,[34],[1697105253720]
5071,439,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271977,1697105275207.0,120,,,[210],[1697105272187]
5072,738,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255029,1697105256010.0,120,,,[21],[1697105255050]
5073,384,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236781.0,120,,,[166],[1697105235088]
5074,168,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256016,1697105258913.0,120,,,[174],[1697105256190]
5075,743,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236783,1697105238408.0,120,,,[91],[1697105236874]
5076,176,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238411,1697105240330.0,120,,,[84],[1697105238495]
5077,409,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257118,1697105260463.0,120,,,[182],[1697105257300]
5078,537,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240333,1697105241995.0,120,,,[46],[1697105240379]
5079,770,35,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105260467,1697105262243.0,120,13.0,1.0,"[238, 1538]","[1697105260705, 1697105262243]"
5080,54,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243755.0,120,,,[10],[1697105242011]
5081,128,40,[],200,EleutherAI/gpt-neox-20b,128,1,1483.0,1.0,1,H100,1697105274415,1697105275898.0,120,9.0,1.0,"[17, 1466]","[1697105274432, 1697105275898]"
5082,201,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262244,1697105264083.0,120,,,[29],[1697105262273]
5083,649,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264087,1697105265928.0,120,,,[212],[1697105264299]
5084,408,22,[],200,EleutherAI/gpt-neox-20b,128,1,2438.0,1.0,1,H100,1697105243758,1697105246196.0,120,16.0,1.0,"[266, 2172]","[1697105244024, 1697105246196]"
5085,74,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265932,1697105267796.0,120,,,[73],[1697105266005]
5086,763,23,[],200,EleutherAI/gpt-neox-20b,128,1,1812.0,1.0,1,H100,1697105246197,1697105248009.0,120,20.0,1.0,"[21, 1790]","[1697105246218, 1697105248008]"
5087,432,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105270302.0,120,,,[191],[1697105267992]
5088,530,27,[],200,EleutherAI/gpt-neox-20b,128,1,2228.0,1.0,1,H100,1697105253716,1697105255944.0,120,26.0,1.0,"[266, 1962]","[1697105253982, 1697105255944]"
5089,885,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255948,1697105257115.0,120,,,[25],[1697105255973]
5090,313,29,[],200,EleutherAI/gpt-neox-20b,128,1,1732.0,1.0,1,H100,1697105257118,1697105258850.0,120,20.0,1.0,"[162, 1570]","[1697105257280, 1697105258850]"
5091,837,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271978,1697105275207.0,120,,,[220],[1697105272198]
5092,368,19,[],200,EleutherAI/gpt-neox-20b,128,1,3837.0,1.0,1,H100,1697105224418,1697105228255.0,120,88.0,20.0,"[4, 817, 82, 78, 74, 74, 705, 91, 85, 65, 84, 486, 91, 89, 85, 583, 93, 84, 84, 83]","[1697105224422, 1697105225239, 1697105225321, 1697105225399, 1697105225473, 1697105225547, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227911, 1697105228004, 1697105228088, 1697105228172, 1697105228255]"
5093,192,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248010,1697105250348.0,120,,,[5],[1697105248015]
5094,787,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270303,1697105271973.0,120,,,[9],[1697105270312]
5095,553,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252037.0,120,,,[138],[1697105250489]
5096,496,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258916,1697105260462.0,120,,,[52],[1697105258968]
5097,847,35,[],200,EleutherAI/gpt-neox-20b,128,1,1779.0,1.0,1,H100,1697105260464,1697105262243.0,120,10.0,1.0,"[44, 1735]","[1697105260508, 1697105262243]"
5098,277,36,[],200,EleutherAI/gpt-neox-20b,128,1,827.0,1.0,1,H100,1697105262244,1697105263071.0,120,18.0,1.0,"[49, 778]","[1697105262293, 1697105263071]"
5099,620,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248637,1697105250348.0,120,,,[9],[1697105248646]
5100,219,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271977,1697105273584.0,120,,,[201],[1697105272178]
5101,884,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253710.0,120,,,[129],[1697105252170]
5102,50,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252037.0,120,,,[150],[1697105250501]
5103,316,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105255027.0,120,,,[100],[1697105253814]
5104,407,33,[],200,EleutherAI/gpt-neox-20b,128,1,1640.0,1.0,1,H100,1697105252042,1697105253682.0,120,16.0,1.0,"[52, 1588]","[1697105252094, 1697105253682]"
5105,635,37,[],200,EleutherAI/gpt-neox-20b,128,1,1932.0,1.0,1,H100,1697105263072,1697105265004.0,120,23.0,1.0,"[29, 1903]","[1697105263101, 1697105265004]"
5106,66,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265006,1697105267796.0,120,,,[17],[1697105265023]
5107,549,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273587,1697105275208.0,120,,,[38],[1697105273625]
5108,670,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255029,1697105256010.0,120,,,[22],[1697105255051]
5109,100,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258914.0,120,,,[33],[1697105256046]
5110,772,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253686,1697105255027.0,120,,,[52],[1697105253738]
5111,343,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241206,1697105243753.0,120,,,[13],[1697105241219]
5112,173,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257114.0,120,,,[52],[1697105255082]
5113,530,36,[],200,EleutherAI/gpt-neox-20b,128,1,1732.0,1.0,1,H100,1697105257118,1697105258850.0,120,26.0,1.0,"[73, 1659]","[1697105257191, 1697105258850]"
5114,309,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105231730,1697105234919.0,120,,,"[5, 1321, 600, 617]","[1697105231735, 1697105233056, 1697105233656, 1697105234273]"
5115,881,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258851,1697105260463.0,120,,,[13],[1697105258864]
5116,702,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243756,1697105245502.0,120,,,[55],[1697105243811]
5117,311,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260468,1697105262307.0,120,,,[128],[1697105260596]
5118,669,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262315,1697105265927.0,120,,,[293],[1697105262608]
5119,663,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236780.0,120,,,[149],[1697105235071]
5120,72,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267796.0,120,,,[58],[1697105265989]
5121,435,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267799,1697105269598.0,120,,,[101],[1697105267900]
5122,60,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236783,1697105238408.0,120,,,[15],[1697105236798]
5123,792,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270302.0,120,,,[44],[1697105269644]
5124,418,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238411,1697105240330.0,120,,,[16],[1697105238427]
5125,777,20,[],200,EleutherAI/gpt-neox-20b,128,1,1598.0,1.0,1,H100,1697105240333,1697105241931.0,120,9.0,1.0,"[270, 1328]","[1697105240603, 1697105241931]"
5126,210,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105241932,1697105243754.0,120,,,[32],[1697105241964]
5127,542,22,[],200,EleutherAI/gpt-neox-20b,128,1,2438.0,1.0,1,H100,1697105243758,1697105246196.0,120,11.0,1.0,"[243, 2195]","[1697105244001, 1697105246196]"
5128,901,23,[],200,EleutherAI/gpt-neox-20b,128,1,1812.0,1.0,1,H100,1697105246197,1697105248009.0,120,17.0,1.0,"[29, 1783]","[1697105246226, 1697105248009]"
5129,326,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248010,1697105250348.0,120,,,[13],[1697105248023]
5130,403,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[82],[1697105267880]
5131,223,43,[],200,EleutherAI/gpt-neox-20b,128,1,1636.0,1.0,1,H100,1697105270309,1697105271945.0,120,16.0,1.0,"[72, 1564]","[1697105270381, 1697105271945]"
5132,215,32,[],200,EleutherAI/gpt-neox-20b,128,1,1519.0,1.0,1,H100,1697105258919,1697105260438.0,120,12.0,1.0,"[175, 1344]","[1697105259094, 1697105260438]"
5133,569,33,[],200,EleutherAI/gpt-neox-20b,128,1,1804.0,1.0,1,H100,1697105260439,1697105262243.0,120,16.0,1.0,"[41, 1763]","[1697105260480, 1697105262243]"
5134,2,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262244,1697105264083.0,120,,,[4],[1697105262248]
5135,573,44,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271946,1697105273585.0,120,,,[4],[1697105271950]
5136,361,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264086,1697105265928.0,120,,,[123],[1697105264209]
5137,901,45,[],200,EleutherAI/gpt-neox-20b,128,1,2309.0,1.0,1,H100,1697105273589,1697105275898.0,120,17.0,1.0,"[218, 2091]","[1697105273807, 1697105275898]"
5138,582,18,[],200,EleutherAI/gpt-neox-20b,128,1,1647.0,1.0,1,H100,1697105228005,1697105229652.0,120,19.0,1.0,"[13, 1634]","[1697105228018, 1697105229652]"
5139,458,30,[],200,EleutherAI/gpt-neox-20b,128,1,2505.0,1.0,1,H100,1697105258925,1697105261430.0,120,11.0,1.0,"[181, 2324]","[1697105259106, 1697105261430]"
5140,786,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105261431,1697105264082.0,120,,,[9],[1697105261440]
5141,11,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105229653,1697105232145.0,120,,,"[16, 1836, 76, 75, 74, 73]","[1697105229669, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
5142,216,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265928.0,120,,,[95],[1697105264180]
5143,518,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105270302.0,120,,,[180],[1697105267981]
5144,268,13,[],200,EleutherAI/gpt-neox-20b,128,1,2542.0,1.0,1,H100,1697105215296,1697105217838.0,120,19.0,1.0,"[12, 2530]","[1697105215308, 1697105217838]"
5145,626,14,[],200,EleutherAI/gpt-neox-20b,128,1,2198.0,1.0,1,H100,1697105217839,1697105220037.0,120,10.0,1.0,"[8, 2190]","[1697105217847, 1697105220037]"
5146,874,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270306,1697105271972.0,120,,,[34],[1697105270340]
5147,305,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271976,1697105273585.0,120,,,[98],[1697105272074]
5148,209,30,[],200,EleutherAI/gpt-neox-20b,128,1,1779.0,1.0,1,H100,1697105260464,1697105262243.0,120,20.0,1.0,"[28, 1751]","[1697105260492, 1697105262243]"
5149,373,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232151,1697105233608.0,120,,,[48],[1697105232199]
5150,759,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258851,1697105260463.0,120,,,[21],[1697105258872]
5151,655,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273588,1697105275208.0,120,,,[122],[1697105273710]
5152,811,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228257,1697105232145.0,120,,,"[16, 2243, 989, 76, 75, 74, 73]","[1697105228273, 1697105230516, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
5153,727,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233610,1697105234919.0,120,,,[24],[1697105233634]
5154,244,22,[],200,EleutherAI/gpt-neox-20b,128,1,1834.0,1.0,1,H100,1697105234922,1697105236756.0,120,9.0,1.0,"[25, 1809]","[1697105234947, 1697105236756]"
5155,236,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232153,1697105233609.0,120,,,[150],[1697105232303]
5156,594,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233611,1697105236781.0,120,,,[67],[1697105233678]
5157,24,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105238409.0,120,,,[130],[1697105236914]
5158,606,16,[],200,EleutherAI/gpt-neox-20b,128,1,1576.0,1.0,1,H100,1697105220997,1697105222573.0,120,9.0,1.0,"[10, 1566]","[1697105221007, 1697105222573]"
5159,34,17,[],200,EleutherAI/gpt-neox-20b,128,1,1588.0,1.0,1,H100,1697105222574,1697105224162.0,120,12.0,1.0,"[20, 1568]","[1697105222594, 1697105224162]"
5160,367,18,[],200,EleutherAI/gpt-neox-20b,128,1,1385.0,1.0,1,H100,1697105224162,1697105225547.0,120,92.0,6.0,"[5, 1072, 82, 78, 74, 74]","[1697105224167, 1697105225239, 1697105225321, 1697105225399, 1697105225473, 1697105225547]"
5161,389,24,[],200,EleutherAI/gpt-neox-20b,128,1,1854.0,1.0,1,H100,1697105238412,1697105240266.0,120,8.0,1.0,"[179, 1674]","[1697105238591, 1697105240265]"
5162,719,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240267,1697105241994.0,120,,,[28],[1697105240295]
5163,218,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245505,1697105247243.0,120,,,[164],[1697105245669]
5164,810,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265936,1697105271972.0,120,,,"[258, 2783, 670, 704, 685]","[1697105266194, 1697105268977, 1697105269647, 1697105270351, 1697105271036]"
5165,897,22,[],200,EleutherAI/gpt-neox-20b,128,1,1662.0,1.0,1,H100,1697105245506,1697105247168.0,120,9.0,1.0,"[204, 1458]","[1697105245710, 1697105247168]"
5166,323,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247169,1697105248696.0,120,,,[9],[1697105247178]
5167,677,24,[],200,EleutherAI/gpt-neox-20b,128,1,1623.0,1.0,1,H100,1697105248699,1697105250322.0,120,9.0,1.0,"[194, 1429]","[1697105248893, 1697105250322]"
5168,730,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.02 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.80 GiB is free. Process 1645736 has 77.30 GiB memory in use. Of the allocated memory 54.21 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105225548,1697105228772.0,120,,,[4],[1697105225552]
5169,158,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 8.24 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.68 GiB is free. Process 1645736 has 72.42 GiB memory in use. Of the allocated memory 54.80 GiB is allocated by PyTorch, and 16.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228775,1697105230475.0,120,,,[21],[1697105228796]
5170,240,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271975,1697105273584.0,120,,,[27],[1697105272002]
5171,518,21,[],200,EleutherAI/gpt-neox-20b,128,1,1647.0,1.0,1,H100,1697105230478,1697105232125.0,120,23.0,1.0,"[52, 1595]","[1697105230530, 1697105232125]"
5172,105,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250323,1697105252037.0,120,,,[12],[1697105250335]
5173,439,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252042,1697105253712.0,120,,,[244],[1697105252286]
5174,594,38,[],200,EleutherAI/gpt-neox-20b,128,1,5246.0,1.0,1,H100,1697105273589,1697105278835.0,120,216.0,119.0,"[285, 2070, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 32, 33, 32, 33, 29, 28, 28, 28, 32, 27, 27, 27, 27, 31, 26, 26, 29, 26, 26, 28, 25, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 24, 26, 25, 23, 23, 23, 24, 24, 21, 22, 22, 22, 22, 22, 23, 22, 22, 20, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21]","[1697105273874, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276501, 1697105276534, 1697105276566, 1697105276599, 1697105276628, 1697105276656, 1697105276684, 1697105276712, 1697105276744, 1697105276771, 1697105276798, 1697105276825, 1697105276852, 1697105276883, 1697105276909, 1697105276935, 1697105276964, 1697105276990, 1697105277016, 1697105277044, 1697105277069, 1697105277093, 1697105277118, 1697105277143, 1697105277168, 1697105277193, 1697105277218, 1697105277243, 1697105277268, 1697105277293, 1697105277318, 1697105277342, 1697105277368, 1697105277393, 1697105277416, 1697105277439, 1697105277462, 1697105277486, 1697105277510, 1697105277531, 1697105277553, 1697105277575, 1697105277597, 1697105277619, 1697105277641, 1697105277664, 1697105277686, 1697105277708, 1697105277728, 1697105277749, 1697105277770, 1697105277791, 1697105277812, 1697105277833, 1697105277853, 1697105277874, 1697105277895, 1697105277916, 1697105277937, 1697105277957, 1697105277978, 1697105277999, 1697105278020, 1697105278041, 1697105278062, 1697105278083, 1697105278103, 1697105278124, 1697105278145, 1697105278166, 1697105278187, 1697105278208, 1697105278229, 1697105278249, 1697105278270, 1697105278291, 1697105278312, 1697105278333, 1697105278354, 1697105278375, 1697105278396, 1697105278417, 1697105278437, 1697105278458, 1697105278479, 1697105278500, 1697105278521, 1697105278542, 1697105278563, 1697105278584, 1697105278605, 1697105278626, 1697105278646, 1697105278667, 1697105278688, 1697105278709, 1697105278730, 1697105278751, 1697105278772, 1697105278793, 1697105278814, 1697105278835]"
5175,760,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[36],[1697105269636]
5176,801,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105255028.0,120,,,[202],[1697105253918]
5177,191,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270990,1697105273585.0,120,,,[84],[1697105271074]
5178,548,43,[],200,EleutherAI/gpt-neox-20b,128,1,2976.0,1.0,1,H100,1697105273590,1697105276566.0,120,86.0,20.0,"[229, 2125, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 33, 32, 32]","[1697105273819, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276502, 1697105276534, 1697105276566]"
5179,872,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232126,1697105234919.0,120,,,"[5, 925, 600, 617]","[1697105232131, 1697105233056, 1697105233656, 1697105234273]"
5180,229,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255030,1697105257115.0,120,,,[77],[1697105255107]
5181,598,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.93 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 15.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236757,1697105238409.0,120,,,[8],[1697105236765]
5182,51,15,[],200,EleutherAI/gpt-neox-20b,128,1,7966.0,1.0,1,H100,1697105220038,1697105228004.0,120,364.0,36.0,"[8, 1919, 702, 87, 84, 83, 81, 401, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 579, 82, 77, 75, 73, 707, 90, 84, 66, 84, 486, 91, 89, 85, 582, 94]","[1697105220046, 1697105221965, 1697105222667, 1697105222754, 1697105222838, 1697105222921, 1697105223002, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225239, 1697105225321, 1697105225398, 1697105225473, 1697105225546, 1697105226253, 1697105226343, 1697105226427, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227910, 1697105228004]"
5183,31,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238412,1697105240330.0,120,,,[107],[1697105238519]
5184,390,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241993.0,120,,,[137],[1697105240471]
5185,588,29,[],200,EleutherAI/gpt-neox-20b,128,1,2654.0,1.0,1,H100,1697105257118,1697105259772.0,120,11.0,1.0,"[254, 2400]","[1697105257372, 1697105259772]"
5186,719,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242006,1697105245502.0,120,,,[282],[1697105242288]
5187,267,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236780.0,120,,,[153],[1697105235075]
5188,10,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105259773,1697105262306.0,120,,,[16],[1697105259789]
5189,570,31,[],200,EleutherAI/gpt-neox-20b,128,1,827.0,1.0,1,H100,1697105262244,1697105263071.0,120,18.0,1.0,"[25, 802]","[1697105262269, 1697105263071]"
5190,926,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263072,1697105265927.0,120,,,[12],[1697105263084]
5191,227,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250350,1697105252038.0,120,,,[9],[1697105250359]
5192,456,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262311,1697105264083.0,120,,,[64],[1697105262375]
5193,586,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252042,1697105253712.0,120,,,[236],[1697105252278]
5194,147,27,[],200,EleutherAI/gpt-neox-20b,128,1,1664.0,1.0,1,H100,1697105245504,1697105247168.0,120,182.0,1.0,"[96, 1568]","[1697105245600, 1697105247168]"
5195,680,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252037.0,120,,,[126],[1697105250477]
5196,188,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260467,1697105262306.0,120,,,[121],[1697105260588]
5197,546,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262312,1697105264081.0,120,,,[183],[1697105262495]
5198,905,33,[],200,EleutherAI/gpt-neox-20b,128,1,1778.0,1.0,1,H100,1697105264085,1697105265863.0,120,11.0,1.0,"[31, 1747]","[1697105264116, 1697105265863]"
5199,330,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265864,1697105267796.0,120,,,[9],[1697105265873]
5200,110,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252041,1697105253713.0,120,,,[49],[1697105252090]
5201,663,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267799,1697105269598.0,120,,,[117],[1697105267916]
5202,914,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[254],[1697105253970]
5203,442,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[316],[1697105254032]
5204,325,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267796.0,120,,,[66],[1697105265997]
5205,679,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105270302.0,120,,,[192],[1697105267993]
5206,92,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[85],[1697105269685]
5207,453,37,[],200,EleutherAI/gpt-neox-20b,128,1,1759.0,1.0,1,H100,1697105270989,1697105272748.0,120,26.0,1.0,"[41, 1718]","[1697105271030, 1697105272748]"
5208,809,38,[],200,EleutherAI/gpt-neox-20b,128,1,1664.0,1.0,1,H100,1697105272750,1697105274414.0,120,16.0,1.0,"[16, 1648]","[1697105272766, 1697105274414]"
5209,208,39,[],200,EleutherAI/gpt-neox-20b,128,1,2151.0,1.0,1,H100,1697105274415,1697105276566.0,120,96.0,20.0,"[17, 1512, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 33, 32, 32]","[1697105274432, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276502, 1697105276534, 1697105276566]"
5210,113,35,[],200,EleutherAI/gpt-neox-20b,128,1,1636.0,1.0,1,H100,1697105270309,1697105271945.0,120,13.0,1.0,"[80, 1556]","[1697105270389, 1697105271945]"
5211,626,24,[],200,EleutherAI/gpt-neox-20b,128,1,1601.0,1.0,1,H100,1697105236784,1697105238385.0,120,10.0,1.0,"[29, 1572]","[1697105236813, 1697105238385]"
5212,801,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258913.0,120,,,[96],[1697105256109]
5213,470,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271946,1697105273585.0,120,,,[13],[1697105271959]
5214,234,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258918,1697105260462.0,120,,,"[87, 1432]","[1697105259005, 1697105260437]"
5215,59,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105238386,1697105240331.0,120,,,[12],[1697105238398]
5216,588,30,[],200,EleutherAI/gpt-neox-20b,128,1,1778.0,1.0,1,H100,1697105260465,1697105262243.0,120,11.0,1.0,"[107, 1671]","[1697105260572, 1697105262243]"
5217,420,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 55.42 GiB is allocated by PyTorch, and 15.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240334,1697105241994.0,120,,,[234],[1697105240568]
5218,18,31,[],200,EleutherAI/gpt-neox-20b,128,1,827.0,1.0,1,H100,1697105262244,1697105263071.0,120,15.0,1.0,"[37, 790]","[1697105262281, 1697105263071]"
5219,832,37,[],200,EleutherAI/gpt-neox-20b,128,1,1543.0,1.0,1,H100,1697105273589,1697105275132.0,120,15.0,1.0,"[190, 1353]","[1697105273779, 1697105275132]"
5220,750,27,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105242001,1697105243753.0,120,,,[90],[1697105242091]
5221,381,16,[],200,EleutherAI/gpt-neox-20b,128,1,2511.0,1.0,1,H100,1697105228005,1697105230516.0,120,140.0,2.0,"[4, 2506]","[1697105228009, 1697105230515]"
5222,175,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243757,1697105245503.0,120,,,[143],[1697105243900]
5223,742,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105230516,1697105234918.0,120,,,"[201, 2339, 600, 617]","[1697105230717, 1697105233056, 1697105233656, 1697105234273]"
5224,813,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264086,1697105265928.0,120,,,[118],[1697105264204]
5225,573,33,[],200,EleutherAI/gpt-neox-20b,128,1,3043.0,1.0,1,H100,1697105265935,1697105268978.0,120,874.0,2.0,"[243, 2800]","[1697105266178, 1697105268978]"
5226,249,33,[],200,EleutherAI/gpt-neox-20b,128,1,5101.0,1.0,1,H100,1697105265935,1697105271036.0,120,874.0,5.0,"[255, 2788, 669, 704, 685]","[1697105266190, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
5227,343,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258907.0,120,,,[29],[1697105256042]
5228,463,32,[],200,EleutherAI/gpt-neox-20b,128,1,1932.0,1.0,1,H100,1697105263072,1697105265004.0,120,39.0,1.0,"[21, 1911]","[1697105263093, 1697105265004]"
5229,506,28,[],200,EleutherAI/gpt-neox-20b,128,1,839.0,1.0,1,H100,1697105247170,1697105248009.0,120,16.0,1.0,"[32, 807]","[1697105247202, 1697105248009]"
5230,863,29,[],200,EleutherAI/gpt-neox-20b,128,1,1670.0,1.0,1,H100,1697105248011,1697105249681.0,120,10.0,1.0,"[28, 1642]","[1697105248039, 1697105249681]"
5231,7,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105268979,1697105270302.0,120,,,[4],[1697105268983]
5232,292,30,[],200,EleutherAI/gpt-neox-20b,128,1,1502.0,1.0,1,H100,1697105249682,1697105251184.0,120,286.0,1.0,"[12, 1490]","[1697105249694, 1697105251184]"
5233,362,35,[],200,EleutherAI/gpt-neox-20b,128,1,1636.0,1.0,1,H100,1697105270309,1697105271945.0,120,14.0,1.0,"[96, 1540]","[1697105270405, 1697105271945]"
5234,690,36,[],200,EleutherAI/gpt-neox-20b,128,1,803.0,1.0,1,H100,1697105271946,1697105272749.0,120,39.0,1.0,"[25, 778]","[1697105271971, 1697105272749]"
5235,121,37,[],200,EleutherAI/gpt-neox-20b,128,1,1664.0,1.0,1,H100,1697105272750,1697105274414.0,120,13.0,1.0,"[24, 1640]","[1697105272774, 1697105274414]"
5236,478,38,[],200,EleutherAI/gpt-neox-20b,128,1,3225.0,1.0,1,H100,1697105274416,1697105277641.0,120,161.0,62.0,"[28, 1500, 41, 41, 34, 33, 41, 39, 33, 33, 32, 39, 31, 32, 32, 32, 32, 33, 32, 32, 33, 29, 28, 28, 28, 32, 27, 27, 27, 28, 30, 26, 26, 29, 26, 26, 28, 25, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 23, 23, 24, 23, 24, 21, 22, 22, 22, 22, 22]","[1697105274444, 1697105275944, 1697105275985, 1697105276026, 1697105276060, 1697105276093, 1697105276134, 1697105276173, 1697105276206, 1697105276239, 1697105276271, 1697105276310, 1697105276341, 1697105276373, 1697105276405, 1697105276437, 1697105276469, 1697105276502, 1697105276534, 1697105276566, 1697105276599, 1697105276628, 1697105276656, 1697105276684, 1697105276712, 1697105276744, 1697105276771, 1697105276798, 1697105276825, 1697105276853, 1697105276883, 1697105276909, 1697105276935, 1697105276964, 1697105276990, 1697105277016, 1697105277044, 1697105277069, 1697105277093, 1697105277118, 1697105277143, 1697105277168, 1697105277193, 1697105277218, 1697105277243, 1697105277268, 1697105277293, 1697105277318, 1697105277343, 1697105277368, 1697105277393, 1697105277416, 1697105277439, 1697105277463, 1697105277486, 1697105277510, 1697105277531, 1697105277553, 1697105277575, 1697105277597, 1697105277619, 1697105277641]"
5237,702,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258916,1697105260462.0,120,,,[53],[1697105258969]
5238,147,26,[],200,EleutherAI/gpt-neox-20b,128,1,1553.0,1.0,1,H100,1697105242001,1697105243554.0,120,182.0,1.0,"[183, 1370]","[1697105242184, 1697105243554]"
5239,622,31,[],200,EleutherAI/gpt-neox-20b,128,1,1379.0,1.0,1,H100,1697105251186,1697105252565.0,120,20.0,1.0,"[24, 1354]","[1697105251210, 1697105252564]"
5240,498,27,[],200,EleutherAI/gpt-neox-20b,128,1,922.0,1.0,1,H100,1697105243555,1697105244477.0,120,9.0,1.0,"[37, 885]","[1697105243592, 1697105244477]"
5241,857,28,[],200,EleutherAI/gpt-neox-20b,128,1,1718.0,1.0,1,H100,1697105244478,1697105246196.0,120,18.0,1.0,"[13, 1705]","[1697105244491, 1697105246196]"
5242,535,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105247243.0,120,,,[208],[1697105245714]
5243,51,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252565,1697105256010.0,120,,,"[5, 2488]","[1697105252570, 1697105255058]"
5244,889,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105247254,1697105250347.0,120,,,[241],[1697105247495]
5245,410,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258912.0,120,,,[41],[1697105256054]
5246,768,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258915,1697105260463.0,120,,,[22],[1697105258937]
5247,286,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105246198,1697105248696.0,120,,,[44],[1697105246242]
5248,197,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260467,1697105262306.0,120,,,[129],[1697105260596]
5249,527,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262313,1697105264082.0,120,,,[263],[1697105262576]
5250,618,30,[],200,EleutherAI/gpt-neox-20b,128,1,2485.0,1.0,1,H100,1697105248699,1697105251184.0,120,9.0,1.0,"[202, 2283]","[1697105248901, 1697105251184]"
5251,52,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105251185,1697105253711.0,120,,,[21],[1697105251206]
5252,884,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264085,1697105265927.0,120,,,[83],[1697105264168]
5253,410,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105255027.0,120,,,[95],[1697105253809]
5254,320,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250349,1697105252037.0,120,,,[60],[1697105250409]
5255,764,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255029,1697105257113.0,120,,,[33],[1697105255062]
5256,766,32,[],200,EleutherAI/gpt-neox-20b,128,1,1639.0,1.0,1,H100,1697105252042,1697105253681.0,120,11.0,1.0,"[160, 1479]","[1697105252202, 1697105253681]"
5257,199,33,[],200,EleutherAI/gpt-neox-20b,128,1,386.0,1.0,1,H100,1697105253685,1697105254071.0,120,13.0,1.0,"[10, 376]","[1697105253695, 1697105254071]"
5258,312,38,[],200,EleutherAI/gpt-neox-20b,128,1,1840.0,1.0,1,H100,1697105265932,1697105267772.0,120,23.0,1.0,"[137, 1703]","[1697105266069, 1697105267772]"
5259,190,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105257117,1697105258913.0,120,,,[26],[1697105257143]
5260,663,9,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.51 GiB is free. Process 1645736 has 77.59 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105197390,1697105201999.0,120,,,"[4, 3232, 296, 80, 292, 160, 212]","[1697105197394, 1697105200626, 1697105200922, 1697105201002, 1697105201294, 1697105201454, 1697105201666]"
5261,553,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105254072,1697105256011.0,120,,,[4],[1697105254076]
5262,173,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.83 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.30 GiB is allocated by PyTorch, and 20.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105234922,1697105236782.0,120,,,[17],[1697105234939]
5263,820,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265006,1697105267795.0,120,,,[17],[1697105265023]
5264,534,19,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.53 GiB is free. Process 1645736 has 71.56 GiB memory in use. Of the allocated memory 54.49 GiB is allocated by PyTorch, and 16.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105236784,1697105240330.0,120,,,[206],[1697105236990]
5265,131,31,[],200,EleutherAI/gpt-neox-20b,128,1,1778.0,1.0,1,H100,1697105260465,1697105262243.0,120,8.0,1.0,"[103, 1675]","[1697105260568, 1697105262243]"
5266,250,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267799,1697105269598.0,120,,,[97],[1697105267896]
5267,912,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 14.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105256013,1697105258913.0,120,,,[173],[1697105256186]
5268,608,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[36],[1697105269636]
5269,50,20,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.12 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 15.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105240333,1697105243753.0,120,,,[267],[1697105240600]
5270,36,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270989,1697105273584.0,120,,,[17],[1697105271006]
5271,405,21,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.37 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 14.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105243757,1697105245502.0,120,,,[114],[1697105243871]
5272,367,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273587,1697105275208.0,120,,,[91],[1697105273678]
5273,759,22,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.41 GiB is allocated by PyTorch, and 13.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105245506,1697105248695.0,120,,,[278],[1697105245784]
5274,341,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258920,1697105260463.0,120,,,[149],[1697105259069]
5275,187,23,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.90 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 12.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105248697,1697105250348.0,120,,,[72],[1697105248769]
5276,550,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105250351,1697105252037.0,120,,,[146],[1697105250497]
5277,94,10,[],200,EleutherAI/gpt-neox-20b,128,1,4078.0,1.0,1,H100,1697105202004,1697105206082.0,120,86.0,20.0,"[83, 1631, 88, 88, 87, 269, 87, 86, 84, 415, 92, 89, 88, 69, 87, 86, 390, 90, 85, 84]","[1697105202087, 1697105203718, 1697105203806, 1697105203894, 1697105203981, 1697105204250, 1697105204337, 1697105204423, 1697105204507, 1697105204922, 1697105205014, 1697105205103, 1697105205191, 1697105205260, 1697105205347, 1697105205433, 1697105205823, 1697105205913, 1697105205998, 1697105206082]"
5278,492,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262244,1697105264083.0,120,,,[29],[1697105262273]
5279,883,25,[],200,EleutherAI/gpt-neox-20b,128,1,1641.0,1.0,1,H100,1697105252041,1697105253682.0,120,563.0,1.0,"[73, 1568]","[1697105252114, 1697105253682]"
5280,313,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 57.99 GiB is allocated by PyTorch, and 11.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253686,1697105255027.0,120,,,[36],[1697105253722]
5281,6,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264087,1697105267795.0,120,,,[224],[1697105264311]
5282,669,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260465,1697105262307.0,120,,,[19],[1697105260484]
5283,100,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262311,1697105264083.0,120,,,[96],[1697105262407]
5284,457,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264087,1697105267795.0,120,,,[199],[1697105264286]
5285,518,35,[],200,EleutherAI/gpt-neox-20b,128,1,1522.0,1.0,1,H100,1697105258916,1697105260438.0,120,23.0,1.0,"[65, 1457]","[1697105258981, 1697105260438]"
5286,877,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105260439,1697105262307.0,120,,,[16],[1697105260455]
5287,310,37,[],200,EleutherAI/gpt-neox-20b,128,1,1677.0,1.0,1,H100,1697105262313,1697105263990.0,120,26.0,1.0,"[187, 1490]","[1697105262500, 1697105263990]"
5288,671,38,[],200,EleutherAI/gpt-neox-20b,128,1,1013.0,1.0,1,H100,1697105263992,1697105265005.0,120,12.0,1.0,"[56, 957]","[1697105264048, 1697105265005]"
5289,189,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265006,1697105267796.0,120,,,[33],[1697105265039]
5290,543,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.57 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267801,1697105270302.0,120,,,[199],[1697105268000]
5291,900,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270305,1697105271973.0,120,,,[23],[1697105270328]
5292,326,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271977,1697105273584.0,120,,,[197],[1697105272174]
5293,687,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273587,1697105275208.0,120,,,[22],[1697105273609]
5294,363,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269598.0,120,,,[90],[1697105267888]
5295,608,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271037,1697105273585.0,120,,,[57],[1697105271094]
5296,576,23,[],200,EleutherAI/gpt-neox-20b,128,1,2427.0,1.0,1,H100,1697105247254,1697105249681.0,120,14.0,1.0,"[245, 2182]","[1697105247499, 1697105249681]"
5297,6,24,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 10.82 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105249682,1697105252037.0,120,,,[8],[1697105249690]
5298,820,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267798,1697105269599.0,120,,,[78],[1697105267876]
5299,245,41,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[76],[1697105269676]
5300,455,11,[],200,EleutherAI/gpt-neox-20b,128,1,5399.0,1.0,1,H100,1697105206084,1697105211483.0,120,91.0,20.0,"[5, 1888, 86, 83, 82, 64, 434, 87, 84, 79, 77, 385, 77, 618, 86, 83, 502, 82, 428, 168]","[1697105206089, 1697105207977, 1697105208063, 1697105208146, 1697105208228, 1697105208292, 1697105208726, 1697105208813, 1697105208897, 1697105208976, 1697105209053, 1697105209438, 1697105209515, 1697105210133, 1697105210219, 1697105210302, 1697105210804, 1697105210886, 1697105211314, 1697105211482]"
5301,364,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105252045,1697105253712.0,120,,,[282],[1697105252327]
5302,725,26,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253716,1697105256010.0,120,,,[270],[1697105253986]
5303,672,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267773,1697105271972.0,120,,,"[9, 1196, 669, 704, 685]","[1697105267782, 1697105268978, 1697105269647, 1697105270351, 1697105271036]"
5304,717,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[32],[1697105269632]
5305,671,27,[],200,EleutherAI/gpt-neox-20b,128,1,915.0,1.0,1,H100,1697105255029,1697105255944.0,120,12.0,1.0,"[5, 910]","[1697105255034, 1697105255944]"
5306,97,40,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271977,1697105273584.0,120,,,[21],[1697105271998]
5307,547,41,[],200,EleutherAI/gpt-neox-20b,128,1,1545.0,1.0,1,H100,1697105273587,1697105275132.0,120,12.0,1.0,"[27, 1518]","[1697105273614, 1697105275132]"
5308,92,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.27 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 14.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105255948,1697105257114.0,120,,,[19],[1697105255967]
5309,123,27,[],200,EleutherAI/gpt-neox-20b,128,1,2017.0,1.0,1,H100,1697105256013,1697105258030.0,120,14.0,1.0,"[161, 1856]","[1697105256174, 1697105258030]"
5310,151,36,[],200,EleutherAI/gpt-neox-20b,128,1,1758.0,1.0,1,H100,1697105270990,1697105272748.0,120,39.0,1.0,"[84, 1674]","[1697105271074, 1697105272748]"
5311,480,28,[],200,EleutherAI/gpt-neox-20b,128,1,1741.0,1.0,1,H100,1697105258031,1697105259772.0,120,26.0,1.0,"[24, 1717]","[1697105258055, 1697105259772]"
5312,8,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273587,1697105275208.0,120,,,[18],[1697105273605]
5313,834,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.64 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.75 GiB is allocated by PyTorch, and 12.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105259773,1697105262307.0,120,,,[24],[1697105259797]
5314,509,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105272749,1697105275207.0,120,,,[9],[1697105272758]
5315,573,42,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270989,1697105273584.0,120,,,[17],[1697105271006]
5316,268,30,[],200,EleutherAI/gpt-neox-20b,128,1,1676.0,1.0,1,H100,1697105262314,1697105263990.0,120,19.0,1.0,"[294, 1382]","[1697105262608, 1697105263990]"
5317,4,43,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273587,1697105275208.0,120,,,[34],[1697105273621]
5318,625,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105263991,1697105265927.0,120,,,[8],[1697105263999]
5319,27,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265931,1697105267796.0,120,,,[38],[1697105265969]
5320,451,29,[],200,EleutherAI/gpt-neox-20b,128,1,1733.0,1.0,1,H100,1697105257117,1697105258850.0,120,286.0,1.0,"[70, 1663]","[1697105257187, 1697105258850]"
5321,388,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267799,1697105269598.0,120,,,[73],[1697105267872]
5322,742,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[52],[1697105269652]
5323,172,35,[],200,EleutherAI/gpt-neox-20b,128,1,956.0,1.0,1,H100,1697105270989,1697105271945.0,120,19.0,1.0,"[37, 919]","[1697105271026, 1697105271945]"
5324,526,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271946,1697105273584.0,120,,,[17],[1697105271963]
5325,779,30,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258851,1697105260463.0,120,,,[9],[1697105258860]
5326,858,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273588,1697105275209.0,120,,,[114],[1697105273702]
5327,779,12,[],200,EleutherAI/gpt-neox-20b,128,1,3158.0,1.0,1,H100,1697105211484,1697105214642.0,120,563.0,10.0,"[28, 2318, 94, 90, 89, 68, 246, 85, 64, 76]","[1697105211512, 1697105213830, 1697105213924, 1697105214014, 1697105214103, 1697105214171, 1697105214417, 1697105214502, 1697105214566, 1697105214642]"
5328,215,31,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105260467,1697105262243.0,120,12.0,1.0,"[145, 1631]","[1697105260612, 1697105262243]"
5329,574,32,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262244,1697105264083.0,120,,,[13],[1697105262257]
5330,3,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.89 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.85 GiB is allocated by PyTorch, and 10.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105264086,1697105265928.0,120,,,[204],[1697105264290]
5331,357,34,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.97 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.89 GiB is allocated by PyTorch, and 18.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265935,1697105271972.0,120,,,"[263, 2780, 668, 705, 685]","[1697105266198, 1697105268978, 1697105269646, 1697105270351, 1697105271036]"
5332,209,13,[],200,EleutherAI/gpt-neox-20b,128,1,2169.0,1.0,1,H100,1697105214643,1697105216812.0,120,20.0,1.0,"[11, 2158]","[1697105214654, 1697105216812]"
5333,684,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105271975,1697105273585.0,120,,,[35],[1697105272010]
5334,563,14,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.19 GiB. GPU 0 has a total capacty of 79.11 GiB of which 1.48 GiB is free. Process 1645736 has 77.61 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 22.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105216813,1697105220995.0,120,,,"[5, 3006, 62, 233, 79, 229, 81, 198]","[1697105216818, 1697105219824, 1697105219886, 1697105220119, 1697105220198, 1697105220427, 1697105220508, 1697105220706]"
5335,112,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273587,1697105275208.0,120,,,[30],[1697105273617]
5336,926,15,[],200,EleutherAI/gpt-neox-20b,128,1,7006.0,1.0,1,H100,1697105220998,1697105228004.0,120,563.0,30.0,"[174, 2231, 71, 92, 87, 86, 85, 81, 351, 91, 70, 88, 87, 68, 580, 81, 78, 74, 73, 706, 91, 85, 65, 84, 486, 91, 89, 85, 582, 94]","[1697105221172, 1697105223403, 1697105223474, 1697105223566, 1697105223653, 1697105223739, 1697105223824, 1697105223905, 1697105224256, 1697105224347, 1697105224417, 1697105224505, 1697105224592, 1697105224660, 1697105225240, 1697105225321, 1697105225399, 1697105225473, 1697105225546, 1697105226252, 1697105226343, 1697105226428, 1697105226493, 1697105226577, 1697105227063, 1697105227154, 1697105227243, 1697105227328, 1697105227910, 1697105228004]"
5337,355,16,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 20.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105228005,1697105232145.0,120,,,"[4, 2507, 989, 76, 75, 74, 73]","[1697105228009, 1697105230516, 1697105231505, 1697105231581, 1697105231656, 1697105231730, 1697105231803]"
5338,803,17,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.06 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 19.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105232150,1697105233609.0,120,,,[61],[1697105232211]
5339,234,18,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.76 GiB. GPU 0 has a total capacty of 79.11 GiB of which 3.49 GiB is free. Process 1645736 has 75.61 GiB memory in use. Of the allocated memory 53.30 GiB is allocated by PyTorch, and 21.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105233610,1697105234919.0,120,,,"[60, 1212]","[1697105233670, 1697105234882]"
5340,587,19,[],200,EleutherAI/gpt-neox-20b,128,1,1833.0,1.0,1,H100,1697105234923,1697105236756.0,120,13.0,1.0,"[60, 1773]","[1697105234983, 1697105236756]"
5341,12,20,[],200,EleutherAI/gpt-neox-20b,128,1,1628.0,1.0,1,H100,1697105236757,1697105238385.0,120,11.0,1.0,"[40, 1588]","[1697105236797, 1697105238385]"
5342,371,21,[],200,EleutherAI/gpt-neox-20b,128,1,953.0,1.0,1,H100,1697105238386,1697105239339.0,120,13.0,1.0,"[20, 933]","[1697105238406, 1697105239339]"
5343,703,22,[],200,EleutherAI/gpt-neox-20b,128,1,1863.0,1.0,1,H100,1697105239342,1697105241205.0,120,12.0,1.0,"[47, 1816]","[1697105239389, 1697105241205]"
5344,136,23,[],200,EleutherAI/gpt-neox-20b,128,1,1484.0,1.0,1,H100,1697105241206,1697105242690.0,120,31.0,1.0,"[17, 1467]","[1697105241223, 1697105242690]"
5345,495,24,[],200,EleutherAI/gpt-neox-20b,128,1,1786.0,1.0,1,H100,1697105242691,1697105244477.0,120,13.0,1.0,"[9, 1777]","[1697105242700, 1697105244477]"
5346,853,25,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.12 GiB is allocated by PyTorch, and 13.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105244478,1697105247242.0,120,,,[5],[1697105244483]
5347,250,26,[],200,EleutherAI/gpt-neox-20b,128,1,2429.0,1.0,1,H100,1697105247251,1697105249680.0,120,31.0,1.0,"[228, 2201]","[1697105247479, 1697105249680]"
5348,605,27,[],200,EleutherAI/gpt-neox-20b,128,1,1502.0,1.0,1,H100,1697105249682,1697105251184.0,120,8.0,1.0,"[32, 1470]","[1697105249714, 1697105251184]"
5349,32,28,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 11.75 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 13.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105251186,1697105253711.0,120,,,[40],[1697105251226]
5350,395,29,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 9.69 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 53.81 GiB is allocated by PyTorch, and 15.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105253714,1697105256011.0,120,,,[196],[1697105253910]
5351,757,30,[],200,EleutherAI/gpt-neox-20b,128,1,2017.0,1.0,1,H100,1697105256013,1697105258030.0,120,20.0,1.0,"[165, 1852]","[1697105256178, 1697105258030]"
5352,156,31,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.68 GiB. GPU 0 has a total capacty of 79.11 GiB of which 8.46 GiB is free. Process 1645736 has 70.64 GiB memory in use. Of the allocated memory 56.77 GiB is allocated by PyTorch, and 12.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105258031,1697105260463.0,120,,,[20],[1697105258051]
5353,515,32,[],200,EleutherAI/gpt-neox-20b,128,1,1776.0,1.0,1,H100,1697105260467,1697105262243.0,120,11.0,1.0,"[242, 1534]","[1697105260709, 1697105262243]"
5354,866,33,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.53 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.49 GiB is free. Process 1645736 has 67.60 GiB memory in use. Of the allocated memory 55.64 GiB is allocated by PyTorch, and 11.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105262244,1697105264082.0,120,,,[41],[1697105262285]
5355,296,34,[],200,EleutherAI/gpt-neox-20b,128,1,1778.0,1.0,1,H100,1697105264085,1697105265863.0,120,6.0,1.0,"[91, 1687]","[1697105264176, 1697105265863]"
5356,654,35,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 13.07 GiB. GPU 0 has a total capacty of 79.11 GiB of which 11.21 GiB is free. Process 1645736 has 67.89 GiB memory in use. Of the allocated memory 56.04 GiB is allocated by PyTorch, and 10.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105265864,1697105267796.0,120,,,[21],[1697105265885]
5357,176,36,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.62 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.96 GiB is allocated by PyTorch, and 18.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105267799,1697105269598.0,120,,,[105],[1697105267904]
5358,536,37,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 6.52 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 56.95 GiB is allocated by PyTorch, and 18.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105269600,1697105270988.0,120,,,[44],[1697105269644]
5359,893,38,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.38 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.72 GiB is free. Process 1645736 has 76.38 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 20.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105270989,1697105273585.0,120,,,[49],[1697105271038]
5360,318,39,"['{""code"":2,""details"":[],""message"":""Request failed during generation: Unexpected <class \'torch.cuda.OutOfMemoryError\'>: CUDA out of memory. Tried to allocate 12.81 GiB. GPU 0 has a total capacty of 79.11 GiB of which 12.01 GiB is free. Process 1645736 has 67.09 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 10.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF""}']",408,EleutherAI/gpt-neox-20b,128,1,,,1,H100,1697105273587,1697105275208.0,120,,,[19],[1697105273606]
